% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={The Little Book of Algorithms},
  pdfauthor={Duc-Tam Nguyen},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{The Little Book of Algorithms}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Version 0.3.0}
\author{Duc-Tam Nguyen}
\date{2025-10-06}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter{Content}\label{content}

\emph{A Friendly Guide from Numbers to Neural Networks}

\begin{itemize}
\tightlist
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.pdf}{Download
  PDF} - print-ready
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.epub}{Download
  EPUB} - e-reader friendly
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.tex}{View
  LaTex} - \texttt{.tex} source
\item
  \href{https://github.com/little-book-of/algorithms}{Source code
  (Github)} - Markdown source
\item
  \href{https://little-book-of.github.io/algorithms}{Read on GitHub
  Pages} - view online
\end{itemize}

Licensed under \textbf{CC BY-NC-SA 4.0}.

\subsubsection{Chapter 1. Foundations of
Algorithms}\label{chapter-1.-foundations-of-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    What Is an Algorithm?\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Measuring Time and Space\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    Big-O, Big-Theta, Big-Omega\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{3}
  \tightlist
  \item
    Algorithmic Paradigms (Greedy, Divide and Conquer, DP)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{4}
  \tightlist
  \item
    Recurrence Relations\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{5}
  \tightlist
  \item
    Searching Basics\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{6}
  \tightlist
  \item
    Sorting Basics\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{7}
  \tightlist
  \item
    Data Structures Overview\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{8}
  \tightlist
  \item
    Graphs and Trees Overview\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{9}
  \tightlist
  \item
    Algorithm Design Patterns
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 2. Sorting and
Searching}\label{chapter-2.-sorting-and-searching}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{10}
  \tightlist
  \item
    Elementary Sorting (Bubble, Insertion, Selection)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{11}
  \tightlist
  \item
    Divide-and-Conquer Sorting (Merge, Quick, Heap)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{12}
  \tightlist
  \item
    Counting and Distribution Sorts (Counting, Radix, Bucket)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{13}
  \tightlist
  \item
    Hybrid Sorts (IntroSort, Timsort)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{14}
  \tightlist
  \item
    Special Sorts (Cycle, Gnome, Comb, Pancake)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{15}
  \tightlist
  \item
    Linear and Binary Search\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{16}
  \tightlist
  \item
    Interpolation and Exponential Search\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{17}
  \tightlist
  \item
    Selection Algorithms (Quickselect, Median of Medians)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{18}
  \tightlist
  \item
    Range Searching and Nearest Neighbor\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{19}
  \tightlist
  \item
    Search Optimizations and Variants
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 3. Data Structures in
Action}\label{chapter-3.-data-structures-in-action}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{20}
  \tightlist
  \item
    Arrays, Linked Lists, Stacks, Queues\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{21}
  \tightlist
  \item
    Hash Tables and Variants (Cuckoo, Robin Hood, Consistent)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{22}
  \tightlist
  \item
    Heaps (Binary, Fibonacci, Pairing)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{23}
  \tightlist
  \item
    Balanced Trees (AVL, Red-Black, Splay, Treap)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{24}
  \tightlist
  \item
    Segment Trees and Fenwick Trees\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{25}
  \tightlist
  \item
    Disjoint Set Union (Union-Find)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{26}
  \tightlist
  \item
    Probabilistic Data Structures (Bloom, Count-Min, HyperLogLog)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{27}
  \tightlist
  \item
    Skip Lists and B-Trees\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{28}
  \tightlist
  \item
    Persistent and Functional Data Structures\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{29}
  \tightlist
  \item
    Advanced Trees and Range Queries
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 4. Graph
Algorithms}\label{chapter-4.-graph-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{30}
  \tightlist
  \item
    Traversals (DFS, BFS, Iterative Deepening)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{31}
  \tightlist
  \item
    Strongly Connected Components (Tarjan, Kosaraju)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{32}
  \tightlist
  \item
    Shortest Paths (Dijkstra, Bellman-Ford, A*, Johnson)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{33}
  \tightlist
  \item
    Shortest Path Variants (0--1 BFS, Bidirectional, Heuristic A*)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{34}
  \tightlist
  \item
    Minimum Spanning Trees (Kruskal, Prim, Borůvka)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{35}
  \tightlist
  \item
    Flows (Ford--Fulkerson, Edmonds--Karp, Dinic)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{36}
  \tightlist
  \item
    Cuts (Stoer--Wagner, Karger, Gomory--Hu)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{37}
  \tightlist
  \item
    Matchings (Hopcroft--Karp, Hungarian, Blossom)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{38}
  \tightlist
  \item
    Tree Algorithms (LCA, HLD, Centroid Decomposition)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{39}
  \tightlist
  \item
    Advanced Graph Algorithms and Tricks
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 5. Dynamic
Programming}\label{chapter-5.-dynamic-programming}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{40}
  \tightlist
  \item
    DP Basics and State Transitions\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{41}
  \tightlist
  \item
    Classic Problems (Knapsack, Subset Sum, Coin Change)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{42}
  \tightlist
  \item
    Sequence Problems (LIS, LCS, Edit Distance)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{43}
  \tightlist
  \item
    Matrix and Chain Problems\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{44}
  \tightlist
  \item
    Bitmask DP and Traveling Salesman\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{45}
  \tightlist
  \item
    Digit DP and SOS DP\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{46}
  \tightlist
  \item
    DP Optimizations (Divide \& Conquer, Convex Hull Trick, Knuth)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{47}
  \tightlist
  \item
    Tree DP and Rerooting\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{48}
  \tightlist
  \item
    DP Reconstruction and Traceback\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{49}
  \tightlist
  \item
    Meta-DP and Optimization Templates
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 6. Mathematics for
Algorithms}\label{chapter-6.-mathematics-for-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{50}
  \tightlist
  \item
    Number Theory (GCD, Modular Arithmetic, CRT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{51}
  \tightlist
  \item
    Primality and Factorization (Miller--Rabin, Pollard Rho)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{52}
  \tightlist
  \item
    Combinatorics (Permutations, Combinations, Subsets)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{53}
  \tightlist
  \item
    Probability and Randomized Algorithms\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{54}
  \tightlist
  \item
    Sieve Methods and Modular Math\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{55}
  \tightlist
  \item
    Linear Algebra (Gaussian Elimination, LU, SVD)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{56}
  \tightlist
  \item
    FFT and NTT (Fast Transforms)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{57}
  \tightlist
  \item
    Numerical Methods (Newton, Simpson, Runge--Kutta)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{58}
  \tightlist
  \item
    Mathematical Optimization (Simplex, Gradient, Convex)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{59}
  \tightlist
  \item
    Algebraic Tricks and Transform Techniques
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 7. Strings and Text
Algorithms}\label{chapter-7.-strings-and-text-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{60}
  \tightlist
  \item
    String Matching (KMP, Z, Rabin--Karp, Boyer--Moore)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{61}
  \tightlist
  \item
    Multi-Pattern Search (Aho--Corasick)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{62}
  \tightlist
  \item
    Suffix Structures (Suffix Array, Suffix Tree, LCP)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{63}
  \tightlist
  \item
    Palindromes and Periodicity (Manacher)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{64}
  \tightlist
  \item
    Edit Distance and Alignment\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{65}
  \tightlist
  \item
    Compression (Huffman, Arithmetic, LZ77, BWT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{66}
  \tightlist
  \item
    Cryptographic Hashes and Checksums\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{67}
  \tightlist
  \item
    Approximate and Streaming Matching\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{68}
  \tightlist
  \item
    Bioinformatics Alignment (Needleman--Wunsch, Smith--Waterman)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{69}
  \tightlist
  \item
    Text Indexing and Search Structures
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 8. Geometry, Graphics, and Spatial
Algorithms}\label{chapter-8.-geometry-graphics-and-spatial-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{70}
  \tightlist
  \item
    Convex Hull (Graham, Andrew, Chan)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{71}
  \tightlist
  \item
    Closest Pair and Segment Intersection\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{72}
  \tightlist
  \item
    Line Sweep and Plane Sweep Algorithms\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{73}
  \tightlist
  \item
    Delaunay and Voronoi Diagrams\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{74}
  \tightlist
  \item
    Point in Polygon and Polygon Triangulation\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{75}
  \tightlist
  \item
    Spatial Data Structures (KD, R-tree)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{76}
  \tightlist
  \item
    Rasterization and Scanline Techniques\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{77}
  \tightlist
  \item
    Computer Vision (Canny, Hough, SIFT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{78}
  \tightlist
  \item
    Pathfinding in Space (A*, RRT, PRM)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{79}
  \tightlist
  \item
    Computational Geometry Variants and Applications
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 9. Systems, Databases, and Distributed
Algorithms}\label{chapter-9.-systems-databases-and-distributed-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{80}
  \tightlist
  \item
    Concurrency Control (2PL, MVCC, OCC)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{81}
  \tightlist
  \item
    Logging, Recovery, and Commit Protocols\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{82}
  \tightlist
  \item
    Scheduling (Round Robin, EDF, Rate-Monotonic)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{83}
  \tightlist
  \item
    Caching and Replacement (LRU, LFU, CLOCK)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{84}
  \tightlist
  \item
    Networking (Routing, Congestion Control)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{85}
  \tightlist
  \item
    Distributed Consensus (Paxos, Raft, PBFT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{86}
  \tightlist
  \item
    Load Balancing and Rate Limiting\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{87}
  \tightlist
  \item
    Search and Indexing (Inverted, BM25, WAND)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{88}
  \tightlist
  \item
    Compression and Encoding in Systems\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{89}
  \tightlist
  \item
    Fault Tolerance and Replication
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 10. AI, ML, and
Optimization}\label{chapter-10.-ai-ml-and-optimization}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{90}
  \tightlist
  \item
    Classical ML (k-means, Naive Bayes, SVM, Decision Trees)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{91}
  \tightlist
  \item
    Ensemble Methods (Bagging, Boosting, Random Forests)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{92}
  \tightlist
  \item
    Gradient Methods (SGD, Adam, RMSProp)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{93}
  \tightlist
  \item
    Deep Learning (Backpropagation, Dropout, Normalization)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{94}
  \tightlist
  \item
    Sequence Models (Viterbi, Beam Search, CTC)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{95}
  \tightlist
  \item
    Metaheuristics (GA, SA, PSO, ACO)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{96}
  \tightlist
  \item
    Reinforcement Learning (Q-learning, Policy Gradients)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{97}
  \tightlist
  \item
    Approximation and Online Algorithms\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{98}
  \tightlist
  \item
    Fairness, Causal Inference, and Robust Optimization\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{99}
  \tightlist
  \item
    AI Planning, Search, and Learning Systems
  \end{enumerate}
\end{itemize}

\bookmarksetup{startatroot}

\chapter{The Book}\label{the-book}

\begin{itemize}
\tightlist
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.pdf}{Download
  PDF} - print-ready
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.epub}{Download
  EPUB} - e-reader friendly
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.tex}{View
  LaTex} - \texttt{.tex} source
\item
  \href{https://github.com/little-book-of/algorithms}{Source code
  (Github)} - Markdown source
\item
  \href{https://little-book-of.github.io/algorithms/books/en-US/book.html}{Read
  on GitHub Pages} - view online
\end{itemize}

Licensed under CC BY-NC-SA 4.0.

\section{Chapter 1. Foundations of
algorithms}\label{chapter-1.-foundations-of-algorithms-1}

\subsection{1. What Is an Algorithm?}\label{what-is-an-algorithm}

Let's begin at the very heart of computer science. Before we dive into
code, data, or performance, we need to understand what an algorithm
\emph{really is}.

An algorithm is a clear, step-by-step procedure to solve a problem.
Think of it like a recipe: you have inputs (ingredients), a series of
steps (instructions), and an output (the finished dish).

At its core, an algorithm must be:

\begin{itemize}
\tightlist
\item
  Precise: Every step is well-defined and unambiguous.- Finite: It must
  finish after a certain number of steps.- Effective: Each step is
  doable by a machine or human.- Deterministic (usually): Same input,
  same output. When you write an algorithm, you're describing \emph{how}
  to get from question to answer, not just \emph{what} the answer is.
\end{itemize}

\subsubsection{Example: A Simple Sum}\label{example-a-simple-sum}

Suppose you want to find the sum of numbers from 1 to ( n ).

You could describe it like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with total = 0
\item
  For i = 1 to n 3. Add i to total
\item
  Return total
\end{enumerate}

That's an algorithm! It's clear, finite, and mechanical.

You can express it in pseudocode:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Algorithm SumToN(n):}
\NormalTok{    total ← 0}
\NormalTok{    for i ← 1 to n:}
\NormalTok{        total ← total + i}
\NormalTok{    return total}
\end{Highlighting}
\end{Shaded}

Or even write it in C:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_to\_n}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Tiny Code}\label{tiny-code}

Let's run a quick example by hand.

If ( n = 5 ):

\begin{itemize}
\tightlist
\item
  total = 0- Add 1 → total = 1- Add 2 → total = 3- Add 3 → total = 6-
  Add 4 → total = 10- Add 5 → total = 15 Output = 15
\end{itemize}

We can even derive a formula later (you'll see it soon!): \[
1 + 2 + 3 + \dots + n = \frac{n(n+1)}{2}
\]

\subsubsection{Why It Matters}\label{why-it-matters}

Algorithms are the blueprints of computation. Every software system,
from a calculator to an AI model, is built from algorithms.

Without algorithms, computers would be powerless , they're just fast
machines following instructions. Algorithms give them purpose and
direction.

Understanding algorithms means you understand how thinking turns into
code.

Later, you'll learn to analyze them (how fast, how big, how smart), but
for now, remember:

\begin{quote}
Algorithms are the language of problem solving.
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a simple algorithm to find the maximum number in a list.
\item
  Write an algorithm to reverse a string.
\item
  For extra fun, describe your morning routine as an algorithm (inputs,
  steps, output).
\end{enumerate}

The best way to learn is to think algorithmically , break problems into
small, clear, executable steps.

\subsection{2. Measuring Time and Space}\label{measuring-time-and-space}

Now that you know what an algorithm is, it's time to ask a deeper
question:

\begin{quote}
How do we know if one algorithm is \emph{better} than another?
\end{quote}

It's not enough for an algorithm to be correct , it should also be
\emph{efficient}. We measure efficiency in two key ways: time and space.

\subsubsection{Time Complexity}\label{time-complexity}

Time means how long an algorithm takes to run, relative to its input
size. We don't measure in seconds, because hardware changes. Instead, we
count steps or operations.

For example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Hi}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This loop runs ( n ) times, so we say it has time complexity O(n) , it
grows linearly with input size.

Another example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"*"}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

This one runs \(n \times n = n^2\) times → O(n²).

You'll see these ``Big-O'' symbols a lot , they express how runtime
grows as inputs grow.

\subsubsection{Space Complexity}\label{space-complexity}

Space means how much memory the algorithm uses.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}        \CommentTok{// O(1) space}
\end{Highlighting}
\end{Shaded}

Uses a constant amount of memory.

But an array like:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}         \CommentTok{// O(n) space}
\end{Highlighting}
\end{Shaded}

uses space proportional to the input size.

Sometimes you'll trade time for space. For example:

\begin{itemize}
\tightlist
\item
  Using a hash table speeds up lookups (more memory, less time)- Using a
  streaming algorithm saves memory (less space, more time)
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-1}

Let's compare two ways to compute a sum from 1 to n:

Method 1: Loop

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_loop}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ total }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Time: ( O(n) )- Space: ( O(1) ) Method 2: Formula
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_formula}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{*} \OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Time: ( O(1) )- Space: ( O(1) ) Both are correct , but one is
  \emph{faster}. That's why analyzing time and space matters.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-1}

When data grows huge (millions, billions), small inefficiencies explode.

An algorithm that takes ( O\(n^2\) ) might seem fine for 10 elements,
but impossible for 1,000,000.

Knowing how to measure time and space helps you:

\begin{itemize}
\tightlist
\item
  Predict performance- Compare solutions- Optimize intelligently It's
  your compass for navigating complexity.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a simple algorithm to find the minimum in an array. Estimate its
  time and space complexity.
\item
  Compare two algorithms that solve the same problem , which one scales
  better?
\item
  Can you think of a task in daily life that's O(n)? What about O(1)?
\end{enumerate}

Understanding these measurements early will make every algorithm you
meet more meaningful.

\subsection{3. Big-O, Big-Theta,
Big-Omega}\label{big-o-big-theta-big-omega}

Now that you can \emph{measure} time and space, let's learn the language
used to describe those measurements.

When we say an algorithm is O(n), we're using asymptotic notation , a
way to describe how an algorithm's running time or memory grows as input
size ( n ) increases.

It's not about exact steps, but how the cost \emph{scales} for very
large ( n ).

\subsubsection{The Big-O (Upper Bound)}\label{the-big-o-upper-bound}

Big-O answers: \emph{``How bad can it get?''} It gives an upper bound on
growth , the worst-case scenario.

If an algorithm takes at most ( 5n + 20 ) steps, we write ( O(n) ). We
drop constants and lower-order terms because they don't matter at scale.

Common Big-O notations:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1774}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1290}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2581}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4355}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Growth
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Constant & O(1) & Flat & Accessing array element \\
Logarithmic & O(log n) & Very slow growth & Binary search \\
Linear & O(n) & Proportional & Single loop \\
Quadratic & O(n²) & Grows quickly & Double loop \\
Exponential & O(2ⁿ) & Explodes & Recursive subset generation \\
\end{longtable}

So if your algorithm is ( O(n) ), doubling input size doubles runtime.
If it's ( O\(n^2\) ), doubling input size makes it four times slower.

\subsubsection{The Big-Theta (Tight
Bound)}\label{the-big-theta-tight-bound}

Big-Theta (Θ) gives a tight bound , when you know the algorithm's growth
from above and below.

If runtime is roughly ( 3n + 2 ), then ( T(n) = Θ(n) ). That means it's
both ( O(n) ) and ( Ω(n) ).

\subsubsection{The Big-Omega (Lower
Bound)}\label{the-big-omega-lower-bound}

Big-Omega (Ω) answers: \emph{``How fast can it possibly be?''} It's the
best-case growth , the lower limit.

Example:

\begin{itemize}
\tightlist
\item
  Linear search: ( Ω(1) ) if the element is at the start- ( O(n) ) in
  the worst case if it's at the end So we might say: \[
  T(n) = Ω(1),\ Θ(n) = O(n)
  \]
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-2}

Let's see Big-O in action.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_pairs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}        \CommentTok{// O(n)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}    \CommentTok{// O(n)}
\NormalTok{            total }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{;}            \CommentTok{// O(1)}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Total steps ≈ \(n \times n = n^2\). So ( T(n) = O\(n^2\) ).

If we added a constant-time operation before or after the loops, it
wouldn't matter. Constants vanish in asymptotic notation.

\subsubsection{Why It Matters}\label{why-it-matters-2}

Big-O, Big-Theta, and Big-Omega let you talk precisely about
performance. They're like the grammar of efficiency.

When you can write:

\begin{quote}
``Algorithm A runs in O(n log n) time, O(n) space,'' you've captured its
essence clearly and compared it meaningfully.
\end{quote}

They help you:

\begin{itemize}
\tightlist
\item
  Predict behavior at scale- Choose better data structures- Communicate
  efficiency in interviews and papers It's not about exact timing , it's
  about growth.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Analyze this code:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*=} \DecValTok{2}\OperatorTok{)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

  What's the time complexity?
\item
  Write an algorithm that's O(n log n) , hint: merge sort!
\item
  Identify the best, worst, and average-case complexities for linear
  search and binary search.
\end{enumerate}

Learning Big-O is like learning a new language , once you're fluent, you
can \emph{see} how code grows before you even run it.

\subsection{4. Algorithmic Paradigms (Greedy, Divide and Conquer,
DP)}\label{algorithmic-paradigms-greedy-divide-and-conquer-dp}

Once you can measure performance, it's time to explore how algorithms
are designed. Behind every clever solution is a guiding paradigm , a way
of thinking about problems.

Three of the most powerful are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Greedy Algorithms
\item
  Divide and Conquer
\item
  Dynamic Programming (DP)
\end{enumerate}

Each one represents a different mindset for problem-solving.

\subsubsection{1. Greedy Algorithms}\label{greedy-algorithms}

A greedy algorithm makes the best local choice at each step, hoping it
leads to a global optimum.

Think of it like:

\begin{quote}
``Take what looks best right now, don't worry about the future.''
\end{quote}

They're fast and simple, but not always correct , they only work when
the greedy choice property holds.

Example: Coin Change (Greedy version) Suppose you want to make 63 cents
using US coins (25, 10, 5, 1). The greedy approach:

\begin{itemize}
\tightlist
\item
  Take 25 → 38 left- Take 25 → 13 left- Take 10 → 3 left- Take 1 × 3
  Works here, but not always (try coins 1, 3, 4 for 6).
\end{itemize}

Simple but not guaranteed optimal.

Common greedy algorithms:

\begin{itemize}
\tightlist
\item
  Kruskal's MST- Prim's MST- Dijkstra's (non-negative weights)- Huffman
  coding
\end{itemize}

\subsubsection{2. Divide and Conquer}\label{divide-and-conquer}

This one's a classic. You break the problem into smaller subproblems,
solve each recursively, and then combine the results.

It's like splitting a task among friends, then merging the answers.

Formally: \[
T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]

Examples:

\begin{itemize}
\tightlist
\item
  Merge Sort: divide the array, sort halves, merge- Quick Sort:
  partition around pivot- Binary Search: halve the range each step
  Elegant and powerful, but recursion overhead can add cost if poorly
  structured.
\end{itemize}

\subsubsection{3. Dynamic Programming
(DP)}\label{dynamic-programming-dp}

DP is for problems with overlapping subproblems and optimal
substructure. You solve smaller subproblems once and store the results
to avoid recomputation.

It's like divide and conquer with memory.

Example: Fibonacci Naive recursion: exponential DP with memoization:
linear

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{static} \DataTypeTok{int}\NormalTok{ memo}\OperatorTok{[}\DecValTok{1000}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{    memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Efficient reuse, but requires insight into subproblem structure.

\subsubsection{Tiny Code}\label{tiny-code-3}

Here's a quick comparison using Fibonacci:

Naive (Divide and Conquer)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib\_dc}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fib\_dc}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib\_dc}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{);}  \CommentTok{// exponential}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

DP (Memoization)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib\_dp}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ memo}\OperatorTok{[])} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fib\_dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ memo}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib\_dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{,}\NormalTok{ memo}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-3}

Algorithmic paradigms give you patterns for design:

\begin{itemize}
\tightlist
\item
  Greedy: when local choices lead to global optimum- Divide \& Conquer:
  when the problem splits naturally- Dynamic Programming: when
  subproblems overlap Once you recognize a problem's structure, you'll
  instantly know which mindset fits best.
\end{itemize}

Think of paradigms as \emph{templates for reasoning} , not just
techniques, but philosophies.

\subsubsection{Try It Yourself}\label{try-it-yourself-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a greedy algorithm to make change using coins {[}1, 3, 4{]} for
  amount 6. Does it work?
\item
  Implement merge sort using divide and conquer.
\item
  Solve Fibonacci both ways (naive vs DP) and compare speeds.
\item
  Can you think of a real-life task you solve greedily?
\end{enumerate}

Learning paradigms is like learning styles of thought , once you know
them, every problem starts to look familiar.

\subsection{5. Recurrence Relations}\label{recurrence-relations}

Every time you break a problem into smaller subproblems, you create a
recurrence , a mathematical way to describe how the total cost grows.

Recurrence relations are the backbone of analyzing recursive algorithms.
They tell us how much time or space an algorithm uses, based on the cost
of its subproblems.

\subsubsection{What Is a Recurrence?}\label{what-is-a-recurrence}

A recurrence relation expresses ( T(n) ), the total cost for input size
( n ), in terms of smaller instances.

Example: For merge sort: \[
T(n) = 2T(n/2) + O(n)
\] That means:

\begin{itemize}
\item
  It divides the problem into 2 halves (2T(n/2))- Merges results in O(n)
  time You'll often see recurrences like:
\item
  ( T(n) = T(n - 1) + O(1) )- ( T(n) = 2T(n/2) + O(n) )- ( T(n) = T(n/2)
  + O(1) ) Each one represents a different structure of recursion.
\end{itemize}

\subsubsection{Example 1: Simple Linear
Recurrence}\label{example-1-simple-linear-recurrence}

Consider this code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ count\_down}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{return} \DecValTok{1} \OperatorTok{+}\NormalTok{ count\_down}\OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This calls itself once for each smaller input → \[
T(n) = T(n - 1) + O(1)
\]

Solve it: \[
T(n) = O(n)
\]

Because it runs once per level.

\subsubsection{Example 2: Binary
Recurrence}\label{example-2-binary-recurrence}

For binary recursion:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_tree}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ sum\_tree}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{2}\OperatorTok{)} \OperatorTok{+}\NormalTok{ sum\_tree}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{2}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Here we do two subcalls on ( n/2 ) and a constant amount of extra work.
\[
T(n) = 2T(n/2) + O(1)
\] Solve it: ( T(n) = O(n) )

Why? Each level doubles calls, but halves size. There are log n levels,
and total work adds up to O(n).

\subsubsection{Solving Recurrences}\label{solving-recurrences}

There are several ways to solve them:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Substitution Method Guess the solution, then prove it by induction.
\item
  Recursion Tree Method Expand the recurrence into a tree and sum the
  cost per level.
\item
  Master Theorem Use a formula when recurrence matches: \[
  T(n) = aT(n/b) + f(n)
  \]
\end{enumerate}

\subsubsection{Master Theorem (Quick
Summary)}\label{master-theorem-quick-summary}

If ( T(n) = aT(n/b) + f(n) ), then:

\begin{itemize}
\tightlist
\item
  If ( f(n) = O\(n^{\log_b a - \epsilon}\) ), then ( T(n) =
  Θ\(n^{\log_b a}\) )- If ( f(n) = Θ\(n^{\log_b a}\) ), then ( T(n) =
  Θ\(n^{\log_b a} \log n\) )- If ( f(n) = Ω\(n^{\log_b a + \epsilon}\)
  ), and regularity condition holds, then ( T(n) = Θ(f(n)) ) Example:
  Merge Sort → ( a = 2, b = 2, f(n) = O(n) ) \[
  T(n) = 2T(n/2) + O(n) = O(n \log n)
  \]
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-4}

Let's write a quick recursive sum:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_array}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{==}\NormalTok{ r}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ arr}\OperatorTok{[}\NormalTok{l}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{l }\OperatorTok{+}\NormalTok{ r}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ sum\_array}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{)} \OperatorTok{+}\NormalTok{ sum\_array}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Recurrence: \[
T(n) = 2T(n/2) + O(1)
\] → ( O(n) )

If you added merging (like in merge sort), you'd get ( +O(n) ), → (
O\(n \log n\) )

\subsubsection{Why It Matters}\label{why-it-matters-4}

Recurrence relations let you predict the cost of recursive solutions.

Without them, recursion feels like magic , with them, you can quantify
efficiency.

They're key to understanding:

\begin{itemize}
\tightlist
\item
  Divide and conquer- Dynamic programming- Backtracking Once you can set
  up a recurrence, solving it becomes a game of algebra and logic.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write a recurrence for binary search. Solve it.
\item
  Write a recurrence for merge sort. Solve it.
\item
  Analyze this function:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ fun}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\OperatorTok{;}
\NormalTok{    fun}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{2}\OperatorTok{);}
\NormalTok{    fun}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{3}\OperatorTok{);}
\NormalTok{    fun}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{6}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

  What's the recurrence? Approximate the complexity.
\item
  Expand ( T(n) = T(n-1) + 1 ) into its explicit sum.
\end{enumerate}

Learning recurrences helps you \emph{see inside} recursion , they turn
code into equations.

\subsection{6. Searching Basics}\label{searching-basics}

Before we sort or optimize, we need a way to find things. Searching is
one of the most fundamental actions in computing , whether it's looking
up a name, finding a key, or checking if something exists.

A search algorithm takes a collection (array, list, tree, etc.) and a
target, and returns whether the target is present (and often its
position).

Let's begin with two foundational techniques: Linear Search and Binary
Search.

\subsubsection{1. Linear Search}\label{linear-search}

Linear search is the simplest method:

\begin{itemize}
\tightlist
\item
  Start at the beginning- Check each element in turn- Stop if you find
  the target It works on any list , sorted or not , but can be slow for
  large data.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ linear\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: If arr = {[}2, 4, 6, 8, 10{]} and key = 6, it finds it at index
2.

Complexity:

\begin{itemize}
\tightlist
\item
  Time: ( O(n) )- Space: ( O(1) ) Linear search is simple and guaranteed
  to find the target if it exists, but slow when lists are large.
\end{itemize}

\subsubsection{2. Binary Search}\label{binary-search}

When the list is sorted, we can do much better. Binary search repeatedly
divides the search space in half.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check the middle element.
\item
  If it matches, you're done.
\item
  If target \textless{} mid, search left half.
\item
  Else search right half.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}2, 4, 6, 8, 10{]}, key = 8

\begin{itemize}
\item
  mid = 6 → key \textgreater{} mid → search right half- mid = 8 → found
  Complexity:
\item
  Time: ( O\(\log n\) )- Space: ( O(1) ) Binary search is a massive
  improvement , doubling input only adds one extra step.
\end{itemize}

\subsubsection{3. Recursive Binary
Search}\label{recursive-binary-search}

Binary search can also be written recursively:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textgreater{}}\NormalTok{ high}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Same logic, different structure. Both iterative and recursive forms are
equally efficient.

\subsubsection{4. Choosing Between Them}\label{choosing-between-them}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Method & Works On & Time & Space & Needs Sorting \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & Any list & O(n) & O(1) & No \\
Binary Search & Sorted list & O(log n) & O(1) & Yes \\
\end{longtable}

If data is unsorted or very small, linear search is fine. If data is
sorted and large, binary search is far superior.

\subsubsection{Tiny Code}\label{tiny-code-5}

Compare the steps: For n = 16:

\begin{itemize}
\tightlist
\item
  Linear search → up to 16 comparisons- Binary search →
  \(\log_2 16 = 4\) comparisons That's a huge difference.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-5}

Searching is the core of information retrieval , every database,
compiler, and system relies on it.

Understanding simple searches prepares you for:

\begin{itemize}
\tightlist
\item
  Hash tables (constant-time lookups)- Tree searches (ordered
  structures)- Graph traversals (structured exploration) It's not just
  about finding values , it's about learning how data structure and
  algorithm design fit together.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a linear search that returns all indices where a target appears.
\item
  Modify binary search to return the first occurrence of a target in a
  sorted array.
\item
  Compare runtime on arrays of size 10, 100, 1000.
\item
  What happens if you run binary search on an unsorted list?
\end{enumerate}

Search is the foundation , once you master it, you'll recognize its
patterns everywhere.

\subsection{7. Sorting Basics}\label{sorting-basics}

Sorting is one of the most studied problems in computer science. Why?
Because order matters , it makes searching faster, patterns clearer, and
data easier to manage.

A sorting algorithm arranges elements in a specific order (usually
ascending or descending). Once sorted, many operations (like binary
search, merging, or deduplication) become much simpler.

Let's explore the foundational sorting methods and the principles behind
them.

\subsubsection{1. What Makes a Sort
Algorithm}\label{what-makes-a-sort-algorithm}

A sorting algorithm should define:

\begin{itemize}
\tightlist
\item
  Input: A sequence of elements- Output: The same elements, in sorted
  order- Stability: Keeps equal elements in the same order (important
  for multi-key sorts)- In-place: Uses only a constant amount of extra
  space Different algorithms balance speed, memory, and simplicity.
\end{itemize}

\subsubsection{2. Bubble Sort}\label{bubble-sort}

Idea: Repeatedly ``bubble up'' the largest element to the end by
swapping adjacent pairs.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bubble\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Each pass moves the largest remaining item to its final position.

\begin{itemize}
\tightlist
\item
  Time: ( O\(n^2\) )- Space: ( O(1) )- Stable: Yes Simple but
  inefficient for large data.
\end{itemize}

\subsubsection{3. Selection Sort}\label{selection-sort}

Idea: Repeatedly select the smallest element and put it in the correct
position.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ selection\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ min\_idx }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{])}\NormalTok{ min\_idx }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
        \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Time: ( O\(n^2\) )- Space: ( O(1) )- Stable: No Fewer swaps, but still
  quadratic.
\end{itemize}

\subsubsection{4. Insertion Sort}\label{insertion-sort}

Idea: Build the sorted list one item at a time, inserting each new item
in the right place.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ insertion\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ key }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j }\OperatorTok{\textgreater{}=} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{            j}\OperatorTok{{-}{-};}
        \OperatorTok{\}}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Time: ( O\(n^2\) ) (best case ( O(n) ) when nearly sorted)- Space: (
  O(1) )- Stable: Yes Insertion sort is great for small or nearly sorted
  datasets , used as a base in hybrid sorts like Timsort.
\end{itemize}

\subsubsection{5. Comparing the Basics}\label{comparing-the-basics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1525}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2034}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1695}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1017}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1356}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-place
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & O(n) & O(n²) & O(n²) & Yes & Yes \\
Selection Sort & O(n²) & O(n²) & O(n²) & No & Yes \\
Insertion Sort & O(n) & O(n²) & O(n²) & Yes & Yes \\
\end{longtable}

All three are quadratic in time, but Insertion Sort performs best on
small, partially sorted data.

\subsubsection{Tiny Code}\label{tiny-code-6}

Quick check with \texttt{arr\ =\ {[}5,\ 3,\ 4,\ 1,\ 2{]}}:

Insertion Sort (step by step)

\begin{itemize}
\tightlist
\item
  Insert 3 before 5 → {[}3, 5, 4, 1, 2{]}- Insert 4 → {[}3, 4, 5, 1,
  2{]}- Insert 1 → {[}1, 3, 4, 5, 2{]}- Insert 2 → {[}1, 2, 3, 4, 5{]}
  Sorted!
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-6}

Sorting is a gateway algorithm , it teaches you about iteration,
swapping, and optimization.

Efficient sorting is critical for:

\begin{itemize}
\tightlist
\item
  Preprocessing data for binary search- Organizing data for analysis-
  Building indexes and ranking systems It's the first step toward deeper
  concepts like divide-and-conquer and hybrid optimization.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement all three: bubble, selection, insertion.
\item
  Test them on arrays of size 10, 100, 1000 , note timing differences.
\item
  Try sorting an array that's already sorted. Which one adapts best?
\item
  Modify insertion sort to sort in descending order.
\end{enumerate}

Sorting may seem simple, but it's a cornerstone , mastering it will
shape your intuition for almost every other algorithm.

\subsection{8. Data Structures Overview}\label{data-structures-overview}

Algorithms and data structures are two sides of the same coin. An
algorithm is how you solve a problem. A data structure is where you
store and organize data so that your algorithm can work efficiently.

You can think of data structures as containers , each one shaped for
specific access patterns, trade-offs, and performance needs. Choosing
the right one is often the \emph{key} to designing a fast algorithm.

\subsubsection{1. Why Data Structures
Matter}\label{why-data-structures-matter}

Imagine you want to find a book quickly.

\begin{itemize}
\tightlist
\item
  If all books are piled randomly → you must scan every one (O(n)).- If
  they're sorted on a shelf → you can use binary search (O(log n)).- If
  you have an index or catalog → you can find it instantly (O(1)).
  Different structures unlock different efficiencies.
\end{itemize}

\subsubsection{2. The Core Data
Structures}\label{the-core-data-structures}

Let's walk through the most essential ones:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3730}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1508}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Operations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Array & Fixed-size contiguous memory & Access ( O(1) ), Insert/Delete (
O(n) ) & Fast index access \\
Linked List & Sequence of nodes with pointers & Insert/Delete ( O(1) ),
Access ( O(n) ) & Dynamic sequences \\
Stack & LIFO (last-in, first-out) & push(), pop() in ( O(1) ) & Undo,
recursion \\
Queue & FIFO (first-in, first-out) & enqueue(), dequeue() in ( O(1) ) &
Scheduling, buffers \\
Hash Table & Key-value pairs via hashing & Average ( O(1) ), Worst (
O(n) ) & Lookup, caching \\
Heap & Partially ordered tree & Insert ( O\(\log n\) ), Extract-Min (
O\(\log n\) ) & Priority queues \\
Tree & Hierarchical structure & Access ( O\(\log n\) ) (balanced) &
Sorted storage \\
Graph & Nodes + edges & Traversal ( O(V+E) ) & Networks, paths \\
Set / Map & Collections of unique keys or key-value pairs & (
O\(\log n\) ) or ( O(1) ) & Membership tests \\
\end{longtable}

Each comes with trade-offs , arrays are fast but rigid, linked lists are
flexible but slower to access, and hash tables are lightning-fast but
unordered.

\subsubsection{3. Abstract Data Types
(ADTs)}\label{abstract-data-types-adts}

An ADT defines what operations you can do, not how they're implemented.
For example, a Stack ADT promises:

\begin{itemize}
\tightlist
\item
  \texttt{push(x)}- \texttt{pop()}- \texttt{peek()} It can be
  implemented with arrays or linked lists , the \emph{behavior} stays
  the same.
\end{itemize}

Common ADTs:

\begin{itemize}
\tightlist
\item
  Stack- Queue- Deque- Priority Queue- Map / Dictionary This separation
  of interface and implementation helps design flexible systems.
\end{itemize}

\subsubsection{4. The Right Tool for the
Job}\label{the-right-tool-for-the-job}

Choosing the correct data structure often decides the performance of
your algorithm:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Good Choice & Reason \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undo feature & Stack & LIFO fits history \\
Scheduling tasks & Queue & FIFO order \\
Dijkstra's algorithm & Priority Queue & Extract smallest distance \\
Counting frequencies & Hash Map & Fast key lookup \\
Dynamic median & Heap + Heap & Balance two halves \\
Search by prefix & Trie & Fast prefix lookups \\
\end{longtable}

Good programmers don't just write code , they pick the right structure.

\subsubsection{Tiny Code}\label{tiny-code-7}

Example: comparing array vs linked list

Array:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[}\DecValTok{5}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{5}\OperatorTok{\};}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\DecValTok{3}\OperatorTok{]);} \CommentTok{// O(1)}
\end{Highlighting}
\end{Shaded}

Linked List:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{;} \KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;} \OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

To get the 4th element, you must traverse → ( O(n) )

Different structures, different access costs.

\subsubsection{Why It Matters}\label{why-it-matters-7}

Every efficient algorithm depends on the right data structure.

\begin{itemize}
\tightlist
\item
  Searching, sorting, and storing all rely on structure.- Memory layout
  affects cache performance.- The wrong choice can turn O(1) into O(n²).
  Understanding these structures is like knowing the tools in a workshop
  , once you recognize their shapes, you'll instinctively know which to
  grab.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a stack using an array. Then implement it using a linked
  list.
\item
  Write a queue using two stacks.
\item
  Try storing key-value pairs in a hash table (hint: mod by table size).
\item
  Compare access times for arrays vs linked lists experimentally.
\end{enumerate}

Data structures aren't just storage , they are the \emph{skeletons} your
algorithms stand on.

\subsection{9. Graphs and Trees
Overview}\label{graphs-and-trees-overview}

Now that you've seen linear structures like arrays and linked lists,
it's time to explore nonlinear structures , graphs and trees. These are
the shapes behind networks, hierarchies, and relationships.

They're everywhere: family trees, file systems, maps, social networks,
and knowledge graphs all rely on them.

\subsubsection{1. Trees}\label{trees}

A tree is a connected structure with no cycles. It's a hierarchy , every
node (except the root) has one parent.

\begin{itemize}
\item
  Root: the top node- Child: a node directly connected below- Leaf: a
  node with no children- Height: the longest path from root to a leaf A
  binary tree is one where each node has at most two children. A binary
  search tree (BST) keeps elements ordered:
\item
  Left child \textless{} parent \textless{} Right child Basic
  Operations:
\item
  Insert- Search- Delete- Traverse (preorder, inorder, postorder,
  level-order) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ val}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Insert in BST:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ insert}\OperatorTok{(}\KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{val}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{val}\OperatorTok{)}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Common Tree Types}\label{common-tree-types}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4889}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Tree & Each node has ≤ 2 children & General hierarchy \\
Binary Search Tree (BST) & Left \textless{} Root \textless{} Right &
Ordered data \\
AVL / Red-Black Tree & Self-balancing BST & Fast search/insert \\
Heap & Complete binary tree, parent ≥ or ≤ children & Priority queues \\
Trie & Tree of characters & Prefix search \\
Segment Tree & Tree over ranges & Range queries \\
Fenwick Tree & Tree with prefix sums & Efficient updates \\
\end{longtable}

Balanced trees keep height ( O\(\log n\) ), guaranteeing fast
operations.

\subsubsection{3. Graphs}\label{graphs}

A graph generalizes the idea of trees , now, nodes (vertices) can
connect freely. A graph is a set of vertices ( V ) and edges ( E ): \[
G = (V, E)
\]

Directed vs Undirected

\begin{itemize}
\item
  Directed: edges have direction (A → B)- Undirected: edges connect both
  ways (A , B) Weighted vs Unweighted
\item
  Weighted: each edge has a cost- Unweighted: all edges equal
  Representation:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjacency Matrix \(n \times n\) matrix; entry (i, j) = 1 if edge
  exists
\item
  Adjacency List Array of lists: each vertex stores neighbors
\end{enumerate}

Example adjacency list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ graph}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{graph}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
\NormalTok{graph}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\DecValTok{2}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Common Graph Types}\label{common-graph-types}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4103}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3205}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2692}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Graph Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & Edges without direction & Friendship network \\
Directed & Arrows indicate direction & Web links \\
Weighted & Edges have costs & Road network \\
Cyclic & Contains loops & Task dependencies \\
Acyclic & No loops & Family tree \\
DAG (Directed Acyclic Graph) & Directed, no cycles & Scheduling,
compilers \\
Complete & All pairs connected & Dense networks \\
Sparse & Few edges & Real-world graphs \\
\end{longtable}

\subsubsection{5. Basic Graph Operations}\label{basic-graph-operations}

\begin{itemize}
\tightlist
\item
  Add Vertex / Edge- Traversal: Depth-First Search (DFS), Breadth-First
  Search (BFS)- Path Finding: Dijkstra, Bellman-Ford- Connectivity:
  Union-Find, Tarjan (SCC)- Spanning Trees: Kruskal, Prim Each graph
  problem has its own flavor , from finding shortest paths to detecting
  cycles.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-8}

Breadth-first search (BFS):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ graph}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{bool}\NormalTok{ visited}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{    memset}\OperatorTok{(}\NormalTok{visited}\OperatorTok{,} \KeywordTok{false}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{visited}\OperatorTok{));}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{start}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ node }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{        printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ node}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ neighbor }\OperatorTok{:}\NormalTok{ graph}\OperatorTok{[}\NormalTok{node}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{neighbor}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                visited}\OperatorTok{[}\NormalTok{neighbor}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{neighbor}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This explores level by level , perfect for shortest paths in unweighted
graphs.

\subsubsection{Why It Matters}\label{why-it-matters-8}

Trees and graphs model relationships and connections, not just
sequences. They're essential for:

\begin{itemize}
\tightlist
\item
  Search engines (web graph)- Compilers (syntax trees, dependency DAGs)-
  AI (state spaces, decision trees)- Databases (indexes, joins,
  relationships) Understanding them unlocks an entire world of
  algorithms , from DFS and BFS to Dijkstra, Kruskal, and beyond.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a simple binary search tree and implement inorder traversal.
\item
  Represent a graph with adjacency lists and print all edges.
\item
  Write a DFS and BFS for a small graph.
\item
  Draw a directed graph with a cycle and detect it manually.
\end{enumerate}

Graphs and trees move you beyond linear thinking , they let you explore
\emph{connections}, not just collections.

\subsection{10. Algorithm Design
Patterns}\label{algorithm-design-patterns}

By now, you've seen what algorithms \emph{are} and how they're
\emph{analyzed}. You've explored searches, sorts, structures, and
recursion. The next step is learning patterns , reusable
\emph{strategies} that guide how you build new algorithms from scratch.

Just like design patterns in software architecture, algorithmic design
patterns give structure to your thinking. Once you recognize them, many
problems suddenly feel familiar.

\subsubsection{1. Brute Force}\label{brute-force}

Start simple. Try every possibility, pick the best result. Brute force
is often your baseline , clear but inefficient.

Example: Find the maximum subarray sum by checking all subarrays.

\begin{itemize}
\tightlist
\item
  Time: ( O\(n^2\) )- Advantage: easy to reason about- Disadvantage:
  explodes for large input Sometimes, brute force helps you see the
  structure needed for a better approach.
\end{itemize}

\subsubsection{2. Divide and Conquer}\label{divide-and-conquer-1}

Split the problem into smaller parts, solve each, and combine. Ideal for
problems with self-similarity.

Classic examples:

\begin{itemize}
\tightlist
\item
  Merge Sort → split and merge- Binary Search → halve the search space-
  Quick Sort → partition and sort General form: \[
  T(n) = aT(n/b) + f(n)
  \]
\end{itemize}

Use recurrence relations and the Master Theorem to analyze them.

\subsubsection{3. Greedy}\label{greedy}

Make the best local decision at each step. Works only when local optimal
choices lead to a global optimum.

Examples:

\begin{itemize}
\tightlist
\item
  Activity Selection- Huffman Coding- Dijkstra's (for non-negative
  weights) Greedy algorithms are simple and fast , when they fit.
\end{itemize}

\subsubsection{4. Dynamic Programming
(DP)}\label{dynamic-programming-dp-1}

When subproblems overlap, store results and reuse them. Think recursion
+ memory.

Two main styles:

\begin{itemize}
\item
  Top-Down (Memoization): recursive with caching- Bottom-Up
  (Tabulation): iterative filling table Used in:
\item
  Fibonacci numbers- Knapsack- Longest Increasing Subsequence (LIS)-
  Matrix Chain Multiplication DP transforms exponential recursion into
  polynomial time.
\end{itemize}

\subsubsection{5. Backtracking}\label{backtracking}

Explore all possibilities, but prune when constraints fail. It's brute
force with early exits.

Perfect for:

\begin{itemize}
\tightlist
\item
  N-Queens- Sudoku- Permutation generation- Subset sums Backtracking
  builds solutions incrementally, abandoning paths that cannot lead to a
  valid result.
\end{itemize}

\subsubsection{6. Two Pointers}\label{two-pointers}

Move two indices through a sequence to find patterns or meet conditions.

Common use:

\begin{itemize}
\tightlist
\item
  Sorted arrays (sum pairs, partitions)- String problems (palindromes,
  sliding windows)- Linked lists (slow/fast pointers) Simple, but
  surprisingly powerful.
\end{itemize}

\subsubsection{7. Sliding Window}\label{sliding-window}

Maintain a window over data, expand or shrink it as needed.

Used for:

\begin{itemize}
\tightlist
\item
  Maximum sum subarray (Kadane's algorithm)- Substrings of length k-
  Longest substring without repeating characters Helps reduce ( O\(n^2\)
  ) to ( O(n) ) in sequence problems.
\end{itemize}

\subsubsection{8. Binary Search on
Answer}\label{binary-search-on-answer}

Sometimes, the input isn't sorted , but the answer space is. If you can
define a function \texttt{check(mid)} that's monotonic (true/false
changes once), you can apply binary search on possible answers.

Example:

\begin{itemize}
\tightlist
\item
  Minimum capacity to ship packages in D days- Smallest feasible value
  satisfying a constraint Powerful for optimization under monotonic
  conditions.
\end{itemize}

\subsubsection{9. Graph-Based}\label{graph-based}

Think in terms of nodes and edges, paths and flows.

Patterns include:

\begin{itemize}
\tightlist
\item
  BFS / DFS (exploration)- Topological Sort (ordering)- Dijkstra /
  Bellman-Ford (shortest paths)- Union-Find (connectivity)- Kruskal /
  Prim (spanning trees) Graphs often reveal relationships hidden in
  data.
\end{itemize}

\subsubsection{10. Meet-in-the-Middle}\label{meet-in-the-middle}

Split problem into two halves, compute all possibilities for each, and
combine efficiently. Used in problems where brute force ( O\(2^n\) ) is
too large but ( O\(2^{n/2}\) ) is manageable.

Example:

\begin{itemize}
\tightlist
\item
  Subset sum (divide into two halves)- Search problems in combinatorics
  A clever compromise between brute force and efficiency.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-9}

Example: Two Pointers to find pair sum:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ find\_pair\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ sum }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sum }\OperatorTok{==}\NormalTok{ target}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sum }\OperatorTok{\textless{}}\NormalTok{ target}\OperatorTok{)}\NormalTok{ i}\OperatorTok{++;}
        \ControlFlowTok{else}\NormalTok{ j}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Works in ( O(n) ) for sorted arrays , elegant and fast.

\subsubsection{Why It Matters}\label{why-it-matters-9}

Patterns are mental shortcuts. They turn ``blank page'' problems into
``I've seen this shape before.''

Once you recognize the structure, you can choose a suitable pattern and
adapt it. This is how top coders solve complex problems under time
pressure , not by memorizing algorithms, but by \emph{seeing patterns}.

\subsubsection{Try It Yourself}\label{try-it-yourself-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a brute-force and a divide-and-conquer solution for maximum
  subarray sum. Compare speed.
\item
  Solve the coin change problem using both greedy and DP.
\item
  Implement N-Queens with backtracking.
\item
  Use two pointers to find the smallest window with a given sum.
\item
  Pick a problem you've solved before , can you reframe it using a
  different design pattern?
\end{enumerate}

The more patterns you practice, the faster you'll map new problems to
known strategies , and the more powerful your algorithmic intuition will
become.

\section{Chapter 2. Sorting and
Searching}\label{chapter-2.-sorting-and-searching-1}

\subsection{11. Elementary Sorting (Bubble, Insertion,
Selection)}\label{elementary-sorting-bubble-insertion-selection}

Before diving into advanced sorts like mergesort or heapsort, it's
important to understand the elementary sorting algorithms , the building
blocks. They're simple, intuitive, and great for learning how sorting
works under the hood.

In this section, we'll cover three classics:

\begin{itemize}
\tightlist
\item
  Bubble Sort - swap adjacent out-of-order pairs- Selection Sort -
  select the smallest element each time- Insertion Sort - insert
  elements one by one in order These algorithms share ( O\(n^2\) ) time
  complexity but differ in behavior and stability.
\end{itemize}

\subsubsection{1. Bubble Sort}\label{bubble-sort-1}

Idea: Compare adjacent pairs and swap if they're out of order. Repeat
until the array is sorted. Each pass ``bubbles'' the largest element to
the end.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare \texttt{arr{[}j{]}} and \texttt{arr{[}j+1{]}}
\item
  Swap if \texttt{arr{[}j{]}\ \textgreater{}\ arr{[}j+1{]}}
\item
  Continue passes until no swaps are needed
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bubble\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ swapped }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{                swapped }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{swapped}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best: ( O(n) ) (already sorted)- Worst: ( O\(n^2\) )- Space: ( O(1) )-
  Stable: Yes Intuition: Imagine bubbles rising , after each pass, the
  largest ``bubble'' settles at the top.
\end{itemize}

\subsubsection{2. Selection Sort}\label{selection-sort-1}

Idea: Find the smallest element and place it at the front.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each position \texttt{i}, find the smallest element in the
  remainder of the array
\item
  Swap it with \texttt{arr{[}i{]}}
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ selection\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ min\_idx }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{])}
\NormalTok{                min\_idx }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
        \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best: ( O\(n^2\) )- Worst: ( O\(n^2\) )- Space: ( O(1) )- Stable: No
  Intuition: Selection sort ``selects'' the next correct element and
  fixes it. It minimizes swaps but still scans all elements.
\end{itemize}

\subsubsection{3. Insertion Sort}\label{insertion-sort-1}

Idea: Build a sorted array one element at a time by inserting each new
element into its correct position.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start from index 1
\item
  Compare with previous elements
\item
  Shift elements greater than key to the right
\item
  Insert key into the correct place
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ insertion\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ key }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j }\OperatorTok{\textgreater{}=} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{            j}\OperatorTok{{-}{-};}
        \OperatorTok{\}}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best: ( O(n) ) (nearly sorted)- Worst: ( O\(n^2\) )- Space: ( O(1) )-
  Stable: Yes Intuition: It's like sorting cards in your hand , take the
  next card and slide it into the right place.
\end{itemize}

\subsubsection{4. Comparing the Three}\label{comparing-the-three}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1474}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0947}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1263}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1053}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0632}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0842}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3789}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-Place
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & O(n) & O(n²) & O(n²) & Yes & Yes & Early exit possible \\
Selection Sort & O(n²) & O(n²) & O(n²) & No & Yes & Few swaps \\
Insertion Sort & O(n) & O(n²) & O(n²) & Yes & Yes & Great on small or
nearly sorted data \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-10}

Let's see how insertion sort works on \texttt{{[}5,\ 3,\ 4,\ 1,\ 2{]}}:

\begin{itemize}
\tightlist
\item
  Start with 3 → insert before 5 → \texttt{{[}3,\ 5,\ 4,\ 1,\ 2{]}}-
  Insert 4 → \texttt{{[}3,\ 4,\ 5,\ 1,\ 2{]}}- Insert 1 →
  \texttt{{[}1,\ 3,\ 4,\ 5,\ 2{]}}- Insert 2 →
  \texttt{{[}1,\ 2,\ 3,\ 4,\ 5{]}} Sorted in five passes.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-10}

Elementary sorts teach you:

\begin{itemize}
\tightlist
\item
  How comparisons and swaps drive order- The trade-off between
  simplicity and efficiency- How to reason about stability and
  adaptability While these aren't used for large datasets in practice,
  they're used \emph{inside} hybrid algorithms like Timsort and
  IntroSort, which switch to insertion sort for small chunks.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-10}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement all three and print the array after each pass.
\item
  Test on arrays: already sorted, reversed, random, partially sorted.
\item
  Modify bubble sort to sort descending.
\item
  Try insertion sort on 10,000 elements and note its behavior.
\item
  Can you detect when the list is already sorted and stop early?
\end{enumerate}

Start simple. Master these patterns. They'll be your foundation for
everything from merge sort to radix sort.

\subsection{12. Divide-and-Conquer Sorting (Merge, Quick,
Heap)}\label{divide-and-conquer-sorting-merge-quick-heap}

Elementary sorts are great for learning, but their (O\(n^2\)) runtime
quickly becomes a bottleneck. To scale beyond small arrays, we need
algorithms that divide problems into smaller parts, sort them
independently, and combine the results.

This is the essence of divide and conquer , break it down, solve
subproblems, merge solutions. In sorting, this approach yields some of
the fastest general-purpose algorithms: Merge Sort, Quick Sort, and Heap
Sort.

\subsubsection{1. Merge Sort}\label{merge-sort}

Idea: Split the array in half, sort each half recursively, then merge
the two sorted halves.

Merge sort is stable, works well with linked lists, and guarantees
(O\(n \log n\)) time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide the array into halves
\item
  Recursively sort each half
\item
  Merge two sorted halves into one
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ merge}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n1 }\OperatorTok{=}\NormalTok{ m }\OperatorTok{{-}}\NormalTok{ l }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ n2 }\OperatorTok{=}\NormalTok{ r }\OperatorTok{{-}}\NormalTok{ m}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ L}\OperatorTok{[}\NormalTok{n1}\OperatorTok{],}\NormalTok{ R}\OperatorTok{[}\NormalTok{n2}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{l }\OperatorTok{+}\NormalTok{ i}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n2}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{m }\OperatorTok{+} \DecValTok{1} \OperatorTok{+}\NormalTok{ j}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ k }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n1 }\OperatorTok{\&\&}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n2}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}=}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{++];}
        \ControlFlowTok{else}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{++];}
    \OperatorTok{\}}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n1}\OperatorTok{)}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{++];}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j }\OperatorTok{\textless{}}\NormalTok{ n2}\OperatorTok{)}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{++];}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ merge\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \OperatorTok{(}\NormalTok{l }\OperatorTok{+}\NormalTok{ r}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{        merge\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ m}\OperatorTok{);}
\NormalTok{        merge\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ m }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
\NormalTok{        merge}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ m}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n \log n\)) (always)- Space: (O(n)) (temporary arrays)-
  Stable: Yes Merge sort is predictable, making it ideal for external
  sorting (like sorting data on disk).
\end{itemize}

\subsubsection{2. Quick Sort}\label{quick-sort}

Idea: Pick a pivot, partition the array so smaller elements go left and
larger go right, then recursively sort both sides.

Quick sort is usually the fastest in practice due to good cache locality
and low constant factors.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose a pivot (often middle or random)
\item
  Partition: move smaller elements to left, larger to right
\item
  Recursively sort the two partitions
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ low }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ pivot}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            i}\OperatorTok{++;}
            \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ quick\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ pi }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
\NormalTok{        quick\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\NormalTok{        quick\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best / Average: (O\(n \log n\))- Worst: (O\(n^2\)) (bad pivot,
  e.g.~sorted input with naive pivot)- Space: (O\(\log n\)) (recursion)-
  Stable: No (unless modified) Quick sort is often used in standard
  libraries due to its efficiency in real-world workloads.
\end{itemize}

\subsubsection{3. Heap Sort}\label{heap-sort}

Idea: Turn the array into a heap, repeatedly extract the largest
element, and place it at the end.

A heap is a binary tree where every parent is ≥ its children (max-heap).

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a max-heap
\item
  Swap the root (max) with the last element
\item
  Reduce heap size, re-heapify
\item
  Repeat until sorted
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ heapify}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ largest }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ l }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ r }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ i }\OperatorTok{+} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{l}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{])}\NormalTok{ largest }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{r}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{])}\NormalTok{ largest }\OperatorTok{=}\NormalTok{ r}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{largest }\OperatorTok{!=}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ largest}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ heap\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{/} \DecValTok{2} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n \log n\))- Space: (O(1))- Stable: No Heap sort is reliable
  and space-efficient but less cache-friendly than quicksort.
\end{itemize}

\subsubsection{4. Comparison}\label{comparison}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1067}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0800}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2533}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Merge Sort & O(n log n) & O(n log n) & O(n log n) & O(n) & Yes &
Predictable, stable \\
Quick Sort & O(n log n) & O(n log n) & O(n²) & O(log n) & No & Fast in
practice \\
Heap Sort & O(n log n) & O(n log n) & O(n log n) & O(1) & No & In-place,
robust \\
\end{longtable}

Each one fits a niche:

\begin{itemize}
\tightlist
\item
  Merge Sort → stability and guarantees- Quick Sort → speed and cache
  performance- Heap Sort → low memory usage and simplicity
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-11}

Try sorting \texttt{{[}5,\ 1,\ 4,\ 2,\ 8{]}} with merge sort:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Split → \texttt{{[}5,1,4{]}}, \texttt{{[}2,8{]}}
\item
  Sort each → \texttt{{[}1,4,5{]}}, \texttt{{[}2,8{]}}
\item
  Merge → \texttt{{[}1,2,4,5,8{]}}
\end{enumerate}

Each recursive split halves the problem, yielding (O\(\log n\)) depth
with (O(n)) work per level.

\subsubsection{Why It Matters}\label{why-it-matters-11}

Divide-and-conquer sorting is the foundation for efficient order
processing. It introduces ideas you'll reuse in:

\begin{itemize}
\tightlist
\item
  Binary search (halving)- Matrix multiplication- Fast Fourier
  Transform- Dynamic programming These sorts teach how recursion,
  partitioning, and merging combine into scalable solutions.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-11}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement merge sort, quick sort, and heap sort.
\item
  Test all three on the same random array. Compare runtime.
\item
  Modify quick sort to use a random pivot.
\item
  Build a stable version of heap sort.
\item
  Visualize merge sort's recursion tree and merging process.
\end{enumerate}

Mastering these sorts gives you a template for solving any
divide-and-conquer problem efficiently.

\subsection{13. Counting and Distribution Sorts (Counting, Radix,
Bucket)}\label{counting-and-distribution-sorts-counting-radix-bucket}

So far, we've seen comparison-based sorts like merge sort and quicksort.
These rely on comparing elements and are bounded by the O(n log n) lower
limit for comparisons.

But what if you don't need to compare elements directly , what if
they're integers or values from a limited range?

That's where counting and distribution sorts come in. They exploit
structure, not just order, to achieve linear-time sorting in the right
conditions.

\subsubsection{1. Counting Sort}\label{counting-sort}

Idea: If your elements are integers in a known range ({[}0, k)), you can
count occurrences of each value, then reconstruct the sorted output.

Counting sort doesn't compare , it counts.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the range of input (max value (k))
\item
  Count occurrences in a frequency array
\item
  Convert counts to cumulative counts
\item
  Place elements into their sorted positions
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ counting\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ k}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ count}\OperatorTok{[}\NormalTok{k }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ output}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ k}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ count}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ count}\OperatorTok{[}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]++;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ k}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ count}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ count}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
\NormalTok{        output}\OperatorTok{[}\NormalTok{count}\OperatorTok{[}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        count}\OperatorTok{[}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ output}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}4, 2, 2, 8, 3, 3, 1{]}, k = 8 → count =
{[}0,1,2,2,1,0,0,0,1{]} → cumulative = {[}0,1,3,5,6,6,6,6,7{]} → sorted
= {[}1,2,2,3,3,4,8{]}

Complexity:

\begin{itemize}
\item
  Time: (O(n + k))- Space: (O(k))- Stable: Yes When to use:
\item
  Input is integers- Range (k) not much larger than (n)
\end{itemize}

\subsubsection{2. Radix Sort}\label{radix-sort}

Idea: Sort digits one at a time, from least significant (LSD) or most
significant (MSD), using a stable sub-sort like counting sort.

Radix sort works best when all elements have fixed-length
representations (e.g., integers, strings of equal length).

Steps (LSD method):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each digit position (from rightmost to leftmost)
\item
  Sort all elements by that digit using a stable sort (like counting
  sort)
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ get\_max}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ mx }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ mx}\OperatorTok{)}\NormalTok{ mx }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ mx}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ counting\_sort\_digit}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ exp}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ output}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ count}\OperatorTok{[}\DecValTok{10}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        count}\OperatorTok{[(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/}\NormalTok{ exp}\OperatorTok{)} \OperatorTok{\%} \DecValTok{10}\OperatorTok{]++;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{10}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        count}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ count}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ digit }\OperatorTok{=} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/}\NormalTok{ exp}\OperatorTok{)} \OperatorTok{\%} \DecValTok{10}\OperatorTok{;}
\NormalTok{        output}\OperatorTok{[}\NormalTok{count}\OperatorTok{[}\NormalTok{digit}\OperatorTok{]} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        count}\OperatorTok{[}\NormalTok{digit}\OperatorTok{]{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ output}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ radix\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=}\NormalTok{ get\_max}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ exp }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ m }\OperatorTok{/}\NormalTok{ exp }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ exp }\OperatorTok{*=} \DecValTok{10}\OperatorTok{)}
\NormalTok{        counting\_sort\_digit}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ exp}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}170, 45, 75, 90, 802, 24, 2, 66{]} → sort by 1s → 10s
→ 100s → final = {[}2, 24, 45, 66, 75, 90, 170, 802{]}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O(d \times (n + b))), where

  \begin{itemize}
  \tightlist
  \item
    (d): number of digits - (b): base (10 for decimal)- Space: (O(n +
    b))- Stable: Yes When to use:
  \end{itemize}
\item
  Fixed-length numbers- Bounded digits (e.g., base 10 or 2)
\end{itemize}

\subsubsection{3. Bucket Sort}\label{bucket-sort}

Idea: Divide elements into buckets based on value ranges, sort each
bucket individually, then concatenate.

Works best when data is uniformly distributed in a known interval.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create (k) buckets for value ranges
\item
  Distribute elements into buckets
\item
  Sort each bucket (often using insertion sort)
\item
  Merge buckets
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bucket\_sort}\OperatorTok{(}\DataTypeTok{float}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{float}\OperatorTok{\textgreater{}}\NormalTok{ buckets}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ n }\OperatorTok{*}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];} \CommentTok{// assuming 0 \textless{}= arr[i] \textless{} 1}
\NormalTok{        buckets}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        sort}\OperatorTok{(}\NormalTok{buckets}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ buckets}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{end}\OperatorTok{());}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{float}\NormalTok{ val }\OperatorTok{:}\NormalTok{ buckets}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{idx}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ val}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\item
  Average: (O(n + k))- Worst: (O\(n^2\)) (if all fall in one bucket)-
  Space: (O(n + k))- Stable: Depends on bucket sort method When to use:
\item
  Real numbers uniformly distributed in ({[}0,1))
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1688}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1558}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0779}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2338}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2597}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Counting Sort & O(n + k) & O(k) & Yes & Non-comparison & Small integer
range \\
Radix Sort & O(d(n + b)) & O(n + b) & Yes & Non-comparison &
Fixed-length numbers \\
Bucket Sort & O(n + k) avg & O(n + k) & Often & Distribution-based &
Uniform floats \\
\end{longtable}

These algorithms achieve O(n) behavior when assumptions hold , they're
specialized but incredibly fast when applicable.

\subsubsection{Tiny Code}\label{tiny-code-12}

Let's walk counting sort on
\texttt{arr\ =\ {[}4,\ 2,\ 2,\ 8,\ 3,\ 3,\ 1{]}}:

\begin{itemize}
\tightlist
\item
  Count occurrences → {[}1,2,2,1,0,0,0,1{]}- Cumulative count →
  positions- Place elements → {[}1,2,2,3,3,4,8{]} Sorted , no
  comparisons.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-12}

Distribution sorts teach a key insight:

\begin{quote}
If you know the structure of your data, you can sort faster than
comparison allows.
\end{quote}

They show how data properties , range, distribution, digit length , can
drive algorithm design.

You'll meet these ideas again in:

\begin{itemize}
\tightlist
\item
  Hashing (bucketing)- Indexing (range partitioning)- Machine learning
  (binning, histogramming)
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-12}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement counting sort for integers from 0 to 100.
\item
  Extend radix sort to sort strings by character.
\item
  Visualize bucket sort for values between 0 and 1.
\item
  What happens if you use counting sort on negative numbers? Fix it.
\item
  Compare counting vs quick sort on small integer arrays.
\end{enumerate}

These are the first glimpses of linear-time sorting , harnessing
knowledge about data to break the (O\(n \log n\)) barrier.

\subsection{14. Hybrid Sorts (IntroSort,
Timsort)}\label{hybrid-sorts-introsort-timsort}

In practice, no single sorting algorithm is perfect for all cases. Some
are fast on average but fail in worst cases (like Quick Sort). Others
are consistent but slow due to overhead (like Merge Sort). Hybrid
sorting algorithms combine multiple techniques to get the \emph{best of
all worlds} , practical speed, stability, and guaranteed performance.

Two of the most widely used hybrids in modern systems are IntroSort and
Timsort , both power the sorting functions in major programming
languages.

\subsubsection{1. The Idea Behind Hybrid
Sorting}\label{the-idea-behind-hybrid-sorting}

Real-world data is messy: sometimes nearly sorted, sometimes random,
sometimes pathological. A smart sorting algorithm should adapt to the
data.

Hybrids switch between different strategies based on:

\begin{itemize}
\tightlist
\item
  Input size- Recursion depth- Degree of order- Performance thresholds
  So, the algorithm ``introspects'' or ``adapts'' while running.
\end{itemize}

\subsubsection{2. IntroSort}\label{introsort}

IntroSort (short for \emph{introspective sort}) begins like Quick Sort,
but when recursion gets too deep , which means Quick Sort's worst case
may be coming , it switches to Heap Sort to guarantee (O\(n \log n\))
time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Quick Sort as long as recursion depth \textless{} \(2 \log n\)
\item
  If depth exceeds limit → switch to Heap Sort
\item
  For very small subarrays → switch to Insertion Sort
\end{enumerate}

This triple combo ensures:

\begin{itemize}
\tightlist
\item
  Fast average case (Quick Sort)- Guaranteed upper bound (Heap Sort)-
  Efficiency on small arrays (Insertion Sort) Code Sketch:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ intro\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ depth\_limit }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ log}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    intro\_sort\_util}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ depth\_limit}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ intro\_sort\_util}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ begin}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ end}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ depth\_limit}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ size }\OperatorTok{=}\NormalTok{ end }\OperatorTok{{-}}\NormalTok{ begin }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{size }\OperatorTok{\textless{}} \DecValTok{16}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ size}\OperatorTok{);}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{depth\_limit }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        heap\_sort\_range}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ end}\OperatorTok{);}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ end}\OperatorTok{);}
\NormalTok{    intro\_sort\_util}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ pivot }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ depth\_limit }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\NormalTok{    intro\_sort\_util}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pivot }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ end}\OperatorTok{,}\NormalTok{ depth\_limit }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\item
  Average: (O\(n \log n\))- Worst: (O\(n \log n\))- Space:
  (O\(\log n\))- Stable: No (depends on partition scheme) Used in:
\item
  C++ STL's \texttt{std::sort}- Many systems where performance
  guarantees matter
\end{itemize}

\subsubsection{3. Timsort}\label{timsort}

Timsort is a stable hybrid combining Insertion Sort and Merge Sort. It
was designed to handle real-world data, which often has runs (already
sorted segments).

Developed by Tim Peters (Python core dev), Timsort is now used in:

\begin{itemize}
\item
  Python's \texttt{sorted()} and \texttt{.sort()}- Java's
  \texttt{Arrays.sort()} for objects Idea:
\item
  Identify runs , segments already ascending or descending- Reverse
  descending runs (to make them ascending)- Sort small runs with
  Insertion Sort- Merge runs with Merge Sort Timsort adapts beautifully
  to partially ordered data.
\end{itemize}

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Scan array, detect runs (sequences already sorted)
\item
  Push runs to a stack
\item
  Merge runs using a carefully balanced merge strategy
\end{enumerate}

Pseudocode (simplified):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ timsort(arr):}
\NormalTok{    RUN }\OperatorTok{=} \DecValTok{32}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}

    \CommentTok{\# Step 1: sort small chunks}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, n, RUN):}
\NormalTok{        insertion\_sort(arr, i, }\BuiltInTok{min}\NormalTok{((i }\OperatorTok{+}\NormalTok{ RUN }\OperatorTok{{-}} \DecValTok{1}\NormalTok{), n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{))}

    \CommentTok{\# Step 2: merge sorted runs}
\NormalTok{    size }\OperatorTok{=}\NormalTok{ RUN}
    \ControlFlowTok{while}\NormalTok{ size }\OperatorTok{\textless{}}\NormalTok{ n:}
        \ControlFlowTok{for}\NormalTok{ start }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, n, size }\OperatorTok{*} \DecValTok{2}\NormalTok{):}
\NormalTok{            mid }\OperatorTok{=}\NormalTok{ start }\OperatorTok{+}\NormalTok{ size }\OperatorTok{{-}} \DecValTok{1}
\NormalTok{            end }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(start }\OperatorTok{+}\NormalTok{ size }\OperatorTok{*} \DecValTok{2} \OperatorTok{{-}} \DecValTok{1}\NormalTok{, n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{            merge(arr, start, mid, end)}
\NormalTok{        size }\OperatorTok{*=} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\item
  Best: (O(n)) (already sorted data)- Average: (O\(n \log n\))- Worst:
  (O\(n \log n\))- Space: (O(n))- Stable: Yes Key Strengths:
\item
  Excellent for real-world, partially sorted data- Stable (keeps equal
  keys in order)- Optimized merges (adaptive merging)
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1071}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1071}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Base Methods
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Real Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
IntroSort & Quick + Heap + Insertion & No & O(n log n) & O(n log n) &
O(n log n) & C++ STL \\
Timsort & Merge + Insertion & Yes & O(n) & O(n log n) & O(n log n) &
Python, Java \\
\end{longtable}

IntroSort prioritizes performance guarantees. Timsort prioritizes
adaptivity and stability.

Both show that ``one size fits all'' sorting doesn't exist , great
systems detect \emph{what's going on} and adapt.

\subsubsection{Tiny Code}\label{tiny-code-13}

Suppose we run Timsort on \texttt{{[}1,\ 2,\ 3,\ 7,\ 6,\ 5,\ 8,\ 9{]}}:

\begin{itemize}
\tightlist
\item
  Detect runs: \texttt{{[}1,2,3{]}}, \texttt{{[}7,6,5{]}},
  \texttt{{[}8,9{]}}- Reverse \texttt{{[}7,6,5{]}} →
  \texttt{{[}5,6,7{]}}- Merge runs → \texttt{{[}1,2,3,5,6,7,8,9{]}}
  Efficient because it leverages the existing order.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-13}

Hybrid sorts are the real-world heroes , they combine theory with
practice. They teach an important principle:

\begin{quote}
When one algorithm's weakness shows up, switch to another's strength.
\end{quote}

These are not academic curiosities , they're in your compiler, your
browser, your OS, your database. Understanding them means you understand
how modern languages optimize fundamental operations.

\subsubsection{Try It Yourself}\label{try-it-yourself-13}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement IntroSort and test on random, sorted, and reverse-sorted
  arrays.
\item
  Simulate Timsort's run detection on nearly sorted input.
\item
  Compare sorting speed of Insertion Sort vs Timsort for small arrays.
\item
  Add counters to Quick Sort and see when IntroSort should switch.
\item
  Explore Python's \texttt{sorted()} with different input shapes , guess
  when it uses merge vs insertion.
\end{enumerate}

Hybrid sorts remind us: good algorithms adapt , they're not rigid,
they're smart.

\subsection{15. Special Sorts (Cycle, Gnome, Comb,
Pancake)}\label{special-sorts-cycle-gnome-comb-pancake}

Not all sorting algorithms follow the mainstream divide-and-conquer or
distribution paradigms. Some were designed to solve niche problems, to
illustrate elegant ideas, or simply to experiment with different
mechanisms of ordering.

These special sorts, Cycle Sort, Gnome Sort, Comb Sort, and Pancake
Sort, are fascinating not because they're the fastest, but because they
reveal creative ways to think about permutation, local order, and
in-place operations.

\subsubsection{1. Cycle Sort}\label{cycle-sort}

Idea: Minimize the number of writes. Cycle sort rearranges elements into
cycles, placing each value directly in its correct position. It performs
exactly as many writes as there are misplaced elements, making it ideal
for flash memory or systems where writes are expensive.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each position \texttt{i}, find where \texttt{arr{[}i{]}} belongs
  (its rank).
\item
  If it's not already there, swap it into position.
\item
  Continue the cycle until the current position is correct.
\item
  Move to the next index.
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ cycle\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ cycle\_start }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ cycle\_start }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ cycle\_start}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ item }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{cycle\_start}\OperatorTok{];}
        \DataTypeTok{int}\NormalTok{ pos }\OperatorTok{=}\NormalTok{ cycle\_start}\OperatorTok{;}

        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ cycle\_start }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ item}\OperatorTok{)}\NormalTok{ pos}\OperatorTok{++;}

        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{==}\NormalTok{ cycle\_start}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}

        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{item }\OperatorTok{==}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{])}\NormalTok{ pos}\OperatorTok{++;}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{=}\NormalTok{ item}\OperatorTok{;}
\NormalTok{        item }\OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}

        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{pos }\OperatorTok{!=}\NormalTok{ cycle\_start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            pos }\OperatorTok{=}\NormalTok{ cycle\_start}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ cycle\_start }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ item}\OperatorTok{)}\NormalTok{ pos}\OperatorTok{++;}
            \ControlFlowTok{while} \OperatorTok{(}\NormalTok{item }\OperatorTok{==}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{])}\NormalTok{ pos}\OperatorTok{++;}
\NormalTok{            temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{];}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{=}\NormalTok{ item}\OperatorTok{;}
\NormalTok{            item }\OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n^2\))- Writes: minimal (exactly n-c, where c = \#cycles)-
  Stable: No Use Case: When minimizing writes is more important than
  runtime.
\end{itemize}

\subsubsection{2. Gnome Sort}\label{gnome-sort}

Idea: A simpler variation of insertion sort. Gnome sort moves back and
forth like a ``gnome'' tidying flower pots: if two adjacent pots are out
of order, swap and step back; otherwise, move forward.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start at index 1
\item
  If \texttt{arr{[}i{]}\ \textgreater{}=\ arr{[}i-1{]}}, move forward
\item
  Else, swap and step back (if possible)
\item
  Repeat until the end
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ gnome\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{])}\NormalTok{ i}\OperatorTok{++;}
        \ControlFlowTok{else} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{            i}\OperatorTok{{-}{-};}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n^2\))- Space: (O(1))- Stable: Yes Use Case: Educational
  simplicity. It's a readable form of insertion logic without nested
  loops.
\end{itemize}

\subsubsection{3. Comb Sort}\label{comb-sort}

Idea: An improvement over Bubble Sort by introducing a gap between
compared elements, shrinking it gradually. By jumping farther apart
early, Comb Sort helps eliminate small elements that are ``stuck'' near
the end.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with gap = n
\item
  On each pass, shrink gap = gap / 1.3
\item
  Compare and swap items \texttt{gap} apart
\item
  Stop when gap = 1 and no swaps occur
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ comb\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ gap }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ swapped }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{gap }\OperatorTok{\textgreater{}} \DecValTok{1} \OperatorTok{||}\NormalTok{ swapped}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        gap }\OperatorTok{=} \OperatorTok{(}\NormalTok{gap }\OperatorTok{*} \DecValTok{10}\OperatorTok{)} \OperatorTok{/} \DecValTok{13}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{gap }\OperatorTok{==} \DecValTok{9} \OperatorTok{||}\NormalTok{ gap }\OperatorTok{==} \DecValTok{10}\OperatorTok{)}\NormalTok{ gap }\OperatorTok{=} \DecValTok{11}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{gap }\OperatorTok{\textless{}} \DecValTok{1}\OperatorTok{)}\NormalTok{ gap }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{        swapped }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ gap }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ gap}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ gap}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ gap}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{                swapped }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Average: (O\(n \log n\))- Worst: (O\(n^2\))- Space: (O(1))- Stable: No
  Use Case: When a simple, in-place, nearly linear-time alternative to
  bubble sort is desired.
\end{itemize}

\subsubsection{4. Pancake Sort}\label{pancake-sort}

Idea: Sort an array using only one operation: flip (reversing a prefix).
It's like sorting pancakes on a plate, flip the stack so the largest
pancake goes to the bottom, then repeat for the rest.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the maximum unsorted element
\item
  Flip it to the front
\item
  Flip it again to its correct position
\item
  Reduce the unsorted portion by one
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ flip}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ start }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{start }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{start}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{        start}\OperatorTok{++;}
\NormalTok{        i}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ pancake\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ curr\_size }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ curr\_size }\OperatorTok{\textgreater{}} \DecValTok{1}\OperatorTok{;}\NormalTok{ curr\_size}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mi }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ curr\_size}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{mi}\OperatorTok{])}\NormalTok{ mi }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mi }\OperatorTok{!=}\NormalTok{ curr\_size }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            flip}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mi}\OperatorTok{);}
\NormalTok{            flip}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ curr\_size }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n^2\))- Space: (O(1))- Stable: No Fun Fact: Pancake sort is
  the only known algorithm whose operations mimic a kitchen utensil, and
  inspired the Burnt Pancake Problem in combinatorics and genome
  rearrangement theory.
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2090}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0746}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0896}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.4478}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Distinctive Trait
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Cycle Sort & O(n²) & O(1) & No & Minimal writes \\
Gnome Sort & O(n²) & O(1) & Yes & Simple insertion-like behavior \\
Comb Sort & O(n log n) avg & O(1) & No & Shrinking gap, improved
bubble \\
Pancake Sort & O(n²) & O(1) & No & Prefix reversals only \\
\end{longtable}

Each highlights a different design goal:

\begin{itemize}
\tightlist
\item
  Cycle: minimize writes- Gnome: simplify logic- Comb: optimize
  comparisons- Pancake: restrict operations
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-14}

Example (Pancake Sort on \texttt{{[}3,\ 6,\ 1,\ 9{]}}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Max = 9 at index 3 → flip(3) → \texttt{{[}9,1,6,3{]}}
\item
  flip(3) → \texttt{{[}3,6,1,9{]}} (9 fixed)
\item
  Max = 6 → flip(1) → \texttt{{[}6,3,1,9{]}}
\item
  flip(2) → \texttt{{[}1,3,6,9{]}}
\end{enumerate}

Sorted using only flips.

\subsubsection{Why It Matters}\label{why-it-matters-14}

Special sorts show there's more than one way to think about ordering.
They're laboratories for exploring new ideas: minimizing swaps, limiting
operations, or optimizing stability. Even if they're not the go-to in
production, they deepen your intuition about sorting mechanics.

\subsubsection{Try It Yourself}\label{try-it-yourself-14}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement each algorithm and visualize their operations step-by-step.
\item
  Measure how many writes Cycle Sort performs vs.~others.
\item
  Compare Gnome and Insertion sort on nearly sorted arrays.
\item
  Modify Comb Sort's shrink factor, how does performance change?
\item
  Write Pancake Sort with printouts of every flip to see the ``stack''
  in motion.
\end{enumerate}

These quirky algorithms prove that sorting isn't just science, it's also
art and experimentation.

\subsection{16. Linear and Binary
Search}\label{linear-and-binary-search}

Searching is the process of finding a target value within a collection
of data. Depending on whether the data is sorted or unsorted, you'll use
different strategies.

In this section, we revisit two of the most fundamental searching
methods , Linear Search and Binary Search , and see how they underpin
many higher-level algorithms and data structures.

\subsubsection{1. Linear Search}\label{linear-search-1}

Idea: Check each element one by one until you find the target. This is
the simplest possible search and works on unsorted data.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start from index 0
\item
  Compare \texttt{arr{[}i{]}} with the target
\item
  If match, return index
\item
  If end reached, return -1
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ linear\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}7, 2, 4, 9, 1{]}, key = 9

\begin{itemize}
\item
  Compare 7, 2, 4, then 9 → found at index 3 Complexity:
\item
  Time: ( O(n) )- Space: ( O(1) )- Best case: ( O(1) ) (first element)-
  Worst case: ( O(n) ) Pros:
\item
  Works on any data (sorted or unsorted)- Simple to implement Cons:
\item
  Inefficient on large arrays Use it when data is small or unsorted, or
  when simplicity matters more than speed.
\end{itemize}

\subsubsection{2. Binary Search}\label{binary-search-1}

Idea: If the array is sorted, you can repeatedly halve the search space.
Compare the middle element to the target , if it's greater, search left;
if smaller, search right.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the midpoint
\item
  If \texttt{arr{[}mid{]}\ ==\ key}, done
\item
  If \texttt{arr{[}mid{]}\ \textgreater{}\ key}, search left
\item
  If \texttt{arr{[}mid{]}\ \textless{}\ key}, search right
\item
  Repeat until range is empty
\end{enumerate}

Iterative Version:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Recursive Version:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textgreater{}}\NormalTok{ high}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else}
        \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}1, 3, 5, 7, 9, 11{]}, key = 7

\begin{itemize}
\item
  mid = 5 → key \textgreater{} mid → move right- mid = 7 → found
  Complexity:
\item
  Time: ( O\(\log n\) )- Space: ( O(1) ) (iterative) or ( O\(\log n\) )
  (recursive)- Best case: ( O(1) ) (middle element) Requirements:
\item
  Must be sorted- Must have random access (array, not linked list) Pros:
\item
  Very fast for large sorted arrays- Foundation for advanced searches
  (e.g.~interpolation, exponential) Cons:
\item
  Needs sorted data- Doesn't adapt to frequent insertions/deletions
\end{itemize}

\subsubsection{3. Binary Search Variants}\label{binary-search-variants}

Binary search is a \emph{pattern} as much as a single algorithm. You can
tweak it to find:

\begin{itemize}
\tightlist
\item
  First occurrence: move left if \texttt{arr{[}mid{]}\ ==\ key}- Last
  occurrence: move right if \texttt{arr{[}mid{]}\ ==\ key}- Lower bound:
  first index ≥ key- Upper bound: first index \textgreater{} key Example
  (Lower Bound):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lower\_bound}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ low}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Usage: These variants power functions like \texttt{std::lower\_bound()}
in C++ and binary search trees' lookup logic.

\subsubsection{4. Comparison}\label{comparison-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1688}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0649}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2338}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3247}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Works On
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sorted Data Needed
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & Any & O(n) & O(1) & No & Best for small/unsorted \\
Binary Search & Sorted & O(log n) & O(1) & Yes & Fastest on ordered
arrays \\
\end{longtable}

Binary search trades simplicity for power , once your data is sorted,
you unlock sublinear search.

\subsubsection{Tiny Code}\label{tiny-code-15}

Compare on array \texttt{{[}2,\ 4,\ 6,\ 8,\ 10{]}}, key = 8:

\begin{itemize}
\tightlist
\item
  Linear: 4 steps- Binary: 2 steps This gap grows huge with size , for
  \(n = 10^6\), linear takes up to a million steps, binary about 20.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-15}

These two searches form the foundation of retrieval. Linear search shows
brute-force iteration; binary search shows how structure (sorted order)
leads to exponential improvement.

From databases to compiler symbol tables to tree lookups, this principle
, \emph{divide to search faster} , is everywhere.

\subsubsection{Try It Yourself}\label{try-it-yourself-15}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement linear and binary search.
\item
  Count comparisons for ( n = 10, 100, 1000 ).
\item
  Modify binary search to return the first occurrence of a duplicate.
\item
  Try binary search on unsorted data , what happens?
\item
  Combine with sorting: sort array, then search.
\end{enumerate}

Mastering these searches builds intuition for all lookup operations ,
they are the gateway to efficient data retrieval.

\subsection{17. Interpolation and Exponential
Search}\label{interpolation-and-exponential-search}

Linear and binary search work well across many scenarios, but they don't
take into account how data is distributed. When values are uniformly
distributed, we can \emph{estimate} where the target lies, instead of
always splitting the range in half. This leads to Interpolation Search,
which ``jumps'' close to where the value should be.

For unbounded or infinite lists, we can't even know the size of the
array up front , that's where Exponential Search shines, by quickly
expanding its search window before switching to binary search.

Let's dive into both.

\subsubsection{1. Interpolation Search}\label{interpolation-search}

Idea: If data is sorted and uniformly distributed, you can
\emph{predict} where a key might be using linear interpolation. Instead
of splitting at the middle, estimate the position based on the value's
proportion in the range.

Formula: \[
\text{pos} = \text{low} + \frac{(key - arr[low]) \times (high - low)}{arr[high] - arr[low]}
\]

This ``guesses'' where the key lies. If (key = arr{[}pos{]}), we're
done. Otherwise, adjust \texttt{low} or \texttt{high} and repeat.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute estimated position \texttt{pos}
\item
  Compare \texttt{arr{[}pos{]}} with \texttt{key}
\item
  Narrow range accordingly
\item
  Repeat while \texttt{low\ \textless{}=\ high} and \texttt{key} within
  range
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ interpolation\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high }\OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textgreater{}=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textless{}=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{==}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ low}\OperatorTok{;}
            \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ pos }\OperatorTok{=}\NormalTok{ low }\OperatorTok{+} \OperatorTok{((}\DataTypeTok{double}\OperatorTok{)(}\NormalTok{key }\OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{])} \OperatorTok{*} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low}\OperatorTok{))} \OperatorTok{/} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{]);}

        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)}
            \ControlFlowTok{return}\NormalTok{ pos}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{            low }\OperatorTok{=}\NormalTok{ pos }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}
\NormalTok{            high }\OperatorTok{=}\NormalTok{ pos }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}10, 20, 30, 40, 50{]}, key = 40 pos = 0 + ((40 - 10) *
(4 - 0)) / (50 - 10) = 3 → found at index 3

Complexity:

\begin{itemize}
\item
  Best: (O(1))- Average: (O\(\log \log n\)) (uniform data)- Worst:
  (O(n)) (non-uniform or skewed data)- Space: (O(1)) When to Use:
\item
  Data is sorted and nearly uniform- Numeric data where values grow
  steadily Note: Interpolation search is adaptive , faster when data is
  predictable, slower when data is irregular.
\end{itemize}

\subsubsection{2. Exponential Search}\label{exponential-search}

Idea: When you don't know the array size (e.g., infinite streams, linked
data, files), you can't just binary search from 0 to n-1. Exponential
search finds a search range dynamically by doubling its step size until
it overshoots the target, then does binary search within that range.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \texttt{arr{[}0{]}\ ==\ key}, return 0
\item
  Find a range \texttt{{[}bound/2,\ bound{]}} such that
  \texttt{arr{[}bound{]}\ \textgreater{}=\ key}
\item
  Perform binary search in that range
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ exponential\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ bound }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{bound }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{bound}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{        bound }\OperatorTok{*=} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=}\NormalTok{ bound }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ high }\OperatorTok{=} \OperatorTok{(}\NormalTok{bound }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{?}\NormalTok{ bound }\OperatorTok{:}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \CommentTok{// Binary search in [low, high]}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}2, 4, 6, 8, 10, 12, 14, 16{]}, key = 10

\begin{itemize}
\item
  Step: bound = 1 (4), 2 (6), 4 (10 ≥ key)- Binary search {[}2,4{]} →
  found Complexity:
\item
  Time: (O\(\log i\)), where (i) is index of the target- Space: (O(1))-
  Best: (O(1)) When to Use:
\item
  Unbounded or streamed data- Unknown array size but sorted order
\end{itemize}

\subsubsection{3. Comparison}\label{comparison-5}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2376}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0891}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1188}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0990}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1584}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2970}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Requirement
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & O(1) & O(n) & O(n) & Unsorted & Works everywhere \\
Binary Search & O(1) & O(log n) & O(log n) & Sorted & Predictable
halving \\
Interpolation Search & O(1) & O(log log n) & O(n) & Sorted + Uniform &
Adaptive, fast on uniform data \\
Exponential Search & O(1) & O(log n) & O(log n) & Sorted & Great for
unknown size \\
\end{longtable}

Interpolation improves on binary \emph{if} data is smooth. Exponential
shines when size is unknown.

\subsubsection{Tiny Code}\label{tiny-code-16}

Interpolation intuition: If your data is evenly spaced (10, 20, 30, 40,
50), the value 40 should be roughly 75\% along. Instead of halving every
time, we jump \emph{right near it}. It's data-aware searching.

Exponential intuition: When size is unknown, ``expand until you find the
wall,'' then search within.

\subsubsection{Why It Matters}\label{why-it-matters-16}

These two searches show how context shapes algorithm design:

\begin{itemize}
\tightlist
\item
  \emph{Distribution} (Interpolation Search)- \emph{Boundaries}
  (Exponential Search) They teach that performance depends not only on
  structure (sortedness) but also metadata , how much you know about
  data spacing or limits.
\end{itemize}

These principles resurface in skip lists, search trees, and
probabilistic indexing.

\subsubsection{Try It Yourself}\label{try-it-yourself-16}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Test interpolation search on {[}10, 20, 30, 40, 50{]} , note how few
  steps it takes.
\item
  Try the same on {[}1, 2, 4, 8, 16, 32, 64{]} , note slowdown.
\item
  Implement exponential search and simulate an ``infinite'' array by
  stopping at \texttt{n}.
\item
  Compare binary vs interpolation search on random vs uniform data.
\item
  Extend exponential search to linked lists , how does complexity
  change?
\end{enumerate}

Understanding these searches helps you tailor lookups to the shape of
your data , a key skill in algorithmic thinking.

\subsection{18. Selection Algorithms (Quickselect, Median of
Medians)}\label{selection-algorithms-quickselect-median-of-medians}

Sometimes you don't need to sort an entire array , you just want the
k-th smallest (or largest) element. Sorting everything is overkill when
you only need one specific rank. Selection algorithms solve this problem
efficiently, often in linear time.

They're the backbone of algorithms for median finding, percentiles, and
order statistics, and they underpin operations like \emph{pivot
selection} in Quick Sort.

\subsubsection{1. The Selection Problem}\label{the-selection-problem}

Given an unsorted array of ( n ) elements and a number ( k ), find the
element that would be at position ( k ) if the array were sorted.

For example: arr = {[}7, 2, 9, 4, 6{]}, (k = 3) → Sorted = {[}2, 4, 6,
7, 9{]} → 3rd smallest = 6

We can solve this without sorting everything.

\subsubsection{2. Quickselect}\label{quickselect}

Idea: Quickselect is a selection variant of Quick Sort. It partitions
the array around a pivot, but recurses only on the side that contains
the k-th element.

It has average-case O(n) time because each partition roughly halves the
search space.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose a pivot (random or last element)
\item
  Partition array into elements \textless{} pivot and \textgreater{}
  pivot
\item
  Let \texttt{pos} be the pivot's index after partition
\item
  If \texttt{pos\ ==\ k-1} → done
\item
  If \texttt{pos\ \textgreater{}\ k-1} → recurse left
\item
  If \texttt{pos\ \textless{}\ k-1} → recurse right
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ pivot}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{            i}\OperatorTok{++;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ quickselect}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ k}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{==}\NormalTok{ high}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ pos }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ rank }\OperatorTok{=}\NormalTok{ pos }\OperatorTok{{-}}\NormalTok{ low }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank }\OperatorTok{==}\NormalTok{ k}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{];}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank }\OperatorTok{\textgreater{}}\NormalTok{ k}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ quickselect}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ pos }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ k}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ quickselect}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pos }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ k }\OperatorTok{{-}}\NormalTok{ rank}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}7, 2, 9, 4, 6{]}, ( k = 3 )

\begin{itemize}
\item
  Pivot = 6- Partition → {[}2, 4, 6, 9, 7{]}, pos = 2- rank = 3 → found
  (6) Complexity:
\item
  Average: (O(n))- Worst: (O\(n^2\)) (bad pivots)- Space: (O(1))-
  In-place When to Use:
\item
  Fast average case- You don't need full sorting Quickselect is used in
  C++'s \texttt{nth\_element()} and many median-finding implementations.
\end{itemize}

\subsubsection{3. Median of Medians}\label{median-of-medians}

Idea: Guarantee worst-case ( O(n) ) time by choosing a good pivot
deterministically.

This method ensures the pivot divides the array into reasonably balanced
parts every time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide array into groups of 5
\item
  Find the median of each group (using insertion sort)
\item
  Recursively find the median of these medians → pivot
\item
  Partition array around this pivot
\item
  Recurse into the side containing the k-th element
\end{enumerate}

This guarantees at least 30\% of elements are eliminated each step →
linear time in worst case.

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ select\_pivot}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ high }\OperatorTok{{-}}\NormalTok{ low }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{5}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ low}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
        \ControlFlowTok{return}\NormalTok{ low }\OperatorTok{+}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \OperatorTok{\}}

    \DataTypeTok{int}\NormalTok{ medians}\OperatorTok{[(}\NormalTok{n }\OperatorTok{+} \DecValTok{4}\OperatorTok{)} \OperatorTok{/} \DecValTok{5}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{/} \DecValTok{5}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5}\OperatorTok{,} \DecValTok{5}\OperatorTok{);}
\NormalTok{        medians}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5} \OperatorTok{+} \DecValTok{2}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{*} \DecValTok{5} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5}\OperatorTok{,}\NormalTok{ n }\OperatorTok{\%} \DecValTok{5}\OperatorTok{);}
\NormalTok{        medians}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5} \OperatorTok{+} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%} \DecValTok{5}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{];}
\NormalTok{        i}\OperatorTok{++;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ select\_pivot}\OperatorTok{(}\NormalTok{medians}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

You'd then partition around \texttt{pivot} and recurse just like
Quickselect.

Complexity:

\begin{itemize}
\tightlist
\item
  Worst: (O(n))- Space: (O(1)) (in-place version)- Stable: No (doesn't
  preserve order) Why It Matters: Median of Medians is slower in
  practice than Quickselect but provides theoretical guarantees , vital
  in real-time or critical systems.
\end{itemize}

\subsubsection{4. Special Cases}\label{special-cases}

\begin{itemize}
\tightlist
\item
  Min / Max: trivial , just scan once ((O(n)))- Median:
  \(k = \lceil n/2 \rceil\) , can use Quickselect or Median of Medians-
  Top-k Elements: use partial selection or heaps (k smallest/largest)
  Example: To get top 5 scores from a million entries, use Quickselect
  to find 5th largest, then filter ≥ threshold.
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-6}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1910}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0787}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0899}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3034}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-Place
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Quickselect & O(n) & O(n) & O(n²) & No & Yes & Fast in practice \\
Median of Medians & O(n) & O(n) & O(n) & No & Yes & Deterministic \\
Sorting & O(n log n) & O(n log n) & O(n log n) & Depends & Depends &
Overkill for single element \\
\end{longtable}

Quickselect is fast and simple; Median of Medians is safe and
predictable.

\subsubsection{Tiny Code}\label{tiny-code-17}

Find 4th smallest in {[}9, 7, 2, 5, 4, 3{]}:

\begin{itemize}
\tightlist
\item
  Pivot = 4 → partition {[}2,3,4,9,7,5{]}- 4 at position 2 → rank = 3
  \textless{} 4 → recurse right- New range {[}9,7,5{]}, ( k = 1 ) →
  smallest = 5 Result: 5
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-17}

Selection algorithms reveal a key insight:

\begin{quote}
Sometimes you don't need everything , just what matters.
\end{quote}

They form the basis for:

\begin{itemize}
\tightlist
\item
  Median filters in signal processing- Partitioning steps in sorting-
  k-th order statistics- Robust statistics and quantile computation They
  embody a ``partial work, full answer'' philosophy , do exactly enough.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-17}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Quickselect and find k-th smallest for various k.
\item
  Compare runtime vs full sorting.
\item
  Modify Quickselect to find k-th largest.
\item
  Implement Median of Medians pivot selection.
\item
  Use Quickselect to find median of 1,000 random elements.
\end{enumerate}

Mastering selection algorithms helps you reason about efficiency ,
you'll learn when to stop sorting and start selecting.

\subsection{19. Range Searching and Nearest
Neighbor}\label{range-searching-and-nearest-neighbor}

Searching isn't always about finding a single key. Often, you need to
find all elements within a given range , or the closest match to a query
point.

These problems are central to databases, computational geometry, and
machine learning (like k-NN classification). This section introduces
algorithms for range queries (e.g.~find all values between \texttt{L}
and \texttt{R}) and nearest neighbor searches (e.g.~find the point
closest to query \texttt{q}).

\subsubsection{1. Range Searching}\label{range-searching}

Idea: Given a set of data points (1D or multidimensional), quickly
report all points within a specified range.

In 1D (simple arrays), range queries can be handled by binary search and
prefix sums. In higher dimensions, we need trees designed for efficient
spatial querying.

\subsubsection{A. 1D Range Query (Sorted
Array)}\label{a.-1d-range-query-sorted-array}

Goal: Find all elements in \texttt{{[}L,\ R{]}}.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use lower bound to find first element ≥ L
\item
  Use upper bound to find first element \textgreater{} R
\item
  Output all elements in between
\end{enumerate}

Code (C++-style pseudo):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ l }\OperatorTok{=}\NormalTok{ lower\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,}\NormalTok{ L}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=}\NormalTok{ upper\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,}\NormalTok{ R}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Time Complexity:

\begin{itemize}
\tightlist
\item
  Binary search bounds: (O\(\log n\))- Reporting results: (O(k)) where
  (k) = number of elements in range → Total: (O\(\log n + k\))
\end{itemize}

\subsubsection{B. Prefix Sum Range Query (For
sums)}\label{b.-prefix-sum-range-query-for-sums}

If you just need the sum (not the actual elements), use prefix sums:

\[
\text{prefix}[i] = a_0 + a_1 + \ldots + a_i
\]

Then range sum: \[
\text{sum}(L, R) = \text{prefix}[R] - \text{prefix}[L - 1]
\]

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{prefix}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    prefix}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ range\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{R}\OperatorTok{]} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{L }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{?}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{L }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{:} \DecValTok{0}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: (O(1)) per query after (O(n)) preprocessing.

Used in:

\begin{itemize}
\tightlist
\item
  Databases for fast range aggregation- Fenwick trees, segment trees
\end{itemize}

\subsubsection{C. 2D Range Queries (Rectangular
Regions)}\label{c.-2d-range-queries-rectangular-regions}

For points ((x, y)), queries like:

\begin{quote}
``Find all points where \(L_x ≤ x ≤ R_x\) and \(L_y ≤ y ≤ R_y\)''
\end{quote}

Use specialized structures:

\begin{itemize}
\tightlist
\item
  Range Trees (balanced BSTs per dimension)- Fenwick Trees / Segment
  Trees (for 2D arrays)- KD-Trees (spatial decomposition) Time:
  (O\(\log^2 n + k\)) typical for 2D Space: (O\(n \log n\))
\end{itemize}

\subsubsection{2. Nearest Neighbor
Search}\label{nearest-neighbor-search}

Idea: Given a set of points, find the one closest to query (q). Distance
is often Euclidean, but can be any metric.

Brute Force: Check all points → (O(n)) per query. Too slow for large
datasets.

We need structures that let us prune far regions fast.

\subsubsection{A. KD-Tree}\label{a.-kd-tree}

KD-tree = K-dimensional binary tree. Each level splits points by one
coordinate, alternating axes. Used for efficient nearest neighbor search
in low dimensions (2D-10D).

Construction:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose axis = depth \% k
\item
  Sort points by axis
\item
  Pick median → root
\item
  Recursively build left and right
\end{enumerate}

Query (Nearest Neighbor):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Traverse down tree based on query position
\item
  Backtrack , check whether hypersphere crosses splitting plane
\item
  Keep track of best (closest) distance
\end{enumerate}

Complexity:

\begin{itemize}
\item
  Build: (O\(n \log n\))- Query: (O\(\log n\)) avg, (O(n)) worst Use
  Cases:
\item
  Nearest city lookup- Image / feature vector matching- Game AI spatial
  queries Code Sketch (2D Example):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Point }\OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\};}

\DataTypeTok{double}\NormalTok{ dist}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ sqrt}\OperatorTok{((}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)*(}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{+} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{)*(}\NormalTok{a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

(Full KD-tree implementation omitted for brevity , idea is recursive
partitioning.)

\subsubsection{B. Ball Tree / VP-Tree}\label{b.-ball-tree-vp-tree}

For high-dimensional data, KD-trees degrade. Alternatives like Ball
Trees (split by hyperspheres) or VP-Trees (Vantage Point Trees) perform
better.

They split based on distance metrics, not coordinate axes.

\subsubsection{C. Approximate Nearest Neighbor
(ANN)}\label{c.-approximate-nearest-neighbor-ann}

For large-scale, high-dimensional data (e.g.~embeddings, vectors):

\begin{itemize}
\item
  Locality Sensitive Hashing (LSH)- HNSW (Hierarchical Navigable Small
  World Graphs) These trade exactness for speed, common in:
\item
  Vector databases- Recommendation systems- AI model retrieval
\end{itemize}

\subsubsection{3. Summary}\label{summary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1358}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2099}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Brute Force
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimized
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time (Query)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1D Range Query & Scan O(n) & Binary Search & O(log n + k) & Sorted
data \\
Range Sum & O(n) & Prefix Sum & O(1) & Static data \\
2D Range Query & O(n) & Range Tree & O(log² n + k) & Spatial
filtering \\
Nearest Neighbor & O(n) & KD-Tree & O(log n) avg & Exact, low-dim \\
Nearest Neighbor (high-dim) & O(n) & HNSW / LSH & \textasciitilde O(1) &
Approximate \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-18}

Simple 1D range query:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{5}\OperatorTok{,} \DecValTok{7}\OperatorTok{,} \DecValTok{9}\OperatorTok{,} \DecValTok{11}\OperatorTok{\};}
\DataTypeTok{int}\NormalTok{ L }\OperatorTok{=} \DecValTok{4}\OperatorTok{,}\NormalTok{ R }\OperatorTok{=} \DecValTok{10}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ l }\OperatorTok{=}\NormalTok{ lower\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+} \DecValTok{6}\OperatorTok{,}\NormalTok{ L}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=}\NormalTok{ upper\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+} \DecValTok{6}\OperatorTok{,}\NormalTok{ R}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);} \CommentTok{// 5 7 9}
\end{Highlighting}
\end{Shaded}

Output: \texttt{5\ 7\ 9}

\subsubsection{Why It Matters}\label{why-it-matters-18}

Range and nearest-neighbor queries power:

\begin{itemize}
\tightlist
\item
  Databases (SQL range filters, BETWEEN)- Search engines (spatial
  indexing)- ML (k-NN classifiers, vector similarity)- Graphics / Games
  (collision detection, spatial queries) These are not just searches ,
  they're geometric lookups, linking algorithms to spatial reasoning.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-18}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function to return all numbers in \texttt{{[}L,\ R{]}} using
  binary search.
\item
  Build a prefix sum array and answer 5 range-sum queries in O(1).
\item
  Implement a KD-tree for 2D points and query nearest neighbor.
\item
  Compare brute-force vs KD-tree search on 1,000 random points.
\item
  Explore Python's \texttt{scipy.spatial.KDTree} or
  \texttt{sklearn.neighbors}.
\end{enumerate}

These algorithms bridge searching with geometry and analytics, forming
the backbone of spatial computation.

\subsection{20. Search Optimizations and
Variants}\label{search-optimizations-and-variants}

We've explored the main search families , linear, binary, interpolation,
exponential , each fitting a different data shape or constraint. Now
let's move one step further: optimizing search for performance and
adapting it to specialized scenarios.

This section introduces practical variants and enhancements used in real
systems, databases, and competitive programming, including jump search,
fibonacci search, ternary search, and exponential + binary combinations.

\subsubsection{1. Jump Search}\label{jump-search}

Idea: If data is sorted, we can ``jump'' ahead by fixed steps instead of
scanning linearly. It's like hopping through the array in blocks , when
you overshoot the target, you step back and linearly search that block.

It strikes a balance between linear and binary search , fewer
comparisons without the recursion or halving of binary search.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose jump size = \(\sqrt{n}\)
\item
  Jump by blocks until \texttt{arr{[}step{]}\ \textgreater{}\ key}
\item
  Linear search in previous block
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ jump\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ step }\OperatorTok{=}\NormalTok{ sqrt}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ prev }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{min}\OperatorTok{(}\NormalTok{step}\OperatorTok{,}\NormalTok{ n}\OperatorTok{)} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        prev }\OperatorTok{=}\NormalTok{ step}\OperatorTok{;}
\NormalTok{        step }\OperatorTok{+=}\NormalTok{ sqrt}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{prev }\OperatorTok{\textgreater{}=}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ prev}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ min}\OperatorTok{(}\NormalTok{step}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}1, 3, 5, 7, 9, 11, 13, 15{]}, key = 11

\begin{itemize}
\item
  step = 2- Jump 5, 7, 9, 11 → found Complexity:
\item
  Time: (O\(\sqrt{n}\))- Space: (O(1))- Works on sorted data When to
  Use: For moderately sized sorted lists when you want fewer comparisons
  but minimal overhead.
\end{itemize}

\subsubsection{2. Fibonacci Search}\label{fibonacci-search}

Idea: Similar to binary search, but it splits the array based on
Fibonacci numbers instead of midpoints. This allows using only addition
and subtraction (no division), useful on hardware where division is
costly.

Also, like binary search, it halves (roughly) the search space each
iteration.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the smallest Fibonacci number ≥ n
\item
  Use it to compute probe index
\item
  Compare and move interval accordingly
\end{enumerate}

Code (Sketch):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fibonacci\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ fibMMm2 }\OperatorTok{=} \DecValTok{0}\OperatorTok{;} \CommentTok{// (m{-}2)\textquotesingle{}th Fibonacci}
    \DataTypeTok{int}\NormalTok{ fibMMm1 }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// (m{-}1)\textquotesingle{}th Fibonacci}
    \DataTypeTok{int}\NormalTok{ fibM }\OperatorTok{=}\NormalTok{ fibMMm2 }\OperatorTok{+}\NormalTok{ fibMMm1}\OperatorTok{;} \CommentTok{// m\textquotesingle{}th Fibonacci}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{fibM }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        fibMMm2 }\OperatorTok{=}\NormalTok{ fibMMm1}\OperatorTok{;}
\NormalTok{        fibMMm1 }\OperatorTok{=}\NormalTok{ fibM}\OperatorTok{;}
\NormalTok{        fibM }\OperatorTok{=}\NormalTok{ fibMMm2 }\OperatorTok{+}\NormalTok{ fibMMm1}\OperatorTok{;}
    \OperatorTok{\}}

    \DataTypeTok{int}\NormalTok{ offset }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{fibM }\OperatorTok{\textgreater{}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{offset }\OperatorTok{+}\NormalTok{ fibMMm2}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            fibM }\OperatorTok{=}\NormalTok{ fibMMm1}\OperatorTok{;}
\NormalTok{            fibMMm1 }\OperatorTok{=}\NormalTok{ fibMMm2}\OperatorTok{;}
\NormalTok{            fibMMm2 }\OperatorTok{=}\NormalTok{ fibM }\OperatorTok{{-}}\NormalTok{ fibMMm1}\OperatorTok{;}
\NormalTok{            offset }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \OperatorTok{\}} \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            fibM }\OperatorTok{=}\NormalTok{ fibMMm2}\OperatorTok{;}
\NormalTok{            fibMMm1 }\OperatorTok{=}\NormalTok{ fibMMm1 }\OperatorTok{{-}}\NormalTok{ fibMMm2}\OperatorTok{;}
\NormalTok{            fibMMm2 }\OperatorTok{=}\NormalTok{ fibM }\OperatorTok{{-}}\NormalTok{ fibMMm1}\OperatorTok{;}
        \OperatorTok{\}} \ControlFlowTok{else} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fibMMm1 }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{offset }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ offset }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(\log n\))- Space: (O(1))- Sorted input required Fun Fact:
  Fibonacci search was originally designed for tape drives , where
  random access is expensive, and predictable jumps matter.
\end{itemize}

\subsubsection{3. Ternary Search}\label{ternary-search}

Idea: When the function or sequence is unimodal (strictly increasing
then decreasing), you can locate a maximum or minimum by splitting the
range into three parts instead of two.

Used not for discrete lookup but for optimization on sorted functions.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide range into thirds
\item
  Evaluate at two midpoints \texttt{m1}, \texttt{m2}
\item
  Eliminate one-third based on comparison
\item
  Repeat until range is small
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ ternary\_search}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{double} \OperatorTok{(*}\NormalTok{f}\OperatorTok{)(}\DataTypeTok{double}\OperatorTok{))} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ m1 }\OperatorTok{=}\NormalTok{ low }\OperatorTok{+} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low}\OperatorTok{)} \OperatorTok{/} \DecValTok{3}\OperatorTok{;}
        \DataTypeTok{double}\NormalTok{ m2 }\OperatorTok{=}\NormalTok{ high }\OperatorTok{{-}} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low}\OperatorTok{)} \OperatorTok{/} \DecValTok{3}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{f}\OperatorTok{(}\NormalTok{m1}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ f}\OperatorTok{(}\NormalTok{m2}\OperatorTok{))}
\NormalTok{            low }\OperatorTok{=}\NormalTok{ m1}\OperatorTok{;}
        \ControlFlowTok{else}
\NormalTok{            high }\OperatorTok{=}\NormalTok{ m2}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: Find minimum of ( f(x) = (x-3)\^{}2 ) between {[}0,10{]}. After
iterations, converges to (x ≈ 3).

Complexity:

\begin{itemize}
\tightlist
\item
  Time: \(O(\log\text{range})\)
\item
  Space: \(O(1)\)
\item
  Works for unimodal functions
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Mathematical optimization
\item
  Search-based tuning
\item
  Game AI decision models
\end{itemize}

\subsubsection{4. Binary Search Variants
(Review)}\label{binary-search-variants-review}

Binary search can be tailored to answer richer queries:

\begin{itemize}
\tightlist
\item
  Lower Bound: first index ≥ key- Upper Bound: first index
  \textgreater{} key- Equal Range: range of all equal elements- Rotated
  Arrays: find element in rotated sorted array- Infinite Arrays: use
  exponential expansion Rotated Example: arr = {[}6,7,9,1,3,4{]}, key =
  3 → Find pivot, then binary search correct side.
\end{itemize}

\subsubsection{5. Combined Searches}\label{combined-searches}

Real systems often chain algorithms:

\begin{itemize}
\tightlist
\item
  Exponential + Binary Search → when bounds unknown- Interpolation +
  Linear Search → when near target- Jump + Linear Search → hybrid
  iteration These hybrids use context switching , pick a fast search,
  then fall back to simple scan in a narrowed window.
\end{itemize}

\subsubsection{6. Summary}\label{summary-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2537}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0746}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2388}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2537}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Requirement
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Special Strength
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Jump Search & O(√n) & O(1) & Sorted & Fewer comparisons \\
Fibonacci Search & O(log n) & O(1) & Sorted & Division-free \\
Ternary Search & O(log range) & O(1) & Unimodal & Optimization \\
Binary Variants & O(log n) & O(1) & Sorted & Bound finding \\
Combined Searches & Adaptive & O(1) & Mixed & Practical hybrids \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-19}

Jump Search intuition:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Blocks of size sqrt(n)}
\OperatorTok{[}\DecValTok{1}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{5}\OperatorTok{,} \DecValTok{7}\OperatorTok{,} \DecValTok{9}\OperatorTok{,} \DecValTok{11}\OperatorTok{,} \DecValTok{13}\OperatorTok{,} \DecValTok{15}\OperatorTok{]}
\NormalTok{Step}\OperatorTok{:} \DecValTok{3}\NormalTok{ → }\DecValTok{7} \OperatorTok{\textgreater{}} \DecValTok{6}\NormalTok{ → search previous block}
\end{Highlighting}
\end{Shaded}

Jumps reduce comparisons dramatically vs linear scan.

\subsubsection{Why It Matters}\label{why-it-matters-19}

Search optimization is about adapting structure to context. You don't
always need a fancy data structure , sometimes a tweak like fixed-step
jumping or Fibonacci spacing yields massive gains.

These ideas influence:

\begin{itemize}
\tightlist
\item
  Indexing in databases- Compilers' symbol resolution- Embedded systems
  with low-level constraints They embody the principle: search smarter,
  not harder.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-19}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Jump Search and test vs Binary Search on 1M elements.
\item
  Write a Fibonacci Search , compare steps taken.
\item
  Use Ternary Search to find min of a convex function.
\item
  Modify binary search to find element in rotated array.
\item
  Combine Jump + Linear , how does it behave for small n?
\end{enumerate}

Understanding these variants arms you with flexibility , the heart of
algorithmic mastery.

\section{Chapter 3. Data Structures in
Actions}\label{chapter-3.-data-structures-in-actions}

\subsection{21. Arrays, Linked Lists, Stacks,
Queues}\label{arrays-linked-lists-stacks-queues}

Every data structure is built on top of a few core foundations , the
ones that teach you how data is stored, accessed, and moved. In this
section, we'll revisit the essentials: arrays, linked lists, stacks, and
queues.

They're simple, but they show you the most important design trade-offs
in algorithms:

\begin{itemize}
\tightlist
\item
  Contiguity vs.~flexibility- Speed vs.~dynamic growth-
  Last-in-first-out vs.~first-in-first-out access
\end{itemize}

\subsubsection{1. Arrays}\label{arrays}

Idea: A contiguous block of memory storing elements of the same type.
Access by index in O(1) time , that's their superpower.

Operations:

\begin{itemize}
\tightlist
\item
  Access \texttt{arr{[}i{]}}: (O(1))- Update \texttt{arr{[}i{]}}:
  (O(1))- Insert at end: (O(1)) (amortized for dynamic arrays)- Insert
  in middle: (O(n))- Delete: (O(n)) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[}\DecValTok{5}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{10}\OperatorTok{,} \DecValTok{20}\OperatorTok{,} \DecValTok{30}\OperatorTok{,} \DecValTok{40}\OperatorTok{,} \DecValTok{50}\OperatorTok{\};}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\DecValTok{2}\OperatorTok{]);} \CommentTok{// 30}
\end{Highlighting}
\end{Shaded}

Strengths:

\begin{itemize}
\item
  Fast random access- Cache-friendly (contiguous memory)- Simple,
  predictable Weaknesses:
\item
  Fixed size (unless using dynamic array)- Costly inserts/deletes
  Dynamic Arrays: Languages provide resizable arrays (like
  \texttt{vector} in C++ or \texttt{ArrayList} in Java) using doubling
  strategy , when full, allocate new array twice as big and copy. This
  gives amortized (O(1)) insertion at end.
\end{itemize}

\subsubsection{2. Linked Lists}\label{linked-lists}

Idea: A chain of nodes, where each node stores a value and a pointer to
the next. No contiguous memory required.

Operations:

\begin{itemize}
\tightlist
\item
  Access: (O(n))- Insert/Delete at head: (O(1))- Search: (O(n)) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ data}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ head }\OperatorTok{=}\NormalTok{ NULL}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Types:

\begin{itemize}
\item
  Singly Linked List: one pointer (next)- Doubly Linked List: two
  pointers (next, prev)- Circular Linked List: last node points back to
  first Strengths:
\item
  Dynamic size- Fast insert/delete (no shifting) Weaknesses:
\item
  Slow access- Extra memory for pointers- Poor cache locality Linked
  lists shine when memory is fragmented or frequent insertions/deletions
  are needed.
\end{itemize}

\subsubsection{3. Stack}\label{stack}

Idea: A Last-In-First-Out (LIFO) structure , the most recently added
element is the first to be removed.

Used in:

\begin{itemize}
\item
  Function call stacks- Expression evaluation- Undo operations
  Operations:
\item
  \texttt{push(x)}: add element on top- \texttt{pop()}: remove top
  element- \texttt{peek()}: view top element Example (Array-based
  Stack):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define MAX }\DecValTok{100}
\DataTypeTok{int}\NormalTok{ stack}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ top }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ push}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ stack}\OperatorTok{[++}\NormalTok{top}\OperatorTok{]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ pop}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ stack}\OperatorTok{[}\NormalTok{top}\OperatorTok{{-}{-}];} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ peek}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ stack}\OperatorTok{[}\NormalTok{top}\OperatorTok{];} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: All (O(1)): push, pop, peek

Variants:

\begin{itemize}
\tightlist
\item
  Linked-list-based stack (no fixed size)- Min-stack (tracks minimums)
  Stacks also appear implicitly , in recursion and backtracking
  algorithms.
\end{itemize}

\subsubsection{4. Queue}\label{queue}

Idea: A First-In-First-Out (FIFO) structure , the first added element
leaves first.

Used in:

\begin{itemize}
\item
  Task scheduling- BFS traversal- Producer-consumer pipelines
  Operations:
\item
  \texttt{enqueue(x)}: add to rear- \texttt{dequeue()}: remove from
  front- \texttt{front()}: view front Example (Array-based Queue):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define MAX }\DecValTok{100}
\DataTypeTok{int}\NormalTok{ queue}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ front }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ rear }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ enqueue}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ queue}\OperatorTok{[}\NormalTok{rear}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ dequeue}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ queue}\OperatorTok{[}\NormalTok{front}\OperatorTok{++];} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This simple implementation can waste space. A circular queue fixes that
by wrapping indices modulo \texttt{MAX}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rear }\OperatorTok{=} \OperatorTok{(}\NormalTok{rear }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ MAX}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Complexity: All (O(1)): enqueue, dequeue

Variants:

\begin{itemize}
\tightlist
\item
  Deque (double-ended queue): push/pop from both ends- Priority Queue:
  dequeue highest priority (not strictly FIFO)
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-7}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2794}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Order
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Memory
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Array & O(1) & O(n) & O(n) & Indexed & Contiguous & Fast access \\
Linked List & O(n) & O(1)* & O(1)* & Sequential & Pointers & Flexible
size \\
Stack & O(1) & O(1) & O(1) & LIFO & Minimal & Call stack, parsing \\
Queue & O(1) & O(1) & O(1) & FIFO & Minimal & Scheduling, BFS \\
\end{longtable}

(* at head or tail with pointer)

\subsubsection{Tiny Code}\label{tiny-code-20}

Simple stack example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{push}\OperatorTok{(}\DecValTok{10}\OperatorTok{);}
\NormalTok{push}\OperatorTok{(}\DecValTok{20}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ pop}\OperatorTok{());} \CommentTok{// 20}
\end{Highlighting}
\end{Shaded}

Simple queue example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{enqueue}\OperatorTok{(}\DecValTok{5}\OperatorTok{);}
\NormalTok{enqueue}\OperatorTok{(}\DecValTok{8}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ dequeue}\OperatorTok{());} \CommentTok{// 5}
\end{Highlighting}
\end{Shaded}

These short routines appear in almost every algorithm , from recursion
stacks to graph traversals.

\subsubsection{Why It Matters}\label{why-it-matters-20}

These four structures form the spine of data structures:

\begin{itemize}
\tightlist
\item
  Arrays teach indexing and memory- Linked lists teach pointers and
  dynamic allocation- Stacks teach recursion and reversal- Queues teach
  scheduling and order maintenance Every complex structure (trees,
  heaps, graphs) builds on these.
\end{itemize}

Master them, and every algorithm will feel more natural.

\subsubsection{Try It Yourself}\label{try-it-yourself-20}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a linked list with \texttt{insert\_front} and
  \texttt{delete\_value}.
\item
  Build a stack and use it to reverse an array.
\item
  Implement a queue for a round-robin scheduler.
\item
  Convert infix expression to postfix using a stack.
\item
  Compare time taken to insert 1000 elements in array vs linked list.
\end{enumerate}

Understanding these foundations gives you the vocabulary of structure ,
the way algorithms organize their thoughts in memory.

\subsection{22. Hash Tables and Variants (Cuckoo, Robin Hood,
Consistent)}\label{hash-tables-and-variants-cuckoo-robin-hood-consistent}

When you need lightning-fast lookups, insertions, and deletions, few
data structures match the raw efficiency of a hash table. They're
everywhere , from symbol tables and caches to compilers and databases ,
powering average-case O(1) access.

In this section, we'll unpack how hash tables work, their collision
strategies, and explore modern variants like Cuckoo Hashing, Robin Hood
Hashing, and Consistent Hashing, each designed to handle different
real-world needs.

\subsubsection{1. The Core Idea}\label{the-core-idea}

A hash table maps keys to values using a hash function that transforms
the key into an index in an array.

\[
\text{index} = h(\text{key}) \bmod \text{table\_size}
\]

If no two keys hash to the same index, all operations are (O(1)). But in
practice, collisions happen , two keys may map to the same slot , and we
must handle them smartly.

\subsubsection{2. Collision Resolution
Strategies}\label{collision-resolution-strategies}

A. Separate Chaining Each table slot holds a linked list (or dynamic
array) of entries with the same hash.

Pros: Simple, handles load factor \textgreater{} 1 Cons: Extra pointers,
memory overhead

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ value}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ table}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ value}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ node }\OperatorTok{=}\NormalTok{ malloc}\OperatorTok{(}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{=}\NormalTok{ key}\OperatorTok{;}\NormalTok{ node}\OperatorTok{{-}\textgreater{}}\NormalTok{value }\OperatorTok{=}\NormalTok{ value}\OperatorTok{;}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{next }\OperatorTok{=}\NormalTok{ table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{];}
\NormalTok{    table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ node}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

B. Open Addressing All keys live directly in the table. On collision,
find another slot.

Three main strategies:

\begin{itemize}
\tightlist
\item
  Linear probing: try next slot (+1)- Quadratic probing: step size
  increases quadratically- Double hashing: second hash decides step size
  Example (Linear Probing):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ value}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{used}\OperatorTok{)}
\NormalTok{        idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
\NormalTok{    table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{Entry}\OperatorTok{)\{}\NormalTok{key}\OperatorTok{,}\NormalTok{ value}\OperatorTok{,} \DecValTok{1}\OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Load Factor \(\alpha = \frac{n}{m}\) affects performance , when too
high, rehash to larger size.

\subsubsection{3. Modern Variants}\label{modern-variants}

Classic hash tables can degrade under heavy collisions. Modern variants
reduce probe chains and balance load more evenly.

\subsubsection{A. Cuckoo Hashing}\label{a.-cuckoo-hashing}

Idea: Each key has two possible locations , if both full, evict one
(``kick out the cuckoo'') and reinsert. Ensures constant lookup , at
most two probes.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute two hashes (h\_1(key)), (h\_2(key))
\item
  If slot 1 empty → place
\item
  Else evict occupant, reinsert it using alternate hash
\item
  Repeat until placed or cycle detected (rehash if needed)
\end{enumerate}

Code Sketch (Conceptual):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ h1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ h2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{key }\OperatorTok{/}\NormalTok{ SIZE}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pos1 }\OperatorTok{=}\NormalTok{ h1}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{])} \OperatorTok{\{}\NormalTok{ table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;} \ControlFlowTok{return}\OperatorTok{;} \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ displaced }\OperatorTok{=}\NormalTok{ table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{];}\NormalTok{ table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}

    \DataTypeTok{int}\NormalTok{ pos2 }\OperatorTok{=}\NormalTok{ h2}\OperatorTok{(}\NormalTok{displaced}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{table2}\OperatorTok{[}\NormalTok{pos2}\OperatorTok{])} \OperatorTok{\{}\NormalTok{ table2}\OperatorTok{[}\NormalTok{pos2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ displaced}\OperatorTok{;} \ControlFlowTok{return}\OperatorTok{;} \OperatorTok{\}}
    \CommentTok{// continue evicting if needed}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pros:

\begin{itemize}
\item
  Worst-case O(1) lookup (constant probes)- Predictable latency Cons:
\item
  Rehash needed on insertion failure- More complex logic Used in
  high-performance caches and real-time systems.
\end{itemize}

\subsubsection{B. Robin Hood Hashing}\label{b.-robin-hood-hashing}

Idea: Steal slots from richer (closer) keys to ensure fairness. When
inserting, if you find someone with smaller probe distance, swap ,
``steal from the rich, give to the poor.''

This balances probe lengths and improves variance and average lookup
time.

Key Principle: \[
\text{If new\_probe\_distance} > \text{existing\_probe\_distance} \Rightarrow \text{swap}
\]

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dist }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{used}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{dist }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{)} \OperatorTok{\{}
            \CommentTok{// swap entries}
\NormalTok{            Entry tmp }\OperatorTok{=}\NormalTok{ table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{];}
\NormalTok{            table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{Entry}\OperatorTok{)\{}\NormalTok{key}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{,} \DecValTok{1}\OperatorTok{\};}
\NormalTok{            key }\OperatorTok{=}\NormalTok{ tmp}\OperatorTok{.}\NormalTok{key}\OperatorTok{;}
\NormalTok{            dist }\OperatorTok{=}\NormalTok{ tmp}\OperatorTok{.}\NormalTok{dist}\OperatorTok{;}
        \OperatorTok{\}}
\NormalTok{        idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
\NormalTok{        dist}\OperatorTok{++;}
    \OperatorTok{\}}
\NormalTok{    table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{Entry}\OperatorTok{)\{}\NormalTok{key}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{,} \DecValTok{1}\OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pros:

\begin{itemize}
\item
  Reduced variance- Better performance under high load Cons:
\item
  Slightly slower insertion Used in modern languages like Rust
  (\texttt{hashbrown}) and Swift.
\end{itemize}

\subsubsection{C. Consistent Hashing}\label{c.-consistent-hashing}

Idea: When distributing keys across multiple nodes, you want minimal
movement when adding/removing a node. Consistent hashing maps both keys
and nodes onto a circular hash ring.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Hash nodes into a ring
\item
  Hash keys into same ring
\item
  Each key belongs to the next node clockwise
\end{enumerate}

When a node is added or removed, only nearby keys move.

Used in:

\begin{itemize}
\tightlist
\item
  Distributed caches (Memcached, DynamoDB)- Load balancing- Sharding in
  databases Code (Conceptual):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ring: 0 {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} 2\^{}32}
\NormalTok{Nodes: N1 at hash("A"), N2 at hash("B")}
\NormalTok{Key: hash("User42") → assign to next node clockwise}
\end{Highlighting}
\end{Shaded}

Pros:

\begin{itemize}
\item
  Minimal rebalancing- Scalable Cons:
\item
  More complex setup- Requires virtual nodes for even distribution
\end{itemize}

\subsubsection{4. Complexity Overview}\label{complexity-overview}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2059}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1029}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3382}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Search
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Memory
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Chaining & O(1) avg & O(1) avg & O(1) avg & High & Simple, dynamic \\
Linear Probing & O(1) avg & O(1) avg & O(1) avg & Low & Clustering
risk \\
Cuckoo & O(1) & O(1) & O(1) & Medium & Two tables, predictable \\
Robin Hood & O(1) & O(1) & O(1) & Low & Balanced probes \\
Consistent & O(log n) & O(log n) & O(log n) & Depends & Distributed
keys \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-21}

Simple hash table with linear probing:

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define SIZE }\DecValTok{10}
\DataTypeTok{int}\NormalTok{ keys}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{],}\NormalTok{ values}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{],}\NormalTok{ used}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ value}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{idx}\OperatorTok{])}\NormalTok{ idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
\NormalTok{    keys}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}\NormalTok{ values}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ value}\OperatorTok{;}\NormalTok{ used}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Lookup:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ get}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{idx}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{keys}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ values}\OperatorTok{[}\NormalTok{idx}\OperatorTok{];}
\NormalTok{        idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-21}

Hash tables show how structure and randomness combine for speed. They
embody the idea that a good hash function + smart collision handling =
near-constant performance.

Variants like Cuckoo and Robin Hood are examples of modern engineering
trade-offs , balancing performance, memory, and predictability.
Consistent hashing extends these ideas to distributed systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-21}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a hash table with chaining and test collision handling.
\item
  Modify it to use linear probing , measure probe lengths.
\item
  Simulate Cuckoo hashing with random inserts.
\item
  Implement Robin Hood swapping logic , observe fairness.
\item
  Draw a consistent hash ring with 3 nodes and 10 keys , track movement
  when adding one node.
\end{enumerate}

Once you master these, you'll see hashing everywhere , from dictionaries
to distributed databases.

\subsection{23. Heaps (Binary, Fibonacci,
Pairing)}\label{heaps-binary-fibonacci-pairing}

Heaps are priority-driven data structures , they always give you fast
access to the most important element, typically the minimum or maximum.
They're essential for priority queues, scheduling, graph algorithms
(like Dijkstra), and streaming analytics.

In this section, we'll start from the basic binary heap and then explore
more advanced ones like Fibonacci and pairing heaps, which trade off
simplicity, speed, and amortized guarantees.

\subsubsection{1. The Heap Property}\label{the-heap-property}

A heap is a tree-based structure (often represented as an array) that
satisfies:

\begin{itemize}
\tightlist
\item
  Min-Heap: Every node ≤ its children- Max-Heap: Every node ≥ its
  children This ensures the root always holds the smallest (or largest)
  element.
\end{itemize}

Complete Binary Tree: All levels filled except possibly the last, which
is filled left to right.

Example (Min-Heap):

\begin{verbatim}
        2
      /   \
     4     5
    / \   /
   9  10 15
\end{verbatim}

Here, the smallest element (2) is at the root.

\subsubsection{2. Binary Heap}\label{binary-heap}

Storage: Stored compactly in an array. For index \texttt{i} (0-based):

\begin{itemize}
\tightlist
\item
  Parent = \texttt{(i\ -\ 1)\ /\ 2}- Left child = \texttt{2i\ +\ 1}-
  Right child = \texttt{2i\ +\ 2} Operations:
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Description & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{push(x)} & Insert element & (O\(\log n\)) \\
\texttt{pop()} & Remove root & (O\(\log n\)) \\
\texttt{peek()} & Get root & (O(1)) \\
\texttt{heapify()} & Build heap & (O(n)) \\
\end{longtable}

\subsubsection{A. Insertion (Push)}\label{a.-insertion-push}

Insert at the end, then bubble up until heap property is restored.

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ push}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[],} \DataTypeTok{int} \OperatorTok{*}\NormalTok{n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \OperatorTok{(*}\NormalTok{n}\OperatorTok{)++;}
\NormalTok{    heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ heap}\OperatorTok{[(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)/}\DecValTok{2}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heap}\OperatorTok{[(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)/}\DecValTok{2}\OperatorTok{];}
\NormalTok{        heap}\OperatorTok{[(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)/}\DecValTok{2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        i }\OperatorTok{=} \OperatorTok{(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Removal (Pop)}\label{b.-removal-pop}

Replace root with last element, then bubble down (heapify).

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ heapify}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ smallest }\OperatorTok{=}\NormalTok{ i}\OperatorTok{,}\NormalTok{ l }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ r }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{i }\OperatorTok{+} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ heap}\OperatorTok{[}\NormalTok{l}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{])}\NormalTok{ smallest }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ heap}\OperatorTok{[}\NormalTok{r}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{])}\NormalTok{ smallest }\OperatorTok{=}\NormalTok{ r}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{smallest }\OperatorTok{!=}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{];}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ smallest}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pop:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ pop}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[],} \DataTypeTok{int} \OperatorTok{*}\NormalTok{n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ root }\OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
\NormalTok{    heap}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heap}\OperatorTok{[{-}{-}(*}\NormalTok{n}\OperatorTok{)];}
\NormalTok{    heapify}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{*}\NormalTok{n}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Building a Heap}\label{c.-building-a-heap}

Heapify bottom-up from last non-leaf: (O(n))

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n}\OperatorTok{/}\DecValTok{2} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})}
\NormalTok{    heapify}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Applications}\label{d.-applications}

\begin{itemize}
\tightlist
\item
  Heapsort: Repeatedly pop min (O(n log n))- Priority Queue: Fast access
  to smallest/largest- Graph Algorithms: Dijkstra, Prim- Streaming:
  Median finding using two heaps
\end{itemize}

\subsubsection{3. Fibonacci Heap}\label{fibonacci-heap}

Idea: A heap optimized for algorithms that do many decrease-key
operations (like Dijkstra's). It stores a collection of trees with lazy
merging, giving amortized bounds:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation & Amortized Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & (O(1)) \\
Find-Min & (O(1)) \\
Extract-Min & (O\(\log n\)) \\
Decrease-Key & (O(1)) \\
Merge & (O(1)) \\
\end{longtable}

It achieves this by delaying structural fixes until absolutely necessary
(using potential method in amortized analysis).

Structure:

\begin{itemize}
\tightlist
\item
  A circular linked list of roots- Each node can have multiple children-
  Consolidation on extract-min ensures minimal degree duplication Used
  in theoretical optimizations where asymptotic complexity matters
  (e.g.~Dijkstra in (O\(E + V \log V\)) vs (O\(E \log V\))).
\end{itemize}

\subsubsection{4. Pairing Heap}\label{pairing-heap}

Idea: A simpler, practical alternative to Fibonacci heaps.
Self-adjusting structure using a tree with multiple children.

Operations:

\begin{itemize}
\item
  Insert: (O(1))- Extract-Min: (O\(\log n\)) amortized- Decrease-Key:
  (O\(\log n\)) amortized Steps:
\item
  \texttt{merge} two heaps: attach one as child of the other-
  \texttt{extract-min}: remove root, merge children in pairs, then merge
  all results Why It's Popular:
\item
  Easier to implement- Great real-world performance- Used in functional
  programming and priority schedulers
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-8}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1707}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0976}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1341}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1463}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0610}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1220}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2683}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Heap Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Extract-Min
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Decrease-Key
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Merge
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Simplicity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Heap & O(log n) & O(log n) & O(log n) & O(n) & Easy &
General-purpose \\
Fibonacci Heap & O(1) & O(log n) & O(1) & O(1) & Complex & Theoretical
optimality \\
Pairing Heap & O(1) & O(log n) & O(log n) & O(1) & Moderate & Practical
alternative \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-22}

Binary Heap Demo:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[}\DecValTok{100}\OperatorTok{],}\NormalTok{ n }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{push}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{,} \DecValTok{10}\OperatorTok{);}
\NormalTok{push}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{,} \DecValTok{4}\OperatorTok{);}
\NormalTok{push}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{,} \DecValTok{7}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ pop}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{));} \CommentTok{// 4}
\end{Highlighting}
\end{Shaded}

Output: \texttt{4}

\subsubsection{Why It Matters}\label{why-it-matters-22}

Heaps show how to prioritize elements dynamically. From sorting to
scheduling, they're the backbone of many ``choose the best next''
algorithms. Variants like Fibonacci and Pairing Heaps demonstrate how
amortized analysis can unlock deeper efficiency , crucial in graph
theory and large-scale optimization.

\subsubsection{Try It Yourself}\label{try-it-yourself-22}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a binary min-heap with \texttt{push}, \texttt{pop}, and
  \texttt{peek}.
\item
  Use a heap to sort a list (Heapsort).
\item
  Build a priority queue for task scheduling.
\item
  Study how Dijkstra changes when replacing arrays with heaps.
\item
  Explore Fibonacci heap pseudo-code , trace \texttt{decrease-key}.
\end{enumerate}

Mastering heaps gives you a deep sense of priority-driven design , how
to keep ``the best'' element always within reach.

\subsection{24. Balanced Trees (AVL, Red-Black, Splay,
Treap)}\label{balanced-trees-avl-red-black-splay-treap}

Unbalanced trees can degrade into linear lists, turning your beautiful
(O\(\log n\)) search into a sad (O(n)) crawl. Balanced trees solve this
, they keep the height logarithmic, guaranteeing fast lookups,
insertions, and deletions.

In this section, you'll learn how different balancing philosophies work
, AVL (strict balance), Red-Black (relaxed balance), Splay
(self-adjusting), and Treap (randomized balance).

\subsubsection{1. The Idea of Balance}\label{the-idea-of-balance}

For a binary search tree (BST):

\[
\text{height} = O(\log n)
\]

only if it's balanced , meaning the number of nodes in left and right
subtrees differ by a small factor.

Unbalanced BST (bad):

\begin{verbatim}
1
 \
  2
   \
    3
\end{verbatim}

Balanced BST (good):

\begin{verbatim}
  2
 / \
1   3
\end{verbatim}

Balance ensures efficient:

\begin{itemize}
\tightlist
\item
  \texttt{search(x)} → (O\(\log n\))- \texttt{insert(x)} →
  (O\(\log n\))- \texttt{delete(x)} → (O\(\log n\))
\end{itemize}

\subsubsection{2. AVL Tree (Adelson-Velsky \&
Landis)}\label{avl-tree-adelson-velsky-landis}

Invented in 1962, AVL is the first self-balancing BST. It enforces
strict balance: \[
| \text{height(left)} - \text{height(right)} | \le 1
\]

Whenever this condition breaks, rotations fix it.

Rotations:

\begin{itemize}
\tightlist
\item
  LL (Right Rotation): imbalance on left-left- RR (Left Rotation):
  imbalance on right-right- LR / RL: double rotation cases Code
  (Rotation Example):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ y}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ x }\OperatorTok{=}\NormalTok{ y}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{;}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ T }\OperatorTok{=}\NormalTok{ x}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{;}
\NormalTok{    x}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ y}\OperatorTok{;}
\NormalTok{    y}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ T}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Height \& Balance Factor:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ height}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{?}\NormalTok{ n}\OperatorTok{{-}\textgreater{}}\NormalTok{h }\OperatorTok{:} \DecValTok{0}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ balance}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ height}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ height}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{);} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Properties:

\begin{itemize}
\tightlist
\item
  Strict height bound: (O\(\log n\))- More rotations (slower
  insertions)- Excellent lookup speed Used when lookups \textgreater{}
  updates (databases, indexing).
\end{itemize}

\subsubsection{3. Red-Black Tree}\label{red-black-tree}

Idea: A slightly looser balance for faster insertions. Each node has a
color (Red/Black) with these rules:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Root is black
\item
  Red node's children are black
\item
  Every path has same number of black nodes
\item
  Null nodes are black
\end{enumerate}

Balance through color flips + rotations

Compared to AVL:

\begin{itemize}
\item
  Fewer rotations (faster insert/delete)- Slightly taller (slower
  lookup)- Simpler amortized balance Used in:
\item
  C++ \texttt{std::map}, \texttt{std::set}- Java \texttt{TreeMap}, Linux
  scheduler Complexity: All major operations (O\(\log n\))
\end{itemize}

\subsubsection{4. Splay Tree}\label{splay-tree}

Idea: Bring recently accessed node to root via splaying (rotations). It
adapts to access patterns , the more you access a key, the faster it
becomes.

Splaying Steps:

\begin{itemize}
\tightlist
\item
  Zig: one rotation (root child)- Zig-Zig: two rotations (same side)-
  Zig-Zag: two rotations (different sides) Code (Conceptual):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ splay}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root }\OperatorTok{||}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
        \CommentTok{// splay in left subtree}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}
\NormalTok{            root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ splay}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{),}
\NormalTok{            root }\OperatorTok{=}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}
\NormalTok{            root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ splay}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{),}
\NormalTok{            root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ rotateLeft}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{);}
        \ControlFlowTok{return}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
        \CommentTok{// symmetric}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Why It's Cool: No strict balance, but amortized (O\(\log n\)).
Frequently accessed elements stay near top.

Used in self-adjusting caches, rope data structures, memory allocators.

\subsubsection{5. Treap (Tree + Heap)}\label{treap-tree-heap}

Idea: Each node has two keys:

\begin{itemize}
\tightlist
\item
  BST key → order property- Priority → heap property Insertion = normal
  BST insert + heap fix via rotation.
\end{itemize}

Balance comes from randomization , random priorities ensure expected
(O\(\log n\)) height.

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ priority}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ insert}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{key}\OperatorTok{,}\NormalTok{ rand}\OperatorTok{());}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}

    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{\&\&}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{priority }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{priority}\OperatorTok{)}
\NormalTok{        root }\OperatorTok{=}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{\&\&}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{{-}\textgreater{}}\NormalTok{priority }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{priority}\OperatorTok{)}
\NormalTok{        root }\OperatorTok{=}\NormalTok{ rotateLeft}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Advantages:

\begin{itemize}
\tightlist
\item
  Simple logic- Random balancing- Expected (O\(\log n\)) Used in
  randomized algorithms and functional programming.
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-9}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0947}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1263}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0947}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2211}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1368}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1684}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1579}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tree
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Balance Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rotations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Height
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert/Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lookup
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
AVL & Strict & More & (O\(\log n\)) & Medium & Fast & Lookup-heavy \\
Red-Black & Relaxed & Fewer & (O\(\log n\)) & Fast & Medium & Library
std \\
Splay & Adaptive & Variable & Amortized (O\(\log n\)) & Fast & Fast
(amortized) & Access patterns \\
Treap & Randomized & Avg few & (O\(\log n\)) expected & Simple & Simple
& Probabilistic \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-23}

AVL Insert (Skeleton):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ insert}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
\NormalTok{    root}\OperatorTok{{-}\textgreater{}}\NormalTok{h }\OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ max}\OperatorTok{(}\NormalTok{height}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{),}\NormalTok{ height}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{));}
    \DataTypeTok{int}\NormalTok{ b }\OperatorTok{=}\NormalTok{ balance}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}} \DecValTok{1} \OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textless{}} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ rotateLeft}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \CommentTok{// other cases...}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-23}

Balanced trees guarantee predictable performance under dynamic updates.
Each variant represents a philosophy:

\begin{itemize}
\tightlist
\item
  AVL: precision- Red-Black: practicality- Splay: adaptability- Treap:
  randomness Together, they teach one core idea , keep height in check,
  no matter the operations.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-23}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement an AVL tree and visualize rotations.
\item
  Insert keys {[}10, 20, 30, 40, 50{]} and trace Red-Black color
  changes.
\item
  Splay after each access , see which keys stay near top.
\item
  Build a Treap with random priorities , measure average height.
\item
  Compare performance of BST vs AVL on sorted input.
\end{enumerate}

Balanced trees are the architects of order , always keeping chaos one
rotation away.

\subsection{25. Segment Trees and Fenwick
Trees}\label{segment-trees-and-fenwick-trees}

When you need to answer range queries quickly (like sum, min, max) and
support updates to individual elements, simple prefix sums won't cut it
anymore.

You need something smarter , data structures that can divide and conquer
over ranges, updating and combining results efficiently.

That's exactly what Segment Trees and Fenwick Trees (Binary Indexed
Trees) do:

\begin{itemize}
\tightlist
\item
  Query over a range in (O\(\log n\))- Update elements in (O\(\log n\))
  They're the backbone of competitive programming, signal processing,
  and database analytics.
\end{itemize}

\subsubsection{1. The Problem}\label{the-problem}

Given an array \texttt{A{[}0..n-1{]}}, support:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{update(i,\ x)} → change \texttt{A{[}i{]}} to \texttt{x}
\item
  \texttt{query(L,\ R)} → compute sum (or min, max) of
  \texttt{A{[}L..R{]}}
\end{enumerate}

Naive approach:

\begin{itemize}
\tightlist
\item
  Update: (O(1))- Query: (O(n)) Prefix sums fix one but not both.
  Segment and Fenwick trees fix both.
\end{itemize}

\subsubsection{2. Segment Tree}\label{segment-tree}

Idea: Divide the array into segments (intervals) recursively. Each node
stores an aggregate (sum, min, max) of its range. You can combine child
nodes to get any range result.

Structure (Sum Example):

\begin{verbatim}
           [0,7] sum=36
         /           \
   [0,3]=10         [4,7]=26
   /     \           /      \
[0,1]=3 [2,3]=7  [4,5]=11  [6,7]=15
\end{verbatim}

Each node represents a range {[}L,R{]}. Leaf nodes = single elements.

\subsubsection{A. Build}\label{a.-build}

Recursive Construction: Time: (O(n))

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ build}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ node}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)}\NormalTok{ tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{L}\OperatorTok{];}
    \ControlFlowTok{else} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L }\OperatorTok{+}\NormalTok{ R}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{        build}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{);}
\NormalTok{        build}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{);}
\NormalTok{        tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{]} \OperatorTok{+}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Query (Range Sum)}\label{b.-query-range-sum}

Query {[}l, r{]} recursively:

\begin{itemize}
\tightlist
\item
  If current range {[}L, R{]} fully inside {[}l, r{]}, return node
  value- If disjoint, return 0- Else combine children
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ node}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ L }\OperatorTok{||}\NormalTok{ R }\OperatorTok{\textless{}}\NormalTok{ l}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}=}\NormalTok{ L }\OperatorTok{\&\&}\NormalTok{ R }\OperatorTok{\textless{}=}\NormalTok{ r}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L }\OperatorTok{+}\NormalTok{ R}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ query}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ r}\OperatorTok{)}
         \OperatorTok{+}\NormalTok{ query}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Update}\label{c.-update}

Change \texttt{arr{[}i{]}\ =\ x} and update tree nodes covering
\texttt{i}.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ update}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ node}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)}\NormalTok{ tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
    \ControlFlowTok{else} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L }\OperatorTok{+}\NormalTok{ R}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}=}\NormalTok{ mid}\OperatorTok{)}\NormalTok{ update}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
        \ControlFlowTok{else}\NormalTok{ update}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\NormalTok{        tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{]} \OperatorTok{+}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexities:

\begin{itemize}
\tightlist
\item
  Build: (O(n))- Query: (O\(\log n\))- Update: (O\(\log n\))- Space:
  (O(4n))
\end{itemize}

\subsubsection{D. Variants}\label{d.-variants}

Segment trees are flexible:

\begin{itemize}
\tightlist
\item
  Range minimum/maximum- Range GCD- Lazy propagation → range updates- 2D
  segment tree for grids
\end{itemize}

\subsubsection{3. Fenwick Tree (Binary Indexed
Tree)}\label{fenwick-tree-binary-indexed-tree}

Idea: Stores cumulative frequencies using bit manipulation. Each node
covers a range size = LSB(index).

Simpler, smaller, but supports only associative ops (sum, xor, etc.)

Indexing:

\begin{itemize}
\tightlist
\item
  Parent: \texttt{i\ +\ (i\ \&\ -i)}- Child: \texttt{i\ -\ (i\ \&\ -i)}
  Build: Initialize with zero, then add elements one by one.
\end{itemize}

Add / Update:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Prefix Sum:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{{-}=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        res }\OperatorTok{+=}\NormalTok{ bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Range Sum {[}L, R{]}: \[
\text{sum}(R) - \text{sum}(L-1)
\]

Complexities:

\begin{itemize}
\tightlist
\item
  Build: (O\(n \log n\))- Query: (O\(\log n\))- Update: (O\(\log n\))-
  Space: (O(n))
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-10}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Segment Tree & Fenwick Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Space & O(4n) & O(n) \\
Build & O(n) & O(n log n) \\
Query & O(log n) & O(log n) \\
Update & O(log n) & O(log n) \\
Range Update & With Lazy & Tricky \\
Range Query & Flexible & Sum/XOR only \\
Implementation & Moderate & Simple \\
\end{longtable}

\subsubsection{5. Applications}\label{applications}

\begin{itemize}
\item
  Sum / Min / Max / XOR queries- Frequency counts- Inversions counting-
  Order statistics- Online problems where array updates over time Used
  in:
\item
  Competitive programming- Databases (analytics on changing data)- Time
  series queries- Games (damage/range updates)
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-24}

Fenwick Tree Example:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ bit}\OperatorTok{[}\DecValTok{1001}\OperatorTok{],}\NormalTok{ n}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ update}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ val}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{{-}=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        res }\OperatorTok{+=}\NormalTok{ bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}

\CommentTok{// range sum}
\DataTypeTok{int}\NormalTok{ range\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ query}\OperatorTok{(}\NormalTok{R}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ query}\OperatorTok{(}\NormalTok{L }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-24}

Segment and Fenwick trees embody divide-and-conquer over data ,
balancing dynamic updates with range queries. They're how modern systems
aggregate live data efficiently.

They teach a powerful mindset:

\begin{quote}
``If you can split a problem, you can solve it fast.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-24}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a segment tree for sum queries.
\item
  Add range minimum queries (RMQ).
\item
  Implement a Fenwick tree , test with prefix sums.
\item
  Solve: number of inversions in array using Fenwick tree.
\item
  Add lazy propagation to segment tree for range updates.
\end{enumerate}

Once you master these, range queries will never scare you again , you'll
slice through them in logarithmic time.

\subsection{26. Disjoint Set Union
(Union-Find)}\label{disjoint-set-union-union-find}

Many problems involve grouping elements into sets and efficiently
checking whether two elements belong to the same group , like connected
components in a graph, network connectivity, Kruskal's MST, or even
social network clustering.

For these, the go-to structure is the Disjoint Set Union (DSU), also
called Union-Find. It efficiently supports two operations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{find(x)} → which set does \texttt{x} belong to?
\item
  \texttt{union(x,\ y)} → merge the sets containing \texttt{x} and
  \texttt{y}.
\end{enumerate}

With path compression and union by rank, both operations run in
near-constant time, specifically (O(\alpha(n))), where \(\alpha\) is the
inverse Ackermann function (practically ≤ 4).

\subsubsection{1. The Problem}\label{the-problem-1}

Suppose you have (n) elements initially in separate sets. Over time, you
want to:

\begin{itemize}
\tightlist
\item
  Merge two sets- Check if two elements share the same set Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sets: \{1\}, \{2\}, \{3\}, \{4\}, \{5\}}
\NormalTok{Union(1,2) → \{1,2\}, \{3\}, \{4\}, \{5\}}
\NormalTok{Union(3,4) → \{1,2\}, \{3,4\}, \{5\}}
\NormalTok{Find(2) == Find(1)? Yes}
\NormalTok{Find(5) == Find(3)? No}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Basic Implementation}\label{basic-implementation}

Each element has a parent pointer. Initially, every node is its own
parent.

Parent array representation:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ make\_set}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ v}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This works, but deep trees can form , making \texttt{find} slow. We fix
that with path compression.

\subsubsection{3. Path Compression}\label{path-compression}

Every time we call \texttt{find(v)}, we make all nodes along the path
point directly to the root. This flattens the tree dramatically.

Optimized Find:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ v}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

So next time, lookups will be (O(1)) for those nodes.

\subsubsection{4. Union by Rank / Size}\label{union-by-rank-size}

When merging, always attach the smaller tree to the larger to keep depth
small.

Union by Rank:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{N}\OperatorTok{],}\NormalTok{ rank}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ make\_set}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{    rank}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}
\NormalTok{            swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{==}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}
\NormalTok{            rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]++;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Union by Size (Alternative): Track size of each set and attach smaller
to larger.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ size}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}
\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{size}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ size}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\NormalTok{        size}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ size}\OperatorTok{[}\NormalTok{b}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Complexity}\label{complexity}

With both path compression and union by rank, all operations are
effectively constant time: \[
O(\alpha(n)) \approx O(1)
\]

For all practical (n), (\alpha(n) \le 4).

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Make set & O(1) \\
Find & O(α(n)) \\
Union & O(α(n)) \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-1}

\begin{itemize}
\tightlist
\item
  Graph Connectivity: determine connected components- Kruskal's MST: add
  edges, avoid cycles- Dynamic connectivity- Image segmentation- Network
  clustering- Cycle detection in undirected graphs Example: Kruskal's
  Algorithm
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sort}\OperatorTok{(}\NormalTok{edges}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ edges}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{edge e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{)} \OperatorTok{!=}\NormalTok{ find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        union\_sets}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{v}\OperatorTok{);}
\NormalTok{        mst\_weight }\OperatorTok{+=}\NormalTok{ e}\OperatorTok{.}\NormalTok{w}\OperatorTok{;}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Example}\label{example}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\DecValTok{6}\OperatorTok{],}\NormalTok{ rank}\OperatorTok{[}\DecValTok{6}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ init}\OperatorTok{()} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=} \DecValTok{5}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{        rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    init}\OperatorTok{();}
\NormalTok{    union\_sets}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{    union\_sets}\OperatorTok{(}\DecValTok{3}\OperatorTok{,} \DecValTok{4}\OperatorTok{);}
\NormalTok{    union\_sets}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ find}\OperatorTok{(}\DecValTok{4}\OperatorTok{));} \CommentTok{// prints representative of \{1,2,3,4\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Result: \texttt{\{1,2,3,4\}}, \texttt{\{5\}}

\subsubsection{8. Visualization}\label{visualization}

\begin{verbatim}
Before compression:
1
 \
  2
   \
    3

After compression:
1
├─2
└─3
\end{verbatim}

Every \texttt{find} call makes future queries faster.

\subsubsection{9. Comparison}\label{comparison-11}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Variant & Find & Union & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Basic & O(n) & O(n) & Deep trees \\
Path Compression & O(α(n)) & O(α(n)) & Very fast \\
+ Rank / Size & O(α(n)) & O(α(n)) & Balanced \\
Persistent DSU & O(log n) & O(log n) & Undo/rollback support \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-25}

Full DSU with path compression + rank:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\DecValTok{1000}\OperatorTok{],}\NormalTok{ rank}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ make\_set}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{    rank}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{==}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}
\NormalTok{            rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]++;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-25}

Union-Find embodies structural sharing and lazy optimization , you don't
balance eagerly, but just enough. It's one of the most elegant
demonstrations of how constant-time algorithms are possible through
clever organization.

It teaches a key algorithmic lesson:

\begin{quote}
``Work only when necessary, and fix structure as you go.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-25}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement DSU and test \texttt{find}/\texttt{union}.
\item
  Build a program that counts connected components.
\item
  Solve Kruskal's MST using DSU.
\item
  Add \texttt{get\_size(v)} to return component size.
\item
  Try rollback DSU (keep stack of changes).
\end{enumerate}

Union-Find is the quiet powerhouse behind many graph and connectivity
algorithms , simple, fast, and deeply elegant.

\subsection{27. Probabilistic Data Structures (Bloom, Count-Min,
HyperLogLog)}\label{probabilistic-data-structures-bloom-count-min-hyperloglog}

When you work with massive data streams , billions of elements, too big
for memory , you can't store everything. But what if you don't need
\emph{perfect} answers, just \emph{fast and tiny approximate ones}?

That's where probabilistic data structures shine. They trade a bit of
accuracy for huge space savings and constant-time operations.

In this section, we'll explore three of the most famous:

\begin{itemize}
\tightlist
\item
  Bloom Filters → membership queries- Count-Min Sketch → frequency
  estimation- HyperLogLog → cardinality estimation Each of them answers
  ``How likely is X?'' or ``How many?'' efficiently , perfect for modern
  analytics, caching, and streaming systems.
\end{itemize}

\subsubsection{1. Bloom Filter , ``Is this element probably in the
set?''}\label{bloom-filter-is-this-element-probably-in-the-set}

A Bloom filter answers:

\begin{quote}
``Is \texttt{x} in the set?'' with either maybe yes or definitely no.
\end{quote}

No false negatives, but \emph{some} false positives.

\subsubsection{A. Idea}\label{a.-idea}

Use an array of bits (size \texttt{m}), all initialized to 0. Use k
different hash functions.

To insert an element:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute k hashes: ( h\_1(x), h\_2(x), \ldots, h\_k(x) )
\item
  Set each bit position \(b_i = 1\)
\end{enumerate}

To query an element:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute same k hashes
\item
  If all bits are 1 → maybe yes
\item
  If any bit is 0 → definitely no
\end{enumerate}

\subsubsection{B. Example}\label{b.-example}

Insert \texttt{dog}:

\begin{itemize}
\tightlist
\item
  (h\_1(dog)=2, h\_2(dog)=5, h\_3(dog)=9) Set bits 2, 5, 9 → 1
\end{itemize}

Check \texttt{cat}:

\begin{itemize}
\tightlist
\item
  If any hash bit = 0 → not present
\end{itemize}

\subsubsection{C. Complexity}\label{c.-complexity}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Accuracy \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(k) & O(m) & Tunable \\
Query & O(k) & O(m) & False positives \\
\end{longtable}

False positive rate ≈ ( \(1 - e^{-kn/m}\)\^{}k )

Choose \texttt{m} and \texttt{k} based on expected \texttt{n} and
acceptable error.

\subsubsection{D. Code}\label{d.-code}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define M }\DecValTok{1000}
\DataTypeTok{int}\NormalTok{ bitset}\OperatorTok{[}\NormalTok{M}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{*} \DecValTok{17}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ hash2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{*} \DecValTok{31} \OperatorTok{+} \DecValTok{7}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    bitset}\OperatorTok{[}\NormalTok{hash1}\OperatorTok{(}\NormalTok{x}\OperatorTok{)]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{    bitset}\OperatorTok{[}\NormalTok{hash2}\OperatorTok{(}\NormalTok{x}\OperatorTok{)]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ contains}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ bitset}\OperatorTok{[}\NormalTok{hash1}\OperatorTok{(}\NormalTok{x}\OperatorTok{)]} \OperatorTok{\&\&}\NormalTok{ bitset}\OperatorTok{[}\NormalTok{hash2}\OperatorTok{(}\NormalTok{x}\OperatorTok{)];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Used in:

\begin{itemize}
\tightlist
\item
  Caches (check before disk lookup)- Spam filters- Databases (join
  filtering)- Blockchain and peer-to-peer networks
\end{itemize}

\subsubsection{2. Count-Min Sketch , ``How often has this
appeared?''}\label{count-min-sketch-how-often-has-this-appeared}

Tracks frequency counts in a stream, using sub-linear memory.

Instead of a full table, it uses a 2D array of counters, each row hashed
with a different hash function.

\subsubsection{A. Insert}\label{a.-insert}

For each row \texttt{i}:

\begin{itemize}
\tightlist
\item
  Compute hash (h\_i(x))- Increment \texttt{count{[}i{]}{[}h\_i(x){]}++}
  \#\#\#\# B. Query
\end{itemize}

For element \texttt{x}:

\begin{itemize}
\tightlist
\item
  Compute all (h\_i(x))- Take \texttt{min(count{[}i{]}{[}h\_i(x){]})}
  across rows → gives an upper-bounded estimate of true frequency
\end{itemize}

\subsubsection{C. Code}\label{c.-code}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define W }\DecValTok{1000}
\PreprocessorTok{\#define D }\DecValTok{5}
\DataTypeTok{int}\NormalTok{ count}\OperatorTok{[}\NormalTok{D}\OperatorTok{][}\NormalTok{W}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{*} \OperatorTok{(}\DecValTok{17}\OperatorTok{*}\NormalTok{i }\OperatorTok{+} \DecValTok{3}\OperatorTok{))} \OperatorTok{\%}\NormalTok{ W}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ D}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        count}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{hash}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{)]++;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ res }\OperatorTok{=}\NormalTok{ INT\_MAX}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ D}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        res }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{res}\OperatorTok{,}\NormalTok{ count}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{hash}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{)]);}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Complexity}\label{d.-complexity}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(D) & O(W×D) \\
Query & O(D) & O(W×D) \\
\end{longtable}

Error controlled by: \[
\varepsilon = \frac{1}{W}, \quad \delta = 1 - e^{-D}
\]

Used in:

\begin{itemize}
\tightlist
\item
  Frequency counting in streams- Hot-key detection- Network flow
  analysis- Trending topics
\end{itemize}

\subsubsection{3. HyperLogLog , ``How many unique
items?''}\label{hyperloglog-how-many-unique-items}

Estimates cardinality (number of distinct elements) with very small
memory (\textasciitilde1.5 KB for millions).

\subsubsection{A. Idea}\label{a.-idea-1}

Hash each element uniformly → 32-bit value. Split hash into:

\begin{itemize}
\tightlist
\item
  Prefix bits → bucket index- Suffix bits → count leading zeros Each
  bucket stores the max leading zero count seen. At the end, use
  harmonic mean of counts to estimate distinct values.
\end{itemize}

\subsubsection{B. Formula}\label{b.-formula}

\[
E = \alpha_m \cdot m^2 \cdot \Big(\sum_{i=1}^m 2^{-M[i]}\Big)^{-1}
\]

where \texttt{M{[}i{]}} is the zero count in bucket \texttt{i}, and
\(\alpha_m\) is a correction constant.

Accuracy: \textasciitilde1.04 / √m

\subsubsection{C. Complexity}\label{c.-complexity-1}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Error \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Add & O(1) & O(m) & \textasciitilde1.04/√m \\
Merge & O(m) & O(m) & , \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Web analytics (unique visitors)- Databases (\texttt{COUNT\ DISTINCT})-
  Distributed systems (mergeable estimates)
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-12}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0735}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2206}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2353}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Query
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Memory
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bloom & Membership & O(k) & Tiny & False positives & No deletions \\
Count-Min & Frequency & O(D) & Small & Overestimate & Streaming
counts \\
HyperLogLog & Cardinality & O(1) & Very small & \textasciitilde1\% &
Mergeable \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-26}

Bloom Filter Demo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add}\OperatorTok{(}\DecValTok{42}\OperatorTok{);}
\NormalTok{add}\OperatorTok{(}\DecValTok{17}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ contains}\OperatorTok{(}\DecValTok{42}\OperatorTok{));} \CommentTok{// 1 (maybe yes)}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ contains}\OperatorTok{(}\DecValTok{99}\OperatorTok{));} \CommentTok{// 0 (definitely no)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-26}

Probabilistic data structures show how approximation beats impossibility
when resources are tight. They make it feasible to process massive
streams in real time, when storing everything is impossible.

They teach a deeper algorithmic truth:

\begin{quote}
``A bit of uncertainty can buy you a world of scalability.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-26}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a Bloom filter with 3 hash functions.
\item
  Measure false positive rate for 10K elements.
\item
  Build a Count-Min Sketch and test frequency estimation.
\item
  Approximate unique elements using HyperLogLog logic.
\item
  Explore real-world systems: Redis (Bloom/CM Sketch), PostgreSQL
  (HyperLogLog).
\end{enumerate}

These tiny probabilistic tools are how big data becomes tractable.

\subsection{28. Skip Lists and B-Trees}\label{skip-lists-and-b-trees}

When you want fast search, insert, and delete but need a structure
that's easier to code than trees or optimized for disk and memory
blocks, two clever ideas step in:

\begin{itemize}
\tightlist
\item
  Skip Lists → randomized, layered linked lists that behave like
  balanced BSTs- B-Trees → multi-way trees that minimize disk I/O and
  organize large data blocks Both guarantee (O\(\log n\)) operations,
  but they shine in very different environments , Skip Lists in-memory,
  B-Trees on disk.
\end{itemize}

\subsubsection{1. Skip Lists}\label{skip-lists}

Invented by: William Pugh (1990) Goal: Simulate binary search using
linked lists with probabilistic shortcuts.

\subsubsection{A. Idea}\label{a.-idea-2}

A skip list is a stack of linked lists, each level skipping over more
elements.

Example:

\begin{verbatim}
Level 3:        ┌───────> 50 ───────┐
Level 2:   ┌──> 10 ─────> 30 ─────> 50 ───┐
Level 1:  5 ──> 10 ──> 20 ──> 30 ──> 40 ──> 50
\end{verbatim}

Higher levels are sparser and let you ``skip'' large chunks of the list.

You search top-down:

\begin{itemize}
\tightlist
\item
  Move right while next ≤ target- Drop down when you can't go further
  This mimics binary search , logarithmic layers, logarithmic hops.
\end{itemize}

\subsubsection{B. Construction}\label{b.-construction}

Each inserted element is given a random height, with geometric
distribution:

\begin{itemize}
\tightlist
\item
  Level 1 (base) always exists- Level 2 with probability ½- Level 3 with
  ¼, etc. Expected total nodes = 2n, Expected height = (O\(\log n\))
\end{itemize}

\subsubsection{C. Operations}\label{c.-operations}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Search & (O\(\log n\)) & O(n) & Randomized balance \\
Insert & (O\(\log n\)) & O(n) & Rebuild towers \\
Delete & (O\(\log n\)) & O(n) & Rewire pointers \\
\end{longtable}

Search Algorithm:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ search}\OperatorTok{(}\NormalTok{SkipList}\OperatorTok{*}\NormalTok{ sl}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ sl}\OperatorTok{{-}\textgreater{}}\NormalTok{head}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ lvl }\OperatorTok{=}\NormalTok{ sl}\OperatorTok{{-}\textgreater{}}\NormalTok{level}\OperatorTok{;}\NormalTok{ lvl }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ lvl}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]{-}\textgreater{}}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{            cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ cur}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ NULL}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Skip Lists are simple, fast, and probabilistically balanced , no
rotations, no rebalancing.

\subsubsection{D. Why Use Skip Lists?}\label{d.-why-use-skip-lists}

\begin{itemize}
\item
  Easier to implement than balanced trees- Support concurrent access
  well- Randomized, not deterministic , but highly reliable Used in:
\item
  Redis (sorted sets)- LevelDB / RocksDB internals- Concurrent maps
\end{itemize}

\subsubsection{2. B-Trees}\label{b-trees}

Invented by: Rudolf Bayer \& Ed McCreight (1972) Goal: Reduce disk
access by grouping data in blocks.

A B-Tree is a generalization of a BST:

\begin{itemize}
\tightlist
\item
  Each node holds multiple keys and children- Keys are kept sorted-
  Child subtrees span ranges between keys
\end{itemize}

\subsubsection{A. Structure}\label{a.-structure}

A B-Tree of order \texttt{m}:

\begin{itemize}
\tightlist
\item
  Each node has ≤ \texttt{m} children- Each internal node has
  \texttt{k-1} keys if it has \texttt{k} children- All leaves at the
  same depth Example (order 3):
\end{itemize}

\begin{verbatim}
        [17 | 35]
       /    |     \
 [5 10] [20 25 30] [40 45 50]
\end{verbatim}

\subsubsection{B. Operations}\label{b.-operations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Search

  \begin{itemize}
  \tightlist
  \item
    Traverse from root - Binary search in each node's key array - Follow
    appropriate child → (O\(\log_m n\))
  \end{itemize}
\item
  Insert

  \begin{itemize}
  \tightlist
  \item
    Insert in leaf - If overflow → split node - Promote median key to
    parent
  \end{itemize}
\item
  Delete

  \begin{itemize}
  \tightlist
  \item
    Borrow or merge if node underflows Each split or merge keeps height
    minimal.
  \end{itemize}
\end{enumerate}

\subsubsection{C. Complexity}\label{c.-complexity-2}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Disk Accesses & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Search & (O\(\log_m n\)) & (O\(\log_m n\)) & m = branching factor \\
Insert & (O\(\log_m n\)) & (O(1)) splits & Balanced \\
Delete & (O\(\log_m n\)) & (O(1)) merges & Balanced \\
\end{longtable}

Height ≈ \(\log_m n\) → very shallow when (m) large (e.g.~100).

\subsubsection{D. B+ Tree Variant}\label{d.-b-tree-variant}

In B+ Trees:

\begin{itemize}
\item
  All data in leaves (internal nodes = indexes)- Leaves linked →
  efficient range queries Used in:
\item
  Databases (MySQL, PostgreSQL)- File systems (NTFS, HFS+)- Key-value
  stores
\end{itemize}

\subsubsection{E. Example Flow}\label{e.-example-flow}

Insert 25:

\begin{verbatim}
[10 | 20 | 30] → overflow
Split → [10] [30]
Promote 20
Root: [20]
\end{verbatim}

\subsubsection{3. Comparison}\label{comparison-13}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Skip List & B-Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Balancing & Randomized & Deterministic \\
Fanout & 2 (linked) & m-way \\
Environment & In-memory & Disk-based \\
Search & O(log n) & O\(log_m n\) \\
Insert/Delete & O(log n) & O\(log_m n\) \\
Concurrency & Easy & Complex \\
Range Queries & Sequential scan & Linked leaves (B+) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-27}

Skip List Search (Conceptual):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ search}\OperatorTok{(}\NormalTok{SkipList}\OperatorTok{*}\NormalTok{ list}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ list}\OperatorTok{{-}\textgreater{}}\NormalTok{head}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ lvl }\OperatorTok{=}\NormalTok{ list}\OperatorTok{{-}\textgreater{}}\NormalTok{level}\OperatorTok{;}\NormalTok{ lvl }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ lvl}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]{-}\textgreater{}}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{            cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \OperatorTok{?}\NormalTok{ cur }\OperatorTok{:}\NormalTok{ NULL}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

B-Tree Node (Skeleton):

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define M }\DecValTok{4}
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ keys}\OperatorTok{[}\NormalTok{M}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ child}\OperatorTok{[}\NormalTok{M}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ n}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-27}

Skip Lists and B-Trees show two paths to balance:

\begin{itemize}
\tightlist
\item
  Randomized simplicity (Skip List)- Block-based order (B-Tree) Both
  offer logarithmic guarantees, but one optimizes pointer chasing, the
  other I/O.
\end{itemize}

They're fundamental to:

\begin{itemize}
\tightlist
\item
  In-memory caches (Skip List)- On-disk indexes (B-Tree, B+ Tree)-
  Sorted data structures across systems
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-27}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a basic skip list and insert random keys.
\item
  Trace a search path across levels.
\item
  Implement B-Tree insert and split logic.
\item
  Compare height of BST vs B-Tree for 1,000 keys.
\item
  Explore how Redis and MySQL use these internally.
\end{enumerate}

Together, they form the bridge between linked lists and balanced trees,
uniting speed, structure, and scalability.

\subsection{29. Persistent and Functional Data
Structures}\label{persistent-and-functional-data-structures}

Most data structures are ephemeral , when you update them, the old
version disappears. But sometimes, you want to keep all past versions,
so you can go back in time, undo operations, or run concurrent reads
safely.

That's the magic of persistent data structures: every update creates a
new version while sharing most of the old structure.

This section introduces the idea of persistence, explores how to make
classic structures like arrays and trees persistent, and explains why
functional programming loves them.

\subsubsection{1. What Is Persistence?}\label{what-is-persistence}

A persistent data structure preserves previous versions after updates.
You can access any version , past or present , without side effects.

Three levels:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1184}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6842}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1974}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Partial & Can access past versions, but only modify the latest & Undo
stack \\
Full & Can access and modify any version & Immutable map \\
Confluent & Can combine different versions & Git-like merges \\
\end{longtable}

This is essential in functional programming, undo systems, version
control, persistent segment trees, and immutable databases.

\subsubsection{2. Ephemeral vs
Persistent}\label{ephemeral-vs-persistent}

Ephemeral:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arr}\OperatorTok{[}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \DecValTok{7}\OperatorTok{;} \CommentTok{// old value lost forever}
\end{Highlighting}
\end{Shaded}

Persistent:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_arr }\OperatorTok{=}\NormalTok{ update}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{7}\OperatorTok{);} \CommentTok{// old\_arr still exists}
\end{Highlighting}
\end{Shaded}

Persistent structures use structural sharing , unchanged parts are
reused, not copied.

\subsubsection{3. Persistent Linked List}\label{persistent-linked-list}

Easiest example: each update creates a new head, reusing the tail.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{;}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;} \OperatorTok{\};}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ push}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ head}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ newHead }\OperatorTok{=}\NormalTok{ malloc}\OperatorTok{(}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
\NormalTok{    newHead}\OperatorTok{{-}\textgreater{}}\NormalTok{val }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
\NormalTok{    newHead}\OperatorTok{{-}\textgreater{}}\NormalTok{next }\OperatorTok{=}\NormalTok{ head}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ newHead}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Now both \texttt{old\_head} and \texttt{new\_head} coexist. Each version
is immutable , you never change existing nodes.

Access: old and new lists share most of their structure:

\begin{verbatim}
v0: 1 → 2 → 3
v1: 0 → 1 → 2 → 3
\end{verbatim}

Only one new node was created.

\subsubsection{4. Persistent Binary Tree}\label{persistent-binary-tree}

For trees, updates create new paths from the root to the modified node,
reusing the rest.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ update}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pos}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{val}\OperatorTok{);}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ node }\OperatorTok{=}\NormalTok{ malloc}\OperatorTok{(}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
    \OperatorTok{*}\NormalTok{node }\OperatorTok{=} \OperatorTok{*}\NormalTok{root}\OperatorTok{;} \CommentTok{// copy}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}\NormalTok{ node}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ update}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ node}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ update}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ node}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Each \texttt{update} creates a new version , only (O\(\log n\)) new
nodes per change.

This is the core of persistent segment trees used in competitive
programming.

\subsubsection{5. Persistent Array (Functional
Trick)}\label{persistent-array-functional-trick}

Arrays are trickier because of random access. Solutions:

\begin{itemize}
\item
  Use balanced binary trees as array replacements- Each update replaces
  one node- Persistent vector = tree of small arrays (used in Clojure,
  Scala) This gives:
\item
  Access: (O\(\log n\))- Update: (O\(\log n\))- Space: (O\(\log n\)) per
  update
\end{itemize}

\subsubsection{6. Persistent Segment
Tree}\label{persistent-segment-tree}

Used for versioned range queries:

\begin{itemize}
\tightlist
\item
  Each update = new root- Each version = snapshot of history Example:
  Track how array changes over time, query ``sum in range {[}L,R{]} at
  version t''.
\end{itemize}

Build:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ build}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{L}\OperatorTok{]);}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L}\OperatorTok{+}\NormalTok{R}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}
\NormalTok{        build}\OperatorTok{(}\NormalTok{L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{),}
\NormalTok{        build}\OperatorTok{(}\NormalTok{mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{),}
\NormalTok{        sum}
    \OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Update: only (O\(\log n\)) new nodes

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ update}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ prev}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pos}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{val}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L}\OperatorTok{+}\NormalTok{R}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{\textless{}=}\NormalTok{ mid}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{update}\OperatorTok{(}\NormalTok{prev}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{),}\NormalTok{ prev}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{);}
    \ControlFlowTok{else}
        \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{prev}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ update}\OperatorTok{(}\NormalTok{prev}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Each version = new root; old ones still valid.

\subsubsection{7. Functional Perspective}\label{functional-perspective}

In functional programming, data is immutable by default. Instead of
mutating, you create a new version.

This allows:

\begin{itemize}
\tightlist
\item
  Thread-safety (no races)- Time-travel debugging- Undo/redo systems-
  Concurrency without locks Languages like Haskell, Clojure, and Elm
  build everything this way.
\end{itemize}

For example, Clojure's \texttt{persistent\ vector} uses path copying and
branching factor 32 for (O\(\log_{32} n\)) access.

\subsubsection{8. Applications}\label{applications-2}

\begin{itemize}
\tightlist
\item
  Undo / Redo stacks (text editors, IDEs)- Version control (Git trees)-
  Immutable databases (Datomic)- Segment trees over time (competitive
  programming)- Snapshots in memory allocators or games
\end{itemize}

\subsubsection{9. Complexity}\label{complexity-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2361}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space per Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Persistent Linked List & O(1) & O(1) & O(1) & Simple sharing \\
Persistent Tree & O(log n) & O(log n) & O(log n) & Path copying \\
Persistent Array & O(log n) & O(log n) & O(log n) & Tree-backed \\
Persistent Segment Tree & O(log n) & O(log n) & O(log n) & Versioned
queries \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-28}

Persistent Linked List Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ v0 }\OperatorTok{=}\NormalTok{ NULL}\OperatorTok{;}
\NormalTok{v0 }\OperatorTok{=}\NormalTok{ push}\OperatorTok{(}\NormalTok{v0}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{v0 }\OperatorTok{=}\NormalTok{ push}\OperatorTok{(}\NormalTok{v0}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{Node}\OperatorTok{*}\NormalTok{ v1 }\OperatorTok{=}\NormalTok{ push}\OperatorTok{(}\NormalTok{v0}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\CommentTok{// v0 = [2,3], v1 = [1,2,3]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-28}

Persistence is about time as a first-class citizen. It lets you:

\begin{itemize}
\tightlist
\item
  Roll back- Compare versions- Work immutably and safely It's the
  algorithmic foundation behind functional programming, time-travel
  debugging, and immutable data systems.
\end{itemize}

It teaches this powerful idea:

\begin{quote}
``Never destroy , always build upon what was.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-28}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a persistent stack using linked lists.
\item
  Write a persistent segment tree for range sums.
\item
  Track array versions after each update and query old states.
\item
  Compare space/time with an ephemeral one.
\item
  Explore persistent structures in Clojure (\texttt{conj},
  \texttt{assoc}) or Rust (\texttt{im} crate).
\end{enumerate}

Persistence transforms data from fleeting state into a history you can
navigate , a timeline of structure and meaning.

\subsection{30. Advanced Trees and Range
Queries}\label{advanced-trees-and-range-queries}

So far, you've seen balanced trees (AVL, Red-Black, Treap) and
segment-based structures (Segment Trees, Fenwick Trees). Now it's time
to combine those ideas and step into advanced trees , data structures
that handle dynamic sets, order statistics, intervals, ranges, and
geometry-like queries in logarithmic time.

This chapter is about trees that go beyond search , they store order,
track ranges, and answer complex queries efficiently.

We'll explore:

\begin{itemize}
\tightlist
\item
  Order Statistic Trees (k-th element, rank queries)- Interval Trees
  (range overlaps)- Range Trees (multi-dimensional search)- KD-Trees
  (spatial partitioning)- Merge Sort Trees (offline range queries)
\end{itemize}

\subsubsection{1. Order Statistic Tree}\label{order-statistic-tree}

Goal: find the k-th smallest element, or the rank of an element, in
(O\(\log n\)).

Built on top of a balanced BST (e.g.~Red-Black) by storing subtree
sizes.

\subsubsection{A. Augmented Tree Nodes}\label{a.-augmented-tree-nodes}

Each node keeps:

\begin{itemize}
\tightlist
\item
  \texttt{key}: element value- \texttt{left}, \texttt{right}: children-
  \texttt{size}: number of nodes in subtree
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ size}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Whenever you rotate or insert, update \texttt{size}:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{?}\NormalTok{ n}\OperatorTok{{-}\textgreater{}}\NormalTok{size }\OperatorTok{:} \DecValTok{0}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{void}\NormalTok{ update\_size}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n}\OperatorTok{)}\NormalTok{ n}\OperatorTok{{-}\textgreater{}}\NormalTok{size }\OperatorTok{=}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{+}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Find k-th Element}\label{b.-find-k-th-element}

Recursively use subtree sizes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ kth}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ k}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ left }\OperatorTok{=}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k }\OperatorTok{==}\NormalTok{ left }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textless{}=}\NormalTok{ left}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ kth}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ k}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{return}\NormalTok{ kth}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ k }\OperatorTok{{-}}\NormalTok{ left }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: (O\(\log n\))

\subsubsection{C. Find Rank}\label{c.-find-rank}

Find position of a key (number of smaller elements):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ rank}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ rank}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{+} \DecValTok{1} \OperatorTok{+}\NormalTok{ rank}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Used in:

\begin{itemize}
\tightlist
\item
  Databases (ORDER BY, pagination)- Quantile queries- Online median
  maintenance
\end{itemize}

\subsubsection{2. Interval Tree}\label{interval-tree}

Goal: find all intervals overlapping with a given point or range.

Used in computational geometry, scheduling, and genomic data.

\subsubsection{A. Structure}\label{a.-structure-1}

BST ordered by interval low endpoint. Each node stores:

\begin{itemize}
\tightlist
\item
  \texttt{low}, \texttt{high}: interval bounds- \texttt{max}: maximum
  \texttt{high} in its subtree
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ max}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Query Overlap}\label{b.-query-overlap}

Check if \texttt{x} overlaps \texttt{node-\textgreater{}interval}: If
not, go left or right based on \texttt{max} values.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ overlap}\OperatorTok{(}\NormalTok{Interval a}\OperatorTok{,}\NormalTok{ Interval b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{.}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ b}\OperatorTok{.}\NormalTok{high }\OperatorTok{\&\&}\NormalTok{ b}\OperatorTok{.}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ a}\OperatorTok{.}\NormalTok{high}\OperatorTok{;}
\OperatorTok{\}}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,}\NormalTok{ Interval q}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ NULL}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{overlap}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{interval}\OperatorTok{,}\NormalTok{ q}\OperatorTok{))} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{\&\&}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{max }\OperatorTok{\textgreater{}=}\NormalTok{ q}\OperatorTok{.}\NormalTok{low}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: (O\(\log n\)) average

\subsubsection{C. Use Cases}\label{c.-use-cases}

\begin{itemize}
\tightlist
\item
  Calendar/schedule conflict detection- Collision detection- Genome
  region lookup- Segment intersection
\end{itemize}

\subsubsection{3. Range Tree}\label{range-tree}

Goal: multi-dimensional queries like

\begin{quote}
``How many points fall inside rectangle {[}x1, x2{]} × {[}y1, y2{]}?''
\end{quote}

Structure:

\begin{itemize}
\tightlist
\item
  Primary BST on x- Each node stores secondary BST on y Query time:
  (O\(\log^2 n\)) Space: (O\(n \log n\))
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  2D search- Computational geometry- Databases (spatial joins)
\end{itemize}

\subsubsection{4. KD-Tree}\label{kd-tree}

Goal: efficiently search points in k-dimensional space.

Alternate splitting dimensions at each level:

\begin{itemize}
\item
  Level 0 → split by x- Level 1 → split by y- Level 2 → split by z Each
  node stores:
\item
  Point (vector)- Split axis Used for:
\item
  Nearest neighbor search- Range queries- ML (k-NN classifiers) Time:
\item
  Build: (O\(n \log n\))- Query: (O\(\sqrt{n}\)) average in 2D
\end{itemize}

\subsubsection{5. Merge Sort Tree}\label{merge-sort-tree}

Goal: query ``number of elements ≤ k in range {[}L, R{]}''

Built like a segment tree, but each node stores a sorted list of its
range.

Build: merge children lists Query: binary search in node lists

Time:

\begin{itemize}
\tightlist
\item
  Build: (O\(n \log n\))- Query: (O\(\log^2 n\)) Used in offline queries
  and order-statistics over ranges.
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-14}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1733}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3467}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tree Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Query
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Order Statistic & k-th, rank & O(log n) & O(log n) & Augmented BST \\
Interval & Overlaps & O(log n + k) & O(log n) & Store intervals \\
Range Tree & 2D range & O(log² n + k) & O(log² n) & Multi-dim \\
KD-Tree & Spatial & O(√n) avg & O(log n) & Nearest neighbor \\
Merge Sort Tree & Offline rank & O(log² n) & Static & Built from sorted
segments \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-29}

Order Statistic Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ root }\OperatorTok{=}\NormalTok{ NULL}\OperatorTok{;}
\NormalTok{root }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{10}\OperatorTok{);}
\NormalTok{root }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{20}\OperatorTok{);}
\NormalTok{root }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{30}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ kth}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{2}\OperatorTok{){-}\textgreater{}}\NormalTok{key}\OperatorTok{);} \CommentTok{// 20}
\end{Highlighting}
\end{Shaded}

Interval Query:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Interval q }\OperatorTok{=} \OperatorTok{\{}\DecValTok{15}\OperatorTok{,} \DecValTok{17}\OperatorTok{\};}
\NormalTok{Node}\OperatorTok{*}\NormalTok{ res }\OperatorTok{=}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{root}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{res}\OperatorTok{)}\NormalTok{ printf}\OperatorTok{(}\StringTok{"Overlap: [}\SpecialCharTok{\%d}\StringTok{, }\SpecialCharTok{\%d}\StringTok{]}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ res}\OperatorTok{{-}\textgreater{}}\NormalTok{low}\OperatorTok{,}\NormalTok{ res}\OperatorTok{{-}\textgreater{}}\NormalTok{high}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-29}

These trees extend balance into dimensions and ranges. They let you
query ordered data efficiently: ``How many?'', ``Which overlaps?'',
``Where is k-th smallest?''.

They teach a deeper design principle:

\begin{quote}
``Augment structure with knowledge , balance plus metadata equals
power.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-29}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement an order statistic tree , test rank/k-th queries.
\item
  Insert intervals and test overlap detection.
\item
  Build a simple KD-tree for 2D points.
\item
  Solve rectangle counting with a range tree.
\item
  Precompute a merge sort tree for offline queries.
\end{enumerate}

These advanced trees form the final evolution of structured queries ,
blending geometry, order, and logarithmic precision.

\section{Chapter 4. Graph
Algorithms}\label{chapter-4.-graph-algorithms-1}

\subsection{31. Traversals (DFS, BFS, Iterative
Deepening)}\label{traversals-dfs-bfs-iterative-deepening}

Graphs are everywhere , maps, networks, dependencies, state spaces.
Before you can analyze them, you need a way to visit their vertices ,
systematically, without getting lost or looping forever.

That's where graph traversals come in. They're the foundation for
everything that follows: connected components, shortest paths, spanning
trees, topological sorts, and more.

This section walks through the three pillars:

\begin{itemize}
\tightlist
\item
  DFS (Depth-First Search) , explore deeply before backtracking- BFS
  (Breadth-First Search) , explore level by level- Iterative Deepening ,
  a memory-friendly hybrid
\end{itemize}

\subsubsection{1. Representing Graphs}\label{representing-graphs}

Before traversal, you need a good structure.

Adjacency List (most common):

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define MAX }\DecValTok{1000}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

Add edges:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ add\_edge}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{    adj}\OperatorTok{[}\NormalTok{v}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);} \CommentTok{// omit if directed}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Track visited vertices:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ visited}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Depth-First Search
(DFS)}\label{depth-first-search-dfs}

DFS dives deep, following one branch fully before exploring others. It's
recursive, like exploring a maze by always turning left until you hit a
wall.

\subsubsection{A. Recursive Form}\label{a.-recursive-form}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Start it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfs}\OperatorTok{(}\NormalTok{start\_node}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Iterative Form (with
Stack)}\label{b.-iterative-form-with-stack}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs\_iter}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    stack}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ s}\OperatorTok{;}
\NormalTok{    s}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{start}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{s}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ s}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ s}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ s}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Complexity}\label{c.-complexity-3}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Graph Type & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adjacency List & O(V + E) & O(V) \\
\end{longtable}

DFS is used in:

\begin{itemize}
\tightlist
\item
  Connected components- Cycle detection- Topological sort- Backtracking
  \& search- Articulation points / bridges
\end{itemize}

\subsubsection{3. Breadth-First Search
(BFS)}\label{breadth-first-search-bfs}

BFS explores neighbors first , it's like expanding in waves. This
guarantees shortest path in unweighted graphs.

\subsubsection{A. BFS with Queue}\label{a.-bfs-with-queue}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{start}\OperatorTok{);}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Track Distance}\label{b.-track-distance}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{void}\NormalTok{ bfs\_dist}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ MAX}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Now \texttt{dist{[}v{]}} gives shortest distance from \texttt{s}.

\subsubsection{C. Complexity}\label{c.-complexity-4}

Same as DFS:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
O(V + E) & O(V) \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Shortest paths (unweighted)- Level-order traversal- Bipartite check-
  Connected components
\end{itemize}

\subsubsection{4. Iterative Deepening Search
(IDS)}\label{iterative-deepening-search-ids}

DFS is memory-light but might go too deep. BFS is optimal but can use a
lot of memory. Iterative Deepening Search (IDS) combines both.

It performs DFS with increasing depth limits:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ dls}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ depth}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ target}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{depth }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dls}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ target}\OperatorTok{,}\NormalTok{ depth }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{))} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ ids}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ max\_depth}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ max\_depth}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dls}\OperatorTok{(}\NormalTok{start}\OperatorTok{,}\NormalTok{ target}\OperatorTok{,}\NormalTok{ d}\OperatorTok{))} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Used in:

\begin{itemize}
\tightlist
\item
  AI search problems (state spaces)- Game trees (chess, puzzles)
\end{itemize}

\subsubsection{5. Traversal Order
Examples}\label{traversal-order-examples}

For a graph:

\begin{verbatim}
1 - 2 - 3
|   |
4 - 5
\end{verbatim}

DFS (starting at 1): 1 → 2 → 3 → 5 → 4 BFS (starting at 1): 1 → 2 → 4 →
3 → 5

\subsubsection{6. Directed vs Undirected}\label{directed-vs-undirected}

\begin{itemize}
\item
  Undirected: mark both directions- Directed: follow edge direction only
  DFS on directed graphs is core to:
\item
  SCC (Strongly Connected Components)- Topological Sorting- Reachability
  analysis
\end{itemize}

\subsubsection{7. Traversal Trees}\label{traversal-trees}

Each traversal implicitly builds a spanning tree:

\begin{itemize}
\item
  DFS Tree: based on recursion- BFS Tree: based on levels Use them to:
\item
  Detect cross edges, back edges- Classify edges (important for
  algorithms like Tarjan's)
\end{itemize}

\subsubsection{8. Comparison}\label{comparison-15}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3714}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
DFS
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
BFS
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strategy & Deep first & Level-wise \\
Space & O(V) (stack) & O(V) (queue) \\
Path Optimality & Not guaranteed & Yes (unweighted) \\
Applications & Cycle detection, backtracking & Shortest path, level
order \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-30}

DFS + BFS Combo:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ traverse}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ visited}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
\NormalTok{    dfs}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ visited}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
\NormalTok{    bfs}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-30}

DFS and BFS are the roots of graph theory in practice. Every algorithm
you'll meet later , shortest paths, flows, SCCs , builds upon them.

They teach you how to navigate structure, how to systematically explore
unknowns, and how search lies at the heart of computation.

\subsubsection{Try It Yourself}\label{try-it-yourself-30}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build an adjacency list and run DFS/BFS from vertex 1.
\item
  Track discovery and finish times in DFS.
\item
  Use BFS to compute shortest paths in an unweighted graph.
\item
  Modify DFS to count connected components.
\item
  Implement IDS for a puzzle like the 8-puzzle.
\end{enumerate}

Graph traversal is the art of exploration , once you master it, the rest
of graph theory falls into place.

\subsection{32. Strongly Connected Components (Tarjan,
Kosaraju)}\label{strongly-connected-components-tarjan-kosaraju}

In directed graphs, edges have direction, so connectivity gets tricky.
It's not enough for vertices to be reachable , you need mutual
reachability.

That's the essence of a strongly connected component (SCC):

\begin{quote}
A set of vertices where every vertex can reach every other vertex.
\end{quote}

Think of SCCs as islands of mutual connectivity , inside, you can go
anywhere; outside, you can't. They're the building blocks for
simplifying directed graphs into condensation DAGs (no cycles).

We'll explore two classic algorithms:

\begin{itemize}
\tightlist
\item
  Kosaraju's Algorithm , clean, intuitive, two-pass- Tarjan's Algorithm
  , one-pass, stack-based elegance
\end{itemize}

\subsubsection{1. Definition}\label{definition}

A Strongly Connected Component (SCC) in a directed graph ( G = (V, E) )
is a maximal subset of vertices \(C \subseteq V\) such that for every
pair ( (u, v) \in C ): \(u \to v\) and \(v \to u\).

In other words, every node in (C) is reachable from every other node in
(C).

Example:

\begin{verbatim}
1 → 2 → 3 → 1   forms an SCC  
4 → 5           separate SCCs
\end{verbatim}

\subsubsection{2. Applications}\label{applications-3}

\begin{itemize}
\tightlist
\item
  Condensation DAG: compress SCCs into single nodes , no cycles remain.-
  Component-based reasoning: topological sorting on DAG of SCCs.-
  Program analysis: detecting cycles, dependencies.- Web graphs: find
  clusters of mutually linked pages.- Control-flow: loops and strongly
  connected subroutines.
\end{itemize}

\subsubsection{3. Kosaraju's Algorithm}\label{kosarajus-algorithm}

A simple two-pass algorithm using DFS and graph reversal.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run DFS and push nodes onto a stack in finish-time order.
\item
  Reverse the graph (edges flipped).
\item
  Pop nodes from stack; DFS on reversed graph; each DFS = one SCC.
\end{enumerate}

\subsubsection{A. Implementation}\label{a.-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ rev}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ visited}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{stack}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ st}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ sccs}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ dfs1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            dfs1}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{    st}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ dfs2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ comp}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{    comp}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ rev}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            dfs2}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ comp}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ kosaraju}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \CommentTok{// Pass 1: order by finish time}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ dfs1}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}

    \CommentTok{// Reverse graph}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{            rev}\OperatorTok{[}\NormalTok{v}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}

    \CommentTok{// Pass 2: collect SCCs}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{visited}\OperatorTok{,}\NormalTok{ visited }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{st}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ st}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ st}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ comp}\OperatorTok{;}
\NormalTok{            dfs2}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ comp}\OperatorTok{);}
\NormalTok{            sccs}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{comp}\OperatorTok{);}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: (O(V + E)) , two DFS passes.

Space Complexity: (O(V + E))

\subsubsection{B. Example}\label{b.-example-1}

Graph:

\begin{verbatim}
1 → 2 → 3  
↑   ↓   ↓  
5 ← 4 ← 6
\end{verbatim}

SCCs:

\begin{itemize}
\tightlist
\item
  \{1,2,4,5\}- \{3,6\}
\end{itemize}

\subsubsection{4. Tarjan's Algorithm}\label{tarjans-algorithm}

More elegant: one DFS pass, no reversal, stack-based. It uses discovery
times and low-link values to detect SCC roots.

\subsubsection{A. Idea}\label{a.-idea-3}

\begin{itemize}
\tightlist
\item
  \texttt{disc{[}u{]}}: discovery time of node \texttt{u}-
  \texttt{low{[}u{]}}: smallest discovery time reachable from
  \texttt{u}- A node is root of an SCC if
  \texttt{disc{[}u{]}\ ==\ low{[}u{]}} Maintain a stack of active nodes
  (in current DFS path).
\end{itemize}

\subsubsection{B. Implementation}\label{b.-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ disc}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ low}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ timer}\OperatorTok{;}
\DataTypeTok{bool}\NormalTok{ inStack}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{stack}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ st}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ sccs}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ dfs\_tarjan}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    disc}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \OperatorTok{++}\NormalTok{timer}\OperatorTok{;}
\NormalTok{    st}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
\NormalTok{    inStack}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{disc}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dfs\_tarjan}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{            low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
        \OperatorTok{\}} \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{inStack}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ disc}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{disc}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{==}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ comp}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ st}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ st}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{            inStack}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
\NormalTok{            comp}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ u}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
        \OperatorTok{\}}
\NormalTok{        sccs}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{comp}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ tarjan}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{disc}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{            dfs\_tarjan}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: (O(V + E))

Space Complexity: (O(V))

\subsubsection{C. Walkthrough}\label{c.-walkthrough}

Graph:

\begin{verbatim}
1 → 2 → 3  
↑   ↓   ↓  
5 ← 4 ← 6
\end{verbatim}

DFS visits nodes in order; when it finds a node whose
\texttt{disc\ ==\ low}, it pops from the stack to form an SCC.

Result:

\begin{verbatim}
SCC1: 1 2 4 5
SCC2: 3 6
\end{verbatim}

\subsubsection{5. Comparison}\label{comparison-16}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Kosaraju & Tarjan \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS Passes & 2 & 1 \\
Reversal Needed & Yes & No \\
Stack & Yes (finish order) & Yes (active path) \\
Implementation & Simple conceptually & Compact, efficient \\
Time & O(V + E) & O(V + E) \\
\end{longtable}

\subsubsection{6. Condensation Graph}\label{condensation-graph}

Once SCCs are found, you can build a DAG: Each SCC becomes a node, edges
represent cross-SCC connections. Topological sorting now applies.

Used in:

\begin{itemize}
\tightlist
\item
  Dependency analysis- Strong component compression- DAG dynamic
  programming
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-31}

Print SCCs (Tarjan):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tarjan}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{\&}\NormalTok{comp }\OperatorTok{:}\NormalTok{ sccs}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ x }\OperatorTok{:}\NormalTok{ comp}\OperatorTok{)}\NormalTok{ printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-31}

SCC algorithms turn chaotic directed graphs into structured DAGs.
They're the key to reasoning about cycles, dependencies, and modularity.

Understanding them reveals a powerful truth:

\begin{quote}
``Every complex graph can be reduced to a simple hierarchy , once you
find its strongly connected core.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-31}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement both Kosaraju and Tarjan , verify they match.
\item
  Build SCC DAG and run topological sort on it.
\item
  Detect cycles via SCC size \textgreater{} 1.
\item
  Use SCCs to solve 2-SAT (boolean satisfiability).
\item
  Visualize condensation of a graph with 6 nodes.
\end{enumerate}

Once you can find SCCs, you can tame directionality , transforming messy
networks into ordered systems.

\subsection{33. Shortest Paths (Dijkstra, Bellman-Ford, A*,
Johnson)}\label{shortest-paths-dijkstra-bellman-ford-a-johnson}

Once you can traverse a graph, the next natural question is:

\begin{quote}
``What is the shortest path between two vertices?''
\end{quote}

Shortest path algorithms are the heart of routing, navigation, planning,
and optimization. They compute minimal cost paths , whether distance,
time, or weight , and adapt to different edge conditions (non-negative,
negative, heuristic).

This section covers the most essential algorithms:

\begin{itemize}
\tightlist
\item
  Dijkstra's Algorithm , efficient for non-negative weights-
  Bellman-Ford Algorithm , handles negative edges- A* , best-first with
  heuristics- Johnson's Algorithm , all-pairs shortest paths in sparse
  graphs
\end{itemize}

\subsubsection{1. The Shortest Path
Problem}\label{the-shortest-path-problem}

Given a weighted graph ( G = (V, E) ) and a source ( s ), find
\(\text{dist}[v]\), the minimum total weight to reach every vertex ( v
).

Variants:

\begin{itemize}
\tightlist
\item
  Single-source shortest path (SSSP) , one source to all- Single-pair ,
  one source to one target- All-pairs shortest path (APSP) , every pair-
  Dynamic shortest path , with updates
\end{itemize}

\subsubsection{2. Dijkstra's Algorithm}\label{dijkstras-algorithm}

Best for non-negative weights. Idea: explore vertices in increasing
distance order, like water spreading.

\subsubsection{A. Steps}\label{a.-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize all distances to infinity.
\item
  Set source distance = 0.
\item
  Use a priority queue to always pick the node with smallest tentative
  distance.
\item
  Relax all outgoing edges.
\end{enumerate}

\subsubsection{B. Implementation (Adjacency
List)}\label{b.-implementation-adjacency-list}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}bits/stdc++.h\textgreater{}}
\NormalTok{using namespace std}\OperatorTok{;}

\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];} \CommentTok{// (neighbor, weight)}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ dijkstra}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{},}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\DecValTok{0}\OperatorTok{,}\NormalTok{ s}\OperatorTok{\});}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{d}\OperatorTok{,}\NormalTok{ u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{d }\OperatorTok{!=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
\NormalTok{                pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ v}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Using priority queue (binary heap): \(O((V + E)\log V)\)
\item
  Space: \(O(V + E)\)
\end{itemize}

\subsubsection{C. Example}\label{c.-example}

Graph:

\begin{verbatim}
1 →(2) 2 →(3) 3
↓(4)       ↑(1)
4 →(2)─────┘
\end{verbatim}

\texttt{dijkstra(1)} gives shortest distances:

\begin{verbatim}
dist[1] = 0  
dist[2] = 2  
dist[3] = 5  
dist[4] = 4
\end{verbatim}

\subsubsection{D. Properties}\label{d.-properties}

\begin{itemize}
\tightlist
\item
  Works only if all edges \(w \ge 0\)- Can reconstruct path via
  \texttt{parent{[}v{]}}- Used in:

  \begin{itemize}
  \tightlist
  \item
    GPS and routing systems - Network optimization - Scheduling with
    positive costs
  \end{itemize}
\end{itemize}

\subsubsection{3. Bellman-Ford Algorithm}\label{bellman-ford-algorithm}

Handles negative edge weights, and detects negative cycles.

\subsubsection{A. Idea}\label{a.-idea-4}

Relax all edges (V-1) times. If on (V)-th iteration you can still relax
→ negative cycle exists.

\subsubsection{B. Implementation}\label{b.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Edge }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ edges}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{bool}\NormalTok{ bellman\_ford}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto}\NormalTok{ e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ e}\OperatorTok{.}\NormalTok{w }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{])}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ e}\OperatorTok{.}\NormalTok{w}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \CommentTok{// Check for negative cycle}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto}\NormalTok{ e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ e}\OperatorTok{.}\NormalTok{w }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{])}
            \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;} \CommentTok{// negative cycle}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O(VE)) Works even when (w \textless{} 0).

\subsubsection{C. Example}\label{c.-example-1}

Graph:

\begin{verbatim}
1 →(2) 2 →(-5) 3 →(2) 4
\end{verbatim}

Bellman-Ford finds path 1→2→3→4 with total cost (-1).

If a cycle reduces total weight indefinitely, algorithm detects it.

\subsubsection{D. Use Cases}\label{d.-use-cases}

\begin{itemize}
\tightlist
\item
  Currency exchange arbitrage- Game graphs with penalties- Detecting
  impossible constraints
\end{itemize}

\subsubsection{4. A* Search Algorithm}\label{a-search-algorithm}

Heuristic-guided shortest path, perfect for pathfinding (AI, maps,
games).

It combines actual cost and estimated cost: \[
f(v) = g(v) + h(v)
\] where

\begin{itemize}
\tightlist
\item
  (g(v)): known cost so far- (h(v)): heuristic estimate (must be
  admissible)
\end{itemize}

\subsubsection{A. Pseudocode}\label{a.-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{},}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{h}\OperatorTok{[}\NormalTok{start}\OperatorTok{],}\NormalTok{ start}\OperatorTok{\});}

\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
    \KeywordTok{auto} \OperatorTok{[}\NormalTok{f}\OperatorTok{,}\NormalTok{ u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ goal}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ new\_g }\OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{new\_g }\OperatorTok{\textless{}}\NormalTok{ g}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            g}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ new\_g}\OperatorTok{;}
\NormalTok{            pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{g}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+}\NormalTok{ h}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ v}\OperatorTok{\});}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Heuristic Example:

\begin{itemize}
\tightlist
\item
  Euclidean distance (for grids)- Manhattan distance (for 4-direction
  movement)
\end{itemize}

\subsubsection{B. Use Cases}\label{b.-use-cases}

\begin{itemize}
\tightlist
\item
  Game AI (pathfinding)- Robot motion planning- Map navigation
  Complexity: (O(E)) in best case, depends on heuristic quality.
\end{itemize}

\subsubsection{5. Johnson's Algorithm}\label{johnsons-algorithm}

Goal: All-Pairs Shortest Path in sparse graphs with negative edges (no
negative cycles).

Idea:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add new vertex \texttt{q} connected to all others with edge weight 0
\item
  Run Bellman-Ford from \texttt{q} to get potential \texttt{h(v)}
\item
  Reweight edges: (w'(u, v) = w(u, v) + h(u) - h(v)) (now all weights ≥
  0)
\item
  Run Dijkstra from each vertex
\end{enumerate}

Complexity: (O\(VE + V^2 \log V\))

\subsubsection{6. Summary}\label{summary-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2353}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2157}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1961}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handles Negative Weights
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Detects Negative Cycle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Heuristic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Dijkstra & No & No & No & O((V+E) log V) & Non-negative weights \\
Bellman-Ford & Yes & Yes & No & O(VE) & Negative edges \\
A* & No (unless careful) & No & Yes & Depends & Pathfinding \\
Johnson & Yes (no neg. cycles) & Yes & No & O(VE + V log V) & All-pairs,
sparse \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-32}

Dijkstra Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dijkstra}\OperatorTok{(}\NormalTok{n}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"dist[}\SpecialCharTok{\%d}\StringTok{] = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-32}

Shortest paths are the essence of optimization , not just in graphs, but
in reasoning: finding minimal cost, minimal distance, minimal risk.

These algorithms teach:

\begin{quote}
``The path to a goal isn't random , it's guided by structure, weight,
and knowledge.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-32}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a weighted graph and compare Dijkstra vs Bellman-Ford.
\item
  Introduce a negative edge and observe Bellman-Ford detecting it.
\item
  Implement A* on a grid with obstacles.
\item
  Use Dijkstra to plan routes in a city map dataset.
\item
  Try Johnson's algorithm for all-pairs shortest paths.
\end{enumerate}

Master these, and you master direction + cost = intelligence in motion.

\subsection{34. Shortest Path Variants (0-1 BFS, Bidirectional,
Heuristic
A*)}\label{shortest-path-variants-0-1-bfs-bidirectional-heuristic-a}

Sometimes the classic shortest path algorithms aren't enough. You might
have special edge weights (only 0 or 1), a need for faster searches, or
extra structure you can exploit.

That's where shortest path variants come in , they're optimized
adaptations of the big three (BFS, Dijkstra, A*) for specific scenarios.

In this section, we'll explore:

\begin{itemize}
\tightlist
\item
  0-1 BFS → when edge weights are only 0 or 1- Bidirectional Search →
  meet-in-the-middle for speed- Heuristic A* → smarter exploration
  guided by estimates Each shows how structure in your problem can yield
  speed-ups.
\end{itemize}

\subsubsection{1. 0-1 BFS}\label{bfs}

If all edge weights are either 0 or 1, you don't need a priority queue.
A deque (double-ended queue) is enough for (O(V + E)) time.

Why? Because edges with weight 0 should be processed immediately, while
edges with weight 1 can wait one step longer.

\subsubsection{A. Algorithm}\label{a.-algorithm}

Use a deque.

\begin{itemize}
\tightlist
\item
  When relaxing an edge with weight 0, push to front.- When relaxing an
  edge with weight 1, push to back.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];} \CommentTok{// (v, w)}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ zero\_one\_bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{    deque}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ dq}\OperatorTok{;}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    dq}\OperatorTok{.}\NormalTok{push\_front}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{dq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ dq}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ dq}\OperatorTok{.}\NormalTok{pop\_front}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{w }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dq}\OperatorTok{.}\NormalTok{push\_front}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
                \ControlFlowTok{else}\NormalTok{ dq}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Example}\label{b.-example-2}

Graph:

\begin{verbatim}
1 -0-> 2 -1-> 3  
|              ^  
1              |  
+--------------+
\end{verbatim}

Shortest path from 1 to 3 = 1 (via edge 1-2-3). Deque ensures weight-0
edges don't get delayed.

\subsubsection{C. Complexity}\label{c.-complexity-5}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
O(V + E) & O(V) & Optimal for binary weights \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Layered BFS- Grid problems with binary costs- BFS with teleportation
  (weight 0 edges)
\end{itemize}

\subsubsection{2. Bidirectional Search}\label{bidirectional-search}

Sometimes you just need one path , from source to target , in an
unweighted graph. Instead of expanding from one side, expand from both
ends and stop when they meet.

This reduces search depth from (O\(b^d\)) to (O\(b^{d/2}\)) (huge gain
for large graphs).

\subsubsection{A. Idea}\label{a.-idea-5}

Run BFS from both source and target simultaneously. When their frontiers
intersect, you've found the shortest path.

\subsubsection{B. Implementation}\label{b.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ visited\_from\_s}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ visited\_from\_t}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ qs}\OperatorTok{,}\NormalTok{ qt}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ bidirectional\_bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    qs}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}\NormalTok{ visited\_from\_s}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{    qt}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{t}\OperatorTok{);}\NormalTok{ visited\_from\_t}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{qs}\OperatorTok{.}\NormalTok{empty}\OperatorTok{()} \OperatorTok{\&\&} \OperatorTok{!}\NormalTok{qt}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{step}\OperatorTok{(}\NormalTok{qs}\OperatorTok{,}\NormalTok{ visited\_from\_s}\OperatorTok{,}\NormalTok{ visited\_from\_t}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{step}\OperatorTok{(}\NormalTok{qt}\OperatorTok{,}\NormalTok{ visited\_from\_t}\OperatorTok{,}\NormalTok{ visited\_from\_s}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ step}\OperatorTok{(}\NormalTok{queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ q}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ vis}\OperatorTok{[],} \DataTypeTok{bool}\NormalTok{ other}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ size }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{size}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{other}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{vis}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                vis}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Complexity}\label{c.-complexity-6}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
O\(b^{d/2}\) & O\(b^{d/2}\) & Doubly fast in practice \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Maze solvers- Shortest paths in large sparse graphs- Social network
  ``degrees of separation''
\end{itemize}

\subsubsection{3. Heuristic A* (Revisited)}\label{heuristic-a-revisited}

A* generalizes Dijkstra with goal-directed search using heuristics. We
revisit it here to show how heuristics change exploration order.

\subsubsection{A. Cost Function}\label{a.-cost-function}

\[
f(v) = g(v) + h(v)
\]

\begin{itemize}
\tightlist
\item
  (g(v)): cost so far- (h(v)): estimated cost to goal- (h(v)) must be
  admissible ((h(v) \le \text{true cost}))
\end{itemize}

\subsubsection{B. Implementation}\label{b.-implementation-3}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ v}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ f}\OperatorTok{,}\NormalTok{ g}\OperatorTok{;}
    \DataTypeTok{bool}\NormalTok{ operator}\OperatorTok{\textgreater{}(}\DataTypeTok{const}\NormalTok{ Node}\OperatorTok{\&}\NormalTok{ o}\OperatorTok{)} \DataTypeTok{const} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ f }\OperatorTok{\textgreater{}}\NormalTok{ o}\OperatorTok{.}\NormalTok{f}\OperatorTok{;} \OperatorTok{\}}
\OperatorTok{\};}

\NormalTok{priority\_queue}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ astar}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ goal}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    h}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{start}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{start}\OperatorTok{,}\NormalTok{ g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{+}\NormalTok{ h}\OperatorTok{[}\NormalTok{start}\OperatorTok{],}\NormalTok{ g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]\});}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{u}\OperatorTok{,}\NormalTok{ f\_u}\OperatorTok{,}\NormalTok{ g\_u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ goal}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ new\_g }\OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{new\_g }\OperatorTok{\textless{}}\NormalTok{ g}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                g}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ new\_g}\OperatorTok{;}
                \DataTypeTok{int}\NormalTok{ f\_v }\OperatorTok{=}\NormalTok{ new\_g }\OperatorTok{+}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\NormalTok{                pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{v}\OperatorTok{,}\NormalTok{ f\_v}\OperatorTok{,}\NormalTok{ new\_g}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example Heuristics}\label{c.-example-heuristics}

\begin{itemize}
\tightlist
\item
  Grid map: Manhattan distance (h(x, y) = \textbar x - x\_g\textbar{} +
  \textbar y - y\_g\textbar)
\item
  Navigation: straight-line (Euclidean)- Game tree: evaluation function
\end{itemize}

\subsubsection{D. Performance}\label{d.-performance}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Heuristic & Effect \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect (h = true cost) & Optimal, visits minimal nodes \\
Admissible but weak & Still correct, more nodes \\
Overestimate & May fail (non-admissible) \\
\end{longtable}

\subsubsection{4. Comparison}\label{comparison-17}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1875}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weight Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0-1 BFS & 0 or 1 & Deque-based & O(V+E) & O(V) & No heap \\
Bidirectional BFS & Unweighted & Two-way search & O\(b^{d/2}\) &
O\(b^{d/2}\) & Meets in middle \\
A* & Non-negative & Heuristic search & Depends & O(V) & Guided \\
\end{longtable}

\subsubsection{5. Example Scenario}\label{example-scenario}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4091}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Grid with teleport (cost 0) & 0-1 BFS \\
Huge social graph (find shortest chain) & Bidirectional BFS \\
Game AI pathfinding & A* with Manhattan heuristic \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-33}

0-1 BFS Quick Demo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\NormalTok{zero\_one\_bfs}\OperatorTok{(}\DecValTok{3}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{[}\DecValTok{3}\OperatorTok{]);} \CommentTok{// shortest = 1}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-33}

Special cases deserve special tools. These variants show that
understanding structure (like edge weights or symmetry) can yield huge
gains.

They embody a principle:

\begin{quote}
``Don't just run faster , run smarter, guided by what you know.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-33}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement 0-1 BFS for a grid with cost 0 teleports.
\item
  Compare BFS vs Bidirectional BFS on a large maze.
\item
  Write A* for an 8x8 chessboard knight's move puzzle.
\item
  Tune heuristics , see how overestimating breaks A*.
\item
  Combine A* and 0-1 BFS for hybrid search.
\end{enumerate}

With these in hand, you can bend shortest path search to the shape of
your problem , efficient, elegant, and exact.

\subsection{35. Minimum Spanning Trees (Kruskal, Prim,
Borůvka)}\label{minimum-spanning-trees-kruskal-prim-borux16fvka}

When a graph connects multiple points with weighted edges, sometimes you
don't want the \emph{shortest path}, but the \emph{cheapest network}
that connects everything.

That's the Minimum Spanning Tree (MST) problem:

\begin{quote}
Given a connected, weighted, undirected graph, find a subset of edges
that connects all vertices with minimum total weight and no cycles.
\end{quote}

MSTs are everywhere , from building networks and designing circuits to
clustering and approximation algorithms.

Three cornerstone algorithms solve it beautifully:

\begin{itemize}
\tightlist
\item
  Kruskal's , edge-based, union-find- Prim's , vertex-based, greedy
  expansion- Borůvka's , component merging in parallel
\end{itemize}

\subsubsection{1. What Is a Spanning
Tree?}\label{what-is-a-spanning-tree}

A spanning tree connects all vertices with exactly (V-1) edges. Among
all spanning trees, the one with minimum total weight is the MST.

Properties:

\begin{itemize}
\tightlist
\item
  Contains no cycles- Connects all vertices- Edge count = (V - 1)-
  Unique if all weights distinct
\end{itemize}

\subsubsection{2. MST Applications}\label{mst-applications}

\begin{itemize}
\tightlist
\item
  Network design (roads, cables, pipelines)- Clustering (e.g.,
  hierarchical clustering)- Image segmentation- Approximation (e.g., TSP
  \textasciitilde{} 2 × MST)- Graph simplification
\end{itemize}

\subsubsection{3. Kruskal's Algorithm}\label{kruskals-algorithm}

Build the MST edge-by-edge, in order of increasing weight. Use
Union-Find (Disjoint Set Union) to avoid cycles.

\subsubsection{A. Steps}\label{a.-steps-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Sort all edges by weight.
\item
  Initialize each vertex as its own component.
\item
  For each edge (u, v):

  \begin{itemize}
  \tightlist
  \item
    If \texttt{u} and \texttt{v} are in different components → include
    edge - Union their sets Stop when (V-1) edges chosen.
  \end{itemize}
\end{enumerate}

\subsubsection{B. Implementation}\label{b.-implementation-4}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Edge }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ edges}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{==}\NormalTok{ x }\OperatorTok{?}\NormalTok{ x }\OperatorTok{:}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]);}
\OperatorTok{\}}
\DataTypeTok{bool}\NormalTok{ unite}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}\NormalTok{ b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{==}\NormalTok{ b}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank\_}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank\_}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{==}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{a}\OperatorTok{]++;}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ kruskal}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    iota}\OperatorTok{(}\NormalTok{parent}\OperatorTok{,}\NormalTok{ parent }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\NormalTok{    sort}\OperatorTok{(}\NormalTok{edges}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ edges}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \OperatorTok{[](}\NormalTok{Edge a}\OperatorTok{,}\NormalTok{ Edge b}\OperatorTok{)\{} \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{.}\NormalTok{w }\OperatorTok{\textless{}}\NormalTok{ b}\OperatorTok{.}\NormalTok{w}\OperatorTok{;} \OperatorTok{\});}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{\&}\NormalTok{e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{unite}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))}
\NormalTok{            total }\OperatorTok{+=}\NormalTok{ e}\OperatorTok{.}\NormalTok{w}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Sorting edges: (O\(E \log E\))- Union-Find operations: (O(\alpha(V)))
  (almost constant)- Total: (O\(E \log E\))
\end{itemize}

\subsubsection{C. Example}\label{c.-example-2}

Graph:

\begin{verbatim}
1 -4- 2  
|     |  
2     3  
 \-1-/
\end{verbatim}

Edges sorted: (1-3,1), (1-2,4), (2-3,3)

Pick 1-3, 2-3 → MST weight = 1 + 3 = 4

\subsubsection{4. Prim's Algorithm}\label{prims-algorithm}

Grow MST from a starting vertex, adding the smallest outgoing edge each
step.

Similar to Dijkstra , but pick edges, not distances.

\subsubsection{A. Steps}\label{a.-steps-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with one vertex, mark as visited.
\item
  Use priority queue for candidate edges.
\item
  Pick smallest edge that connects to an unvisited vertex.
\item
  Add vertex to MST, repeat until all visited.
\end{enumerate}

\subsubsection{B. Implementation}\label{b.-implementation-5}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];} \CommentTok{// (v, w)}
\DataTypeTok{bool}\NormalTok{ used}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ prim}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{},}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\DecValTok{0}\OperatorTok{,}\NormalTok{ start}\OperatorTok{\});}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{w}\OperatorTok{,}\NormalTok{ u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        used}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ w}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w2}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{used}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}\NormalTok{ pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{w2}\OperatorTok{,}\NormalTok{ v}\OperatorTok{\});}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  \(O((V+E) \log V)\) with binary heap
\end{itemize}

Used when:

\begin{itemize}
\tightlist
\item
  Graph is dense
\item
  Easier to grow tree than sort all edges
\end{itemize}

\subsubsection{C. Example}\label{c.-example-3}

Graph:

\begin{verbatim}
1 -2- 2  
|     |  
4     1  
 \-3-/
\end{verbatim}

Start at 1 → choose (1-2), (1-3) → MST weight = 2 + 3 = 5

\subsubsection{5. Borůvka's Algorithm}\label{borux16fvkas-algorithm}

Less famous, but elegant , merges cheapest outgoing edge per component
in parallel.

Each component picks one cheapest outgoing edge, adds it, merges
components. Repeat until one component left.

Complexity: (O\(E \log V\))

Used in parallel/distributed MST computations.

\subsubsection{6. Comparison}\label{comparison-18}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1406}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.4062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0938}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2031}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Kruskal & Edge-based, sort all edges & O(E log E) & O(E) & Sparse
graphs \\
Prim & Vertex-based, grow tree & O(E log V) & O(V+E) & Dense graphs \\
Borůvka & Component merging & O(E log V) & O(E) & Parallel MST \\
\end{longtable}

\subsubsection{7. MST Properties}\label{mst-properties}

\begin{itemize}
\tightlist
\item
  Cut Property: For any cut, smallest crossing edge ∈ MST.- Cycle
  Property: For any cycle, largest edge not ∈ MST.- MST may not be
  unique if equal weights.
\end{itemize}

\subsubsection{8. Building the Tree}\label{building-the-tree}

Store MST edges:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ mst\_edges}\OperatorTok{;}
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{unite}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))}\NormalTok{ mst\_edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{e}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Then use MST for:

\begin{itemize}
\tightlist
\item
  Path queries- Clustering (remove largest edge)- Approximation TSP
  (preorder traversal)
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-34}

Kruskal Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(\{}\DecValTok{1}\OperatorTok{,}\DecValTok{2}\OperatorTok{,}\DecValTok{4}\OperatorTok{\});}
\NormalTok{edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(\{}\DecValTok{1}\OperatorTok{,}\DecValTok{3}\OperatorTok{,}\DecValTok{1}\OperatorTok{\});}
\NormalTok{edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(\{}\DecValTok{2}\OperatorTok{,}\DecValTok{3}\OperatorTok{,}\DecValTok{3}\OperatorTok{\});}
\NormalTok{printf}\OperatorTok{(}\StringTok{"MST = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ kruskal}\OperatorTok{(}\DecValTok{3}\OperatorTok{));} \CommentTok{// 4}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-34}

MSTs model connection without redundancy. They're about efficiency ,
connecting everything at minimal cost, a principle that appears in
infrastructure, data, and even ideas.

They teach:

\begin{quote}
``You can connect the whole with less , if you choose wisely.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-34}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Kruskal's algorithm using union-find.
\item
  Run Prim's algorithm and compare output.
\item
  Build MST on random weighted graph , visualize tree.
\item
  Remove heaviest edge from MST to form two clusters.
\item
  Explore Borůvka for parallel execution.
\end{enumerate}

MSTs are how you span complexity with minimal effort , a tree of
balance, economy, and order.

\subsection{36. Flows (Ford-Fulkerson, Edmonds-Karp,
Dinic)}\label{flows-ford-fulkerson-edmonds-karp-dinic}

Some graphs don't just connect , they \emph{carry} something. Imagine
water flowing through pipes, traffic through roads, data through a
network. Each edge has a capacity, and you want to know:

\begin{quote}
``How much can I send from source to sink before the system clogs?''
\end{quote}

That's the Maximum Flow problem , a cornerstone of combinatorial
optimization, powering algorithms for matching, cuts, scheduling, and
more.

This section covers the big three:

\begin{itemize}
\tightlist
\item
  Ford-Fulkerson , the primal idea- Edmonds-Karp , BFS-based
  implementation- Dinic's Algorithm , layered speed
\end{itemize}

\subsubsection{1. Problem Definition}\label{problem-definition}

Given a directed graph ( G = (V, E) ), each edge ( (u, v) ) has a
capacity ( c(u, v) \ge 0 ).

We have:

\begin{itemize}
\tightlist
\item
  Source ( s )- Sink ( t ) We want the maximum flow from ( s ) to ( t ):
  a function ( f(u, v) ) that satisfies:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Capacity constraint: ( 0 \le f(u, v) \le c(u, v) )
\item
  Flow conservation: For every vertex \(v \neq s, t\): (\sum f(u, v) =
  \sum f(v, w))
\end{enumerate}

Total flow = (\sum f(s, v))

\subsubsection{2. The Big Picture}\label{the-big-picture}

Max Flow - Min Cut Theorem:

\begin{quote}
The value of the maximum flow equals the capacity of the minimum cut.
\end{quote}

So finding a max flow is equivalent to finding the bottleneck.

\subsubsection{3. Ford-Fulkerson Method}\label{ford-fulkerson-method}

The idea:

\begin{itemize}
\tightlist
\item
  While there exists a path from (s) to (t) with available capacity,
  push flow along it.
\end{itemize}

Each step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find augmenting path
\item
  Send flow = min residual capacity along it
\item
  Update residual capacities
\end{enumerate}

Repeat until no augmenting path.

\subsubsection{A. Residual Graph}\label{a.-residual-graph}

Residual capacity: \[
r(u, v) = c(u, v) - f(u, v)
\] If ( f(u, v) \textgreater{} 0 ), then add reverse edge ( (v, u) )
with capacity ( f(u, v) ).

This allows undoing flow if needed.

\subsubsection{B. Implementation
(DFS-style)}\label{b.-implementation-dfs-style}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ cap}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{][}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ flow}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ vis}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ t}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\NormalTok{    vis}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ \_}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{vis}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ pushed }\OperatorTok{=}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ min}\OperatorTok{(}\NormalTok{flow}\OperatorTok{,}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]),}\NormalTok{ vis}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pushed }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ pushed}\OperatorTok{;}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ pushed}\OperatorTok{;}
                \ControlFlowTok{return}\NormalTok{ pushed}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ ford\_fulkerson}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ flow }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ vis}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
        \DataTypeTok{int}\NormalTok{ pushed }\OperatorTok{=}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{,}\NormalTok{ vis}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pushed }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{        flow }\OperatorTok{+=}\NormalTok{ pushed}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(E \cdot \text{max flow}\)) , depends on flow magnitude.

\subsubsection{4. Edmonds-Karp Algorithm}\label{edmonds-karp-algorithm}

A refinement:

\begin{quote}
Always choose shortest augmenting path (by edges) using BFS.
\end{quote}

Guarantees polynomial time.

\subsubsection{A. Implementation (BFS + parent
tracking)}\label{a.-implementation-bfs-parent-tracking}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ parent}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{parent}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ parent}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\NormalTok{    queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{s}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{\});}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \OperatorTok{{-}}\DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{u}\OperatorTok{,}\NormalTok{ flow}\OperatorTok{]} \OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ \_}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ new\_flow }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{flow}\OperatorTok{,}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]);}
\NormalTok{                parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ t}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ new\_flow}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{v}\OperatorTok{,}\NormalTok{ new\_flow}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ edmonds\_karp}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ flow }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ parent}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ new\_flow}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{((}\NormalTok{new\_flow }\OperatorTok{=}\NormalTok{ bfs}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ parent}\OperatorTok{,}\NormalTok{ n}\OperatorTok{)))} \OperatorTok{\{}
\NormalTok{        flow }\OperatorTok{+=}\NormalTok{ new\_flow}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ t}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
\NormalTok{            cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ new\_flow}\OperatorTok{;}
\NormalTok{            cap}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ new\_flow}\OperatorTok{;}
\NormalTok{            v }\OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(VE^2\)) Always terminates (no dependence on flow
values).

\subsubsection{5. Dinic's Algorithm}\label{dinics-algorithm}

A modern classic , uses BFS to build level graph, and DFS to send
blocking flow.

It works layer-by-layer, avoiding useless exploration.

\subsubsection{A. Steps}\label{a.-steps-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build level graph via BFS (assign levels to reachable nodes).
\item
  DFS sends flow along level-respecting paths.
\item
  Repeat until no path remains.
\end{enumerate}

\subsubsection{B. Implementation}\label{b.-implementation-6}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ level}\OperatorTok{,}\NormalTok{ ptr}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ bfs\_level}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{level}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ level}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
\NormalTok{    level}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ \_}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{level}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                level}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ level}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ level}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ dfs\_flow}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pushed}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ t }\OperatorTok{||}\NormalTok{ pushed }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ pushed}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int} \OperatorTok{\&}\NormalTok{cid }\OperatorTok{=}\NormalTok{ ptr}\OperatorTok{[}\NormalTok{u}\OperatorTok{];}\NormalTok{ cid }\OperatorTok{\textless{}} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)}\NormalTok{adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{].}\NormalTok{size}\OperatorTok{();}\NormalTok{ cid}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{cid}\OperatorTok{].}\NormalTok{first}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{level}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==}\NormalTok{ level}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ tr }\OperatorTok{=}\NormalTok{ dfs\_flow}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ min}\OperatorTok{(}\NormalTok{pushed}\OperatorTok{,}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]));}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{tr }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ tr}\OperatorTok{;}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ tr}\OperatorTok{;}
                \ControlFlowTok{return}\NormalTok{ tr}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ dinic}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ flow }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    level}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    ptr}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{bfs\_level}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ n}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        fill}\OperatorTok{(}\NormalTok{ptr}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ ptr}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \DecValTok{0}\OperatorTok{);}
        \ControlFlowTok{while} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ pushed }\OperatorTok{=}\NormalTok{ dfs\_flow}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{))}
\NormalTok{            flow }\OperatorTok{+=}\NormalTok{ pushed}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(EV^2\)) worst case, (O\(E \sqrt{V}\)) in practice.

\subsubsection{6. Comparison}\label{comparison-19}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1505}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2151}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2043}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2688}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handles
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ford-Fulkerson & DFS augmenting paths & Integral capacities &
O\(E × max_flow\) & Simple, may loop on reals \\
Edmonds-Karp & BFS augmenting paths & All capacities & O(VE²) & Always
terminates \\
Dinic & Level graph + DFS & All capacities & O(V²E) & Fast in
practice \\
\end{longtable}

\subsubsection{7. Applications}\label{applications-4}

\begin{itemize}
\tightlist
\item
  Network routing- Bipartite matching- Task assignment (flows = people →
  jobs)- Image segmentation (min-cut)- Circulation with demands- Data
  pipelines, max throughput systems
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-35}

Ford-Fulkerson Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{5}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{3}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"Max flow = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ ford\_fulkerson}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{4}\OperatorTok{));} \CommentTok{// 5}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-35}

Flow algorithms transform capacity constraints into solvable systems.
They reveal the deep unity between optimization and structure: every
maximum flow defines a minimum bottleneck cut.

They embody a timeless truth:

\begin{quote}
``To understand limits, follow the flow.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-35}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Ford-Fulkerson using DFS.
\item
  Switch to Edmonds-Karp and observe performance gain.
\item
  Build Dinic's level graph and visualize layers.
\item
  Model job assignment as bipartite flow.
\item
  Verify Max Flow = Min Cut on small examples.
\end{enumerate}

Once you master flows, you'll see them hidden in everything that moves ,
from data to decisions.

\subsection{37. Cuts (Stoer-Wagner, Karger,
Gomory-Hu)}\label{cuts-stoer-wagner-karger-gomory-hu}

Where flow problems ask \emph{``How much can we send?''}, cut problems
ask \emph{``Where does it break?''}

A cut splits a graph into two disjoint sets. The minimum cut is the
smallest set of edges whose removal disconnects the graph , the tightest
``bottleneck'' holding it together.

This chapter explores three major algorithms:

\begin{itemize}
\tightlist
\item
  Stoer-Wagner , deterministic min-cut for undirected graphs- Karger's
  Randomized Algorithm , fast, probabilistic- Gomory-Hu Tree , compress
  all-pairs min-cuts into one tree Cuts reveal hidden structure ,
  clusters, vulnerabilities, boundaries , and form the dual to flows via
  the Max-Flow Min-Cut Theorem.
\end{itemize}

\subsubsection{1. The Min-Cut Problem}\label{the-min-cut-problem}

Given a weighted undirected graph ( G = (V, E) ): Find the minimum total
weight of edges whose removal disconnects the graph.

Equivalent to:

\begin{quote}
The smallest sum of edge weights crossing any partition (
\(S, V \setminus S\) ).
\end{quote}

For directed graphs, you use max-flow methods; For undirected graphs,
specialized algorithms exist.

\subsubsection{2. Applications}\label{applications-5}

\begin{itemize}
\tightlist
\item
  Network reliability , weakest link detection- Clustering , partition
  graph by minimal interconnection- Circuit design , splitting
  components- Image segmentation , separating regions- Community
  detection , sparse connections between groups
\end{itemize}

\subsubsection{3. Stoer-Wagner Algorithm
(Deterministic)}\label{stoer-wagner-algorithm-deterministic}

A clean, deterministic method for global minimum cut in undirected
graphs.

\subsubsection{A. Idea}\label{a.-idea-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start with the full vertex set ( V ).
\item
  Repeatedly run Maximum Adjacency Search:

  \begin{itemize}
  \tightlist
  \item
    Start from a vertex - Grow a set by adding the most tightly
    connected vertex - The last added vertex defines a cut3. Contract
    the last two added vertices into one.
  \end{itemize}
\item
  Keep track of smallest cut seen.
\end{enumerate}

Repeat until one vertex remains.

\subsubsection{B. Implementation (Adjacency
Matrix)}\label{b.-implementation-adjacency-matrix}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ g}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{][}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ w}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ added}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ exist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ stoer\_wagner}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ best }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ v}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    iota}\OperatorTok{(}\NormalTok{v}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ v}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \DecValTok{0}\OperatorTok{);}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textgreater{}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        fill}\OperatorTok{(}\NormalTok{w}\OperatorTok{,}\NormalTok{ w }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\NormalTok{        fill}\OperatorTok{(}\NormalTok{added}\OperatorTok{,}\NormalTok{ added }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
        \DataTypeTok{int}\NormalTok{ prev }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ sel }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
                \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{added}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\&\&} \OperatorTok{(}\NormalTok{sel }\OperatorTok{==} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{||}\NormalTok{ w}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ w}\OperatorTok{[}\NormalTok{sel}\OperatorTok{]))}\NormalTok{ sel }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                best }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{best}\OperatorTok{,}\NormalTok{ w}\OperatorTok{[}\NormalTok{sel}\OperatorTok{]);}
                \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{                    g}\OperatorTok{[}\NormalTok{prev}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{prev}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ g}\OperatorTok{[}\NormalTok{sel}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
\NormalTok{                v}\OperatorTok{.}\NormalTok{erase}\OperatorTok{(}\NormalTok{v}\OperatorTok{.}\NormalTok{begin}\OperatorTok{()} \OperatorTok{+}\NormalTok{ sel}\OperatorTok{);}
\NormalTok{                n}\OperatorTok{{-}{-};}
                \ControlFlowTok{break}\OperatorTok{;}
            \OperatorTok{\}}
\NormalTok{            added}\OperatorTok{[}\NormalTok{sel}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ w}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ g}\OperatorTok{[}\NormalTok{sel}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
\NormalTok{            prev }\OperatorTok{=}\NormalTok{ sel}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ best}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(V^3\)), or (O\(VE + V^2 \log V\)) with heaps Input:
weighted undirected graph Output: global min cut value

\subsubsection{C. Example}\label{c.-example-4}

Graph:

\begin{verbatim}
1 -3- 2  
|     |  
4     2  
 \-5-/
\end{verbatim}

Cuts:

\begin{itemize}
\tightlist
\item
  \{1,2\}\textbar\{3\} → 7- \{1,3\}\textbar\{2\} → 5 Min cut = 5
\end{itemize}

\subsubsection{4. Karger's Algorithm
(Randomized)}\label{kargers-algorithm-randomized}

A simple, elegant probabilistic method. Repeatedly contract random edges
until two vertices remain; the remaining crossing edges form a cut.

Run multiple times → high probability of finding min cut.

\subsubsection{A. Algorithm}\label{a.-algorithm-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  While ( \textbar V\textbar{} \textgreater{} 2 ):

  \begin{itemize}
  \tightlist
  \item
    Choose random edge ((u, v)) - Contract (u, v) into one node - Remove
    self-loops2. Return number of edges between remaining nodes
  \end{itemize}
\end{enumerate}

Repeat (O\(n^2 \log n\)) times for high confidence.

\subsubsection{B. Implementation Sketch}\label{b.-implementation-sketch}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Edge }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ edges}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{==}\NormalTok{ x }\OperatorTok{?}\NormalTok{ x }\OperatorTok{:}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]);} \OperatorTok{\}}
\DataTypeTok{void}\NormalTok{ unite}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ parent}\OperatorTok{[}\NormalTok{find}\OperatorTok{(}\NormalTok{b}\OperatorTok{)]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);} \OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ karger}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=}\NormalTok{ edges}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\NormalTok{    iota}\OperatorTok{(}\NormalTok{parent}\OperatorTok{,}\NormalTok{ parent }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ vertices }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{vertices }\OperatorTok{\textgreater{}} \DecValTok{2}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{edges}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{u}\OperatorTok{),}\NormalTok{ v }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{edges}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{v}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ v}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        unite}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
\NormalTok{        vertices}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ cuts }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto}\NormalTok{ e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{)} \OperatorTok{!=}\NormalTok{ find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))}\NormalTok{ cuts}\OperatorTok{++;}
    \ControlFlowTok{return}\NormalTok{ cuts}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Expected Time: (O\(n^2\)) per run Probability of success: (2 / (n(n-1)))
per run Run multiple trials and take minimum.

\subsubsection{C. Use Case}\label{c.-use-case}

Great for large sparse graphs, or when approximate solutions are
acceptable. Intuitive: the min cut survives random contractions if
chosen carefully enough.

\subsubsection{5. Gomory-Hu Tree}\label{gomory-hu-tree}

A compact way to store all-pairs min-cuts. It compresses (O\(V^2\)) flow
computations into V-1 cuts.

\subsubsection{A. Idea}\label{a.-idea-7}

\begin{itemize}
\tightlist
\item
  Build a tree where the min cut between any two vertices = the minimum
  edge weight on their path in the tree.
\end{itemize}

\subsubsection{B. Algorithm}\label{b.-algorithm}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Pick vertex (s).
\item
  For each vertex \(t \neq s\),

  \begin{itemize}
  \tightlist
  \item
    Run max flow to find min cut between (s, t). - Partition vertices
    accordingly.3. Connect partitions to form a tree.
  \end{itemize}
\end{enumerate}

Result: Gomory-Hu tree (V-1 edges).

Now any pair's min cut = smallest edge on path between them.

Complexity: (O(V)) max flow runs.

\subsubsection{C. Uses}\label{c.-uses}

\begin{itemize}
\tightlist
\item
  Quickly answer all-pairs cut queries- Network reliability-
  Hierarchical clustering
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-20}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1348}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1461}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2584}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2360}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Randomized
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Graph
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Stoer-Wagner & Deterministic & No & Undirected & O(V³) & Global min
cut \\
Karger & Randomized & Yes & Undirected & O(n² log n) (multi-run) &
Probabilistic min cut \\
Gomory-Hu & Deterministic & No & Undirected & O(V × MaxFlow) & All-pairs
min cuts \\
\end{longtable}

\subsubsection{7. Relationship to Flows}\label{relationship-to-flows}

By Max-Flow Min-Cut, min-cut capacity = max-flow value.

So you can find:

\begin{itemize}
\tightlist
\item
  s-t min cut = via max flow- global min cut = min over all (s, t) pairs
  Specialized algorithms just make it faster.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-36}

Stoer-Wagner Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{printf}\OperatorTok{(}\StringTok{"Global Min Cut = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ stoer\_wagner}\OperatorTok{(}\NormalTok{n}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Karger Multi-Run:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ ans }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    ans }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{ans}\OperatorTok{,}\NormalTok{ karger}\OperatorTok{(}\NormalTok{n}\OperatorTok{));}
\NormalTok{printf}\OperatorTok{(}\StringTok{"Approx Min Cut = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ ans}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-36}

Cuts show you fragility , the weak seams of connection. While flows tell
you \emph{how much can pass}, cuts reveal \emph{where it breaks first}.

They teach:

\begin{quote}
``To understand strength, study what happens when you pull things
apart.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-36}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Stoer-Wagner and test on small graphs.
\item
  Run Karger 100 times and track success rate.
\item
  Build a Gomory-Hu tree and answer random pair queries.
\item
  Verify Max-Flow = Min-Cut equivalence on examples.
\item
  Use cuts for community detection in social graphs.
\end{enumerate}

Mastering cuts gives you both grip and insight , where systems hold, and
where they give way.

\subsection{38. Matchings (Hopcroft-Karp, Hungarian,
Blossom)}\label{matchings-hopcroft-karp-hungarian-blossom}

In many problems, we need to pair up elements efficiently: students to
schools, jobs to workers, tasks to machines.

These are matching problems , find sets of edges with no shared
endpoints that maximize cardinality or weight.

Depending on graph type, different algorithms apply:

\begin{itemize}
\tightlist
\item
  Hopcroft-Karp , fast matching in bipartite graphs- Hungarian Algorithm
  , optimal weighted assignment- Edmonds' Blossom Algorithm , general
  graphs (non-bipartite) Matching is a fundamental combinatorial
  structure, appearing in scheduling, flow networks, and resource
  allocation.
\end{itemize}

\subsubsection{1. Terminology}\label{terminology}

\begin{itemize}
\item
  Matching: set of edges with no shared vertices- Maximum Matching:
  matching with largest number of edges- Perfect Matching: covers all
  vertices (each vertex matched once)- Maximum Weight Matching: matching
  with largest total edge weight Graph Types:
\item
  Bipartite: vertices split into two sets (L, R); edges only between
  sets- General: arbitrary connections (may contain odd cycles)
\end{itemize}

\subsubsection{2. Applications}\label{applications-6}

\begin{itemize}
\tightlist
\item
  Job assignment- Network flows- Resource allocation- Student-project
  pairing- Stable marriages (with preferences)- Computer vision (feature
  correspondence)
\end{itemize}

\subsubsection{3. Hopcroft-Karp Algorithm (Bipartite
Matching)}\label{hopcroft-karp-algorithm-bipartite-matching}

A highly efficient algorithm for maximum cardinality matching in
bipartite graphs.

It uses layered BFS + DFS to find multiple augmenting paths
simultaneously.

\subsubsection{A. Idea}\label{a.-idea-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize matching empty.
\item
  While augmenting paths exist:

  \begin{itemize}
  \tightlist
  \item
    BFS builds layer graph (shortest augmenting paths). - DFS finds all
    augmenting paths along those layers. Each phase increases matching
    size significantly.
  \end{itemize}
\end{enumerate}

\subsubsection{B. Complexity}\label{b.-complexity}

\[
O(E \sqrt{V})
\]

Much faster than augmenting one path at a time (like Ford-Fulkerson).

\subsubsection{C. Implementation}\label{c.-implementation}

Let \texttt{pairU{[}u{]}} = matched vertex in R, or 0 if unmatched
\texttt{pairV{[}v{]}} = matched vertex in L, or 0 if unmatched

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adjL}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ pairU}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ pairV}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ dist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ nL}\OperatorTok{,}\NormalTok{ nR}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ bfs}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ nL}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairU}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
        \ControlFlowTok{else}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ found }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ found}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adjL}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
                \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}\NormalTok{ found }\OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
                \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]]} \OperatorTok{==}\NormalTok{ INF}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                    dist}\OperatorTok{[}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{                    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
                \OperatorTok{\}}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ found }\OperatorTok{!=}\NormalTok{ INF}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adjL}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{||} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]]} \OperatorTok{==}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\&\&}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{])))} \OperatorTok{\{}
\NormalTok{            pairU}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{            pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
            \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ hopcroft\_karp}\OperatorTok{()} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ matching }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{bfs}\OperatorTok{())} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ nL}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairU}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{u}\OperatorTok{))}\NormalTok{ matching}\OperatorTok{++;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ matching}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Example}\label{d.-example}

Graph:

\begin{verbatim}
U = {1,2,3}, V = {a,b}
Edges: 1–a, 2–a, 3–b
\end{verbatim}

Matching: \{1-a, 3-b\} (size 2)

\subsubsection{4. Hungarian Algorithm (Weighted Bipartite
Matching)}\label{hungarian-algorithm-weighted-bipartite-matching}

Solves assignment problem , given cost matrix \(c_{ij}\), assign each
(i) to one (j) minimizing total cost (or maximizing profit).

\subsubsection{A. Idea}\label{a.-idea-9}

Subtract minimums row- and column-wise → expose zeros → find minimal
zero-cover → adjust matrix → repeat.

Equivalent to solving min-cost perfect matching on a bipartite graph.

\subsubsection{B. Complexity}\label{b.-complexity-1}

\[
O(V^3)
\]

Works for dense graphs, moderate sizes.

\subsubsection{C. Implementation Sketch (Matrix
Form)}\label{c.-implementation-sketch-matrix-form}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ hungarian}\OperatorTok{(}\DataTypeTok{const}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ cost}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ cost}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ u}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ v}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ p}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ way}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        p}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ j0 }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ minv}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{char}\OperatorTok{\textgreater{}}\NormalTok{ used}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
        \ControlFlowTok{do} \OperatorTok{\{}
\NormalTok{            used}\OperatorTok{[}\NormalTok{j0}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
            \DataTypeTok{int}\NormalTok{ i0 }\OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{j0}\OperatorTok{],}\NormalTok{ delta }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{,}\NormalTok{ j1}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{used}\OperatorTok{[}\NormalTok{j}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i0}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ u}\OperatorTok{[}\NormalTok{i0}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ v}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\textless{}}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ cur}\OperatorTok{,}\NormalTok{ way}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j0}\OperatorTok{;}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ delta}\OperatorTok{)}\NormalTok{ delta }\OperatorTok{=}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{],}\NormalTok{ j1 }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
            \OperatorTok{\}}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ u}\OperatorTok{[}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{]]} \OperatorTok{+=}\NormalTok{ delta}\OperatorTok{,}\NormalTok{ v}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ delta}\OperatorTok{;}
                \ControlFlowTok{else}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ delta}\OperatorTok{;}
\NormalTok{            j0 }\OperatorTok{=}\NormalTok{ j1}\OperatorTok{;}
        \OperatorTok{\}} \ControlFlowTok{while} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{j0}\OperatorTok{]);}
        \ControlFlowTok{do} \OperatorTok{\{} \DataTypeTok{int}\NormalTok{ j1 }\OperatorTok{=}\NormalTok{ way}\OperatorTok{[}\NormalTok{j0}\OperatorTok{];}\NormalTok{ p}\OperatorTok{[}\NormalTok{j0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{j1}\OperatorTok{];}\NormalTok{ j0 }\OperatorTok{=}\NormalTok{ j1}\OperatorTok{;} \OperatorTok{\}} \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j0}\OperatorTok{);}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{v}\OperatorTok{[}\DecValTok{0}\OperatorTok{];} \CommentTok{// minimal cost}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Example}\label{d.-example-1}

Cost matrix:

\begin{verbatim}
  a  b  c
1 3  2  1
2 2  3  2
3 3  2  3
\end{verbatim}

Optimal assignment = 1-c, 2-a, 3-b Cost = 1 + 2 + 2 = 5

\subsubsection{5. Edmonds' Blossom Algorithm (General
Graphs)}\label{edmonds-blossom-algorithm-general-graphs}

For non-bipartite graphs, simple augmenting path logic breaks down (odd
cycles). Blossom algorithm handles this via contraction of blossoms (odd
cycles).

\subsubsection{A. Idea}\label{a.-idea-10}

\begin{itemize}
\tightlist
\item
  Find augmenting paths- When odd cycle encountered (blossom), shrink it
  into one vertex- Continue search- Expand blossoms at end
\end{itemize}

\subsubsection{B. Complexity}\label{b.-complexity-2}

\[
O(V^3)
\]

Though complex to implement, it's the general-purpose solution for
matchings.

\subsubsection{C. Use Cases}\label{c.-use-cases-1}

\begin{itemize}
\tightlist
\item
  Non-bipartite job/task assignments- General pairing problems- Network
  design
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-21}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1970}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1515}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1212}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1515}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3788}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Graph Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weighted
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hopcroft-Karp & Bipartite & No & O(E√V) & Max cardinality \\
Hungarian & Bipartite & Yes & O(V³) & Min/Max cost matching \\
Blossom & General & Yes & O(V³) & Max cardinality or weight \\
\end{longtable}

\subsubsection{7. Relation to Flows}\label{relation-to-flows}

Bipartite matching = max flow on network:

\begin{itemize}
\tightlist
\item
  Left → Source edges (capacity 1)- Right → Sink edges (capacity 1)-
  Between sets → edges (capacity 1) Matching size = flow value
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-37}

Hopcroft-Karp Demo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nL }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}\NormalTok{ nR }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}
\NormalTok{adjL}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{\};}
\NormalTok{adjL}\OperatorTok{[}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{\};}
\NormalTok{adjL}\OperatorTok{[}\DecValTok{3}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{2}\OperatorTok{\};}
\NormalTok{printf}\OperatorTok{(}\StringTok{"Max Matching = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ hopcroft\_karp}\OperatorTok{());} \CommentTok{// 2}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-37}

Matchings are the language of pairing and assignment. They express
cooperation without overlap , a structure of balance.

They reveal a deep duality:

\begin{quote}
``Every match is a flow, every assignment an optimization.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-37}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a bipartite graph and run Hopcroft-Karp.
\item
  Solve an assignment problem with Hungarian algorithm.
\item
  Explore Blossom's contraction idea conceptually.
\item
  Compare max-flow vs matching approach.
\item
  Use matching to model scheduling (people ↔ tasks).
\end{enumerate}

Matching teaches how to pair without conflict, a lesson both
mathematical and universal.

\subsection{39. Tree Algorithms (LCA, HLD, Centroid
Decomposition)}\label{tree-algorithms-lca-hld-centroid-decomposition}

Trees are the backbone of many algorithms , they are connected, acyclic,
and wonderfully structured.

Because of their simplicity, they allow elegant divide-and-conquer,
dynamic programming, and query techniques. This section covers three
fundamental patterns:

\begin{itemize}
\tightlist
\item
  Lowest Common Ancestor (LCA) , answer ancestor queries fast-
  Heavy-Light Decomposition (HLD) , break trees into chains for segment
  trees / path queries- Centroid Decomposition , recursively split tree
  by balance for divide-and-conquer Each reveals a different way to
  reason about trees , by depth, by chains, or by balance.
\end{itemize}

\subsubsection{1. Lowest Common Ancestor
(LCA)}\label{lowest-common-ancestor-lca}

Given a tree, two nodes (u, v). The LCA is the lowest node (farthest
from root) that is an ancestor of both.

Applications:

\begin{itemize}
\tightlist
\item
  Distance queries- Path decomposition- RMQ / binary lifting- Tree DP
  and rerooting
\end{itemize}

\subsubsection{A. Naive Approach}\label{a.-naive-approach}

Climb ancestors until they meet. But this is (O(n)) per query , too slow
for many queries.

\subsubsection{B. Binary Lifting}\label{b.-binary-lifting}

Precompute ancestors at powers of 2. Then jump up by powers to align
depths.

Preprocessing:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DFS to record depth
\item
  \texttt{up{[}v{]}{[}k{]}} = 2\^{}k-th ancestor of v
\end{enumerate}

Answering query:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lift deeper node up to same depth
\item
  Lift both together while
  \texttt{up{[}u{]}{[}k{]}\ !=\ up{[}v{]}{[}k{]}}
\item
  Return parent
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ LOG }\OperatorTok{=} \DecValTok{20}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ up}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{][}\NormalTok{LOG}\OperatorTok{],}\NormalTok{ depth}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ p}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ LOG}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{        up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]][}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ lca}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ diff }\OperatorTok{=}\NormalTok{ depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ LOG}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{diff }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ k}\OperatorTok{))}\NormalTok{ u }\OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ v}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ u}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ LOG}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ k}\OperatorTok{{-}{-})}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ up}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{k}\OperatorTok{])}
\NormalTok{            u }\OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{],}\NormalTok{ v }\OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Preprocess: (O\(n \log n\))- Query: (O\(\log n\))
\end{itemize}

\subsubsection{C. Example}\label{c.-example-5}

Tree:

\begin{verbatim}
    1
   / \
  2   3
 / \
4   5
\end{verbatim}

\begin{itemize}
\tightlist
\item
  LCA(4,5) = 2- LCA(4,3) = 1
\end{itemize}

\subsubsection{2. Heavy-Light Decomposition
(HLD)}\label{heavy-light-decomposition-hld}

When you need to query paths (sum, max, min, etc.) on trees efficiently,
you can use Heavy-Light Decomposition.

\subsubsection{A. Idea}\label{a.-idea-11}

Decompose the tree into chains:

\begin{itemize}
\tightlist
\item
  Heavy edge = edge to child with largest subtree- Light edges = others
  Result: Every path from root to leaf crosses at most (O\(\log n\))
  light edges.
\end{itemize}

So, a path query can be broken into (O\(\log^2 n\)) segment tree
queries.

\subsubsection{B. Steps}\label{b.-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DFS to compute subtree sizes and identify heavy child
\item
  Decompose into chains
\item
  Assign IDs for segment tree
\item
  Use Segment Tree / BIT on linearized array
\end{enumerate}

Key functions:

\begin{itemize}
\tightlist
\item
  \texttt{dfs\_sz(u)} → compute subtree sizes-
  \texttt{decompose(u,\ head)} → assign chain heads Code (core):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ depth}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ heavy}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ head}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ pos}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ cur\_pos }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ dfs\_sz}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ size }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ max\_sz }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
\NormalTok{        depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ sz }\OperatorTok{=}\NormalTok{ dfs\_sz}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sz }\OperatorTok{\textgreater{}}\NormalTok{ max\_sz}\OperatorTok{)}\NormalTok{ max\_sz }\OperatorTok{=}\NormalTok{ sz}\OperatorTok{,}\NormalTok{ heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{        size }\OperatorTok{+=}\NormalTok{ sz}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ size}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ decompose}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ h}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    head}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ h}\OperatorTok{;}
\NormalTok{    pos}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ cur\_pos}\OperatorTok{++;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)}\NormalTok{ decompose}\OperatorTok{(}\NormalTok{heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ h}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ v }\OperatorTok{!=}\NormalTok{ heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{            decompose}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Query path(u, v):

\begin{itemize}
\item
  While heads differ, move up chain by chain- Query segment tree in
  \texttt{{[}pos{[}head{[}u{]}{]},\ pos{[}u{]}{]}}- When in same chain,
  query segment \texttt{{[}pos{[}v{]},\ pos{[}u{]}{]}} Complexity:
\item
  Build: (O(n))- Query/Update: (O\(\log^2 n\))
\end{itemize}

\subsubsection{C. Use Cases}\label{c.-use-cases-2}

\begin{itemize}
\tightlist
\item
  Path sums- Path maximums- Edge updates- Subtree queries
\end{itemize}

\subsubsection{3. Centroid Decomposition}\label{centroid-decomposition}

Centroid = node that splits tree into subtrees ≤ n/2 each. By removing
centroids recursively, we form a centroid tree.

Used for divide-and-conquer on trees.

\subsubsection{A. Steps}\label{a.-steps-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find centroid

  \begin{itemize}
  \item
    DFS to compute subtree sizes - Choose node where largest subtree ≤
    n/22. Decompose:
  \item
    Remove centroid - Recurse on subtrees Code (core):
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ subtree}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ removed}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ dfs\_size}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    subtree}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p }\OperatorTok{\&\&} \OperatorTok{!}\NormalTok{removed}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            subtree}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dfs\_size}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ subtree}\OperatorTok{[}\NormalTok{u}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ find\_centroid}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p }\OperatorTok{\&\&} \OperatorTok{!}\NormalTok{removed}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{subtree}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{)}
                \ControlFlowTok{return}\NormalTok{ find\_centroid}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ u}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ decompose}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ dfs\_size}\OperatorTok{(}\NormalTok{u}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ c }\OperatorTok{=}\NormalTok{ find\_centroid}\OperatorTok{(}\NormalTok{u}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\NormalTok{    removed}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \CommentTok{// process centroid here}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{c}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{removed}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            decompose}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ c}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n \log n\))

\subsubsection{B. Applications}\label{b.-applications}

\begin{itemize}
\tightlist
\item
  Distance queries (decompose + store distance to centroid)- Tree
  problems solvable by divide-and-conquer- Dynamic queries (add/remove
  nodes)
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-22}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1591}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1477}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1477}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2386}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0568}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Query
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Preprocess
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LCA & Ancestor query & (O\(\log n\)) & (O\(n \log n\)) & Fast ancestor
lookup & \\
HLD & Path queries & (O\(\log^2 n\)) & (O(n)) & Segment tree-friendly
& \\
Centroid Decomposition & Divide tree & - & (O\(n \log n\)) & Balanced
splits & \\
\end{longtable}

\subsubsection{5. Interconnections}\label{interconnections}

\begin{itemize}
\tightlist
\item
  HLD often uses LCA internally.- Centroid decomposition may use
  distance to ancestor (via LCA).- All exploit tree structure to achieve
  sublinear queries.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-38}

LCA(4,5):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfs}\OperatorTok{(}\DecValTok{1}\OperatorTok{,}\DecValTok{1}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ lca}\OperatorTok{(}\DecValTok{4}\OperatorTok{,}\DecValTok{5}\OperatorTok{));} \CommentTok{// 2}
\end{Highlighting}
\end{Shaded}

HLD Path Sum: Build segment tree on \texttt{pos{[}u{]}} order, query
along chains.

Centroid: \texttt{decompose(1,\ -1);}

\subsubsection{Why It Matters}\label{why-it-matters-38}

Tree algorithms show how structure unlocks efficiency. They transform
naive traversals into fast, layered, or recursive solutions.

To master data structures, you must learn to ``climb'' and ``cut'' trees
intelligently.

\begin{quote}
``Every rooted path hides a logarithm.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-38}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement binary lifting LCA and test queries.
\item
  Add segment tree over HLD and run path sums.
\item
  Decompose tree by centroid and count nodes at distance k.
\item
  Combine LCA + HLD for path min/max.
\item
  Draw centroid tree of a simple graph.
\end{enumerate}

Master these, and trees will stop being ``just graphs'' , they'll become
\emph{tools}.

\subsection{40. Advanced Graph Algorithms and
Tricks}\label{advanced-graph-algorithms-and-tricks}

By now you've seen the big families , traversals, shortest paths, flows,
matchings, cuts, and trees. But real-world graphs often bring extra
constraints: dynamic updates, multiple sources, layered structures, or
special properties (planar, DAG, sparse).

This section gathers powerful advanced graph techniques , tricks and
patterns that appear across problems once you've mastered the basics.

We'll explore:

\begin{itemize}
\tightlist
\item
  Topological Sorting \& DAG DP- Strongly Connected Components
  (Condensation Graphs)- Articulation Points \& Bridges (2-Edge/Vertex
  Connectivity)- Eulerian \& Hamiltonian Paths- Graph Coloring \&
  Bipartiteness Tests- Cycle Detection \& Directed Acyclic Reasoning-
  Small-to-Large Merging, DSU on Tree, Mo's Algorithm on Trees- Bitmask
  DP on Graphs- Dynamic Graphs (Incremental/Decremental BFS/DFS)-
  Special Graphs (Planar, Sparse, Dense) These aren't just algorithms ,
  they're patterns that let you attack harder graph problems with
  insight.
\end{itemize}

\subsubsection{1. Topological Sorting \& DAG
DP}\label{topological-sorting-dag-dp}

In a DAG (Directed Acyclic Graph), edges always point forward. This
makes it possible to order vertices linearly so all edges go from left
to right , a topological order.

Use cases:

\begin{itemize}
\tightlist
\item
  Task scheduling- Dependency resolution- DP on DAG (longest/shortest
  path, counting paths) Algorithm (Kahn's):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ topo\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ indeg}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ res}\OperatorTok{;}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ indeg}\OperatorTok{[}\NormalTok{v}\OperatorTok{]++;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{indeg}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{        res}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{({-}{-}}\NormalTok{indeg}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

DAG DP:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{:}\NormalTok{ topo\_order}\OperatorTok{)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ weight}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{v}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Complexity: O(V + E)

\subsubsection{2. Strongly Connected Components
(Condensation)}\label{strongly-connected-components-condensation}

In directed graphs, vertices may form SCCs (mutually reachable
components). Condensing SCCs yields a DAG, often easier to reason about.

Use:

\begin{itemize}
\tightlist
\item
  Component compression- Meta-graph reasoning- Cycle condensation
  Tarjan's Algorithm: DFS with low-link values, single pass.
\end{itemize}

Kosaraju's Algorithm: Two passes , DFS on graph and reversed graph.

Complexity: O(V + E)

Once SCCs are built, you can run DP or topological sort on the condensed
DAG.

\subsubsection{3. Articulation Points \&
Bridges}\label{articulation-points-bridges}

Find critical vertices/edges whose removal disconnects the graph.

\begin{itemize}
\tightlist
\item
  Articulation point: vertex whose removal increases component count-
  Bridge: edge whose removal increases component count Algorithm:
  Tarjan's DFS Track discovery time \texttt{tin{[}u{]}} and lowest
  reachable ancestor \texttt{low{[}u{]}}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    tin}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \OperatorTok{++}\NormalTok{timer}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{tin}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{            low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ tin}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ bridge}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}=}\NormalTok{ tin}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ p }\OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)}\NormalTok{ cut\_vertex}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
        \OperatorTok{\}} \ControlFlowTok{else}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ tin}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Applications:

\begin{itemize}
\tightlist
\item
  Network reliability- Biconnected components- 2-edge/vertex
  connectivity tests
\end{itemize}

\subsubsection{4. Eulerian \& Hamiltonian
Paths}\label{eulerian-hamiltonian-paths}

\begin{itemize}
\tightlist
\item
  Eulerian Path: visits every edge exactly once

  \begin{itemize}
  \tightlist
  \item
    Exists if graph is connected and 0 or 2 vertices have odd degree-
    Hamiltonian Path: visits every vertex exactly once (NP-hard) Euler
    Tour Construction: Hierholzer's algorithm (O(E))
  \end{itemize}
\end{itemize}

Applications:

\begin{itemize}
\tightlist
\item
  Route reconstruction (e.g., word chains)- Postman problems
\end{itemize}

\subsubsection{5. Graph Coloring \&
Bipartiteness}\label{graph-coloring-bipartiteness}

Bipartite Check: DFS/ BFS alternating colors Fails if odd cycle found.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ bipartite}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ color}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{color}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}\NormalTok{ color}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{color}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)}
\NormalTok{                    color}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ color}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\^{}} \DecValTok{1}\OperatorTok{,}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
                \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{color}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==}\NormalTok{ color}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
                    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Applications:

\begin{itemize}
\tightlist
\item
  2-SAT reduction- Planar graph coloring- Conflict-free assignment
\end{itemize}

\subsubsection{6. Cycle Detection}\label{cycle-detection}

\begin{itemize}
\tightlist
\item
  DFS + recursion stack for directed graphs- Union-Find for undirected
  graphs Used to test acyclicity, detect back edges, or find cycles for
  rollback or consistency checks.
\end{itemize}

\subsubsection{7. DSU on Tree (Small-to-Large
Merging)}\label{dsu-on-tree-small-to-large-merging}

For queries like ``count distinct colors in subtree,'' merge results
from smaller to larger subtrees to maintain O(n log n).

Pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DFS through children
\item
  Keep large child's data structure
\item
  Merge small child's data in
\end{enumerate}

Applications:

\begin{itemize}
\tightlist
\item
  Offline subtree queries- Heavy subproblem caching
\end{itemize}

\subsubsection{8. Mo's Algorithm on Trees}\label{mos-algorithm-on-trees}

Offline algorithm to answer path queries efficiently:

\begin{itemize}
\tightlist
\item
  Convert path queries to ranges via Euler Tour- Use Mo's ordering to
  process in O((N + Q)√N) Useful when online updates aren't required.
\end{itemize}

\subsubsection{9. Bitmask DP on Graphs}\label{bitmask-dp-on-graphs}

For small graphs (n ≤ 20): State = subset of vertices e.g., Traveling
Salesman Problem (TSP)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min cost to visit mask}\OperatorTok{,}\NormalTok{ end at u}
\end{Highlighting}
\end{Shaded}

Transition:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{v}\OperatorTok{)][}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{])}
\end{Highlighting}
\end{Shaded}

Complexity: O(n² 2ⁿ)

\subsubsection{10. Dynamic Graphs}\label{dynamic-graphs}

Graphs that change:

\begin{itemize}
\tightlist
\item
  Incremental BFS: maintain distances as edges added- Decremental
  connectivity: union-find rollback or dynamic trees Used in online
  queries, evolving networks, or real-time systems.
\end{itemize}

\subsubsection{11. Special Graph Classes}\label{special-graph-classes}

\begin{itemize}
\tightlist
\item
  Planar graphs: ≤ 3V-6E; use face counting- Sparse graphs: adjacency
  lists best- Dense graphs: adjacency matrix / bitset Optimizations
  often hinge on density.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-39}

Topological Order:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{auto}\NormalTok{ order }\OperatorTok{=}\NormalTok{ topo\_sort}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{:}\NormalTok{ order}\OperatorTok{)}\NormalTok{ printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Bridge Check: \texttt{if\ (low{[}v{]}\ \textgreater{}\ tin{[}u{]})} edge
is a bridge.

Euler Path Check: Count odd-degree nodes == 0 or 2.

\subsubsection{Why It Matters}\label{why-it-matters-39}

These advanced techniques complete your toolkit. They're not isolated ,
they combine to solve real-world puzzles: dependency graphs, robust
networks, optimized paths, compressed states.

They teach a mindset:

\begin{quote}
``Graphs are not obstacles , they're shapes of possibility.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-39}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement topological sort and DAG DP.
\item
  Find SCCs and build condensation graph.
\item
  Detect articulation points and bridges.
\item
  Check Euler path conditions on random graphs.
\item
  Try DSU on tree for subtree statistics.
\item
  Solve TSP via bitmask DP for n ≤ 15.
\end{enumerate}

Once you can mix and match these tools, you're no longer just navigating
graphs , you're shaping them.

\section{Chapter 5. Dynamic
Programming}\label{chapter-5.-dynamic-programming-1}

\subsection{41. DP Basics and State
Transitions}\label{dp-basics-and-state-transitions}

Dynamic Programming (DP) is one of the most powerful ideas in algorithm
design. It's about breaking a big problem into smaller overlapping
subproblems, solving each once, and reusing their answers.

When brute force explodes exponentially, DP brings it back under
control. This section introduces the mindset, the mechanics, and the
math behind DP.

\subsubsection{1. The Core Idea}\label{the-core-idea-1}

Many problems have two key properties:

\begin{itemize}
\item
  Overlapping subproblems: The same smaller computations repeat many
  times.
\item
  Optimal substructure: The optimal solution to a problem can be built
  from optimal solutions to its subproblems.
\end{itemize}

DP solves each subproblem once, stores the result, and reuses it. This
saves exponential time , often reducing ( O\(2^n\) ) to ( O\(n^2\) ) or
( O(n) ).

\subsubsection{2. The Recipe}\label{the-recipe}

When approaching a DP problem, follow this pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define the state. Decide what subproblems you'll solve. Example:
  \texttt{dp{[}i{]}\ =\ best\ answer\ for\ first\ i\ elements}.
\item
  Write the recurrence. Express each state in terms of smaller ones.
  Example: \texttt{dp{[}i{]}\ =\ dp{[}i-1{]}\ +\ cost(i)}
\item
  Set the base cases. Where does the recursion start? Example:
  \texttt{dp{[}0{]}\ =\ 0}
\item
  Decide the order. Bottom-up (iterative) or top-down (recursive with
  memoization).
\item
  Return the final answer. Often \texttt{dp{[}n{]}} or
  \texttt{max(dp{[}i{]})}.
\end{enumerate}

\subsubsection{3. Example: Fibonacci
Numbers}\label{example-fibonacci-numbers}

Let's begin with a classic , the nth Fibonacci number ( F(n) = F(n-1) +
F(n-2) ).

Recursive (slow):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This recomputes the same values over and over , exponential time.

Top-Down DP (Memoization):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Bottom-Up DP (Tabulation):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{    dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Space Optimized:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ a }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ b }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ c}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        c }\OperatorTok{=}\NormalTok{ a }\OperatorTok{+}\NormalTok{ b}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{=}\NormalTok{ c}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. States, Transitions, and
Dependencies}\label{states-transitions-and-dependencies}

A DP table is a map from states to answers. Each state depends on others
via a transition function.

Think of it like a graph , each edge represents a recurrence relation.

Example:

\begin{itemize}
\tightlist
\item
  State: \texttt{dp{[}i{]}\ =\ number\ of\ ways\ to\ reach\ step\ i}-
  Transition: \texttt{dp{[}i{]}\ =\ dp{[}i-1{]}\ +\ dp{[}i-2{]}} (like
  stairs)- Base: \texttt{dp{[}0{]}\ =\ 1}
\end{itemize}

\subsubsection{5. Common DP Patterns}\label{common-dp-patterns}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  1D Linear DP

  \begin{itemize}
  \tightlist
  \item
    Problems like Fibonacci, climbing stairs, LIS.
  \end{itemize}
\item
  2D DP

  \begin{itemize}
  \tightlist
  \item
    Grids, sequences, or combinations (LCS, knapsack).
  \end{itemize}
\item
  Bitmask DP

  \begin{itemize}
  \tightlist
  \item
    Subsets, TSP, combinatorial optimization.
  \end{itemize}
\item
  DP on Trees

  \begin{itemize}
  \tightlist
  \item
    Subtree computations (sum, diameter).
  \end{itemize}
\item
  Digit DP

  \begin{itemize}
  \tightlist
  \item
    Counting numbers with properties in a range.
  \end{itemize}
\item
  Segment DP

  \begin{itemize}
  \tightlist
  \item
    Matrix chain multiplication, interval merges.
  \end{itemize}
\end{enumerate}

\subsubsection{6. Top-Down vs Bottom-Up}\label{top-down-vs-bottom-up}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1098}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2805}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2927}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3171}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Pros
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cons
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Top-Down & Recursion + Memoization & Easy to write, intuitive & Stack
overhead, needs memo \\
Bottom-Up & Iteration & Fast, space-optimizable & Harder to derive
order \\
\end{longtable}

When dependencies are simple and acyclic, bottom-up shines. When they're
complex, top-down is easier.

\subsubsection{7. Example 2: Climbing
Stairs}\label{example-2-climbing-stairs}

You can climb 1 or 2 steps at a time. How many distinct ways to reach
step ( n )?

State: \texttt{dp{[}i{]}\ =\ ways\ to\ reach\ step\ i} Transition:
\texttt{dp{[}i{]}\ =\ dp{[}i-1{]}\ +\ dp{[}i-2{]}} Base:
\texttt{dp{[}0{]}\ =\ 1,\ dp{[}1{]}\ =\ 1}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ climb}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{    dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Debugging DP}\label{debugging-dp}

To debug DP:

\begin{itemize}
\tightlist
\item
  Print intermediate states.- Visualize table (especially 2D).- Check
  base cases.- Trace one small example by hand.
\end{itemize}

\subsubsection{9. Complexity}\label{complexity-2}

Most DP algorithms are linear or quadratic in number of states:

\begin{itemize}
\tightlist
\item
  Time = (\#states) × (work per transition)- Space = (\#states) Example:
  Fibonacci: ( O(n) ) time, ( O(1) ) space Knapsack: ( O\(n \times W\) )
  LCS: ( O\(n \times m\) )
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-40}

Fibonacci (tabulated):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\DecValTok{100}\OperatorTok{];}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{];}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-40}

DP is the art of remembering. It transforms recursion into iteration,
chaos into order.

From optimization to counting, from paths to sequences , once you see
substructure, DP becomes your hammer.

\begin{quote}
``Every repetition hides a recurrence.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-40}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write top-down and bottom-up Fibonacci.
\item
  Count ways to climb stairs with steps \{1,2,3\}.
\item
  Compute number of paths in an n×m grid.
\item
  Try to spot state, recurrence, base in each problem.
\item
  Draw dependency graphs to visualize transitions.
\end{enumerate}

DP isn't a formula , it's a mindset: break problems into parts, remember
the past, and build from it.

\subsection{42. Classic Problems (Knapsack, Subset Sum, Coin
Change)}\label{classic-problems-knapsack-subset-sum-coin-change}

Now that you know what dynamic programming \emph{is}, let's dive into
the classic trio , problems that every programmer meets early on:

\begin{itemize}
\tightlist
\item
  Knapsack (maximize value under weight constraint)- Subset Sum (can we
  form a given sum?)- Coin Change (how many ways or fewest coins to
  reach a total) These are the training grounds of DP: each shows how to
  define states, transitions, and base cases clearly.
\end{itemize}

\subsubsection{1. 0/1 Knapsack Problem}\label{knapsack-problem}

Problem: You have \texttt{n} items, each with weight \texttt{w{[}i{]}}
and value \texttt{v{[}i{]}}. A knapsack with capacity \texttt{W}. Pick
items (each at most once) to maximize total value, without exceeding
weight.

\subsubsection{A. State}\label{a.-state}

\texttt{dp{[}i{]}{[}w{]}} = max value using first \texttt{i} items with
capacity \texttt{w}

\subsubsection{B. Recurrence}\label{b.-recurrence}

For item \texttt{i}:

\begin{itemize}
\tightlist
\item
  If we don't take it: \texttt{dp{[}i-1{]}{[}w{]}}- If we take it (if
  \texttt{w{[}i{]}\ ≤\ w}):
  \texttt{dp{[}i-1{]}{[}w\ -\ w{[}i{]}{]}\ +\ v{[}i{]}} So, \[
  dp[i][w] = \max(dp[i-1][w], dp[i-1][w - w[i]] + v[i])
  \]
\end{itemize}

\subsubsection{C. Base Case}\label{c.-base-case}

\texttt{dp{[}0{]}{[}w{]}\ =\ 0} for all w (no items = no value)

\subsubsection{D. Implementation}\label{d.-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ knapsack}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ W}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ w}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ v}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{W}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ W}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ j }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{w}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{\textless{}=}\NormalTok{ j}\OperatorTok{)}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j }\OperatorTok{{-}}\NormalTok{ w}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]]} \OperatorTok{+}\NormalTok{ v}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{W}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: Time: (O(nW)) Space: (O(nW)) (can be optimized to 1D (O(W)))

\subsubsection{E. Space Optimization (1D
DP)}\label{e.-space-optimization-1d-dp}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{W}\OperatorTok{+}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ w }\OperatorTok{=}\NormalTok{ W}\OperatorTok{;}\NormalTok{ w }\OperatorTok{\textgreater{}=}\NormalTok{ weight}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ w}\OperatorTok{{-}{-})}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{w}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{w}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{w }\OperatorTok{{-}}\NormalTok{ weight}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{+}\NormalTok{ value}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{F. Example}\label{f.-example}

Items:

\begin{verbatim}
w = [2, 3, 4, 5]
v = [3, 4, 5, 6]
W = 5
\end{verbatim}

Best: take items 1 + 2 → value 7

\subsubsection{2. Subset Sum}\label{subset-sum}

Problem: Given a set \texttt{S} of integers, can we pick some to sum to
\texttt{target}?

\subsubsection{A. State}\label{a.-state-1}

\texttt{dp{[}i{]}{[}sum{]}\ =\ true} if we can form sum \texttt{sum}
using first \texttt{i} elements.

\subsubsection{B. Recurrence}\label{b.-recurrence-1}

\begin{itemize}
\tightlist
\item
  Don't take: \texttt{dp{[}i-1{]}{[}sum{]}}- Take (if
  \texttt{a{[}i{]}\ ≤\ sum}): \texttt{dp{[}i-1{]}{[}sum\ -\ a{[}i{]}{]}}
  So, \[
  dp[i][sum] = dp[i-1][sum] ; || ; dp[i-1][sum - a[i]]
  \]
\end{itemize}

\subsubsection{C. Base Case}\label{c.-base-case-1}

\texttt{dp{[}0{]}{[}0{]}\ =\ true} (sum 0 possible with no elements)
\texttt{dp{[}0{]}{[}sum{]}\ =\ false} for sum \textgreater{} 0

\subsubsection{D. Implementation}\label{d.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ subset\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{bool}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{target}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ target}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ target}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ j}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{||}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]];}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{target}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: Time: (O\(n \cdot target\))

\subsubsection{E. Example}\label{e.-example}

S = {[}3, 34, 4, 12, 5, 2{]}, target = 9 Yes → 4 + 5

\subsubsection{3. Coin Change}\label{coin-change}

Two variants:

\subsubsection{(a) Count Ways (Unbounded
Coins)}\label{a-count-ways-unbounded-coins}

``How many ways to make total \texttt{T} with coins \texttt{c{[}{]}}?''

Order doesn't matter.

State:
\texttt{dp{[}i{]}{[}t{]}\ =\ ways\ using\ first\ i\ coins\ for\ total\ t}

Recurrence:

\begin{itemize}
\tightlist
\item
  Skip coin: \texttt{dp{[}i-1{]}{[}t{]}}- Take coin (unlimited):
  \texttt{dp{[}i{]}{[}t\ -\ c{[}i{]}{]}} \[
  dp[i][t] = dp[i-1][t] + dp[i][t - c[i]]
  \]
\end{itemize}

Base: \texttt{dp{[}0{]}{[}0{]}\ =\ 1}

1D Simplified:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ coin }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=}\NormalTok{ coin}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t }\OperatorTok{{-}}\NormalTok{ coin}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

\subsubsection{(b) Min Coins (Fewest Coins to Reach
Total)}\label{b-min-coins-fewest-coins-to-reach-total}

State: \texttt{dp{[}t{]}\ =\ min\ coins\ to\ reach\ t}

Recurrence: \[
dp[t] = \min_{c_i \le t}(dp[t - c_i] + 1)
\]

Base: \texttt{dp{[}0{]}\ =\ 0}, rest = INF

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{fill}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{+}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{t }\OperatorTok{\textgreater{}=}\NormalTok{ c}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t }\OperatorTok{{-}}\NormalTok{ c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Example}\label{example-1}

Coins = {[}1,2,5{]}, Total = 5

\begin{itemize}
\tightlist
\item
  Ways: 4 (5; 2+2+1; 2+1+1+1; 1+1+1+1+1)- Min Coins: 1 (5)
\end{itemize}

\subsubsection{4. Summary}\label{summary-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2535}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1408}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2958}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1408}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0/1 Knapsack & Max value & dp{[}i{]}{[}w{]} & max(take, skip) & O(nW) \\
Subset Sum & Feasibility & dp{[}i{]}{[}sum{]} & OR of include/exclude &
O(n * sum) \\
Coin Change (ways) & Counting & dp{[}t{]} & dp{[}t{]} + dp{[}t - coin{]}
& O(nT) \\
Coin Change (min) & Optimization & dp{[}t{]} & min(dp{[}t - coin{]} + 1)
& O(nT) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-41}

Min Coin Change (1D):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{fill}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{+}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=}\NormalTok{ c}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t }\OperatorTok{{-}}\NormalTok{ c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-41}

These three are archetypes:

\begin{itemize}
\tightlist
\item
  Knapsack: optimize under constraint- Subset Sum: choose feasibility-
  Coin Change: count or minimize Once you master them, you can spot
  their patterns in harder problems , from resource allocation to
  pathfinding.
\end{itemize}

\begin{quote}
``Every constraint hides a choice; every choice hides a state.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-41}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement 0/1 Knapsack (2D and 1D).
\item
  Solve Subset Sum for target 30 with random list.
\item
  Count coin combinations for amount 10.
\item
  Compare ``min coins'' vs ``ways to form.''
\item
  Write down state-transition diagram for each.
\end{enumerate}

These three form your DP foundation , the grammar for building more
complex algorithms.

\subsection{43. Sequence Problems (LIS, LCS, Edit
Distance)}\label{sequence-problems-lis-lcs-edit-distance}

Sequence problems form the \emph{heart} of dynamic programming. They
appear in strings, arrays, genomes, text comparison, and version
control. Their power comes from comparing prefixes , building large
answers from aligned smaller ones.

This section explores three cornerstones:

\begin{itemize}
\tightlist
\item
  LIS (Longest Increasing Subsequence)- LCS (Longest Common
  Subsequence)- Edit Distance (Levenshtein Distance) Each teaches a new
  way to think about subproblems, transitions, and structure.
\end{itemize}

\subsubsection{1. Longest Increasing Subsequence
(LIS)}\label{longest-increasing-subsequence-lis}

Problem: Given an array, find the length of the longest subsequence that
is \emph{strictly increasing}.

A subsequence isn't necessarily contiguous , you can skip elements.

Example: \texttt{{[}10,\ 9,\ 2,\ 5,\ 3,\ 7,\ 101,\ 18{]}} → LIS is
\texttt{{[}2,\ 3,\ 7,\ 18{]}} → length 4

\subsubsection{A. State}\label{a.-state-2}

\texttt{dp{[}i{]}} = length of LIS ending at index \texttt{i}

\subsubsection{B. Recurrence}\label{b.-recurrence-2}

\[
dp[i] = 1 + \max_{j < i \land a[j] < a[i]} dp[j]
\]

If no smaller \texttt{a{[}j{]}}, then \texttt{dp{[}i{]}\ =\ 1}.

\subsubsection{C. Base}\label{c.-base}

\texttt{dp{[}i{]}\ =\ 1} for all i (each element alone is an LIS)

\subsubsection{D. Implementation}\label{d.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lis}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{],}\NormalTok{ best }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{        best }\OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{best}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ best}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^2\))

\subsubsection{E. Binary Search
Optimization}\label{e.-binary-search-optimization}

Use a tail array:

\begin{itemize}
\item
  \texttt{tail{[}len{]}\ =\ min\ possible\ ending\ value\ of\ LIS\ of\ length\ len}
  For each \texttt{x}:
\item
  Replace \texttt{tail{[}idx{]}} via lower\_bound
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lis\_fast}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ tail}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ x }\OperatorTok{:}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\{}
        \KeywordTok{auto}\NormalTok{ it }\OperatorTok{=}\NormalTok{ lower\_bound}\OperatorTok{(}\NormalTok{tail}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ tail}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),}\NormalTok{ x}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{it }\OperatorTok{==}\NormalTok{ tail}\OperatorTok{.}\NormalTok{end}\OperatorTok{())}\NormalTok{ tail}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{x}\OperatorTok{);}
        \ControlFlowTok{else} \OperatorTok{*}\NormalTok{it }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ tail}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n \log n\))

\subsubsection{2. Longest Common Subsequence
(LCS)}\label{longest-common-subsequence-lcs}

Problem: Given two strings, find the longest subsequence present in
both.

Example: \texttt{s1\ =\ "ABCBDAB"}, \texttt{s2\ =\ "BDCABA"} LCS =
``BCBA'' → length 4

\subsubsection{A. State}\label{a.-state-3}

\texttt{dp{[}i{]}{[}j{]}} = LCS length between \texttt{s1{[}0..i-1{]}}
and \texttt{s2{[}0..j-1{]}}

\subsubsection{B. Recurrence}\label{b.-recurrence-3}

\[
dp[i][j] =
\begin{cases}
dp[i-1][j-1] + 1, & \text{if } s_1[i-1] = s_2[j-1], \\
\max(dp[i-1][j],\, dp[i][j-1]), & \text{otherwise.}
\end{cases}
\]

\subsubsection{C. Base}\label{c.-base-1}

\texttt{dp{[}0{]}{[}*{]}\ =\ dp{[}*{]}{[}0{]}\ =\ 0} (empty string)

\subsubsection{D. Implementation}\label{d.-implementation-3}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lcs}\OperatorTok{(}\NormalTok{string a}\OperatorTok{,}\NormalTok{ string b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{(),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ b}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ j }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O(nm))

\subsubsection{E. Reconstruct LCS}\label{e.-reconstruct-lcs}

Trace back from \texttt{dp{[}n{]}{[}m{]}}:

\begin{itemize}
\tightlist
\item
  If chars equal → take it and move diagonally- Else move toward larger
  neighbor
\end{itemize}

\subsubsection{F. Example}\label{f.-example-1}

a = ``AGGTAB'', b = ``GXTXAYB'' LCS = ``GTAB'' → 4

\subsubsection{3. Edit Distance (Levenshtein
Distance)}\label{edit-distance-levenshtein-distance}

Problem: Minimum operations (insert, delete, replace) to convert string
\texttt{a} → \texttt{b}.

Example: \texttt{kitten\ →\ sitting} = 3 (replace k→s, insert i, insert
g)

\subsubsection{A. State}\label{a.-state-4}

\texttt{dp{[}i{]}{[}j{]}} = min edits to convert \texttt{a{[}0..i-1{]}}
→ \texttt{b{[}0..j-1{]}}

\subsubsection{B. Recurrence}\label{b.-recurrence-4}

If \texttt{a{[}i-1{]}\ ==\ b{[}j-1{]}}: \[
dp[i][j] = dp[i-1][j-1]
\]

Else: \[
dp[i][j] = 1 + \min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
\] (Delete, Insert, Replace)

\subsubsection{C. Base}\label{c.-base-2}

\begin{itemize}
\tightlist
\item
  \texttt{dp{[}0{]}{[}j{]}\ =\ j} (insert all)-
  \texttt{dp{[}i{]}{[}0{]}\ =\ i} (delete all)
\end{itemize}

\subsubsection{D. Implementation}\label{d.-implementation-4}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ edit\_distance}\OperatorTok{(}\NormalTok{string a}\OperatorTok{,}\NormalTok{ string b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{(),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ b}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{j }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ min}\OperatorTok{(\{}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]\});}
        \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O(nm))

\subsubsection{E. Example}\label{e.-example-1}

a = ``horse'', b = ``ros''

\begin{itemize}
\tightlist
\item
  replace h→r, delete r, delete e → 3
\end{itemize}

\subsubsection{4. Summary}\label{summary-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1806}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LIS & Single seq & dp{[}i{]} & 1 + max(dp{[}j{]}) & O(n²) / O(n log
n) \\
LCS & Two seqs & dp{[}i{]}{[}j{]} & if match +1 else max & O(nm) \\
Edit Distance & Two seqs & dp{[}i{]}{[}j{]} & if match 0 else 1 + min &
O(nm) \\
\end{longtable}

\subsubsection{5. Common Insights}\label{common-insights}

\begin{itemize}
\tightlist
\item
  LIS builds upward , from smaller sequences.- LCS aligns two sequences
  , compare prefixes.- Edit Distance quantifies \emph{difference} ,
  minimal edits. They're templates for bioinformatics, text diffing,
  version control, and more.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-42}

LCS:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\ControlFlowTok{else}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-42}

Sequence DPs teach you how to compare progressions , how structure and
similarity evolve over time.

They transform vague ``compare these'' tasks into crisp recurrence
relations.

\begin{quote}
``To align is to understand.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-42}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement LIS (O(n²) and O(n log n))
\item
  Find LCS of two given strings
\item
  Compute edit distance between ``intention'' and ``execution''
\item
  Modify LCS to print one valid subsequence
\item
  Try to unify LCS and Edit Distance in a single table
\end{enumerate}

Master these, and you can handle any DP on sequences , the DNA of
algorithmic thinking.

\subsection{44. Matrix and Chain
Problems}\label{matrix-and-chain-problems}

Dynamic programming shines when a problem involves choices over
intervals , which order, which split, which parenthesis. This chapter
explores a class of problems built on chains and matrices, where order
matters and substructure is defined by intervals.

We'll study:

\begin{itemize}
\tightlist
\item
  Matrix Chain Multiplication (MCM) - optimal parenthesization- Polygon
  Triangulation - divide shape into minimal-cost triangles- Optimal BST
  / Merge Patterns - weighted merging decisions These problems teach
  interval DP, where each state represents a segment ({[}i, j{]}).
\end{itemize}

\subsubsection{1. Matrix Chain Multiplication
(MCM)}\label{matrix-chain-multiplication-mcm}

Problem: Given matrices \(A_1, A_2, ..., A_n\), find the
parenthesization that minimizes total scalar multiplications.

Matrix \(A_i\) has dimensions \(p[i-1] \times p[i]\). We can multiply
\(A_i \cdot A_{i+1}\) only if inner dimensions match.

Goal: Minimize operations: \[
\text{cost}(i, j) = \min_k \big(\text{cost}(i, k) + \text{cost}(k+1, j) + p[i-1] \cdot p[k] \cdot p[j]\big)
\]

\subsubsection{A. State}\label{a.-state-5}

\texttt{dp{[}i{]}{[}j{]}} = min multiplications to compute \(A_i...A_j\)

\subsubsection{B. Base}\label{b.-base}

\texttt{dp{[}i{]}{[}i{]}\ =\ 0} (single matrix needs no multiplication)

\subsubsection{C. Recurrence}\label{c.-recurrence}

\[
dp[i][j] = \min_{i \le k < j} { dp[i][k] + dp[k+1][j] + p[i-1] \times p[k] \times p[j] }
\]

\subsubsection{D. Implementation}\label{d.-implementation-5}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ matrix\_chain}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ p}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INT\_MAX}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}
\NormalTok{                    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{][}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^3\)) time, (O\(n^2\)) space

\subsubsection{E. Example}\label{e.-example-2}

p = {[}10, 20, 30, 40, 30{]} Optimal order: ((A1A2)A3)A4 → cost 30000

\subsubsection{2. Polygon Triangulation}\label{polygon-triangulation}

Given a convex polygon with \texttt{n} vertices, connect
non-intersecting diagonals to minimize total cost. Cost of a triangle =
perimeter or product of side weights.

This is the same structure as MCM , divide polygon by diagonals.

\subsubsection{A. State}\label{a.-state-6}

\texttt{dp{[}i{]}{[}j{]}} = min triangulation cost for polygon vertices
from i to j.

\subsubsection{B. Recurrence}\label{b.-recurrence-5}

\[
dp[i][j] = \min_{i < k < j} (dp[i][k] + dp[k][j] + cost(i, j, k))
\]

Base: dp{[}i{]}{[}i+1{]} = 0 (fewer than 3 points)

\subsubsection{C. Implementation}\label{c.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ polygon\_triangulation}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Point}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ p}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \DataTypeTok{double}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \FloatTok{1e18}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}
\NormalTok{                    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dist}\OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{])+}\NormalTok{dist}\OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{],}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{])+}\NormalTok{dist}\OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{],}\NormalTok{p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]));}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^3\))

\subsubsection{3. Optimal Binary Search Tree
(OBST)}\label{optimal-binary-search-tree-obst}

Given sorted keys \(k_1 < k_2 < \dots < k_n\) with search frequencies (
f{[}i{]} ), construct a BST with minimal expected search cost.

The more frequently accessed nodes should be nearer the root.

\subsubsection{A. State}\label{a.-state-7}

\texttt{dp{[}i{]}{[}j{]}} = min cost to build BST from keys
\texttt{i..j} \texttt{sum{[}i{]}{[}j{]}} = sum of frequencies from i to
j (precomputed)

\subsubsection{B. Recurrence}\label{b.-recurrence-6}

\[
dp[i][j] = \min_{k=i}^{j} (dp[i][k-1] + dp[k+1][j] + sum[i][j])
\]

Each root adds one to depth of its subtrees → extra cost =
\texttt{sum{[}i{]}{[}j{]}}

\subsubsection{C. Implementation}\label{c.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ optimal\_bst}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ freq}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{],}\NormalTok{ sum}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ freq}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ freq}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{            sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ freq}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+}\NormalTok{len}\OperatorTok{{-}}\DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INT\_MAX}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ r }\OperatorTok{\textless{}=}\NormalTok{ j}\OperatorTok{;}\NormalTok{ r}\OperatorTok{++)} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ left }\OperatorTok{=} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textgreater{}}\NormalTok{ i}\OperatorTok{)} \OperatorTok{?}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{r}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{:} \DecValTok{0}\OperatorTok{;}
                \DataTypeTok{int}\NormalTok{ right }\OperatorTok{=} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)} \OperatorTok{?}\NormalTok{ dp}\OperatorTok{[}\NormalTok{r}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{:} \DecValTok{0}\OperatorTok{;}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ left }\OperatorTok{+}\NormalTok{ right }\OperatorTok{+}\NormalTok{ sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^3\))

\subsubsection{4. Merge Pattern Problems}\label{merge-pattern-problems}

Many problems , merging files, joining ropes, Huffman coding , involve
repeatedly combining elements with minimal total cost.

All follow this template: \[
dp[i][j] = \min_{k} (dp[i][k] + dp[k+1][j] + \text{merge cost})
\]

Same structure as MCM.

\subsubsection{5. Key Pattern: Interval
DP}\label{key-pattern-interval-dp}

State:
\texttt{dp{[}i{]}{[}j{]}\ =\ best\ answer\ for\ subarray\ {[}i..j{]}}
Transition: Try all splits \texttt{k} between \texttt{i} and \texttt{j}

Template:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)}
 \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{       dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{j}\OperatorTok{,}\NormalTok{k}\OperatorTok{));}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{6. Summary}\label{summary-5}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1250}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Recurrence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MCM & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k{]}+dp{[}k+1{]}{[}j{]}+p{[}i-1{]}\emph{p{[}k{]}}p{[}j{]})
& O(n³) \\
Polygon Triangulation & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k{]}+dp{[}k{]}{[}j{]}+cost) & O(n³) \\
OBST & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k-1{]}+dp{[}k+1{]}{[}j{]}+sum{[}i{]}{[}j{]}) & O(n³) \\
Merge Problems & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k{]}+dp{[}k+1{]}{[}j{]}+merge cost) & O(n³) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-43}

Matrix Chain (Compact):

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
  \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-43}

These problems are DP in 2D , reasoning over intervals and splits. They
train your ability to ``cut the problem'' at every possible point.

\begin{quote}
``Between every start and end lies a choice of where to divide.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-43}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement MCM and print parenthesization.
\item
  Solve polygon triangulation with edge weights.
\item
  Build OBST for frequencies {[}34, 8, 50{]}.
\item
  Visualize DP table diagonally.
\item
  Generalize to merging \texttt{k} segments at a time.
\end{enumerate}

Master these, and you'll see interval DP patterns hiding in parsing,
merging, and even AI planning.

\subsection{45. Bitmask DP and Traveling
Salesman}\label{bitmask-dp-and-traveling-salesman}

Some dynamic programming problems require you to track which items have
been used, or which subset of elements is active at a given point. This
is where Bitmask DP shines. It encodes subsets as binary masks, allowing
you to represent state space efficiently.

This technique is a must-know for:

\begin{itemize}
\tightlist
\item
  Traveling Salesman Problem (TSP)- Subset covering / visiting problems-
  Permutations and combinations of sets- Game states and toggles
\end{itemize}

\subsubsection{1. The Idea of Bitmask DP}\label{the-idea-of-bitmask-dp}

A bitmask is an integer whose binary representation encodes a subset.

For ( n ) elements:

\begin{itemize}
\tightlist
\item
  There are \(2^n\) subsets.- A subset is represented by a mask from
  \texttt{0} to \texttt{(1\ \textless{}\textless{}\ n)\ -\ 1}. Example
  for \texttt{n\ =\ 4}:
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Subset & Mask (binary) & Mask (decimal) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
∅ & 0000 & 0 \\
\{0\} & 0001 & 1 \\
\{1\} & 0010 & 2 \\
\{0,1,3\} & 1011 & 11 \\
\end{longtable}

We can check membership:

\begin{itemize}
\tightlist
\item
  \texttt{mask\ \&\ (1\ \textless{}\textless{}\ i)} → whether element
  \texttt{i} is in subset We can add elements:
\item
  \texttt{mask\ \textbar{}\ (1\ \textless{}\textless{}\ i)} → add
  element \texttt{i} We can remove elements:
\item
  \texttt{mask\ \&\ \textasciitilde{}(1\ \textless{}\textless{}\ i)} →
  remove element \texttt{i}
\end{itemize}

\subsubsection{2. Example: Traveling Salesman Problem
(TSP)}\label{example-traveling-salesman-problem-tsp}

Problem: Given \texttt{n} cities and cost matrix
\texttt{cost{[}i{]}{[}j{]}}, find the minimum cost Hamiltonian cycle
visiting all cities exactly once and returning to start.

\subsubsection{A. State}\label{a.-state-8}

\texttt{dp{[}mask{]}{[}i{]}} = minimum cost to reach city \texttt{i}
having visited subset \texttt{mask}

\begin{itemize}
\tightlist
\item
  \texttt{mask} → set of visited cities- \texttt{i} → current city
\end{itemize}

\subsubsection{B. Base Case}\label{b.-base-case}

\texttt{dp{[}1\textless{}\textless{}0{]}{[}0{]}\ =\ 0} (start at city 0,
only 0 visited)

\subsubsection{C. Transition}\label{c.-transition}

For each subset \texttt{mask} and city \texttt{i} in \texttt{mask}, try
moving from \texttt{i} to \texttt{j} not in \texttt{mask}:

\[
dp[mask \cup (1 << j)][j] = \min \big(dp[mask \cup (1 << j)][j], dp[mask][i] + cost[i][j]\big)
\]

\subsubsection{D. Implementation}\label{d.-implementation-6}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ tsp}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ cost}\OperatorTok{[}\DecValTok{20}\OperatorTok{][}\DecValTok{20}\OperatorTok{])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{N}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ m }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ m}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{m}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}

\NormalTok{    dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;} \CommentTok{// start at city 0}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ mask}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{)))} \ControlFlowTok{continue}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ j}\OperatorTok{))} \ControlFlowTok{continue}\OperatorTok{;}
                \DataTypeTok{int}\NormalTok{ next }\OperatorTok{=}\NormalTok{ mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ j}\OperatorTok{);}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{next}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{next}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \DataTypeTok{int}\NormalTok{ ans }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        ans }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{ans}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{N}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ ans}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  States: ( O\(n \cdot 2^n\) )- Transitions: ( O(n) )- Total: (
  O\(n^2 \cdot 2^n\) )
\end{itemize}

\subsubsection{E. Example}\label{e.-example-3}

\begin{verbatim}
n = 4
cost = {
 {0, 10, 15, 20},
 {10, 0, 35, 25},
 {15, 35, 0, 30},
 {20, 25, 30, 0}
}
\end{verbatim}

Optimal path: 0 → 1 → 3 → 2 → 0 Cost = 80

\subsubsection{3. Other Common Bitmask DP
Patterns}\label{other-common-bitmask-dp-patterns}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Subset Sum / Partition
  \texttt{dp{[}mask{]}\ =\ true\ if\ subset\ represented\ by\ mask\ satisfies\ property}
\item
  Counting Set Bits \texttt{\_\_builtin\_popcount(mask)} gives number of
  elements in subset.
\item
  Iterating Over Submasks
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ sub }\OperatorTok{=}\NormalTok{ mask}\OperatorTok{;}\NormalTok{ sub}\OperatorTok{;}\NormalTok{ sub }\OperatorTok{=} \OperatorTok{(}\NormalTok{sub}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\&}\NormalTok{ mask}\OperatorTok{)}
    \CommentTok{// handle subset sub}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Assigning Tasks (Assignment Problem)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Each mask represents set of workers assigned.- State:
  \texttt{dp{[}mask{]}\ =\ min\ cost\ for\ assigned\ tasks}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask}\OperatorTok{)} \ControlFlowTok{for} \OperatorTok{(}\NormalTok{task}\OperatorTok{)}
 \ControlFlowTok{if} \OperatorTok{(!(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ task}\OperatorTok{)))}
\NormalTok{   dp}\OperatorTok{[}\NormalTok{mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ task}\OperatorTok{)]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ task}\OperatorTok{)],}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{\_\_builtin\_popcount}\OperatorTok{(}\NormalTok{mask}\OperatorTok{)][}\NormalTok{task}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Memory Tricks}\label{memory-tricks}

\begin{itemize}
\tightlist
\item
  If only previous masks needed, use rolling arrays:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{next}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \OperatorTok{...}
\NormalTok{swap}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,}\NormalTok{ next\_dp}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Compress dimensions: (O\(2^n\)) memory for small \texttt{n}
\end{itemize}

\subsubsection{5. Summary}\label{summary-6}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
TSP & dp{[}mask{]}{[}i{]} & min(dp{[}mask{]}{[}i{]} +
cost{[}i{]}{[}j{]}) & O(n²·2ⁿ) \\
Assignment & dp{[}mask{]} & add one new element & O(n²·2ⁿ) \\
Subset Sum & dp{[}mask{]} & union of valid subsets & O(2ⁿ·n) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-44}

Core Transition:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask}\OperatorTok{)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{i}\OperatorTok{))}
      \ControlFlowTok{for} \OperatorTok{(}\NormalTok{j}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(!(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{j}\OperatorTok{)))}
\NormalTok{          dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{|(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{j}\OperatorTok{)][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{|(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{j}\OperatorTok{)][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-44}

Bitmask DP is how you enumerate subsets efficiently. It bridges
combinatorics and optimization, solving exponential problems with
manageable constants.

\begin{quote}
``Every subset is a story, and bits are its alphabet.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-44}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve TSP with 4 cities (hand-trace the table).
\item
  Implement Assignment Problem using bitmask DP.
\item
  Count subsets with even sum.
\item
  Use bitmask DP to find maximum compatible set of tasks.
\item
  Explore how to optimize memory with bit tricks.
\end{enumerate}

Bitmask DP unlocks the world of subset-based reasoning , the foundation
of combinatorial optimization.

\subsection{46. Digit DP and SOS DP}\label{digit-dp-and-sos-dp}

In some problems, you don't iterate over indices or subsets , you
iterate over digits or masks to count or optimize over structured
states. Two major flavors stand out:

\begin{itemize}
\tightlist
\item
  Digit DP - counting numbers with certain properties (e.g.~digit sum,
  constraints)- SOS DP (Sum Over Subsets) - efficiently computing
  functions over all subsets These are essential techniques when brute
  force would require enumerating every number or subset, which quickly
  becomes impossible.
\end{itemize}

\subsubsection{1. Digit DP (Counting with
Constraints)}\label{digit-dp-counting-with-constraints}

Digit DP is used to count or sum over all numbers ≤ N that satisfy a
condition, such as:

\begin{itemize}
\tightlist
\item
  The sum of digits equals a target.- The number doesn't contain a
  forbidden digit.- The number has certain parity or divisibility.
  Instead of iterating over all numbers (up to 10¹⁸!), we iterate
  digit-by-digit.
\end{itemize}

\subsubsection{A. State Design}\label{a.-state-design}

Typical DP state:

\texttt{dp{[}pos{]}{[}sum{]}{[}tight{]}{[}leading\_zero{]}}

\begin{itemize}
\tightlist
\item
  \texttt{pos}: current digit index (from most significant to least)-
  \texttt{sum}: property tracker (e.g.~sum of digits, remainder)-
  \texttt{tight}: whether we're still restricted by N's prefix-
  \texttt{leading\_zero}: whether we've started placing nonzero digits
\end{itemize}

\subsubsection{B. Transition}\label{b.-transition}

At each digit position, we choose a digit \texttt{d}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{limit }\OperatorTok{=}\NormalTok{ tight }\OperatorTok{?} \OperatorTok{(}\NormalTok{digit at pos in N}\OperatorTok{)} \OperatorTok{:} \DecValTok{9}
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ limit}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    new\_tight }\OperatorTok{=}\NormalTok{ tight }\OperatorTok{\&\&} \OperatorTok{(}\NormalTok{d }\OperatorTok{==}\NormalTok{ limit}\OperatorTok{)}
\NormalTok{    new\_sum }\OperatorTok{=}\NormalTok{ sum }\OperatorTok{+}\NormalTok{ d}
    \CommentTok{// or new\_mod = (mod * 10 + d) \% M}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Transition accumulates results across valid choices.

\subsubsection{C. Base Case}\label{c.-base-case-2}

When \texttt{pos\ ==\ len(N)} (end of digits):

\begin{itemize}
\tightlist
\item
  Return 1 if condition holds (e.g.~\texttt{sum\ ==\ target}), else 0
\end{itemize}

\subsubsection{D. Example: Count numbers ≤ N with digit sum =
S}\label{d.-example-count-numbers-n-with-digit-sum-s}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ dp}\OperatorTok{[}\DecValTok{20}\OperatorTok{][}\DecValTok{200}\OperatorTok{][}\DecValTok{2}\OperatorTok{];}

\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ solve}\OperatorTok{(}\NormalTok{string s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pos}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sum}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ tight}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{==}\NormalTok{ s}\OperatorTok{.}\NormalTok{size}\OperatorTok{())} \ControlFlowTok{return}\NormalTok{ sum }\OperatorTok{==} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sum }\OperatorTok{\textless{}} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{];}

    \DataTypeTok{int}\NormalTok{ limit }\OperatorTok{=}\NormalTok{ tight }\OperatorTok{?} \OperatorTok{(}\NormalTok{s}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{{-}} \CharTok{\textquotesingle{}0\textquotesingle{}}\OperatorTok{)} \OperatorTok{:} \DecValTok{9}\OperatorTok{;}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ limit}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)}
\NormalTok{        res }\OperatorTok{+=}\NormalTok{ solve}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ sum}\OperatorTok{{-}}\NormalTok{d}\OperatorTok{,}\NormalTok{ tight }\OperatorTok{\&\&} \OperatorTok{(}\NormalTok{d}\OperatorTok{==}\NormalTok{limit}\OperatorTok{));}

    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{]} \OperatorTok{=}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Usage:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{string N }\OperatorTok{=} \StringTok{"12345"}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ S }\OperatorTok{=} \DecValTok{9}\OperatorTok{;}
\NormalTok{memset}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,} \KeywordTok{sizeof}\NormalTok{ dp}\OperatorTok{);}
\NormalTok{cout }\OperatorTok{\textless{}\textless{}}\NormalTok{ solve}\OperatorTok{(}\NormalTok{N}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ S}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Complexity: O(number of digits × sum × 2) → typically O(20 × 200 × 2)

\subsubsection{E. Example Variants}\label{e.-example-variants}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Count numbers divisible by 3 → track remainder:
  \texttt{new\_rem\ =\ (rem*10\ +\ d)\ \%\ 3}
\item
  Count numbers without consecutive equal digits → add
  \texttt{last\_digit} to state.
\item
  Count beautiful numbers (like palindromes, no repeated digits) → track
  bitmask of used digits.
\end{enumerate}

\subsubsection{F. Summary}\label{f.-summary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sum of digits = S & dp{[}pos{]}{[}sum{]}{[}tight{]} & sum-d &
O(len·S) \\
Divisible by k & dp{[}pos{]}{[}rem{]}{[}tight{]} & (rem*10+d)\%k &
O(len·k) \\
No repeated digits & dp{[}pos{]}{[}mask{]}{[}tight{]} & mask &
O(len·2¹⁰) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-45}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ limit}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)}
\NormalTok{    res }\OperatorTok{+=}\NormalTok{ solve}\OperatorTok{(}\NormalTok{pos}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ sum}\OperatorTok{{-}}\NormalTok{d}\OperatorTok{,}\NormalTok{ tight }\OperatorTok{\&\&} \OperatorTok{(}\NormalTok{d}\OperatorTok{==}\NormalTok{limit}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. SOS DP (Sum Over
Subsets)}\label{sos-dp-sum-over-subsets}

When dealing with functions on subsets, we sometimes need to compute:

\[
f(S) = \sum_{T \subseteq S} g(T)
\]

Naively O(3ⁿ). SOS DP reduces it to O(n·2ⁿ).

\subsubsection{A. Setup}\label{a.-setup}

Let \texttt{f{[}mask{]}\ =\ g{[}mask{]}} initially. For each bit
\texttt{i}:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{n}\OperatorTok{);}\NormalTok{ mask}\OperatorTok{++)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{i}\OperatorTok{))}
\NormalTok{        f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{\^{}(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{i}\OperatorTok{)];}
\end{Highlighting}
\end{Shaded}

After this, \texttt{f{[}mask{]}} = sum of \texttt{g{[}sub{]}} for all
\texttt{sub\ ⊆\ mask}.

\subsubsection{B. Example}\label{b.-example-3}

Given array \texttt{a{[}mask{]}}, compute
\texttt{sum{[}mask{]}\ =\ sum\_\{sub\ ⊆\ mask\}\ a{[}sub{]}}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ n }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ n}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ f}\OperatorTok{[}\NormalTok{N}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}
\CommentTok{// initialize a[]}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ mask}\OperatorTok{++)}\NormalTok{ f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{mask}\OperatorTok{];}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ mask}\OperatorTok{++)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{))}
\NormalTok{        f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ f}\OperatorTok{[}\NormalTok{mask }\OperatorTok{\^{}} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{)];}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Why It Works}\label{c.-why-it-works}

Each iteration adds contributions from subsets differing by one bit. By
processing all bits, every subset's contribution propagates upward.

\subsubsection{D. Variants}\label{d.-variants-1}

\begin{itemize}
\tightlist
\item
  Sum over supersets: reverse direction.- Max instead of sum: replace
  \texttt{+=} with \texttt{max=}.- XOR convolution: combine values under
  XOR subset relation.
\end{itemize}

\subsubsection{E. Applications}\label{e.-applications}

\begin{itemize}
\tightlist
\item
  Inclusion-exclusion acceleration- Precomputing subset statistics- DP
  over masks with subset transitions
\end{itemize}

\subsubsection{F. Complexity}\label{f.-complexity}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Naive & SOS DP \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Subset sum & O(3ⁿ) & O(n·2ⁿ) \\
Superset sum & O(3ⁿ) & O(n·2ⁿ) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-45}

Digit DP teaches counting under constraints , thinking digit by digit.
SOS DP teaches subset propagation , spreading information efficiently.

Together, they show how to tame exponential state spaces with structure.

\begin{quote}
``When the search space explodes, symmetry and structure are your
compass.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-45}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count numbers ≤ 10⁹ whose digit sum = 10.
\item
  Count numbers ≤ 10⁶ without repeated digits.
\item
  Compute f{[}mask{]} = sum\_\{sub⊆mask\} a{[}sub{]} for n=4.
\item
  Use SOS DP to find how many subsets of bits have even sum.
\item
  Modify Digit DP to handle leading zeros explicitly.
\end{enumerate}

Master these, and you can handle structured exponential problems with
elegance and speed.

\subsection{47. DP Optimizations (Divide \& Conquer, Convex Hull Trick,
Knuth)}\label{dp-optimizations-divide-conquer-convex-hull-trick-knuth}

Dynamic Programming often starts with a simple recurrence, but naïve
implementations can be too slow (e.g., ( O\(n^2\) ) or worse). When the
recurrence has special structure , such as monotonicity or convexity ,
we can exploit it to reduce time complexity drastically.

This chapter introduces three powerful optimization families:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide and Conquer DP
\item
  Convex Hull Trick (CHT)
\item
  Knuth Optimization
\end{enumerate}

Each one is based on discovering order or geometry hidden inside
transitions.

\subsubsection{1. Divide and Conquer
Optimization}\label{divide-and-conquer-optimization}

If you have a recurrence like: \[
dp[i] = \min_{k < i} { dp[k] + C(k, i) }
\]

and the optimal k for dp{[}i{]} ≤ optimal k for dp{[}i+1{]}, you can use
divide \& conquer to compute dp in ( O\(n \log n\) ) or (
O\(n \log^2 n\) ).

This property is called monotonicity of argmin.

\subsubsection{A. Conditions}\label{a.-conditions}

Let ( C(k, i) ) be the cost to transition from ( k ) to ( i ). Divide
and conquer optimization applies if:

\[
opt(i) \le opt(i+1)
\]

and ( C ) satisfies quadrangle inequality (or similar convex structure).

\subsubsection{B. Template}\label{b.-template}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ compute}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optL}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optR}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textgreater{}}\NormalTok{ r}\OperatorTok{)} \ControlFlowTok{return}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{l }\OperatorTok{+}\NormalTok{ r}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{    pair}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ best }\OperatorTok{=} \OperatorTok{\{}\NormalTok{INF}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ optL}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}=}\NormalTok{ min}\OperatorTok{(}\NormalTok{mid}\OperatorTok{,}\NormalTok{ optR}\OperatorTok{);}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ val }\OperatorTok{=}\NormalTok{ dp\_prev}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{k}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textless{}}\NormalTok{ best}\OperatorTok{.}\NormalTok{first}\OperatorTok{)}\NormalTok{ best }\OperatorTok{=} \OperatorTok{\{}\NormalTok{val}\OperatorTok{,}\NormalTok{ k}\OperatorTok{\};}
    \OperatorTok{\}}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{=}\NormalTok{ best}\OperatorTok{.}\NormalTok{first}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ opt }\OperatorTok{=}\NormalTok{ best}\OperatorTok{.}\NormalTok{second}\OperatorTok{;}
\NormalTok{    compute}\OperatorTok{(}\NormalTok{l}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ optL}\OperatorTok{,}\NormalTok{ opt}\OperatorTok{);}
\NormalTok{    compute}\OperatorTok{(}\NormalTok{mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ r}\OperatorTok{,}\NormalTok{ opt}\OperatorTok{,}\NormalTok{ optR}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

You call it as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compute}\OperatorTok{(}\DecValTok{1}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example: Divide Array into K
Segments}\label{c.-example-divide-array-into-k-segments}

Given array \texttt{a{[}1..n{]}}, divide into \texttt{k} parts to
minimize \[
dp[i][k] = \min_{j < i} dp[j][k-1] + cost(j+1, i)
\] If cost satisfies quadrangle inequality, you can optimize each layer
in ( O\(n \log n\) ).

\subsubsection{D. Complexity}\label{d.-complexity-1}

Naive: ( O\(n^2\) ) → Optimized: ( O\(n \log n\) )

\subsubsection{2. Convex Hull Trick (CHT)}\label{convex-hull-trick-cht}

Applies when DP recurrence is linear in i and k: \[
dp[i] = \min_{k < i} (m_k \cdot x_i + b_k)
\]

where:

\begin{itemize}
\tightlist
\item
  \(m_k\) is slope (depends on k)- ( b\_k = dp{[}k{]} + c(k) )- \(x_i\)
  is known (monotonic) You can maintain lines \(y = m_k x + b_k\) in a
  convex hull, and query min efficiently.
\end{itemize}

\subsubsection{A. Conditions}\label{a.-conditions-1}

\begin{itemize}
\tightlist
\item
  Slopes \(m_k\) are monotonic (either increasing or decreasing)- Query
  points \(x_i\) are sorted If both monotonic, we can use pointer walk
  in O(1) amortized per query. Otherwise, use Li Chao Tree (O(log n)).
\end{itemize}

\subsubsection{B. Implementation (Monotonic
Slopes)}\label{b.-implementation-monotonic-slopes}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Line }\OperatorTok{\{} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{,}\NormalTok{ b}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{deque}\OperatorTok{\textless{}}\NormalTok{Line}\OperatorTok{\textgreater{}}\NormalTok{ hull}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ bad}\OperatorTok{(}\NormalTok{Line l1}\OperatorTok{,}\NormalTok{ Line l2}\OperatorTok{,}\NormalTok{ Line l3}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{l3}\OperatorTok{.}\NormalTok{b }\OperatorTok{{-}}\NormalTok{ l1}\OperatorTok{.}\NormalTok{b}\OperatorTok{)*(}\NormalTok{l1}\OperatorTok{.}\NormalTok{m }\OperatorTok{{-}}\NormalTok{ l2}\OperatorTok{.}\NormalTok{m}\OperatorTok{)} \OperatorTok{\textless{}=} \OperatorTok{(}\NormalTok{l2}\OperatorTok{.}\NormalTok{b }\OperatorTok{{-}}\NormalTok{ l1}\OperatorTok{.}\NormalTok{b}\OperatorTok{)*(}\NormalTok{l1}\OperatorTok{.}\NormalTok{m }\OperatorTok{{-}}\NormalTok{ l3}\OperatorTok{.}\NormalTok{m}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Line l }\OperatorTok{=} \OperatorTok{\{}\NormalTok{m}\OperatorTok{,}\NormalTok{ b}\OperatorTok{\};}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{hull}\OperatorTok{.}\NormalTok{size}\OperatorTok{()} \OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&}\NormalTok{ bad}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{hull}\OperatorTok{.}\NormalTok{size}\OperatorTok{(){-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{.}\NormalTok{back}\OperatorTok{(),}\NormalTok{ l}\OperatorTok{))}
\NormalTok{        hull}\OperatorTok{.}\NormalTok{pop\_back}\OperatorTok{();}
\NormalTok{    hull}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{l}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{hull}\OperatorTok{.}\NormalTok{size}\OperatorTok{()} \OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&} 
\NormalTok{          hull}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{m}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ hull}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{b }\OperatorTok{\textgreater{}=}\NormalTok{ hull}\OperatorTok{[}\DecValTok{1}\OperatorTok{].}\NormalTok{m}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ hull}\OperatorTok{[}\DecValTok{1}\OperatorTok{].}\NormalTok{b}\OperatorTok{)}
\NormalTok{        hull}\OperatorTok{.}\NormalTok{pop\_front}\OperatorTok{();}
    \ControlFlowTok{return}\NormalTok{ hull}\OperatorTok{.}\NormalTok{front}\OperatorTok{().}\NormalTok{m}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ hull}\OperatorTok{.}\NormalTok{front}\OperatorTok{().}\NormalTok{b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example: DP for Line-Based
Recurrence}\label{c.-example-dp-for-line-based-recurrence}

\[
dp[i] = a_i^2 + \min_{j < i} (dp[j] + b_j \cdot a_i)
\] Here \(m_j = b_j\), \(x_i = a_i\), \(b_j = dp[j]\)

\subsubsection{D. Complexity}\label{d.-complexity-2}

\begin{itemize}
\tightlist
\item
  Naive: ( O\(n^2\) )- CHT: ( O(n) ) or ( O\(n \log n\) )
\end{itemize}

\subsubsection{3. Knuth Optimization}\label{knuth-optimization}

Used in interval DP problems (like Matrix Chain, Merging Stones).

If:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(dp[i][j] = \min_{k=i}^{j-1} (dp[i][k] + dp[k+1][j] + w(i,j))\)
\item
  The cost \(w(i,j)\) satisfies the quadrangle inequality: \[
  w(a,c) + w(b,d) \le w(a,d) + w(b,c)
  \]
\item
  And the monotonicity condition: \[
  opt[i][j-1] \le opt[i][j] \le opt[i+1][j]
  \]
\end{enumerate}

Then you can reduce the search space from ( O(n) ) to ( O(1) ) per cell,
making total complexity ( O\(n^2\) ) instead of ( O\(n^3\) ).

\subsubsection{A. Implementation}\label{a.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ opt}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}\NormalTok{ k }\OperatorTok{\textless{}=}\NormalTok{ opt}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ val }\OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{j}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textless{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ val}\OperatorTok{;}
\NormalTok{                opt}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ k}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Example}\label{b.-example-4}

Optimal Binary Search Tree or Merging Stones (with additive cost).
Typical improvement: ( O\(n^3\) \to O\(n^2\) )

\subsubsection{4. Summary}\label{summary-7}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2405}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2278}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2152}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Applies To
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Divide \& Conquer DP & 1D transitions & Monotonic argmin & O(n log n) \\
Convex Hull Trick & Linear transitions & Monotonic slopes & O(n) / O(n
log n) \\
Knuth Optimization & Interval DP & Quadrangle + Monotonicity & O(n²) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-46}

Divide \& Conquer Template

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ compute}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optL}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optR}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

CHT Query

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{size}\OperatorTok{\textgreater{}=}\DecValTok{2} \OperatorTok{\&\&}\NormalTok{ f}\OperatorTok{[}\DecValTok{1}\OperatorTok{](}\NormalTok{x}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ f}\OperatorTok{[}\DecValTok{0}\OperatorTok{](}\NormalTok{x}\OperatorTok{))}\NormalTok{ pop\_front}\OperatorTok{();}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-46}

These optimizations show that DP isn't just brute force with memory ,
it's mathematical reasoning on structure.

Once you spot monotonicity or linearity, you can shrink a quadratic
solution into near-linear time.

\begin{quote}
``Optimization is the art of seeing simplicity hiding in structure.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-46}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Optimize Matrix Chain DP using Knuth.
\item
  Apply Divide \& Conquer on
  \texttt{dp{[}i{]}\ =\ min\_\{k\textless{}i\}(dp{[}k{]}+(i-k)\^{}2)}.
\item
  Solve Slope DP with CHT for convex cost functions.
\item
  Compare runtime vs naive DP on random data.
\item
  Derive conditions for opt monotonicity in your custom recurrence.
\end{enumerate}

Master these techniques, and you'll turn your DPs from slow prototypes
into lightning-fast solutions.

\subsection{48. Tree DP and Rerooting}\label{tree-dp-and-rerooting}

Dynamic Programming on trees is one of the most elegant and powerful
patterns in algorithm design. Unlike linear arrays or grids, trees form
hierarchical structures, where each node depends on its children or
parent. Tree DP teaches you how to aggregate results up and down the
tree, handling problems where subtrees interact.

In this section, we'll cover:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Basic Tree DP (rooted trees)
\item
  DP over children (bottom-up aggregation)
\item
  Rerooting technique (top-down propagation)
\item
  Common applications and examples
\end{enumerate}

\subsubsection{1. Basic Tree DP: The Idea}\label{basic-tree-dp-the-idea}

We define \texttt{dp{[}u{]}} to represent some property of the subtree
rooted at \texttt{u}. Then we combine children's results to compute
\texttt{dp{[}u{]}}.

This bottom-up approach is like postorder traversal.

Example structure:

\begin{verbatim}
function dfs(u, parent):
    dp[u] = base_value
    for v in adj[u]:
        if v == parent: continue
        dfs(v, u)
        dp[u] = combine(dp[u], dp[v])
\end{verbatim}

\subsubsection{Example 1: Size of
Subtree}\label{example-1-size-of-subtree}

Let \texttt{dp{[}u{]}\ =\ number\ of\ nodes\ in\ subtree\ rooted\ at\ u}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Key idea: Combine children's sizes to get parent size. Complexity: (
O(n) )

\subsubsection{Example 2: Height of
Tree}\label{example-2-height-of-tree}

Let \texttt{dp{[}u{]}\ =\ height\ of\ subtree\ rooted\ at\ u}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{],} \DecValTok{1} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This gives you the height when rooted at any node.

\subsubsection{2. DP Over Children (Bottom-Up
Aggregation)}\label{dp-over-children-bottom-up-aggregation}

Tree DP is all about merging children.

For example, if you want the number of ways to color or number of
independent sets, you compute children's dp and merge results at parent.

\subsubsection{Example 3: Counting Independent
Sets}\label{example-3-counting-independent-sets}

In a tree, an independent set is a set of nodes with no two adjacent.

State:

\begin{itemize}
\tightlist
\item
  \texttt{dp{[}u{]}{[}0{]}} = ways if \texttt{u} is not selected-
  \texttt{dp{[}u{]}{[}1{]}} = ways if \texttt{u} is selected Recurrence:
  \[
  dp[u][0] = \prod_{v \in children(u)} (dp[v][0] + dp[v][1])
  \]
\end{itemize}

\[
dp[u][1] = \prod_{v \in children(u)} dp[v][0]
\]

Implementation:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{*=} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\DecValTok{1}\OperatorTok{]);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{1}\OperatorTok{]} \OperatorTok{*=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\DecValTok{0}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Final answer = \texttt{dp{[}root{]}{[}0{]}\ +\ dp{[}root{]}{[}1{]}}

\subsubsection{Example 4: Maximum Path Sum in
Tree}\label{example-4-maximum-path-sum-in-tree}

Let \texttt{dp{[}u{]}} = max path sum starting at \texttt{u} and going
down To find best path anywhere, store a global max over child pairs.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ ans }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ best1 }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ best2 }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ val }\OperatorTok{=}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{)} \OperatorTok{+}\NormalTok{ weight}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textgreater{}}\NormalTok{ best1}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{best1}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textgreater{}}\NormalTok{ best2}\OperatorTok{)}\NormalTok{ best2 }\OperatorTok{=}\NormalTok{ val}\OperatorTok{;}
    \OperatorTok{\}}
\NormalTok{    ans }\OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{ans}\OperatorTok{,}\NormalTok{ best1 }\OperatorTok{+}\NormalTok{ best2}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ best1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This gives tree diameter or max path sum.

\subsubsection{3. Rerooting Technique}\label{rerooting-technique}

Rerooting DP allows you to compute answers for every node as root,
without recomputing from scratch ( O\(n^2\) ). It's also known as DP on
trees with re-rooting.

\subsubsection{Idea}\label{idea}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First, compute \texttt{dp\_down{[}u{]}} = answer for subtree when
  rooted at \texttt{u}.
\item
  Then, propagate info from parent to child (\texttt{dp\_up{[}u{]}}), so
  each node gets info from outside its subtree.
\item
  Combine \texttt{dp\_down} and \texttt{dp\_up} to get
  \texttt{dp\_all{[}u{]}}.
\end{enumerate}

\subsubsection{Example 5: Sum of Distances from Each
Node}\label{example-5-sum-of-distances-from-each-node}

Let's find \texttt{ans{[}u{]}} = sum of distances from \texttt{u} to all
nodes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Root the tree at 0.
\item
  Compute subtree sizes and total distance from root.
\item
  Reroot to adjust distances using parent's info.
\end{enumerate}

Step 1: Bottom-up:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    sz}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs1}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        sz}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Step 2: Top-down:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\NormalTok{        dfs2}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

After \texttt{dfs2}, \texttt{dp{[}u{]}} = sum of distances from node
\texttt{u}.

Complexity: ( O(n) )

\subsubsection{4. General Rerooting
Template}\label{general-rerooting-template}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1. Postorder: compute dp\_down[u] from children}
\DataTypeTok{void}\NormalTok{ dfs\_down}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ p}\OperatorTok{):}
\NormalTok{    dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ base}
    \ControlFlowTok{for}\NormalTok{ v in adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{]:}
        \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{:}
\NormalTok{            dfs\_down}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{)}
\NormalTok{            dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ dp\_down}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}

\CommentTok{// 2. Preorder: use parent\textquotesingle{}s dp\_up to compute dp\_all[u]}
\DataTypeTok{void}\NormalTok{ dfs\_up}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ p}\OperatorTok{,}\NormalTok{ dp\_up\_parent}\OperatorTok{):}
\NormalTok{    ans}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ dp\_up\_parent}\OperatorTok{)}
\NormalTok{    prefix}\OperatorTok{,}\NormalTok{ suffix }\OperatorTok{=}\NormalTok{ prefix products of children}
    \ControlFlowTok{for}\NormalTok{ each child v}\OperatorTok{:}
\NormalTok{        dp\_up\_v }\OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{prefix}\OperatorTok{[}\NormalTok{v}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ suffix}\OperatorTok{[}\NormalTok{v}\OperatorTok{+}\DecValTok{1}\OperatorTok{],}\NormalTok{ dp\_up\_parent}\OperatorTok{)}
\NormalTok{        dfs\_up}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{,}\NormalTok{ dp\_up\_v}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

This template generalizes rerooting to many problems:

\begin{itemize}
\tightlist
\item
  Maximum distance from each node- Number of ways to select subtrees-
  Sum of subtree sizes seen from each root
\end{itemize}

\subsubsection{5. Summary}\label{summary-8}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Pattern & Description & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Basic Tree DP & Combine child subresults & O(n) \\
DP Over Children & Each node depends on children & O(n) \\
Rerooting DP & Compute result for every root & O(n) \\
Multiple States & Track choices (e.g.~include/exclude) & O(n·state) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-47}

Subtree Size

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Reroot Sum Distances

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-47}

Tree DP is how we think recursively over structure , each node's truth
emerges from its children. Rerooting expands this idea globally, giving
every node its own perspective.

\begin{quote}
``In the forest of states, each root sees a different world , yet all
follow the same law.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-47}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count number of nodes in each subtree.
\item
  Compute sum of depths from each node.
\item
  Find tree diameter using DP.
\item
  Count number of independent sets modulo 1e9+7.
\item
  Implement rerooting to find max distance from each node.
\end{enumerate}

Tree DP turns recursive patterns into universal strategies for
hierarchical data.

\subsection{49. DP Reconstruction and
Traceback}\label{dp-reconstruction-and-traceback}

So far, we've focused on computing optimal values (min cost, max score,
count of ways). But in most real problems, we don't just want the number
, we want to know how we got it.

That's where reconstruction comes in: once you've filled your DP table,
you can trace back the decisions that led to the optimal answer.

This chapter shows you how to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Record transitions during DP computation
\item
  Reconstruct paths, subsets, or sequences
\item
  Handle multiple reconstructions (paths, sets, parent links)
\item
  Understand traceback in 1D, 2D, and graph-based DPs
\end{enumerate}

\subsubsection{1. The Core Idea}\label{the-core-idea-2}

Each DP state comes from a choice. If you store \emph{which choice was
best}, you can walk backward from the final state to rebuild the
solution.

Think of it as:

\begin{verbatim}
dp[i] = best over options
choice[i] = argmin or argmax option
\end{verbatim}

Then:

\begin{verbatim}
reconstruction_path = []
i = n
while i > 0:
    reconstruction_path.push(choice[i])
    i = choice[i].prev
\end{verbatim}

You're not just solving , you're remembering the path.

\subsubsection{2. Reconstruction in 1D
DP}\label{reconstruction-in-1d-dp}

\subsubsection{Example: Coin Change (Minimum
Coins)}\label{example-coin-change-minimum-coins}

Problem: Find minimum number of coins to make value \texttt{n}.

Recurrence: \[
dp[x] = 1 + \min_{c \in coins, c \le x} dp[x-c]
\]

To reconstruct which coins were used:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{],}\NormalTok{ prev\_coin}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{];}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ x }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ x }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ x}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x }\OperatorTok{\textgreater{}=}\NormalTok{ c }\OperatorTok{\&\&}\NormalTok{ dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{{-}}\NormalTok{c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{{-}}\NormalTok{c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{            prev\_coin}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ c}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Reconstruction:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ used}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    used}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{prev\_coin}\OperatorTok{[}\NormalTok{cur}\OperatorTok{]);}
\NormalTok{    cur }\OperatorTok{{-}=}\NormalTok{ prev\_coin}\OperatorTok{[}\NormalTok{cur}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Output: coins used in one optimal solution.

\subsubsection{Example: LIS
Reconstruction}\label{example-lis-reconstruction}

You know how to find LIS length. Now reconstruct the sequence.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{],}\NormalTok{ prev}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ best\_end }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ prev}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{            prev}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
        \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{best\_end}\OperatorTok{])}\NormalTok{ best\_end }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Rebuild LIS:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ lis}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ best\_end}\OperatorTok{;}\NormalTok{ i }\OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{=}\NormalTok{ prev}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{    lis}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\NormalTok{reverse}\OperatorTok{(}\NormalTok{lis}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ lis}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Reconstruction in 2D
DP}\label{reconstruction-in-2d-dp}

\subsubsection{Example: LCS (Longest Common
Subsequence)}\label{example-lcs-longest-common-subsequence}

We have \texttt{dp{[}i{]}{[}j{]}} filled using:

\[
dp[i][j] =
\begin{cases}
dp[i-1][j-1] + 1, & \text{if } a[i-1] = b[j-1], \\
\max(dp[i-1][j], dp[i][j-1]), & \text{otherwise.}
\end{cases}
\]

To reconstruct LCS:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=}\NormalTok{ m}\OperatorTok{;}
\NormalTok{string lcs }\OperatorTok{=} \StringTok{""}\OperatorTok{;}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ j }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        lcs}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
\NormalTok{        i}\OperatorTok{{-}{-};}\NormalTok{ j}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ i}\OperatorTok{{-}{-};}
    \ControlFlowTok{else}\NormalTok{ j}\OperatorTok{{-}{-};}
\OperatorTok{\}}
\NormalTok{reverse}\OperatorTok{(}\NormalTok{lcs}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ lcs}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\end{Highlighting}
\end{Shaded}

Output: one valid LCS string.

\subsubsection{Example: Edit Distance}\label{example-edit-distance}

Operations: insert, delete, replace.

You can store the operation:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"match"}\OperatorTok{;}
\ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{)}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"replace"}\OperatorTok{;}
\ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{)}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"delete"}\OperatorTok{;}
\ControlFlowTok{else}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"insert"}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Then backtrack to list operations:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ j }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==} \StringTok{"match"}\OperatorTok{)}\NormalTok{ i}\OperatorTok{{-}{-},}\NormalTok{ j}\OperatorTok{{-}{-};}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==} \StringTok{"replace"}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\StringTok{"Replace"}\OperatorTok{);}\NormalTok{ i}\OperatorTok{{-}{-};}\NormalTok{ j}\OperatorTok{{-}{-};} \OperatorTok{\}}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==} \StringTok{"delete"}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\StringTok{"Delete"}\OperatorTok{);}\NormalTok{ i}\OperatorTok{{-}{-};} \OperatorTok{\}}
    \ControlFlowTok{else} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\StringTok{"Insert"}\OperatorTok{);}\NormalTok{ j}\OperatorTok{{-}{-};} \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Reconstruction in Path
Problems}\label{reconstruction-in-path-problems}

When DP tracks shortest paths, you can keep parent pointers.

\subsubsection{Example: Bellman-Ford Path
Reconstruction}\label{example-bellman-ford-path-reconstruction}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\NormalTok{n}\OperatorTok{],}\NormalTok{ parent}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{dist}\OperatorTok{[}\NormalTok{src}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{u}\OperatorTok{,}\NormalTok{v}\OperatorTok{,}\NormalTok{w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
    \OperatorTok{\}}

\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ path}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ dest}\OperatorTok{;}\NormalTok{ v }\OperatorTok{!=}\NormalTok{ src}\OperatorTok{;}\NormalTok{ v }\OperatorTok{=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{    path}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{path}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{src}\OperatorTok{);}
\NormalTok{reverse}\OperatorTok{(}\NormalTok{path}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ path}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\end{Highlighting}
\end{Shaded}

You now have the actual shortest path.

\subsubsection{5. Handling Multiple
Solutions}\label{handling-multiple-solutions}

Sometimes multiple optimal paths exist. You can:

\begin{itemize}
\tightlist
\item
  Store all predecessors instead of one- Backtrack recursively to
  enumerate all solutions- Tie-break deterministically (e.g.,
  lexicographically smallest) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{new\_val }\OperatorTok{==}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ parents}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{j}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Then recursively generate all possible paths.

\subsubsection{6. Visualization}\label{visualization-1}

DP reconstruction often looks like following arrows in a grid or graph:

\begin{itemize}
\tightlist
\item
  LCS: diagonal (↖), up (↑), left (←)- Shortest path: parent edges- LIS:
  predecessor chain You're walking through decisions, not just numbers.
\end{itemize}

\subsubsection{7. Summary}\label{summary-9}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Type & State & Reconstruction \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1D DP & \texttt{prev{[}i{]}} & Trace chain \\
2D DP & \texttt{op{[}i{]}{[}j{]}} & Follow choices \\
Graph DP & \texttt{parent{[}v{]}} & Follow edges \\
Counting DP & optional & Recover counts / paths \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-48}

General pattern:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{state}\OperatorTok{)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{choice}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{better}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ value}\OperatorTok{;}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ choice}\OperatorTok{;}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{state }\OperatorTok{!=}\NormalTok{ base}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    path}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{state}\OperatorTok{]);}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{state}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-48}

Solving DP gets you the score , reconstructing shows you the story. It's
the difference between knowing the answer and understanding the
reasoning.

\begin{quote}
``Numbers tell you the outcome; pointers tell you the path.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-48}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reconstruct one LIS path.
\item
  Print all LCSs for small strings.
\item
  Show edit operations to transform ``cat'' → ``cut''.
\item
  Track subset used in Knapsack to reach exact weight.
\item
  Recover optimal merge order in Matrix Chain DP.
\end{enumerate}

Reconstruction turns DP from a static table into a narrative of
decisions , a map back through the maze of optimal choices.

\subsection{50. Meta-DP and Optimization
Templates}\label{meta-dp-and-optimization-templates}

We've now explored many flavors of dynamic programming , on sequences,
grids, trees, graphs, subsets, and digits. This final chapter in the DP
arc zooms out to the \emph{meta-level}: how to see DP patterns,
generalize them, and turn them into reusable templates.

If classical DP is about solving one problem, meta-DP is about
recognizing \emph{families} of problems that share structure. You'll
learn how to build your own DP frameworks, use common templates, and
reason from first principles.

\subsubsection{1. What Is Meta-DP?}\label{what-is-meta-dp}

A \emph{Meta-DP} is a high-level abstraction of a dynamic programming
pattern. It encodes:

\begin{itemize}
\tightlist
\item
  State definition pattern- Transition pattern- Optimization structure-
  Dimensional dependencies By learning these patterns, you can design
  DPs faster, reuse logic across problems, and spot optimizations early.
\end{itemize}

Think of Meta-DP as:

\begin{quote}
``Instead of memorizing 100 DPs, master 10 DP blueprints.''
\end{quote}

\subsubsection{2. The Four Building
Blocks}\label{the-four-building-blocks}

Every DP has the same core ingredients:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  State: what subproblem you're solving

  \begin{itemize}
  \item
    Often \texttt{dp{[}i{]}}, \texttt{dp{[}i{]}{[}j{]}}, or
    \texttt{dp{[}mask{]}} - Represents smallest unit of progress2.
    Transition: how to build larger subproblems from smaller ones
  \item
    E.g. \texttt{dp{[}i{]}\ =\ min(dp{[}j{]}\ +\ cost(j,\ i))}3. Base
    Case: known trivial answers
  \item
    E.g. \texttt{dp{[}0{]}\ =\ 0}4. Order: how to fill the states
  \item
    E.g. increasing \texttt{i}, decreasing \texttt{i}, or topological
    order Once you can describe a problem in these four, it \emph{is} a
    DP.
  \end{itemize}
\end{enumerate}

\subsubsection{3. Meta-Templates for Common
Structures}\label{meta-templates-for-common-structures}

Below are generalized templates to use and adapt.

\subsubsection{A. Line DP (1D
Sequential)}\label{a.-line-dp-1d-sequential}

Shape: linear progression Examples:

\begin{itemize}
\tightlist
\item
  Fibonacci- Knapsack (1D capacity)- LIS (sequential dependency)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ base}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{:}\NormalTok{ transitions}\OperatorTok{(}\NormalTok{i}\OperatorTok{))}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{j}\OperatorTok{,}\NormalTok{ i}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Visualization: → → → Each state depends on previous positions.

\subsubsection{B. Grid DP (2D Spatial)}\label{b.-grid-dp-2d-spatial}

Shape: grid or matrix Examples:

\begin{itemize}
\tightlist
\item
  Paths in a grid- Edit Distance- Counting paths with obstacles
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Visualization: ⬇️ ⬇️ ➡️ Moves from top-left to bottom-right.

\subsubsection{C. Interval DP}\label{c.-interval-dp}

Shape: segments or subarrays Examples:

\begin{itemize}
\tightlist
\item
  Matrix Chain Multiplication- Optimal BST- Merging Stones
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{      j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
      \ControlFlowTok{for} \OperatorTok{(}\NormalTok{k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{          dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{j}\OperatorTok{));}
  \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Key Insight: overlapping intervals, split points.

\subsubsection{D. Subset DP}\label{d.-subset-dp}

Shape: subsets of a set Examples:

\begin{itemize}
\tightlist
\item
  Traveling Salesman (TSP)- Assignment problem- SOS DP
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{n}\OperatorTok{);}\NormalTok{ mask}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{sub }\OperatorTok{=}\NormalTok{ mask}\OperatorTok{;}\NormalTok{ sub}\OperatorTok{;}\NormalTok{ sub }\OperatorTok{=} \OperatorTok{(}\NormalTok{sub}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)\&}\NormalTok{mask}\OperatorTok{)}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{sub}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Key Insight: use bitmasks to represent subsets.

\subsubsection{E. Tree DP}\label{e.-tree-dp}

Shape: hierarchical dependencies Examples:

\begin{itemize}
\tightlist
\item
  Subtree sizes- Independent sets- Rerooting
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ p}\OperatorTok{):}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ base}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{v in children}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{)}
\NormalTok{      dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{)}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{F. Graph DP (Topological
Order)}\label{f.-graph-dp-topological-order}

Shape: DAG structure Examples:

\begin{itemize}
\tightlist
\item
  Longest path in DAG- Counting paths- DAG shortest path
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{u in topo\_order}\OperatorTok{)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{v in adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ weight}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{v}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Key: process nodes in topological order.

\subsubsection{G. Digit DP}\label{g.-digit-dp}

Shape: positional digits, constrained transitions Examples:

\begin{itemize}
\tightlist
\item
  Count numbers satisfying digit conditions- Divisibility / digit sum
  problems
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{]} \OperatorTok{=}\NormalTok{ ∑ dp}\OperatorTok{[}\NormalTok{next\_pos}\OperatorTok{][}\NormalTok{new\_sum}\OperatorTok{][}\NormalTok{new\_tight}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

\subsubsection{H. Knuth / Divide \& Conquer / Convex Hull
Trick}\label{h.-knuth-divide-conquer-convex-hull-trick}

Shape: optimization over monotone or convex transitions Examples:

\begin{itemize}
\tightlist
\item
  Cost-based splits- Line-based transitions
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min\_k }\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{k}\OperatorTok{,}\NormalTok{ i}\OperatorTok{))}
\end{Highlighting}
\end{Shaded}

Key: structure in \texttt{opt{[}i{]}} or \texttt{slope}.

\subsubsection{4. Recognizing DP Type}\label{recognizing-dp-type}

Ask these diagnostic questions:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7121}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2879}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Clue
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``Does each step depend on smaller subproblems?'' & DP \\
``Do I split a segment?'' & Interval DP \\
``Do I choose subsets?'' & Subset / Bitmask DP \\
``Do I move along positions?'' & Line DP \\
``Do I merge children?'' & Tree DP \\
``Do I process in a DAG?'' & Graph DP \\
``Do I track digits or constraints?'' & Digit DP \\
\end{longtable}

\subsubsection{5. Optimization Layer}\label{optimization-layer}

Once you have a working DP, ask:

\begin{itemize}
\tightlist
\item
  Can transitions be reduced (monotonicity)?- Can overlapping cost be
  cached (prefix sums)?- Can dimensions be compressed (rolling arrays)?-
  Can you reuse solutions for each segment (Divide \& Conquer / Knuth)?
  This transforms your DP from conceptual to efficient.
\end{itemize}

\subsubsection{6. Meta-DP:
Transformations}\label{meta-dp-transformations}

\begin{itemize}
\tightlist
\item
  Compress dimensions: if only \texttt{dp{[}i-1{]}} needed, use 1D
  array.- Invert loops: bottom-up ↔ top-down.- Change base: prefix-sums
  for range queries.- State lifting: add dimension for new property
  (like remainder, parity, bitmask). \textgreater{} ``When stuck, add a
  dimension. When slow, remove one.''
\end{itemize}

\subsubsection{7. Common Template
Snippets}\label{common-template-snippets}

Rolling 1D Knapsack:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{c }\OperatorTok{=}\NormalTok{ C}\OperatorTok{;}\NormalTok{ c }\OperatorTok{\textgreater{}=}\NormalTok{ w}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ c}\OperatorTok{{-}{-})}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{c}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{c}\OperatorTok{{-}}\NormalTok{w}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{+}\NormalTok{ val}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Top-Down Memoization:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ solve}\OperatorTok{(}\NormalTok{state}\OperatorTok{):}
  \ControlFlowTok{if} \OperatorTok{(}\NormalTok{visited}\OperatorTok{[}\NormalTok{state}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{];}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{solve}\OperatorTok{(}\NormalTok{next\_states}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Iterative DP:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{state in order}\OperatorTok{)}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{prev\_states}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Building Your Own DP
Framework}\label{building-your-own-dp-framework}

You can design a generic \texttt{DP(state,\ transition)} class:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ DP }\OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{;}
\NormalTok{    function}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{(}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{)\textgreater{}}\NormalTok{ cost}\OperatorTok{;}
\NormalTok{    DP}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \KeywordTok{auto}\NormalTok{ cost}\OperatorTok{):}\NormalTok{ dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{),}\NormalTok{ cost}\OperatorTok{(}\NormalTok{cost}\OperatorTok{)} \OperatorTok{\{\}}
    \DataTypeTok{void}\NormalTok{ solve}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ j}\OperatorTok{\textless{}}\NormalTok{i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} 
\NormalTok{         dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{j}\OperatorTok{,}\NormalTok{ i}\OperatorTok{));} \OperatorTok{\}}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Reusable, readable, flexible.

\subsubsection{9. Summary}\label{summary-10}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
DP Type & Core State & Shape & Typical Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Line DP & dp{[}i{]} & Linear & O(n²) → O(n) \\
Grid DP & dp{[}i{]}{[}j{]} & Matrix & O(n·m) \\
Interval DP & dp{[}i{]}{[}j{]} & Triangular & O(n³) \\
Subset DP & dp{[}mask{]} & Exponential & O(n·2ⁿ) \\
Tree DP & dp{[}u{]} & Tree & O(n) \\
Digit DP & dp{[}pos{]}{[}sum{]} & Recursive & O(len·sum) \\
Graph DP & dp{[}v{]} & DAG & O(V+E) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-49}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{state in order}\OperatorTok{)}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{all\_prev}\OperatorTok{(}\NormalTok{state}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-49}

Meta-DP turns your thinking from case-by-case to pattern-by-pattern. You
stop memorizing formulas and start \emph{seeing shapes}: lines, grids,
intervals, trees, masks.

Once you can name the shape, you can write the DP.

\begin{quote}
``DP is not about filling tables. It's about recognizing structure.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-49}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Classify each classic DP problem into a type.
\item
  Write one template per pattern (Line, Grid, Tree, etc.).
\item
  Create a \texttt{dp\_solve(state,\ transitions)} function to
  generalize logic.
\item
  For each pattern, practice a small example.
\item
  Build your own ``Little Book of DP Patterns'' with code snippets.
\end{enumerate}

This is your bridge from concrete solutions to algorithmic fluency , the
foundation for mastering the next 950 algorithms ahead.

\section{Chapter 6. Strings and Text
Algorithms}\label{chapter-6.-strings-and-text-algorithms}

\subsection{51. Number Theory (GCD, Modular Arithmetic,
CRT)}\label{number-theory-gcd-modular-arithmetic-crt}

Number theory forms the mathematical backbone of many algorithms , from
hashing and cryptography to modular combinatorics and primality testing.
In algorithmic problem-solving, it's all about working with integers,
divisibility, and modular systems efficiently.

This section covers the essential toolkit:

\begin{itemize}
\tightlist
\item
  GCD and Extended Euclidean Algorithm- Modular Arithmetic (addition,
  subtraction, multiplication, inverse)- Modular Exponentiation- Chinese
  Remainder Theorem (CRT)
\end{itemize}

\subsubsection{1. The Greatest Common Divisor
(GCD)}\label{the-greatest-common-divisor-gcd}

The GCD of two integers \(a\) and \(b\), denoted \(\gcd(a, b)\), is the
largest integer that divides both. It's the cornerstone for fraction
simplification, Diophantine equations, and modular inverses.

\subsubsection{A. Euclidean Algorithm}\label{a.-euclidean-algorithm}

Based on: \[
\gcd(a, b) = \gcd(b, a \bmod b)
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ gcd}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ b }\OperatorTok{==} \DecValTok{0} \OperatorTok{?}\NormalTok{ a }\OperatorTok{:}\NormalTok{ gcd}\OperatorTok{(}\NormalTok{b}\OperatorTok{,}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ b}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time complexity: \(O(\log \min(a,b))\)

\subsubsection{B. Extended Euclidean
Algorithm}\label{b.-extended-euclidean-algorithm}

Finds integers ( x, y ) such that: \[
ax + by = \gcd(a, b)
\]

This is critical for finding modular inverses.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ ext\_gcd}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{int} \OperatorTok{\&}\NormalTok{x}\OperatorTok{,} \DataTypeTok{int} \OperatorTok{\&}\NormalTok{y}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        x }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ y }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ x1}\OperatorTok{,}\NormalTok{ y1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ g }\OperatorTok{=}\NormalTok{ ext\_gcd}\OperatorTok{(}\NormalTok{b}\OperatorTok{,}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ b}\OperatorTok{,}\NormalTok{ x1}\OperatorTok{,}\NormalTok{ y1}\OperatorTok{);}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ y1}\OperatorTok{;}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ x1 }\OperatorTok{{-}} \OperatorTok{(}\NormalTok{a }\OperatorTok{/}\NormalTok{ b}\OperatorTok{)} \OperatorTok{*}\NormalTok{ y1}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ g}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Bezout's Identity}\label{c.-bezouts-identity}

If \(g = \gcd(a,b)\), then \(ax + by = g\) has integer solutions. If
\(g = 1\), \(x\) is the modular inverse of \(a modulo b\).

\subsubsection{2. Modular Arithmetic}\label{modular-arithmetic}

A modular system ``wraps around'' after a certain value ( m ).

We write: \[
a \equiv b \pmod{m} \quad \text{if } m \mid (a - b)
\]

It behaves like ordinary arithmetic, with the rule:

\begin{itemize}
\tightlist
\item
  \((a + b) \bmod m = ((a \bmod m) + (b \bmod m)) \bmod m\)
\item
  \((a \cdot b) \bmod m = ((a \bmod m) \cdot (b \bmod m)) \bmod m\)
\item
  \((a - b) \bmod m = ((a \bmod m) - (b \bmod m) + m) \bmod m\)
\end{itemize}

\subsubsection{A. Modular
Exponentiation}\label{a.-modular-exponentiation}

Compute \(a^b \bmod m\) efficiently using binary exponentiation.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ modpow}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{    a }\OperatorTok{\%=}\NormalTok{ m}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ res }\OperatorTok{=} \OperatorTok{(}\NormalTok{res }\OperatorTok{*}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=} \OperatorTok{(}\NormalTok{a }\OperatorTok{*}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: ( O\(\log b\) )

\subsubsection{B. Modular Inverse}\label{b.-modular-inverse}

Given ( a ), find \(a^{-1}\) such that: \[
a \cdot a^{-1} \equiv 1 \pmod{m}
\]

Case 1: If ( m ) is prime, use Fermat's Little Theorem: \[
a^{-1} \equiv a^{m-2} \pmod{m}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ modinv}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ m}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{,}\NormalTok{ m}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Case 2: If ( a ) and ( m ) are coprime, use Extended GCD:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ inv}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ g }\OperatorTok{=}\NormalTok{ ext\_gcd}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ m}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{g }\OperatorTok{!=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;} \CommentTok{// no inverse}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{\%}\NormalTok{ m }\OperatorTok{+}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Modular Division}\label{c.-modular-division}

To divide \(a / b \bmod m\): \[
a / b \equiv a \cdot b^{-1} \pmod{m}
\]

So compute the inverse and multiply.

\subsubsection{3. Chinese Remainder Theorem
(CRT)}\label{chinese-remainder-theorem-crt}

The CRT solves systems of congruences: \[
x \equiv a_1 \pmod{m_1}
\]

\[
x \equiv a_2 \pmod{m_2}
\] If moduli \(m_1, m_2, \dots, m_k\) are pairwise coprime, there exists
a unique solution modulo \(M = m_1 m_2 \dots m_k\).

\subsubsection{A. 2-Equation Example}\label{a.-2-equation-example}

Solve: \[
x \equiv a_1 \pmod{m_1}, \quad x \equiv a_2 \pmod{m_2}
\]

Let:

\begin{itemize}
\tightlist
\item
  \(M = m_1 m_2\)- \(M_1 = M / m_1\)- \(M_2 = M / m_2\) Find inverses
  \(inv_1 = M_1^{-1} \bmod m_1\), \(inv_2 = M_2^{-1} \bmod m_2\)
\end{itemize}

Then: \[
x = (a_1 \cdot M_1 \cdot inv_1 + a_2 \cdot M_2 \cdot inv_2) \bmod M
\]

\subsubsection{B. Implementation}\label{b.-implementation-7}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ crt}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ a}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ M }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mod }\OperatorTok{:}\NormalTok{ m}\OperatorTok{)}\NormalTok{ M }\OperatorTok{*=}\NormalTok{ mod}\OperatorTok{;}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ Mi }\OperatorTok{=}\NormalTok{ M }\OperatorTok{/}\NormalTok{ m}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ inv }\OperatorTok{=}\NormalTok{ modinv}\OperatorTok{(}\NormalTok{Mi }\OperatorTok{\%}\NormalTok{ m}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ m}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\NormalTok{        res }\OperatorTok{=} \OperatorTok{(}\NormalTok{res }\OperatorTok{+} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*}\NormalTok{ Mi }\OperatorTok{\%}\NormalTok{ M }\OperatorTok{*}\NormalTok{ inv }\OperatorTok{\%}\NormalTok{ M}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{res }\OperatorTok{\%}\NormalTok{ M }\OperatorTok{+}\NormalTok{ M}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example}\label{c.-example-6}

Solve:

\begin{verbatim}
x ≡ 2 (mod 3)
x ≡ 3 (mod 5)
x ≡ 2 (mod 7)
\end{verbatim}

Solution: ( x = 23 ) (mod 105)

Check:

\begin{itemize}
\tightlist
\item
  ( 23 \% 3 = 2 )- ( 23 \% 5 = 3 )- ( 23 \% 7 = 2 )
\end{itemize}

\subsubsection{4. Tiny Code}\label{tiny-code-50}

GCD

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ gcd}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ b }\OperatorTok{?}\NormalTok{ gcd}\OperatorTok{(}\NormalTok{b}\OperatorTok{,}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ b}\OperatorTok{)} \OperatorTok{:}\NormalTok{ a}\OperatorTok{;} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Modular Power

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modpow}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ m}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

Modular Inverse

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modinv}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ m}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

CRT

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crt}\OperatorTok{(}\NormalTok{a}\OperatorTok{[],}\NormalTok{ m}\OperatorTok{[])}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Summary}\label{summary-11}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4722}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3194}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GCD & \(\gcd(a,b) = \gcd(b, a \bmod b)\) & Simplify ratios \\
Extended GCD & \(ax + by = \gcd(a,b)\) & Find modular inverse \\
Modular Inverse & \(a^{-1} \equiv a^{m-2} \pmod{m}\) & Solve modular
equations \\
Modular Exp & \(a^b \bmod m\) & Fast exponentiation \\
CRT & Combine congruences & Multi-mod system \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-50}

Number theory lets algorithms speak the language of integers , turning
huge computations into modular games. From hashing to RSA, from
combinatorics to cryptography, it's everywhere.

\begin{quote}
``When numbers wrap around, math becomes modular , and algorithms become
magical.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-50}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute gcd(48, 180).
\item
  Find inverse of 7 mod 13.
\item
  Solve \(x ≡ 1 \pmod{2}, x ≡ 2 \pmod{3}, x ≡ 3 \pmod{5}\).
\item
  Implement modular division \(a / b \bmod m\).
\item
  Use modpow to compute \(3^{200} \bmod 13\).
\end{enumerate}

These basics unlock higher algorithms in cryptography, combinatorics,
and beyond.

\subsection{52. Primality and Factorization (Miller-Rabin, Pollard
Rho)}\label{primality-and-factorization-miller-rabin-pollard-rho}

Primality and factorization are core to number theory, cryptography, and
competitive programming. Many modern systems (RSA, ECC) rely on the
hardness of factoring large numbers. Here, we learn how to test if a
number is prime and break it into factors efficiently.

We'll cover:

\begin{itemize}
\tightlist
\item
  Trial Division
\item
  Sieve of Eratosthenes (for precomputation)
\item
  Probabilistic Primality Test (Miller-Rabin)
\item
  Integer Factorization (Pollard Rho)
\end{itemize}

\subsubsection{1. Trial Division}\label{trial-division}

The simplest way to test primality is by dividing by all integers up to
√n.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ is\_prime}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}} \DecValTok{2}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{==} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ i }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=} \DecValTok{2}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%}\NormalTok{ i }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(\sqrt{n}\) ) Good for \(n \le 10^6\), impractical
for large ( n ).

\subsubsection{2. Sieve of Eratosthenes}\label{sieve-of-eratosthenes}

For checking many numbers at once, use a sieve.

Idea: Mark all multiples of each prime starting from 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{bool}\OperatorTok{\textgreater{}}\NormalTok{ sieve}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{bool}\OperatorTok{\textgreater{}}\NormalTok{ is\_prime}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);}
\NormalTok{    is\_prime}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ is\_prime}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_prime}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{)}
\NormalTok{                is\_prime}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ is\_prime}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log \log n\) )

Useful for generating primes up to \(10^7\).

\subsubsection{3. Modular Multiplication}\label{modular-multiplication}

Before we do probabilistic tests or factorization, we need safe modular
multiplication for large numbers.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ modmul}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    \_\_int128 res }\OperatorTok{=} \OperatorTok{(}\NormalTok{\_\_int128}\OperatorTok{)}\NormalTok{a }\OperatorTok{*}\NormalTok{ b }\OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
    \ControlFlowTok{return} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{)}\NormalTok{res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Avoid overflow for \(n \approx 10^{18}\).

\subsubsection{4. Miller-Rabin Primality
Test}\label{miller-rabin-primality-test}

A probabilistic test that can check if ( n ) is prime or composite in (
O\(k \log^3 n\) ).

Idea: For a prime ( n ): \[
a^{n-1} \equiv 1 \pmod{n}
\] But for composites, most ( a ) fail this.

We write \(n - 1 = 2^s \cdot d\), ( d ) odd.

For each base ( a ):

\begin{itemize}
\tightlist
\item
  Compute \(x = a^d \bmod n\)- If ( x = 1 ) or ( x = n - 1 ), pass-
  Else, square ( s-1 ) times- If none equal ( n - 1 ), composite
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ miller\_rabin}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}} \DecValTok{2}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ p }\OperatorTok{:} \OperatorTok{\{}\DecValTok{2}\OperatorTok{,}\DecValTok{3}\OperatorTok{,}\DecValTok{5}\OperatorTok{,}\DecValTok{7}\OperatorTok{,}\DecValTok{11}\OperatorTok{,}\DecValTok{13}\OperatorTok{,}\DecValTok{17}\OperatorTok{,}\DecValTok{19}\OperatorTok{,}\DecValTok{23}\OperatorTok{,}\DecValTok{29}\OperatorTok{,}\DecValTok{31}\OperatorTok{,}\DecValTok{37}\OperatorTok{\})}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%}\NormalTok{ p }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{==}\NormalTok{ p}\OperatorTok{;}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ d }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ s }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{((}\NormalTok{d }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)} \OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ d }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{,}\NormalTok{ s}\OperatorTok{++;}
    \KeywordTok{auto}\NormalTok{ modpow }\OperatorTok{=} \OperatorTok{[\&](}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ r }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ r }\OperatorTok{=}\NormalTok{ modmul}\OperatorTok{(}\NormalTok{r}\OperatorTok{,}\NormalTok{ a}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\NormalTok{            a }\OperatorTok{=}\NormalTok{ modmul}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ a}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\NormalTok{            b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{return}\NormalTok{ r}\OperatorTok{;}
    \OperatorTok{\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a }\OperatorTok{:} \OperatorTok{\{}\DecValTok{2}\OperatorTok{,} \DecValTok{325}\OperatorTok{,} \DecValTok{9375}\OperatorTok{,} \DecValTok{28178}\OperatorTok{,} \DecValTok{450775}\OperatorTok{,} \DecValTok{9780504}\OperatorTok{,} \DecValTok{1795265022}\OperatorTok{\})} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{\%}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ d}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x }\OperatorTok{==} \DecValTok{1} \OperatorTok{||}\NormalTok{ x }\OperatorTok{==}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \DataTypeTok{bool}\NormalTok{ composite }\OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ r }\OperatorTok{\textless{}}\NormalTok{ s}\OperatorTok{;}\NormalTok{ r}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{            x }\OperatorTok{=}\NormalTok{ modmul}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x }\OperatorTok{==}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                composite }\OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
                \ControlFlowTok{break}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{composite}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Deterministic for:

\begin{itemize}
\tightlist
\item
  \(n < 2^{64}\) with bases above. Complexity: ( O\(k \log^3 n\) )
\end{itemize}

\subsubsection{5. Pollard Rho
Factorization}\label{pollard-rho-factorization}

Efficient for finding nontrivial factors of large composites. Based on
Floyd's cycle detection (Tortoise and Hare).

Idea: Define a pseudo-random function: \[
f(x) = (x^2 + c) \bmod n
\] Then find \(\gcd(|x - y|, n)\) where \(x, y\) move at different
speeds.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ pollard\_rho}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{2}\OperatorTok{;}
    \KeywordTok{auto}\NormalTok{ f }\OperatorTok{=} \OperatorTok{[\&](}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ c}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{return} \OperatorTok{(}\NormalTok{modmul}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ n}\OperatorTok{)} \OperatorTok{+}\NormalTok{ c}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ n}\OperatorTok{;}
    \OperatorTok{\};}
    \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{)} \OperatorTok{+} \DecValTok{2}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ y }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ c }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ d }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{d }\OperatorTok{==} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            x }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ c}\OperatorTok{);}
\NormalTok{            y }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{f}\OperatorTok{(}\NormalTok{y}\OperatorTok{,}\NormalTok{ c}\OperatorTok{),}\NormalTok{ c}\OperatorTok{);}
\NormalTok{            d }\OperatorTok{=}\NormalTok{ gcd}\OperatorTok{(}\NormalTok{abs}\OperatorTok{(}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ y}\OperatorTok{),}\NormalTok{ n}\OperatorTok{);}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{d }\OperatorTok{!=}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ d}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check if ( n ) is prime (Miller-Rabin)
\item
  If not, find a factor using Pollard Rho
\item
  Recurse on factors
\end{enumerate}

Complexity: \textasciitilde{} ( O\(n^{1/4}\) ) average

\subsubsection{6. Example}\label{example-2}

Factorize ( n = 8051 ):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Miller-Rabin → composite
\item
  Pollard Rho → factor 83
\item
  ( 8051 / 83 = 97 )
\item
  Both primes ⇒ ( 8051 = 83 × 97 )
\end{enumerate}

\subsubsection{7. Tiny Code}\label{tiny-code-51}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ factor}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{f}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{miller\_rabin}\OperatorTok{(}\NormalTok{n}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        f}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ d }\OperatorTok{=}\NormalTok{ pollard\_rho}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    factor}\OperatorTok{(}\NormalTok{d}\OperatorTok{,}\NormalTok{ f}\OperatorTok{);}
\NormalTok{    factor}\OperatorTok{(}\NormalTok{n }\OperatorTok{/}\NormalTok{ d}\OperatorTok{,}\NormalTok{ f}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Call \texttt{factor(n,\ f)} to get prime factors.

\subsubsection{8. Summary}\label{summary-12}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2188}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2656}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2031}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trial Division & Small primes & ( O\(\sqrt{n}\) ) & Deterministic \\
Sieve & Precompute primes & ( O\(n \log \log n\) ) & Deterministic \\
Miller-Rabin & Primality test & ( O\(k \log^3 n\) ) & Probabilistic \\
Pollard Rho & Factorization & ( O\(n^{1/4}\) ) & Probabilistic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-51}

Modern security, number theory problems, and many algorithmic puzzles
depend on knowing when a number is prime and factoring it quickly when
it isn't. These tools are the entry point to RSA, modular combinatorics,
and advanced cryptography.

\subsubsection{Try It Yourself}\label{try-it-yourself-51}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check if 97 is prime using trial division and Miller-Rabin.
\item
  Factorize 5959 (should yield 59 × 101).
\item
  Generate all primes ≤ 100 using a sieve.
\item
  Write a recursive factorizer using Pollard Rho + Miller-Rabin.
\item
  Measure performance difference between \(\sqrt{n}\) trial and Pollard
  Rho for \(n \approx 10^{12}\).
\end{enumerate}

These techniques make huge numbers approachable , one factor at a time.

\subsection{53. Combinatorics (Permutations, Combinations,
Subsets)}\label{combinatorics-permutations-combinations-subsets}

Combinatorics is the art of counting structures , how many ways can we
arrange, select, or group things? In algorithms, it's everywhere: DP
transitions, counting paths, bitmask enumeration, and probabilistic
reasoning. Here we'll build a toolkit for computing factorials, nCr,
nPr, and subset counts, both exactly and under a modulus.

\subsubsection{1. Factorials and
Precomputation}\label{factorials-and-precomputation}

Most combinatorial formulas rely on factorials: \[
n! = 1 \times 2 \times 3 \times \dots \times n
\]

We can precompute them modulo ( m ) (often \(10^9+7\)) for efficiency.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ MOD }\OperatorTok{=} \FloatTok{1e9} \OperatorTok{+} \DecValTok{7}\OperatorTok{;}
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ MAXN }\OperatorTok{=} \FloatTok{1e6}\OperatorTok{;}
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ fact}\OperatorTok{[}\NormalTok{MAXN }\OperatorTok{+} \DecValTok{1}\OperatorTok{],}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{MAXN }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}

\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ modpow}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ res }\OperatorTok{=}\NormalTok{ res }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=}\NormalTok{ a }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ init\_factorials}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    fact}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ MAXN}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        fact}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fact}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{*}\NormalTok{ i }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{    invfact}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{]} \OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{fact}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{],}\NormalTok{ MOD }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ MAXN }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})}
\NormalTok{        invfact}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{*} \OperatorTok{(}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Now you can compute ( nCr ) and ( nPr ) in ( O(1) ) time.

\subsubsection{2. Combinations ( nCr )}\label{combinations-ncr}

The number of ways to choose r items from ( n ) items: \[
C(n, r) = \frac{n!}{r!(n-r)!}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ nCr}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ r }\OperatorTok{\textgreater{}}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fact}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{*}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{r}\OperatorTok{]} \OperatorTok{\%}\NormalTok{ MOD }\OperatorTok{*}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ r}\OperatorTok{]} \OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Properties:

\begin{itemize}
\tightlist
\item
  \((C(n, 0) = 1),\ (C(n, n) = 1)\)
\item
  \(C(n, r) = C(n, n - r)\)
\item
  Pascal's Rule: \(C(n, r) = C(n - 1, r - 1) + C(n - 1, r)\)
\end{itemize}

\subsubsection{Example}\label{example-3}

( C(5, 2) = 10 ) There are 10 ways to pick 2 elements from a 5-element
set.

\subsubsection{3. Permutations ( nPr )}\label{permutations-npr}

Number of ways to arrange r elements chosen from ( n ): \[
P(n, r) = \frac{n!}{(n-r)!}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ nPr}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ r }\OperatorTok{\textgreater{}}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fact}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{*}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ r}\OperatorTok{]} \OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Example}\label{example-4}

( P(5, 2) = 20 ) Choosing 2 out of 5 elements and arranging them yields
20 orders.

\subsubsection{4. Subsets and Power Set}\label{subsets-and-power-set}

Each element has 2 choices: include or exclude. Hence, number of
subsets: \[
2^n
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ subsets\_count}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ modpow}\OperatorTok{(}\DecValTok{2}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Enumerating subsets using bitmasks:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ n}\OperatorTok{);}\NormalTok{ mask}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{))}
            \OperatorTok{;} \CommentTok{// include element i}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Total: \(2^n\) subsets, ( O\(n2^n\) ) time to enumerate.

\subsubsection{5. Multisets and
Repetition}\label{multisets-and-repetition}

Number of ways to choose ( r ) items from ( n ) with repetition: \[
C(n + r - 1, r)
\]

For example, number of ways to give 5 candies to 3 kids (each can get
0): ( C(3+5-1, 5) = C(7,5) = 21 )

\subsubsection{6. Modular Combinatorics}\label{modular-combinatorics}

When working modulo ( p ): - Use modular inverse for division. -
\(C(n, r) \bmod p = fact[n] \cdot invfact[r] \cdot invfact[n - r] \bmod p\)

When \(n \ge p\), use Lucas' Theorem: \[
C(n, r) \bmod p = C(n/p, r/p) \cdot C(n%p, r%p) \bmod p
\]

\subsubsection{7. Stirling and Bell Numbers
(Advanced)}\label{stirling-and-bell-numbers-advanced}

\begin{itemize}
\tightlist
\item
  Stirling Numbers of 2nd Kind: ways to partition ( n ) items into ( k )
  non-empty subsets \[
  S(n,k) = k \cdot S(n-1,k) + S(n-1,k-1)
  \]
\item
  Bell Numbers: total number of partitions \[
  B(n) = \sum_{k=0}^{n} S(n,k)
  \]
\end{itemize}

Used in set partition and grouping problems.

\subsubsection{8. Tiny Code}\label{tiny-code-52}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init\_factorials}\OperatorTok{();}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%lld\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ nCr}\OperatorTok{(}\DecValTok{10}\OperatorTok{,} \DecValTok{3}\OperatorTok{));}  \CommentTok{// 120}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%lld\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ nPr}\OperatorTok{(}\DecValTok{10}\OperatorTok{,} \DecValTok{3}\OperatorTok{));}  \CommentTok{// 720}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%lld\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ subsets\_count}\OperatorTok{(}\DecValTok{5}\OperatorTok{));} \CommentTok{// 32}
\end{Highlighting}
\end{Shaded}

\subsubsection{9. Summary}\label{summary-13}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1446}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4458}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2289}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1807}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Factorial & \(n!\) & All arrangements & \(5! = 120\) \\
Combination & \(C(n, r) = \frac{n!}{r!(n - r)!}\) & Choose &
\(C(5, 2) = 10\) \\
Permutation & \(P(n, r) = \frac{n!}{(n - r)!}\) & Arrange &
\(P(5, 2) = 20\) \\
Subsets & \(2^n\) & All combinations & \(2^3 = 8\) \\
Multisets & \(C(n + r - 1, r)\) & Repetition allowed &
\(C(4, 2) = 6\) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-52}

Combinatorics underlies probability, DP counting, and modular problems.
You can't master competitive programming or algorithm design without
counting possibilities correctly. It teaches how structure emerges from
choice , and how to count it efficiently.

\subsubsection{Try It Yourself}\label{try-it-yourself-52}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \(C(1000, 500) \bmod (10^9 + 7)\).
\item
  Count the number of 5-bit subsets with exactly 3 bits on,
  i.e.~\(C(5, 3)\).
\item
  Write a loop to print all subsets of \texttt{\{a,\ b,\ c,\ d\}}.
\item
  Use Lucas' theorem for \(C(10^6, 1000) \bmod 13\).
\item
  Implement Stirling recursion and print \(S(5, 2)\).
\end{enumerate}

Every algorithmic counting trick , from Pascal's triangle to binomial
theorem , starts right here.

\subsection{54. Probability and Randomized
Algorithms}\label{probability-and-randomized-algorithms}

Probability introduces controlled randomness into computation. Instead
of deterministic steps, randomized algorithms use random choices to
achieve speed, simplicity, or robustness. This section bridges
probability theory and algorithm design , teaching how to model,
analyze, and exploit randomness.

We'll cover:

\begin{itemize}
\tightlist
\item
  Probability Basics
\item
  Expected Value
\item
  Monte Carlo and Las Vegas Algorithms
\item
  Randomized Data Structures and Algorithms
\end{itemize}

\subsubsection{1. Probability Basics}\label{probability-basics}

Every event has a probability between 0 and 1.\\
If a sample space has \(n\) equally likely outcomes and \(k\) of them
satisfy a condition, then

\[
P(E) = \frac{k}{n}
\]

Examples

\begin{itemize}
\tightlist
\item
  Rolling a fair die: \(P(\text{even}) = \frac{3}{6} = \frac{1}{2}\)
\item
  Drawing an ace from a deck:
  \(P(\text{ace}) = \frac{4}{52} = \frac{1}{13}\)
\end{itemize}

Key Rules

\begin{itemize}
\tightlist
\item
  Complement: \(P(\bar{E}) = 1 - P(E)\)\\
\item
  Addition: \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)\\
\item
  Multiplication: \(P(A \cap B) = P(A) \cdot P(B \mid A)\)
\end{itemize}

\subsubsection{2. Expected Value}\label{expected-value}

The expected value is the weighted average of outcomes.

\[
E[X] = \sum_{i} P(x_i) \cdot x_i
\]

Example: Expected value of a die: \[
E[X] = \frac{1+2+3+4+5+6}{6} = 3.5
\]

Properties:

\begin{itemize}
\tightlist
\item
  Linearity: \(E[aX + bY] = aE[X] + bE[Y]\)
\item
  Useful for average-case analysis
\end{itemize}

In algorithms:

\begin{itemize}
\tightlist
\item
  Expected number of comparisons in QuickSort is \(O(n \log n)\)
\item
  Expected time for hash table lookup is \(O(1)\)
\end{itemize}

\subsubsection{3. Monte Carlo vs Las
Vegas}\label{monte-carlo-vs-las-vegas}

Randomized algorithms are broadly two types:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1807}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3855}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1687}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2651}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Runtime
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Monte Carlo & May be wrong (probabilistically) & Fixed & Miller-Rabin
Primality \\
Las Vegas & Always correct & Random runtime & Randomized QuickSort \\
\end{longtable}

Monte Carlo:

\begin{itemize}
\tightlist
\item
  Faster, approximate
\item
  You can control error probability
\item
  E.g. primality test returns ``probably prime''
\end{itemize}

Las Vegas:

\begin{itemize}
\tightlist
\item
  Output guaranteed correct
\item
  Runtime varies by luck
\item
  E.g. QuickSort with random pivot
\end{itemize}

\subsubsection{4. Randomization in
Algorithms}\label{randomization-in-algorithms}

Randomization helps break worst-case patterns.

\subsubsection{A. Randomized QuickSort}\label{a.-randomized-quicksort}

Pick a random pivot instead of first element. Expected time becomes (
O\(n \log n\) ) regardless of input order.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{l }\OperatorTok{+}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{r }\OperatorTok{{-}}\NormalTok{ l }\OperatorTok{+} \DecValTok{1}\OperatorTok{)];}
    \CommentTok{// move pivot to end, then normal partition}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This avoids adversarial inputs like sorted arrays.

\subsubsection{B. Randomized Hashing}\label{b.-randomized-hashing}

Hash collisions can be exploited by adversaries. Using random
coefficients in hash functions makes attacks infeasible.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{a }\OperatorTok{*}\NormalTok{ x }\OperatorTok{+}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ p}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pick random ( a, b ) for robustness.

\subsubsection{C. Randomized Data
Structures}\label{c.-randomized-data-structures}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Skip List: uses random levels for nodes Expected ( O\(\log n\) )
  search/insert/delete
\item
  Treap: randomized heap priority + BST order Maintains balance in
  expectation
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ priority}\OperatorTok{;}
\NormalTok{    Node }\OperatorTok{*}\NormalTok{l}\OperatorTok{,} \OperatorTok{*}\NormalTok{r}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Randomized balancing gives good average performance without rotation
logic.

\subsubsection{D. Random Sampling}\label{d.-random-sampling}

Pick random elements efficiently:

\begin{itemize}
\tightlist
\item
  Reservoir Sampling: sample ( k ) items from a stream of unknown size-
  Shuffle: Fisher-Yates Algorithm
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Probabilistic
Guarantees}\label{probabilistic-guarantees}

Randomized algorithms often use Chernoff bounds and Markov's inequality
to bound errors:

\begin{itemize}
\tightlist
\item
  Markov: \(P(X \ge kE[X]) \le \frac{1}{k}\)
\item
  Chebyshev: \(P(|X - E[X]| \ge c\sigma) \le \frac{1}{c^2}\)
\item
  Chernoff: Exponentially small tail bounds
\end{itemize}

These ensure ``with high probability'' (\(1 - \frac{1}{n^c}\))
guarantees.

\subsubsection{6. Tiny Code}\label{tiny-code-53}

Randomized QuickSort:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivotIdx }\OperatorTok{=}\NormalTok{ low }\OperatorTok{+}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    swap}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{pivotIdx}\OperatorTok{],}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]);}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{],}\NormalTok{ i }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ pivot}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{++],}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
    \OperatorTok{\}}
\NormalTok{    swap}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ quicksort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ pi }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
\NormalTok{        quicksort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\NormalTok{        quicksort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-14}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3968}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3175}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expected Value & Weighted average outcome & Analyze average case \\
Monte Carlo & Probabilistic correctness & Primality test \\
Las Vegas & Probabilistic runtime & QuickSort \\
Random Pivot & Break worst-case & Sorting \\
Skip List / Treap & Random balancing & Data Structures \\
Reservoir Sampling & Stream selection & Large data \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-53}

Randomization is not ``luck'' , it's a design principle. It transforms
rigid algorithms into adaptive, robust systems. In complexity theory,
randomness helps achieve bounds impossible deterministically.

\begin{quote}
``A bit of randomness turns worst cases into best friends.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-53}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate rolling two dice and compute expected sum.
\item
  Implement randomized QuickSort and measure average runtime.
\item
  Write a Monte Carlo primality checker.
\item
  Create a random hash function for integers.
\item
  Implement reservoir sampling for a large input stream.
\end{enumerate}

These experiments show how uncertainty can become a powerful ally in
algorithm design.

\subsection{55. Sieve Methods and Modular
Math}\label{sieve-methods-and-modular-math}

Sieve methods are essential tools in number theory for generating prime
numbers, prime factors, and function values (φ, μ) efficiently. Combined
with modular arithmetic, they form the backbone of algorithms in
cryptography, combinatorics, and competitive programming.

This section introduces:

\begin{itemize}
\tightlist
\item
  Sieve of Eratosthenes- Optimized Linear Sieve- Sieve for Smallest
  Prime Factor (SPF)- Euler's Totient Function (φ)- Modular Applications
\end{itemize}

\subsubsection{1. The Sieve of
Eratosthenes}\label{the-sieve-of-eratosthenes}

The classic algorithm to find all primes ≤ ( n ).

Idea: Start from 2, mark all multiples as composite. Continue to √n.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ sieve}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ primes}\OperatorTok{;}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{bool}\OperatorTok{\textgreater{}}\NormalTok{ is\_prime}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);}
\NormalTok{    is\_prime}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ is\_prime}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_prime}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{)}
\NormalTok{                is\_prime}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_prime}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ primes}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ primes}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log \log n\) )

Space: ( O(n) )

Example: Primes up to 20 → 2, 3, 5, 7, 11, 13, 17, 19

\subsubsection{2. Linear Sieve (O(n))}\label{linear-sieve-on}

Unlike the basic sieve, each number is marked exactly once by its
smallest prime factor (SPF).

Idea:

\begin{itemize}
\tightlist
\item
  For each prime ( p ), mark \(p \times i\) only once.- Use
  \texttt{spf{[}i{]}} to store smallest prime factor.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \FloatTok{1e6}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ spf}\OperatorTok{[}\NormalTok{N }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ primes}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ linear\_sieve}\OperatorTok{()} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{spf}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            spf}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{            primes}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
        \OperatorTok{\}}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ p }\OperatorTok{:}\NormalTok{ primes}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p }\OperatorTok{\textgreater{}}\NormalTok{ spf}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{||} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ i }\OperatorTok{*}\NormalTok{ p }\OperatorTok{\textgreater{}}\NormalTok{ N}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{            spf}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=}\NormalTok{ p}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Benefits:

\begin{itemize}
\tightlist
\item
  Get primes, SPF, and factorizations in ( O(n) ).- Ideal for problems
  needing many factorizations.
\end{itemize}

\subsubsection{3. Smallest Prime Factor (SPF)
Table}\label{smallest-prime-factor-spf-table}

With \texttt{spf{[}{]}}, factorization becomes ( O\(\log n\) ).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ factorize}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ f}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{x }\OperatorTok{!=} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        f}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{spf}\OperatorTok{[}\NormalTok{x}\OperatorTok{]);}
\NormalTok{        x }\OperatorTok{/=}\NormalTok{ spf}\OperatorTok{[}\NormalTok{x}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ f}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: spf{[}12{]} = 2 → factors = {[}2, 2, 3{]}

\subsubsection{\texorpdfstring{4. Euler's Totient Function ( \varphi(n)
)}{4. Euler's Totient Function ( (n) )}}\label{eulers-totient-function-n}

The number of integers ≤ ( n ) that are coprime with ( n ).

Formula: \[
\varphi(n) = n \prod_{p|n} \left(1 - \frac{1}{p}\right)
\]

Properties:

\begin{itemize}
\tightlist
\item
  \(\varphi(p) = p - 1\) if \(p\) is prime
\item
  Multiplicative: if \(\gcd(a, b) = 1\), then
  \(\varphi(ab) = \varphi(a)\varphi(b)\)
\end{itemize}

Implementation (Linear Sieve):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \FloatTok{1e6}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ phi}\OperatorTok{[}\NormalTok{N }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ is\_comp}\OperatorTok{[}\NormalTok{N }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ primes}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ phi\_sieve}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    phi}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{is\_comp}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            primes}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
\NormalTok{            phi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ p }\OperatorTok{:}\NormalTok{ primes}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ i }\OperatorTok{*}\NormalTok{ p }\OperatorTok{\textgreater{}}\NormalTok{ N}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{            is\_comp}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\%}\NormalTok{ p }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                phi}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=}\NormalTok{ phi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*}\NormalTok{ p}\OperatorTok{;}
                \ControlFlowTok{break}\OperatorTok{;}
            \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{                phi}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=}\NormalTok{ phi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*} \OperatorTok{(}\NormalTok{p }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example:

\begin{itemize}
\tightlist
\item
  \(\varphi(6) = 6(1 - \frac{1}{2})(1 - \frac{1}{3}) = 2\)
\item
  Numbers coprime with 6: 1, 5
\end{itemize}

\subsubsection{5. Modular Math
Applications}\label{modular-math-applications}

Once we have primes and totients, we can do many modular computations.

\subsubsection{A. Fermat's Little
Theorem}\label{a.-fermats-little-theorem}

If ( p ) is prime, \[
a^{p-1} \equiv 1 \pmod{p}
\] Hence, \[
a^{-1} \equiv a^{p-2} \pmod{p}
\]

Used in: modular inverses, combinatorics.

\subsubsection{B. Euler's Theorem}\label{b.-eulers-theorem}

If \(\gcd(a, n) = 1\), then

\[
a^{\varphi(n)} \equiv 1 \pmod{n}
\]

Generalizes Fermat's theorem to composite moduli.

\subsubsection{C. Modular Exponentiation with Totient
Reduction}\label{c.-modular-exponentiation-with-totient-reduction}

For very large powers:

\[
a^b \bmod n = a^{b \bmod \varphi(n)} \bmod n
\]

(when \(a\) and \(n\) are coprime)

\subsubsection{6. Tiny Code}\label{tiny-code-54}

Primes up to n:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{auto}\NormalTok{ primes }\OperatorTok{=}\NormalTok{ sieve}\OperatorTok{(}\DecValTok{100}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Totients up to n:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{phi\_sieve}\OperatorTok{();}
\NormalTok{cout }\OperatorTok{\textless{}\textless{}}\NormalTok{ phi}\OperatorTok{[}\DecValTok{10}\OperatorTok{];} \CommentTok{// 4}
\end{Highlighting}
\end{Shaded}

Factorization:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{auto}\NormalTok{ f }\OperatorTok{=}\NormalTok{ factorize}\OperatorTok{(}\DecValTok{60}\OperatorTok{);} \CommentTok{// [2, 2, 3, 5]}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-15}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1972}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2958}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2535}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2535}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Eratosthenes & Mark multiples & (O\(n \log \log n\)) & Simple prime
gen \\
Linear Sieve & Mark once & (O(n)) & Prime + SPF \\
SPF Table & Smallest prime factor & (O(1)) query & Fast factorization \\
φ(n) & Coprime count & (O(n)) & Modular exponent \\
Fermat / Euler & Inverses, reduction & (O\(\log n\)) & Modular
arithmetic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-54}

Sieve methods are the fastest way to preprocess arithmetic information.
They unlock efficient solutions to problems involving primes, divisors,
modular equations, and cryptography.

\begin{quote}
``Before you can reason about numbers, you must first sieve them
clean.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-54}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate all primes \(\le 10^6\) using a linear sieve.
\item
  Factorize \(840\) using the SPF array.
\item
  Compute \(\varphi(n)\) for \(n = 1..20\).
\item
  Verify \(a^{\varphi(n)} \equiv 1 \pmod{n}\) for \(a = 3\), \(n = 10\).
\item
  Solve \(a^b \bmod n\) with \(b\) very large using \(\varphi(n)\).
\end{enumerate}

Sieve once, and modular math becomes effortless forever after.

\subsection{56. Linear Algebra (Gaussian Elimination, LU,
SVD)}\label{linear-algebra-gaussian-elimination-lu-svd}

Linear algebra gives algorithms their mathematical backbone. From
solving equations to powering ML models, it's the hidden engine behind
optimization, geometry, and numerical computation.

In this section, we'll focus on the algorithmic toolkit:

\begin{itemize}
\tightlist
\item
  Gaussian Elimination (solve systems, invert matrices)
\item
  LU Decomposition (efficient repeated solving)
\item
  SVD (Singular Value Decomposition) overview
\end{itemize}

You'll see how algebra becomes code , step by step.

\subsubsection{1. Systems of Linear
Equations}\label{systems-of-linear-equations}

We want to solve: \[
A \cdot x = b
\] where ( A ) is an \(n \times n\) matrix, and ( x, b ) are vectors.

For example: \[\begin{cases}
2x + 3y = 8 \
x + 2y = 5
\end{cases}\]

The solution is the intersection of two lines. In general, \(A^{-1}b\)
gives ( x ), but we usually solve it more directly using Gaussian
elimination.

\subsubsection{2. Gaussian Elimination (Row
Reduction)}\label{gaussian-elimination-row-reduction}

Idea: Transform ( {[}A\textbar b{]} ) (augmented matrix) into
upper-triangular form, then back-substitute.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each row, select a pivot (non-zero leading element).
\item
  Eliminate below it using row operations.
\item
  After all pivots, back-substitute to get the solution.
\end{enumerate}

\subsubsection{A. Implementation (C)}\label{a.-implementation-c}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{double}\NormalTok{ EPS }\OperatorTok{=} \FloatTok{1e{-}9}\OperatorTok{;}

\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ gauss}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ A}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ A}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \CommentTok{// 1. Find pivot}
        \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textgreater{}}\NormalTok{ fabs}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{pivot}\OperatorTok{][}\NormalTok{i}\OperatorTok{]))}
\NormalTok{                pivot }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
\NormalTok{        swap}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ A}\OperatorTok{[}\NormalTok{pivot}\OperatorTok{]);}
\NormalTok{        swap}\OperatorTok{(}\NormalTok{b}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ b}\OperatorTok{[}\NormalTok{pivot}\OperatorTok{]);}

        \CommentTok{// 2. Normalize pivot row}
        \DataTypeTok{double}\NormalTok{ div }\OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{div}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ EPS}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{/=}\NormalTok{ div}\OperatorTok{;}
\NormalTok{        b}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/=}\NormalTok{ div}\OperatorTok{;}

        \CommentTok{// 3. Eliminate below}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ factor }\OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}\NormalTok{ A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ factor }\OperatorTok{*}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
\NormalTok{            b}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ factor }\OperatorTok{*}\NormalTok{ b}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \CommentTok{// 4. Back substitution}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ x}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
\NormalTok{        x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ b}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{            x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ x}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time complexity: ( O\(n^3\) )

\subsubsection{B. Example}\label{b.-example-5}

Solve: \[\begin{cases}
2x + 3y = 8 \
x + 2y = 5
\end{cases}\]

Augmented matrix: \[\begin{bmatrix}
2 & 3 & | & 8 \
1 & 2 & | & 5
\end{bmatrix}\]

Reduce:

\begin{itemize}
\tightlist
\item
  Row2 ← Row2 − ½ Row1 → \([1, 2 | 5] \to [0, 0.5 | 1]\)- Back
  substitute → ( y = 2, x = 1 )
\end{itemize}

\subsubsection{3. LU Decomposition}\label{lu-decomposition}

LU factorization expresses: \[
A = L \cdot U
\] where ( L ) is lower-triangular (1s on diagonal), ( U ) is
upper-triangular.

This allows solving ( A x = b ) in two triangular solves:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve ( L y = b )
\item
  Solve ( U x = y )
\end{enumerate}

Efficient when solving for multiple b's (same A).

\subsubsection{A. Decomposition
Algorithm}\label{a.-decomposition-algorithm}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ lu\_decompose}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ A}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ L}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ U}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ A}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\NormalTok{    L}\OperatorTok{.}\NormalTok{assign}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}(}\NormalTok{n}\OperatorTok{,} \DecValTok{0}\OperatorTok{));}
\NormalTok{    U}\OperatorTok{.}\NormalTok{assign}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}(}\NormalTok{n}\OperatorTok{,} \DecValTok{0}\OperatorTok{));}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \CommentTok{// Upper}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{                sum }\OperatorTok{+=}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ U}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
\NormalTok{            U}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sum}\OperatorTok{;}
        \OperatorTok{\}}
        \CommentTok{// Lower}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==}\NormalTok{ k}\OperatorTok{)}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{else} \OperatorTok{\{}
                \DataTypeTok{double}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
                \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{                    sum }\OperatorTok{+=}\NormalTok{ L}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ U}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
\NormalTok{                L}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sum}\OperatorTok{)} \OperatorTok{/}\NormalTok{ U}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Solve with forward + backward substitution.

\subsubsection{4. Singular Value Decomposition
(SVD)}\label{singular-value-decomposition-svd}

SVD generalizes diagonalization for non-square matrices: \[
A = U \Sigma V^T
\]

Where:

\begin{itemize}
\item
  ( U ): left singular vectors (orthogonal)- \(\Sigma\): diagonal of
  singular values- \(V^T\): right singular vectors Applications:
\item
  Data compression (PCA)- Noise reduction- Rank estimation-
  Pseudoinverse \(A^+ = V \Sigma^{-1} U^T\) In practice, use libraries
  (e.g.~LAPACK, Eigen).
\end{itemize}

\subsubsection{5. Numerical Stability and
Pivoting}\label{numerical-stability-and-pivoting}

In floating-point math:

\begin{itemize}
\tightlist
\item
  Always pick largest pivot (partial pivoting)- Avoid dividing by small
  numbers- Use EPS = 1e-9 threshold Small numerical errors can amplify
  quickly , stability is key.
\end{itemize}

\subsubsection{6. Tiny Code}\label{tiny-code-55}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ A }\OperatorTok{=} \OperatorTok{\{\{}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{\},} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{\}\};}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ b }\OperatorTok{=} \OperatorTok{\{}\DecValTok{8}\OperatorTok{,} \DecValTok{5}\OperatorTok{\};}
\KeywordTok{auto}\NormalTok{ x }\OperatorTok{=}\NormalTok{ gauss}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\CommentTok{// Output: x = [1, 2]}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-16}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2800}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gaussian Elimination & Solve Ax=b & (O\(n^3\)) & Direct method \\
LU Decomposition & Repeated solves & (O\(n^3\)) & Triangular
factorization \\
SVD & General decomposition & (O\(n^3\)) & Robust, versatile \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-55}

Linear algebra is the language of algorithms , it solves equations,
optimizes functions, and projects data. Whether building solvers or
neural networks, these methods are your foundation.

\begin{quote}
``Every algorithm lives in a vector space , it just needs a basis to
express itself.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-55}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve a 3×3 linear system with Gaussian elimination.
\item
  Implement LU decomposition and test \(L \cdot U = A\).
\item
  Use LU to solve multiple ( b ) vectors.
\item
  Explore SVD using a math library; compute singular values of a 2×2
  matrix.
\item
  Compare results between naive and pivoted elimination for unstable
  systems.
\end{enumerate}

Start with row operations , and you'll see how geometry and algebra
merge into code.

\subsection{57. FFT and NTT (Fast
Transforms)}\label{fft-and-ntt-fast-transforms}

The Fast Fourier Transform (FFT) is one of the most beautiful and
practical algorithms ever invented. It converts data between time (or
coefficient) domain and frequency (or point) domain efficiently. The
Number Theoretic Transform (NTT) is its modular counterpart for integer
arithmetic , ideal for polynomial multiplication under a modulus.

This section covers:

\begin{itemize}
\tightlist
\item
  Why we need transforms- Discrete Fourier Transform (DFT)- Cooley-Tukey
  FFT (complex numbers)- NTT (modular version)- Applications (polynomial
  multiplication, convolution)
\end{itemize}

\subsubsection{1. Motivation}\label{motivation}

Suppose you want to multiply two polynomials: \[
A(x) = a_0 + a_1x + a_2x^2
\]

\[
B(x) = b_0 + b_1x + b_2x^2
\]

Their product has coefficients: \[
c_k = \sum_{i+j=k} a_i \cdot b_j
\]

This is convolution: \[
C = A * B
\] Naively, this takes ( O\(n^2\) ). FFT reduces it to ( O\(n \log n\)
).

\subsubsection{2. Discrete Fourier Transform
(DFT)}\label{discrete-fourier-transform-dft}

The DFT maps coefficients \(a_0, a_1, \ldots, a_{n-1}\) to evaluations
at ( n )-th roots of unity:

\[
A_k = \sum_{j=0}^{n-1} a_j \cdot e^{-2\pi i \cdot jk / n}
\]

and the inverse transform recovers \(a_j\) from \(A_k\).

\subsubsection{3. Cooley-Tukey FFT}\label{cooley-tukey-fft}

Key idea: recursively split the sum into even and odd parts:

\[
A_k = A_{even}(w_n^2) + w_n^k \cdot A_{odd}(w_n^2)
\]

Where \(w_n = e^{-2\pi i / n}\) is an ( n )-th root of unity.

\subsubsection{Implementation (C++)}\label{implementation-c}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}complex\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}vector\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}cmath\textgreater{}}
\KeywordTok{using} \KeywordTok{namespace}\NormalTok{ std}\OperatorTok{;}

\KeywordTok{using}\NormalTok{ cd }\OperatorTok{=}\NormalTok{ complex}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{};}
\AttributeTok{const} \DataTypeTok{double}\NormalTok{ PI }\OperatorTok{=}\NormalTok{ acos}\OperatorTok{({-}}\DecValTok{1}\OperatorTok{);}

\DataTypeTok{void}\NormalTok{ fft}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{cd}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{a}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ invert}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ bit }\OperatorTok{=}\NormalTok{ n }\OperatorTok{\textgreater{}\textgreater{}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ j }\OperatorTok{\&}\NormalTok{ bit}\OperatorTok{;}\NormalTok{ bit }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{)}\NormalTok{ j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
\NormalTok{        j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
    \OperatorTok{\}}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}\textless{}=} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ ang }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ PI }\OperatorTok{/}\NormalTok{ len }\OperatorTok{*} \OperatorTok{(}\NormalTok{invert }\OperatorTok{?} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{:} \DecValTok{1}\OperatorTok{);}
\NormalTok{        cd wlen}\OperatorTok{(}\NormalTok{cos}\OperatorTok{(}\NormalTok{ang}\OperatorTok{),}\NormalTok{ sin}\OperatorTok{(}\NormalTok{ang}\OperatorTok{));}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ len}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            cd w}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{                cd u }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{],}\NormalTok{ v }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{*}\NormalTok{ w}\OperatorTok{;}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v}\OperatorTok{;}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v}\OperatorTok{;}
\NormalTok{                w }\OperatorTok{*=}\NormalTok{ wlen}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{invert}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{cd }\OperatorTok{\&}\NormalTok{x }\OperatorTok{:}\NormalTok{ a}\OperatorTok{)}\NormalTok{ x }\OperatorTok{/=}\NormalTok{ n}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Polynomial Multiplication with
FFT}\label{polynomial-multiplication-with-fft}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}}\NormalTok{ multiply}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}} \AttributeTok{const}\OperatorTok{\&}\NormalTok{ a}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}} \AttributeTok{const}\OperatorTok{\&}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\NormalTok{cd}\OperatorTok{\textgreater{}}\NormalTok{ fa}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ a}\OperatorTok{.}\NormalTok{end}\OperatorTok{()),}\NormalTok{ fb}\OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ b}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)}\NormalTok{a}\OperatorTok{.}\NormalTok{size}\OperatorTok{()} \OperatorTok{+} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)}\NormalTok{b}\OperatorTok{.}\NormalTok{size}\OperatorTok{())}\NormalTok{ n }\OperatorTok{\textless{}\textless{}=} \DecValTok{1}\OperatorTok{;}
\NormalTok{    fa}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    fb}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}

\NormalTok{    fft}\OperatorTok{(}\NormalTok{fa}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
\NormalTok{    fft}\OperatorTok{(}\NormalTok{fb}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ fa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*=}\NormalTok{ fb}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{    fft}\OperatorTok{(}\NormalTok{fa}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);}

\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}}\NormalTok{ result}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        result}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ llround}\OperatorTok{(}\NormalTok{fa}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{real}\OperatorTok{());}
    \ControlFlowTok{return}\NormalTok{ result}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: ( O\(n \log n\) )

\subsubsection{4. Number Theoretic Transform
(NTT)}\label{number-theoretic-transform-ntt}

FFT uses complex numbers , NTT uses modular arithmetic with roots of
unity mod p. We need a prime ( p ) such that: \[
p = c \cdot 2^k + 1
\] so a primitive root ( g ) exists.

Popular choices:

\begin{itemize}
\tightlist
\item
  ( p = 998244353, g = 3 )- ( p = 7340033, g = 3 )
\end{itemize}

\subsubsection{Implementation (NTT)}\label{implementation-ntt}

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{const} \DataTypeTok{int}\NormalTok{ MOD }\OperatorTok{=} \DecValTok{998244353}\OperatorTok{;}
\AttributeTok{const} \DataTypeTok{int}\NormalTok{ G }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ modpow}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ res }\OperatorTok{=}\NormalTok{ res }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ a }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ ntt}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{a}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ invert}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ bit }\OperatorTok{=}\NormalTok{ n }\OperatorTok{\textgreater{}\textgreater{}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ j }\OperatorTok{\&}\NormalTok{ bit}\OperatorTok{;}\NormalTok{ bit }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{)}\NormalTok{ j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
\NormalTok{        j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}\textless{}=} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ wlen }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{G}\OperatorTok{,} \OperatorTok{(}\NormalTok{MOD }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{/}\NormalTok{ len}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{invert}\OperatorTok{)}\NormalTok{ wlen }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{wlen}\OperatorTok{,}\NormalTok{ MOD }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ len}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ w }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{];}
                \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)(}\NormalTok{a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{*}\NormalTok{ w }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{);}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v }\OperatorTok{\textless{}}\NormalTok{ MOD }\OperatorTok{?}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v }\OperatorTok{:}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v }\OperatorTok{{-}}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v }\OperatorTok{\textgreater{}=} \DecValTok{0} \OperatorTok{?}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v }\OperatorTok{:}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v }\OperatorTok{+}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{                w }\OperatorTok{=}\NormalTok{ w }\OperatorTok{*}\NormalTok{ wlen }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{invert}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ inv\_n }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ MOD }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int} \OperatorTok{\&}\NormalTok{x }\OperatorTok{:}\NormalTok{ a}\OperatorTok{)}\NormalTok{ x }\OperatorTok{=} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ x }\OperatorTok{*}\NormalTok{ inv\_n }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Applications}\label{applications-7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Polynomial Multiplication: ( O\(n \log n\) )
\item
  Convolution: digital signal processing
\item
  Big Integer Multiplication (Karatsuba, FFT)
\item
  Subset Convolution and combinatorial transforms
\item
  Number-theoretic sums (NTT-friendly modulus)
\end{enumerate}

\subsubsection{6. Tiny Code}\label{tiny-code-56}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ A }\OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ B }\OperatorTok{=} \OperatorTok{\{}\DecValTok{4}\OperatorTok{,} \DecValTok{5}\OperatorTok{,} \DecValTok{6}\OperatorTok{\};}
\CommentTok{// Result = \{4, 13, 28, 27, 18\}}
\KeywordTok{auto}\NormalTok{ C }\OperatorTok{=}\NormalTok{ multiply}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ B}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-17}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Domain & Complexity & Type \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFT & Complex & ( O\(n^2\) ) & Naive \\
FFT & Complex & ( O\(n \log n\) ) & Recursive \\
NTT & Modular & ( O\(n \log n\) ) & Integer arithmetic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-56}

FFT and NTT bring polynomial algebra to life. They turn slow
convolutions into lightning-fast transforms. From multiplying huge
integers to compressing signals, they're the ultimate divide-and-conquer
on structure.

\begin{quote}
``To multiply polynomials fast, you first turn them into music , then
back again.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-56}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiply (\(1 + 2x + 3x^2\)) and (\(4 + 5x + 6x^2\)) using FFT.
\item
  Implement NTT over 998244353 and verify results mod p.
\item
  Compare ( O\(n^2\) ) vs FFT performance for n = 1024.
\item
  Experiment with inverse FFT (invert = true).
\item
  Explore circular convolution for signal data.
\end{enumerate}

Once you master FFT/NTT, you hold the power of speed in algebraic
computation.

\subsection{58. Numerical Methods (Newton, Simpson,
Runge-Kutta)}\label{numerical-methods-newton-simpson-runge-kutta}

Numerical methods let us approximate solutions when exact algebraic
answers are hard or impossible. They are the foundation of scientific
computing, simulation, and optimization , bridging the gap between
continuous math and discrete computation.

In this section, we'll explore three classics:

\begin{itemize}
\tightlist
\item
  Newton-Raphson: root finding- Simpson's Rule: numerical integration-
  Runge-Kutta (RK4): solving differential equations These algorithms
  showcase how iteration, approximation, and convergence build powerful
  tools.
\end{itemize}

\subsubsection{1. Newton-Raphson Method}\label{newton-raphson-method}

Used to find a root of ( f(x) = 0 ). Starting from a guess \(x_0\),
iteratively refine:

\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
\]

Convergence is quadratic if ( f ) is smooth and \(x_0\) is close enough.

\subsubsection{A. Example}\label{a.-example}

Solve ( f(x) = x\^{}2 - 2 = 0 ) We know root = \(\sqrt{2}\)

Start \(x_0 = 1\)

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Iter & \(x_n\) & (f\(x_n\)) & (f'\(x_n\)) & \(x_{n+1}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1.000 & -1.000 & 2.000 & 1.500 \\
1 & 1.500 & 0.250 & 3.000 & 1.417 \\
2 & 1.417 & 0.006 & 2.834 & 1.414 \\
\end{longtable}

Converged: \(1.414 \approx \sqrt{2}\)

\subsubsection{B. Implementation}\label{b.-implementation-8}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{*}\NormalTok{ x }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{double}\NormalTok{ df}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \DecValTok{2} \OperatorTok{*}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ newton}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x0}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{20}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ fx }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x0}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ dfx }\OperatorTok{=}\NormalTok{ df}\OperatorTok{(}\NormalTok{x0}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{fx}\OperatorTok{)} \OperatorTok{\textless{}} \FloatTok{1e{-}9}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{        x0 }\OperatorTok{=}\NormalTok{ x0 }\OperatorTok{{-}}\NormalTok{ fx }\OperatorTok{/}\NormalTok{ dfx}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ x0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Root: }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ newton}\OperatorTok{(}\FloatTok{1.0}\OperatorTok{));} \CommentTok{// 1.414214}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O(k) ) iterations, each ( O(1) )

\subsubsection{2. Simpson's Rule (Numerical
Integration)}\label{simpsons-rule-numerical-integration}

When you can't integrate ( f(x) ) analytically, approximate the area
under the curve.

Divide interval ({[}a, b{]}) into even ( n ) subintervals (width ( h )).

\[
I \approx \frac{h}{3} \Big( f(a) + 4 \sum f(x_{odd}) + 2 \sum f(x_{even}) + f(b) \Big)
\]

\subsubsection{A. Implementation}\label{a.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{*}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}} \CommentTok{// integrate x\^{}2}

\DataTypeTok{double}\NormalTok{ simpson}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ h }\OperatorTok{=} \OperatorTok{(}\NormalTok{b }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{)} \OperatorTok{/}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{double}\NormalTok{ s }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{a}\OperatorTok{)} \OperatorTok{+}\NormalTok{ f}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ x }\OperatorTok{=}\NormalTok{ a }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*}\NormalTok{ h}\OperatorTok{;}
\NormalTok{        s }\OperatorTok{+=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{)} \OperatorTok{*} \OperatorTok{(}\NormalTok{i }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0} \OperatorTok{?} \DecValTok{2} \OperatorTok{:} \DecValTok{4}\OperatorTok{);}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ s }\OperatorTok{*}\NormalTok{ h }\OperatorTok{/} \DecValTok{3}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"∫₀¹ x² dx ≈ }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ simpson}\OperatorTok{(}\DecValTok{0}\OperatorTok{,} \DecValTok{1}\OperatorTok{,} \DecValTok{100}\OperatorTok{));} \CommentTok{// \textasciitilde{}0.333333}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Accuracy: ( O\(h^4\) ) Note: ( n ) must be even.

\subsubsection{B. Example}\label{b.-example-6}

\[
\int_0^1 x^2 dx = \frac{1}{3}
\] With ( n = 100 ), Simpson gives ( 0.333333 ).

\subsubsection{3. Runge-Kutta (RK4)}\label{runge-kutta-rk4}

Used to solve first-order ODEs: \[
y' = f(x, y), \quad y(x_0) = y_0
\]

RK4 Formula:

\[\begin{aligned}
k_1 &= f(x_n, y_n) \
k_2 &= f(x_n + \frac{h}{2}, y_n + \frac{h}{2}k_1) \
k_3 &= f(x_n + \frac{h}{2}, y_n + \frac{h}{2}k_2) \
k_4 &= f(x_n + h, y_n + hk_3) \
y_{n+1} &= y_n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{aligned}\]

Accuracy: ( O\(h^4\) )

\subsubsection{A. Example}\label{a.-example-1}

Solve ( y' = x + y ), ( y(0) = 1 ), step ( h = 0.1 ).

Each iteration refines ( y ) with weighted slope average.

\subsubsection{B. Implementation}\label{b.-implementation-9}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{+}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ runge\_kutta}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x0}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y0}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ h}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ xn}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ x }\OperatorTok{=}\NormalTok{ x0}\OperatorTok{,}\NormalTok{ y }\OperatorTok{=}\NormalTok{ y0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{x }\OperatorTok{\textless{}}\NormalTok{ xn}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ k1 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ k2 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x }\OperatorTok{+}\NormalTok{ h }\OperatorTok{/} \DecValTok{2}\OperatorTok{,}\NormalTok{ y }\OperatorTok{+}\NormalTok{ h }\OperatorTok{*}\NormalTok{ k1 }\OperatorTok{/} \DecValTok{2}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ k3 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x }\OperatorTok{+}\NormalTok{ h }\OperatorTok{/} \DecValTok{2}\OperatorTok{,}\NormalTok{ y }\OperatorTok{+}\NormalTok{ h }\OperatorTok{*}\NormalTok{ k2 }\OperatorTok{/} \DecValTok{2}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ k4 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x }\OperatorTok{+}\NormalTok{ h}\OperatorTok{,}\NormalTok{ y }\OperatorTok{+}\NormalTok{ h }\OperatorTok{*}\NormalTok{ k3}\OperatorTok{);}
\NormalTok{        y }\OperatorTok{+=}\NormalTok{ h }\OperatorTok{*} \OperatorTok{(}\NormalTok{k1 }\OperatorTok{+} \DecValTok{2}\OperatorTok{*}\NormalTok{k2 }\OperatorTok{+} \DecValTok{2}\OperatorTok{*}\NormalTok{k3 }\OperatorTok{+}\NormalTok{ k4}\OperatorTok{)} \OperatorTok{/} \DecValTok{6}\OperatorTok{;}
\NormalTok{        x }\OperatorTok{+=}\NormalTok{ h}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"y(0.1) ≈ }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ runge\_kutta}\OperatorTok{(}\DecValTok{0}\OperatorTok{,} \DecValTok{1}\OperatorTok{,} \FloatTok{0.1}\OperatorTok{,} \FloatTok{0.1}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Tiny Code Summary}\label{tiny-code-summary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2208}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1558}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3377}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1169}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1688}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Accuracy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Newton-Raphson & Root finding & \(x_{n+1}=x_n-\frac{f}{f'}\) & Quadratic
& Iterative \\
Simpson's Rule & Integration & (h/3(\ldots)) & (O\(h^4\)) &
Deterministic \\
Runge-Kutta (RK4) & ODEs & Weighted slope avg & (O\(h^4\)) &
Iterative \\
\end{longtable}

\subsubsection{5. Numerical Stability}\label{numerical-stability}

\begin{itemize}
\tightlist
\item
  Small step ( h ): better accuracy, more cost- Large ( h ): faster,
  less stable- Always check convergence
  (\(|x_{n+1} - x_n| < \varepsilon\))- Avoid division by small
  derivatives in Newton's method
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-57}

Numerical methods let computers simulate the continuous world. From
physics to AI training, they solve what calculus cannot symbolically.

\begin{quote}
``When equations won't talk, iterate , and they'll whisper their
answers.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-57}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Newton's method for \(\cos x - x = 0\).
\item
  Approximate \(\displaystyle \int_0^{\pi/2} \sin x\,dx\) with Simpson's
  rule.
\item
  Solve \(y' = y - x^2 + 1,\ y(0) = 0.5\) using RK4.
\item
  Compare RK4 with Euler's method for the same ODE.
\item
  Experiment with step sizes \(h \in \{0.1, 0.01, 0.001\}\) and observe
  convergence.
\end{enumerate}

Numerical thinking turns continuous problems into iterative algorithms ,
precise enough to power every simulation and solver you'll ever write.

\subsection{59. Mathematical Optimization (Simplex, Gradient,
Convex)}\label{mathematical-optimization-simplex-gradient-convex}

Mathematical optimization is about finding the best solution , smallest
cost, largest profit, shortest path , under given constraints. It's the
heart of machine learning, operations research, and engineering design.

In this section, we'll explore three pillars:

\begin{itemize}
\tightlist
\item
  Simplex Method , for linear programs
\item
  Gradient Descent , for continuous optimization
\item
  Convex Optimization , the theory ensuring global optima
\end{itemize}

\subsubsection{1. What Is Optimization?}\label{what-is-optimization}

A general optimization problem looks like:

\[
\min_x \ f(x)
\] subject to constraints: \[
g_i(x) \le 0, \quad h_j(x) = 0
\]

When ( f ) and \(g_i, h_j\) are linear, it's a Linear Program (LP). When
( f ) is differentiable, we can use gradients. When ( f ) is convex,
every local minimum is global , the ideal world.

\subsubsection{2. The Simplex Method (Linear
Programming)}\label{the-simplex-method-linear-programming}

A linear program has the form:

\[
\max \ c^T x
\] subject to \[
A x \le b, \quad x \ge 0
\]

Geometrically, each constraint forms a half-space. The feasible region
is a convex polytope, and the optimum lies at a vertex.

\subsubsection{A. Example}\label{a.-example-2}

Maximize ( z = 3x + 2y ) subject to \[\begin{cases}
2x + y \le 18 \
2x + 3y \le 42 \
x, y \ge 0
\end{cases}\]

Solution: ( x=9, y=8 ), ( z=43 )

\subsubsection{B. Algorithm (Sketch)}\label{b.-algorithm-sketch}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Convert inequalities to equalities by adding slack variables.
\item
  Initialize at a vertex (basic feasible solution).
\item
  At each step:

  \begin{itemize}
  \tightlist
  \item
    Choose entering variable (most negative coefficient in objective). -
    Choose leaving variable (min ratio test). - Pivot to new vertex.4.
    Repeat until optimal.
  \end{itemize}
\end{enumerate}

\subsubsection{C. Implementation (Simplified
Pseudocode)}\label{c.-implementation-simplified-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Basic simplex{-}like outline}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{exists negative coefficient in objective row}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    choose entering column j}\OperatorTok{;}
\NormalTok{    choose leaving row i }\OperatorTok{(}\NormalTok{min b}\OperatorTok{[}\NormalTok{i}\OperatorTok{]/}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
\NormalTok{    pivot}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{ j}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Libraries (like \texttt{GLPK} or \texttt{Eigen}) handle full
implementations.

Time Complexity: worst ( O\(2^n\) ), but fast in practice.

\subsubsection{3. Gradient Descent}\label{gradient-descent}

For differentiable ( f(x) ), we move opposite the gradient:

\[
x_{k+1} = x_k - \eta \nabla f(x_k)
\]

where \(\eta\) is the learning rate.

Intuition: ( \nabla f(x) ) points uphill, so step opposite it.

\subsubsection{A. Example}\label{a.-example-3}

Minimize ( f(x) = (x-3)\^{}2 )

\[
f'(x) = 2(x-3)
\]

Start \(x_0 = 0\), \(\eta = 0.1\)

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Iter & \(x_k\) & (f\(x_k\)) & Gradient & New (x) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0 & 9 & -6 & 0.6 \\
1 & 0.6 & 5.76 & -4.8 & 1.08 \\
2 & 1.08 & 3.69 & -3.84 & 1.46 \\
\ldots{} & →3 & →0 & →0 & →3 \\
\end{longtable}

Converges to ( x = 3 )

\subsubsection{B. Implementation}\label{b.-implementation-10}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}} \DecValTok{3}\OperatorTok{)} \OperatorTok{*} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}} \DecValTok{3}\OperatorTok{);} \OperatorTok{\}}
\DataTypeTok{double}\NormalTok{ df}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \DecValTok{2} \OperatorTok{*} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}} \DecValTok{3}\OperatorTok{);} \OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ gradient\_descent}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x0}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ lr}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ g }\OperatorTok{=}\NormalTok{ df}\OperatorTok{(}\NormalTok{x0}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{g}\OperatorTok{)} \OperatorTok{\textless{}} \FloatTok{1e{-}6}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{        x0 }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ g}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ x0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Min at x = }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ gradient\_descent}\OperatorTok{(}\DecValTok{0}\OperatorTok{,} \FloatTok{0.1}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Variants}\label{c.-variants}

\begin{itemize}
\tightlist
\item
  Momentum: ( v = \beta v + \(1-\beta\)\nabla f(x) )- Adam: adaptive
  learning rates- Stochastic Gradient Descent (SGD): random subset of
  data All used heavily in machine learning.
\end{itemize}

\subsubsection{4. Convex Optimization}\label{convex-optimization}

A function ( f ) is convex if: \[
f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda)f(y)
\]

This means any local minimum is global.

Examples:

\begin{itemize}
\tightlist
\item
  ( f(x) = x\^{}2 ) (convex)- ( f(x) = x\^{}3 ) (not convex) For convex
  functions with linear constraints, gradient-based methods always
  converge to the global optimum.
\end{itemize}

\subsubsection{A. Checking Convexity}\label{a.-checking-convexity}

\begin{itemize}
\tightlist
\item
  1D: ( f'\,'(x) \ge 0 )- Multivariate: Hessian ( \nabla\^{}2 f(x) ) is
  positive semidefinite
\end{itemize}

\subsubsection{5. Applications}\label{applications-8}

\begin{itemize}
\tightlist
\item
  Linear Programming (Simplex): logistics, scheduling- Quadratic
  Programming: portfolio optimization- Gradient Methods: ML, curve
  fitting- Convex Programs: control systems, regularization
\end{itemize}

\subsubsection{6. Tiny Code}\label{tiny-code-57}

Simple gradient descent to minimize ( f(x,y)=x\textsuperscript{2+y}2 ):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ y}\OperatorTok{*}\NormalTok{y}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{void}\NormalTok{ grad}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y}\OperatorTok{,} \DataTypeTok{double} \OperatorTok{*}\NormalTok{gx}\OperatorTok{,} \DataTypeTok{double} \OperatorTok{*}\NormalTok{gy}\OperatorTok{)} \OperatorTok{\{}
    \OperatorTok{*}\NormalTok{gx }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{x}\OperatorTok{;} \OperatorTok{*}\NormalTok{gy }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{y}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ optimize}\OperatorTok{()} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ x}\OperatorTok{=}\DecValTok{5}\OperatorTok{,}\NormalTok{ y}\OperatorTok{=}\DecValTok{3}\OperatorTok{,}\NormalTok{ lr}\OperatorTok{=}\FloatTok{0.1}\OperatorTok{;}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)\{}
        \DataTypeTok{double}\NormalTok{ gx}\OperatorTok{,}\NormalTok{ gy}\OperatorTok{;}
\NormalTok{        grad}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{,} \OperatorTok{\&}\NormalTok{gx}\OperatorTok{,} \OperatorTok{\&}\NormalTok{gy}\OperatorTok{);}
\NormalTok{        x }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ gx}\OperatorTok{;}
\NormalTok{        y }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ gy}\OperatorTok{;}
    \OperatorTok{\}}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Min at (}\SpecialCharTok{\%.3f}\StringTok{, }\SpecialCharTok{\%.3f}\StringTok{)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-18}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2025}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1266}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3671}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3038}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Simplex & Linear & Polynomial (average case) & LP solver \\
Gradient Descent & Continuous & \(O(k)\) & Needs step size \\
Convex Methods & Convex & \(O(k \log \frac{1}{\varepsilon})\) & Global
optima guaranteed \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-58}

Optimization turns math into decisions. From fitting curves to planning
resources, it formalizes trade-offs and efficiency. It's where
computation meets purpose , finding the best in all possible worlds.

\begin{quote}
``Every algorithm is, at heart, an optimizer , searching for something
better.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-58}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve a linear program with 2 constraints manually via Simplex.
\item
  Implement gradient descent for \(f(x) = (x - 5)^2 + 2\).
\item
  Add momentum to your gradient descent loop.
\item
  Check convexity by plotting \(f(x) = x^4 - 3x^2\).
\item
  Experiment with learning rates: too small leads to slow convergence;
  too large can diverge.
\end{enumerate}

Mastering optimization means mastering how algorithms improve themselves
, step by step, iteration by iteration.

\subsection{60. Algebraic Tricks and Transform
Techniques}\label{algebraic-tricks-and-transform-techniques}

In algorithm design, algebra isn't just theory , it's a toolbox for
transforming problems. By expressing computations algebraically, we can
simplify, accelerate, or generalize solutions. This section surveys
common algebraic techniques that turn hard problems into manageable
ones.

We'll explore:

\begin{itemize}
\tightlist
\item
  Algebraic identities and factorizations
\item
  Generating functions and transforms
\item
  Convolution tricks
\item
  Polynomial methods and FFT applications
\item
  Matrix and linear transforms for acceleration
\end{itemize}

\subsubsection{1. Algebraic Identities}\label{algebraic-identities}

These let you rewrite or decompose expressions to reveal structure or
reduce complexity.

Classic Forms:

\begin{itemize}
\tightlist
\item
  Difference of squares: \[
  a^2 - b^2 = (a-b)(a+b)
  \]
\item
  Sum of cubes: \[
  a^3 + b^3 = (a+b)(a^2 - ab + b^2)
  \]
\item
  Square of sum: \[
  (a+b)^2 = a^2 + 2ab + b^2
  \]
\end{itemize}

Used in dynamic programming, geometry, and optimization when simplifying
recurrence terms or constraints.

Example: Transforming \((x+y)^2\) lets you compute both \(x^2 + y^2\)
and cross terms efficiently.

\subsubsection{2. Generating Functions}\label{generating-functions}

A generating function encodes a sequence \(a_0, a_1, a_2, \ldots\) into
a formal power series:

\[
G(x) = a_0 + a_1x + a_2x^2 + \ldots
\]

They turn recurrence relations and counting problems into algebraic
equations.

Example: Fibonacci sequence \[
F(x) = F_0 + F_1x + F_2x^2 + \ldots
\] with recurrence \(F_n = F_{n-1} + F_{n-2}\)

Solve algebraically: \[
F(x) = \frac{x}{1 - x - x^2}
\]

Applications: combinatorics, probability, counting partitions.

\subsubsection{3. Convolution Tricks}\label{convolution-tricks}

Convolution arises in combining sequences: \[
(c_n) = (a * b)*n = \sum*{i=0}^{n} a_i b_{n-i}
\]

Naive computation: ( O\(n^2\) ) Using Fast Fourier Transform (FFT): (
O\(n \log n\) )

Example: Polynomial multiplication Let \[
A(x) = a_0 + a_1x + a_2x^2, \quad B(x) = b_0 + b_1x + b_2x^2
\] Then ( C(x) = A(x)B(x) ) gives coefficients by convolution.

This trick is used in:

\begin{itemize}
\tightlist
\item
  Large integer multiplication- Pattern matching (cross-correlation)-
  Subset sum acceleration
\end{itemize}

\subsubsection{4. Polynomial Methods}\label{polynomial-methods}

Many algorithmic problems can be represented as polynomials, where
coefficients encode combinatorial structure.

\subsubsection{A. Polynomial
Interpolation}\label{a.-polynomial-interpolation}

Given ( n+1 ) points, there's a unique degree-( n ) polynomial passing
through them.

Used in error correction, FFT-based reconstruction, and number-theoretic
transforms.

Lagrange Interpolation: \[
P(x) = \sum_i y_i \prod_{j \ne i} \frac{x - x_j}{x_i - x_j}
\]

\subsubsection{B. Root Representation}\label{b.-root-representation}

Solve equations or check identities by working modulo a polynomial. Used
in finite fields and coding theory (e.g., Reed-Solomon).

\subsubsection{5. Transform Techniques}\label{transform-techniques}

Transforms convert problems to simpler domains where operations become
efficient.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2828}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2020}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2828}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2323}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Transform
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Converts
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Used In
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
FFT / NTT & Time ↔ Frequency & Convolution → Multiplication & Signal,
polynomial mult \\
Z-Transform & Sequence ↔ Function & Recurrence solving & DSP, control \\
Laplace Transform & Function ↔ Algebraic & Diff. eq. → Algebraic eq. &
Continuous systems \\
Walsh-Hadamard Transform & Boolean vectors & XOR convolution & Subset
sum, SOS DP \\
\end{longtable}

Example: Subset Convolution via FWT

For all subsets ( S ): \[
f'(S) = \sum_{T \subseteq S} f(T)
\]

Use Fast Walsh-Hadamard Transform (FWHT) to compute in ( O\(n2^n\) )
instead of ( O\(3^n\) ).

\subsubsection{6. Matrix Tricks}\label{matrix-tricks}

Matrix algebra enables transformations and compact formulations.

\begin{itemize}
\tightlist
\item
  Matrix exponentiation: solve recurrences in \(O(\log n)\)
\item
  Diagonalization: \(A = P D P^{-1}\), then \(A^k = P D^k P^{-1}\)
\item
  Fast power: speeds up Fibonacci, linear recurrences, Markov chains
\end{itemize}

Example: Fibonacci

\[
\begin{bmatrix}
F_{n+1} \\
F_n
\end{bmatrix}
=
\begin{bmatrix}
1 & 1 \\
1 & 0
\end{bmatrix}^n
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\]

\subsubsection{7. Tiny Code}\label{tiny-code-58}

Polynomial Multiplication via FFT (Pseudo-C):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Outline using complex FFT library}
\NormalTok{fft}\OperatorTok{(}\NormalTok{A}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
\NormalTok{fft}\OperatorTok{(}\NormalTok{B}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    C}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*}\NormalTok{ B}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{fft}\OperatorTok{(}\NormalTok{C}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);} \CommentTok{// inverse}
\end{Highlighting}
\end{Shaded}

Matrix Power (Fibonacci):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ matmul}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ A}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{],} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ B}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{])} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ C}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{\{}\DecValTok{0}\OperatorTok{\}\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\DecValTok{2}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}}\DecValTok{2}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{k}\OperatorTok{\textless{}}\DecValTok{2}\OperatorTok{;}\NormalTok{k}\OperatorTok{++)}
\NormalTok{                C}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]*}\NormalTok{B}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
\NormalTok{    memcpy}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ C}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{C}\OperatorTok{));}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ matpow}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ A}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ R}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{\{}\DecValTok{1}\OperatorTok{,}\DecValTok{0}\OperatorTok{\},\{}\DecValTok{0}\OperatorTok{,}\DecValTok{1}\OperatorTok{\}\};}
    \ControlFlowTok{while}\OperatorTok{(}\NormalTok{n}\OperatorTok{)\{}
        \ControlFlowTok{if}\OperatorTok{(}\NormalTok{n}\OperatorTok{\&}\DecValTok{1}\OperatorTok{)}\NormalTok{ matmul}\OperatorTok{(}\NormalTok{R}\OperatorTok{,}\NormalTok{A}\OperatorTok{);}
\NormalTok{        matmul}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{A}\OperatorTok{);}
\NormalTok{        n}\OperatorTok{\textgreater{}\textgreater{}=}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
\NormalTok{    memcpy}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{R}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Summary}\label{summary-19}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3611}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Speedup
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Algebraic Identities & Simplify expressions & Constant factor \\
Generating Functions & Solve recurrences & Conceptual \\
FFT / Convolution & Combine sequences fast & (O\(n^2\)
\to O\(n \log n\)) \\
Polynomial Interpolation & Reconstruction & (O\(n^2\)
\to O\(n \log^2 n\)) \\
Matrix Tricks & Accelerate recurrences & (O(n) \to O\(\log n\)) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-59}

Algebra turns computation into structure. By rewriting problems in
algebraic form, you reveal hidden symmetries, exploit fast transforms,
and find elegant solutions. It's not magic , it's the math beneath
performance.

\begin{quote}
``The smartest code is often the one that solves itself on paper
first.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-59}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiply two polynomials using FFT.
\item
  Represent Fibonacci as a matrix and compute \(F_{100}\).
\item
  Use generating functions to count coin change ways.
\item
  Implement subset sum via Walsh-Hadamard transform.
\item
  Derive a recurrence and solve it algebraically.
\end{enumerate}

Understanding algebraic tricks makes you not just a coder, but a
mathematical engineer , bending structure to will.

\section{Chapter 7. Strings and Text
Algorithms}\label{chapter-7.-strings-and-text-algorithms-1}

\subsection{61. String Matching (KMP, Z, Rabin-Karp,
Boyer-Moore)}\label{string-matching-kmp-z-rabin-karp-boyer-moore}

String matching is one of the oldest and most fundamental problems in
computer science: given a text ( T ) of length ( n ) and a pattern ( P )
of length ( m ), find all positions where ( P ) appears in ( T ).

This section walks you through both naive and efficient algorithms ,
from the straightforward brute-force method to elegant linear-time
solutions like KMP and Z-algorithm, and clever heuristics like
Boyer-Moore and Rabin-Karp.

\subsubsection{1. Problem Setup}\label{problem-setup}

We're given:

\begin{itemize}
\tightlist
\item
  Text: \(T = t_1 t_2 \ldots t_n\)- Pattern: \(P = p_1 p_2 \ldots p_m\)
  Goal: find all ( i ) such that \[
  T[i \ldots i+m-1] = P[1 \ldots m]
  \]
\end{itemize}

Naive solution: compare ( P ) with every substring of ( T ) Time
complexity: ( O(nm) )

We'll now see how to reduce it to ( O(n + m) ) or close.

\subsubsection{2. Knuth-Morris-Pratt
(KMP)}\label{knuth-morris-pratt-kmp}

KMP avoids rechecking characters by precomputing overlaps within the
pattern.

It builds a prefix-function (also called failure function), which tells
how much to shift when a mismatch happens.

\subsubsection{A. Prefix Function}\label{a.-prefix-function}

For each position ( i ), compute \(\pi[i]\) = length of longest prefix
that's also a suffix of ( P{[}1..i{]} ).

Example: Pattern \texttt{ababc}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
i & P{[}i{]} & π{[}i{]} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & a & 0 \\
2 & b & 0 \\
3 & a & 1 \\
4 & b & 2 \\
5 & c & 0 \\
\end{longtable}

\subsubsection{B. Search Phase}\label{b.-search-phase}

Use \(\pi[]\) to skip mismatched prefixes in the text.

Time Complexity: ( O(n + m) ) Space: ( O(m) )

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ compute\_pi}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pi}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    pi}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k }\OperatorTok{=}\NormalTok{ pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{==}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
\NormalTok{        pi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ k}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ kmp\_search}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{t}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{t}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ pi}\OperatorTok{[}\NormalTok{m}\OperatorTok{];}\NormalTok{ compute\_pi}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ m}\OperatorTok{,}\NormalTok{ pi}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k }\OperatorTok{=}\NormalTok{ pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{==}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k }\OperatorTok{==}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            printf}\OperatorTok{(}\StringTok{"Found at }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ i }\OperatorTok{{-}}\NormalTok{ m }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{            k }\OperatorTok{=}\NormalTok{ pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Z-Algorithm}\label{z-algorithm}

Z-algorithm computes the Z-array,\\
where \(Z[i]\) = length of the longest substring starting at \(i\) that
matches the prefix of \(P\).

To match \(P\) in \(T\), build the string:

\[
S = P + \# + T
\]

Then every \(i\) where \(Z[i] = |P|\) corresponds to a match.

Time: \(O(n + m)\)\\
Simple and elegant.

Example:

\begin{verbatim}
P = "aba", T = "ababa"
S = "aba#ababa"
Z = [0,0,1,0,3,0,1,0]
Match at index 0, 2
\end{verbatim}

\subsubsection{4. Rabin-Karp (Rolling
Hash)}\label{rabin-karp-rolling-hash}

Instead of comparing strings character-by-character, compute a hash for
each window in ( T ), and compare hashes.

\[
h(s_1s_2\ldots s_m) = (s_1b^{m-1} + s_2b^{m-2} + \ldots + s_m) \bmod M
\]

Use a rolling hash to update in ( O(1) ) per shift.

Time: average ( O(n + m) ), worst ( O(nm) ) Good for multiple pattern
search.

Tiny Code (Rolling Hash)

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define B }\DecValTok{256}
\PreprocessorTok{\#define M }\DecValTok{101}

\DataTypeTok{void}\NormalTok{ rabin\_karp}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{t}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{t}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ h }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ pHash }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ tHash }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ h }\OperatorTok{=} \OperatorTok{(}\NormalTok{h}\OperatorTok{*}\NormalTok{B}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        pHash }\OperatorTok{=} \OperatorTok{(}\NormalTok{B}\OperatorTok{*}\NormalTok{pHash }\OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
\NormalTok{        tHash }\OperatorTok{=} \OperatorTok{(}\NormalTok{B}\OperatorTok{*}\NormalTok{tHash }\OperatorTok{+}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{{-}}\NormalTok{m}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pHash }\OperatorTok{==}\NormalTok{ tHash }\OperatorTok{\&\&}\NormalTok{ strncmp}\OperatorTok{(\&}\NormalTok{t}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ p}\OperatorTok{,}\NormalTok{ m}\OperatorTok{)} \OperatorTok{==} \DecValTok{0}\OperatorTok{)}
\NormalTok{            printf}\OperatorTok{(}\StringTok{"Found at }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{{-}}\NormalTok{m}\OperatorTok{)}
\NormalTok{            tHash }\OperatorTok{=} \OperatorTok{(}\NormalTok{B}\OperatorTok{*(}\NormalTok{tHash }\OperatorTok{{-}}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{]*}\NormalTok{h}\OperatorTok{)} \OperatorTok{+}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\NormalTok{m}\OperatorTok{])} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{tHash }\OperatorTok{\textless{}} \DecValTok{0}\OperatorTok{)}\NormalTok{ tHash }\OperatorTok{+=}\NormalTok{ M}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Boyer-Moore (Heuristic
Skipping)}\label{boyer-moore-heuristic-skipping}

Boyer-Moore compares from right to left and uses two heuristics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bad Character Rule When mismatch at ( j ), shift pattern so next
  occurrence of ( T{[}i{]} ) in ( P ) aligns.
\item
  Good Suffix Rule Shift pattern so a suffix of matched portion aligns
  with another occurrence.
\end{enumerate}

Time: ( O(n/m) ) on average Practical and fast, especially for English
text.

\subsubsection{6. Summary}\label{summary-20}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1642}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1940}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2687}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1940}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive & (O(nm)) & (O(1)) & Direct compare & Simple cases \\
KMP & (O(n+m)) & (O(m)) & Prefix overlap & General use \\
Z & (O(n+m)) & (O(n+m)) & Prefix matching & Pattern prep \\
Rabin-Karp & (O(n+m)) avg & (O(1)) & Hashing & Multi-pattern \\
Boyer-Moore & (O(n/m)) avg & (O\(m+\sigma\)) & Right-to-left skip & Long
texts \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-60}

String matching powers text editors, DNA search, spam filters, and
search engines. These algorithms show how structure and clever
preprocessing turn brute force into elegance.

\begin{quote}
``To find is human, to match efficiently is divine.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-60}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement KMP and print all matches in a sentence.
\item
  Use Rabin-Karp to find multiple keywords.
\item
  Compare running times on large text files.
\item
  Modify KMP for case-insensitive matching.
\item
  Visualize prefix function computation step-by-step.
\end{enumerate}

By mastering these, you'll wield the foundation of pattern discovery ,
the art of finding order in streams of symbols.

\subsection{62. Multi-Pattern Search
(Aho-Corasick)}\label{multi-pattern-search-aho-corasick}

So far, we've matched one pattern against a text. But what if we have
many patterns , say, a dictionary of keywords , and we want to find all
occurrences of all patterns in a single pass?

That's where the Aho-Corasick algorithm shines. It builds a trie with
failure links, turning multiple patterns into one efficient automaton.
Think of it as ``KMP for many words at once.''

\subsubsection{1. Problem Setup}\label{problem-setup-1}

Given:

\begin{itemize}
\tightlist
\item
  A text ( T ) of length ( n )- A set of patterns
  \({ P_1, P_2, \ldots, P_k }\) with total length \(m = \sum |P_i|\)
\end{itemize}

Goal: find all occurrences of every \(P_i\) in ( T ).

Naive solution: Run KMP for each pattern , ( O(kn) )

Better idea: Merge all patterns into a trie, and use failure links to
transition on mismatches.

Aho-Corasick achieves O(n + m + z), where ( z ) = number of matches
reported.

\subsubsection{2. Trie Construction}\label{trie-construction}

Each pattern is inserted into a trie node-by-node.

Example Patterns:

\begin{verbatim}
he, she, his, hers
\end{verbatim}

Trie:

\begin{verbatim}
(root)
 ├─ h ─ e*
 │   └─ r ─ s*
 ├─ s ─ h ─ e*
 └─ h ─ i ─ s*
\end{verbatim}

Each node may mark an output (end of pattern).

\subsubsection{3. Failure Links}\label{failure-links}

Failure link of a node points to the longest proper suffix that's also a
prefix in the trie.

These links let us ``fall back'' like KMP.

When mismatch happens, follow failure link to find next possible match.

\subsubsection{Building Failure Links
(BFS)}\label{building-failure-links-bfs}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Root's failure = null
\item
  Children of root → failure = root
\item
  BFS over nodes:

  \begin{itemize}
  \tightlist
  \item
    For each edge ( (u, c) → v ): follow failure links from ( u ) until
    you find ( f ) with edge ( c ) then \(v.\text{fail} = f.c\)
  \end{itemize}
\end{enumerate}

\subsubsection{Example}\label{example-5}

For ``he'', ``she'', ``his'', ``hers'':

\begin{itemize}
\tightlist
\item
  \texttt{fail("he")\ =\ root}- \texttt{fail("hers")\ =\ "rs"} path
  invalid → fallback to \texttt{"s"} if exists So failure links connect
  partial suffixes.
\end{itemize}

\subsubsection{4. Matching Phase}\label{matching-phase}

Now we can process the text in one pass:

\begin{verbatim}
state = root
for each character c in text:
    while state has no child c and state != root:
        state = state.fail
    if state has child c:
        state = state.child[c]
    else:
        state = root
    if state.output:
        report matches at this position
\end{verbatim}

Each transition costs O(1) amortized. No backtracking , fully linear
time.

\subsubsection{5. Example Walkthrough}\label{example-walkthrough}

Patterns: \texttt{he}, \texttt{she}, \texttt{his}, \texttt{hers} Text:
\texttt{ahishers}

At each character:

\begin{verbatim}
a → root (no match)
h → go to h
i → go to hi
s → go to his → output "his"
h → fallback → h
e → he → output "he"
r → her → continue
s → hers → output "hers"
\end{verbatim}

Outputs: \texttt{"his"}, \texttt{"he"}, \texttt{"hers"}

\subsubsection{6. Tiny Code (C Implementation
Sketch)}\label{tiny-code-c-implementation-sketch}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define ALPHA }\DecValTok{26}

\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{next}\OperatorTok{[}\NormalTok{ALPHA}\OperatorTok{];}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{fail}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ out}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ newNode}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    Node }\OperatorTok{*}\NormalTok{n }\OperatorTok{=}\NormalTok{ calloc}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
    \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\NormalTok{Node }\OperatorTok{*}\NormalTok{root}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ c }\OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{{-}} \CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{])}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{=}\NormalTok{ newNode}\OperatorTok{();}
\NormalTok{        root }\OperatorTok{=}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    root}\OperatorTok{{-}\textgreater{}}\NormalTok{out }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ build\_failures}\OperatorTok{(}\NormalTok{Node }\OperatorTok{*}\NormalTok{root}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node }\OperatorTok{*}\NormalTok{q}\OperatorTok{[}\DecValTok{10000}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ front}\OperatorTok{=}\DecValTok{0}\OperatorTok{,}\NormalTok{ back}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}
\NormalTok{    root}\OperatorTok{{-}\textgreater{}}\NormalTok{fail }\OperatorTok{=}\NormalTok{ root}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{[}\NormalTok{back}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{front }\OperatorTok{\textless{}}\NormalTok{ back}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        Node }\OperatorTok{*}\NormalTok{u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{[}\NormalTok{front}\OperatorTok{++];}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ c}\OperatorTok{\textless{}}\NormalTok{ALPHA}\OperatorTok{;}\NormalTok{ c}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{            Node }\OperatorTok{*}\NormalTok{v }\OperatorTok{=}\NormalTok{ u}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{];}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{v}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{            Node }\OperatorTok{*}\NormalTok{f }\OperatorTok{=}\NormalTok{ u}\OperatorTok{{-}\textgreater{}}\NormalTok{fail}\OperatorTok{;}
            \ControlFlowTok{while} \OperatorTok{(}\NormalTok{f }\OperatorTok{!=}\NormalTok{ root }\OperatorTok{\&\&} \OperatorTok{!}\NormalTok{f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{])}\NormalTok{ f }\OperatorTok{=}\NormalTok{ f}\OperatorTok{{-}\textgreater{}}\NormalTok{fail}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ v}\OperatorTok{)}\NormalTok{ v}\OperatorTok{{-}\textgreater{}}\NormalTok{fail }\OperatorTok{=}\NormalTok{ f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ v}\OperatorTok{{-}\textgreater{}}\NormalTok{fail }\OperatorTok{=}\NormalTok{ root}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v}\OperatorTok{{-}\textgreater{}}\NormalTok{fail}\OperatorTok{{-}\textgreater{}}\NormalTok{out}\OperatorTok{)}\NormalTok{ v}\OperatorTok{{-}\textgreater{}}\NormalTok{out }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{            q}\OperatorTok{[}\NormalTok{back}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Complexity}\label{complexity-3}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Phase & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trie Build & ( O(m) ) & ( O(m) ) \\
Failure Links & ( O(m) ) & ( O(m) ) \\
Search & ( O(n + z) ) & ( O(1) ) \\
\end{longtable}

Total: O(n + m + z)

\subsubsection{8. Summary}\label{summary-21}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Purpose \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trie & Merge patterns \\
Fail Links & Handle mismatches \\
Outputs & Collect matches \\
BFS & Build efficiently \\
One Pass & Match all patterns \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-61}

Aho-Corasick is the core of:

\begin{itemize}
\tightlist
\item
  Spam filters- Intrusion detection (e.g., Snort IDS)- Keyword search in
  compilers- DNA sequence scanners It's a masterclass in blending
  automata theory with practical efficiency.
\end{itemize}

\begin{quote}
``Why search one word at a time when your algorithm can read the whole
dictionary?''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-61}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build an automaton for words \{``he'', ``she'', ``hers''\} and trace
  it manually.
\item
  Modify code for uppercase letters.
\item
  Extend to report overlapping matches.
\item
  Measure runtime vs.~naive multi-search.
\item
  Visualize the failure links in a graph.
\end{enumerate}

Once you grasp Aho-Corasick, you'll see pattern search not as a loop ,
but as a machine that reads and recognizes.

\subsection{63. Suffix Structures (Suffix Array, Suffix Tree,
LCP)}\label{suffix-structures-suffix-array-suffix-tree-lcp}

Suffix-based data structures are among the most powerful tools in string
algorithms. They enable fast searching, substring queries, pattern
matching, and lexicographic operations , all from one fundamental idea:

\begin{quote}
Represent all suffixes of a string in a structured form.
\end{quote}

In this section, we explore three key constructs:

\begin{itemize}
\tightlist
\item
  Suffix Array (SA) - lexicographically sorted suffix indices- Longest
  Common Prefix (LCP) array - shared prefix lengths between neighbors-
  Suffix Tree - compressed trie of all suffixes Together, they power
  many advanced algorithms in text processing, bioinformatics, and
  compression.
\end{itemize}

\subsubsection{1. Suffix Array (SA)}\label{suffix-array-sa}

A suffix array stores all suffixes of a string in lexicographic order,
represented by their starting indices.

Example: String \texttt{banana\$} All suffixes:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Index & Suffix \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & banana\$ \\
1 & anana\$ \\
2 & nana\$ \\
3 & ana\$ \\
4 & na\$ \\
5 & a\$ \\
6 & \$ \\
\end{longtable}

Sort them:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Sorted Order & Suffix & Index \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & \texttt{\$} & 6 \\
1 & \texttt{a\$} & 5 \\
2 & \texttt{ana\$} & 3 \\
3 & \texttt{anana\$} & 1 \\
4 & \texttt{banana\$} & 0 \\
5 & \texttt{na\$} & 4 \\
6 & \texttt{nana\$} & 2 \\
\end{longtable}

Suffix Array: \texttt{{[}6,\ 5,\ 3,\ 1,\ 0,\ 4,\ 2{]}}

\subsubsection{Construction (Prefix
Doubling)}\label{construction-prefix-doubling}

We iteratively sort suffixes by first 2ⁱ characters, using radix sort on
pairs of ranks.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assign initial rank by character.
\item
  Sort by (rank{[}i{]}, rank{[}i+k{]}).
\item
  Repeat doubling \(k \leftarrow 2k\) until all ranks distinct.
\end{enumerate}

Time Complexity: ( O\(n \log n\) ) Space: ( O(n) )

Tiny Code (C, Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{int}\NormalTok{ idx}\OperatorTok{,}\NormalTok{ rank}\OperatorTok{[}\DecValTok{2}\OperatorTok{];} \OperatorTok{\}}\NormalTok{ Suffix}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ cmp}\OperatorTok{(}\NormalTok{Suffix a}\OperatorTok{,}\NormalTok{ Suffix b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]==}\NormalTok{b}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{])} \OperatorTok{?} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]{-}}\NormalTok{b}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{])} \OperatorTok{:} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]{-}}\NormalTok{b}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ buildSA}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    Suffix suf}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{        suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{)} \OperatorTok{?}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{]} \OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}} \DecValTok{2}\OperatorTok{*}\NormalTok{n}\OperatorTok{;}\NormalTok{ k }\OperatorTok{*=} \DecValTok{2}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        qsort}\OperatorTok{(}\NormalTok{suf}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Suffix}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{);}
        \DataTypeTok{int}\NormalTok{ r }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ rank}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}\NormalTok{ rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{idx}\OperatorTok{]=}\DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]!=}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{||}\NormalTok{ suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]!=}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{])}\NormalTok{ r}\OperatorTok{++;}
\NormalTok{            rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{]=}\NormalTok{r}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)\{}
\NormalTok{            suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{];}
\NormalTok{            suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{+}\NormalTok{k}\OperatorTok{/}\DecValTok{2}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{)?}\NormalTok{rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{+}\NormalTok{k}\OperatorTok{/}\DecValTok{2}\OperatorTok{]:{-}}\DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}\NormalTok{ sa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]=}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Longest Common Prefix
(LCP)}\label{longest-common-prefix-lcp}

The LCP array stores the length of the longest common prefix between
consecutive suffixes in SA order.

Example: \texttt{banana\$}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
SA & Suffix & LCP \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
6 & \$ & 0 \\
5 & a\$ & 0 \\
3 & ana\$ & 1 \\
1 & anana\$ & 3 \\
0 & banana\$ & 0 \\
4 & na\$ & 0 \\
2 & nana\$ & 2 \\
\end{longtable}

So LCP = \texttt{{[}0,0,1,3,0,0,2{]}}

\subsubsection{Kasai's Algorithm (Build in
O(n))}\label{kasais-algorithm-build-in-on}

We compute LCP in one pass using inverse SA:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ buildLCP}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ lcp}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ rank}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}\NormalTok{ rank}\OperatorTok{[}\NormalTok{sa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]=}\NormalTok{i}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]==}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;} \ControlFlowTok{continue}\OperatorTok{;} \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ sa}\OperatorTok{[}\NormalTok{rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]+}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i}\OperatorTok{+}\NormalTok{k}\OperatorTok{\textless{}}\NormalTok{n }\OperatorTok{\&\&}\NormalTok{ j}\OperatorTok{+}\NormalTok{k}\OperatorTok{\textless{}}\NormalTok{n }\OperatorTok{\&\&}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\NormalTok{k}\OperatorTok{]==}\NormalTok{s}\OperatorTok{[}\NormalTok{j}\OperatorTok{+}\NormalTok{k}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
\NormalTok{        lcp}\OperatorTok{[}\NormalTok{rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]=}\NormalTok{k}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k}\OperatorTok{\textgreater{}}\DecValTok{0}\OperatorTok{)}\NormalTok{ k}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O(n) )

\subsubsection{3. Suffix Tree}\label{suffix-tree}

A suffix tree is a compressed trie of all suffixes.

Each edge holds a substring interval, not individual characters. This
gives:

\begin{itemize}
\tightlist
\item
  Construction in ( O(n) ) (Ukkonen's algorithm)- Pattern search in (
  O(m) )- Many advanced uses (e.g., longest repeated substring) Example:
  String: \texttt{banana\$} Suffix tree edges:
\end{itemize}

\begin{verbatim}
(root)
 ├─ b[0:0] → ...
 ├─ a[1:1] → ...
 ├─ n[2:2] → ...
\end{verbatim}

Edges compress consecutive letters into intervals like
\texttt{{[}start:end{]}}.

\subsubsection{Comparison}\label{comparison-23}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Structure & Space & Build Time & Search \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Suffix Array & ( O(n) ) & ( O\(n \log n\) ) & ( O\(m \log n\) ) \\
LCP Array & ( O(n) ) & ( O(n) ) & Range queries \\
Suffix Tree & ( O(n) ) & ( O(n) ) & ( O(m) ) \\
\end{longtable}

Suffix Array + LCP ≈ compact Suffix Tree.

\subsubsection{4. Applications}\label{applications-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Substring search - binary search in SA
\item
  Longest repeated substring - max(LCP)
\item
  Lexicographic order - direct from SA
\item
  Distinct substrings count = ( n(n+1)/2 - \sum LCP{[}i{]} )
\item
  Pattern frequency - range query in SA using LCP
\end{enumerate}

\subsubsection{5. Tiny Code (Search via
SA)}\label{tiny-code-search-via-sa}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ searchSA}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ l}\OperatorTok{=}\DecValTok{0}\OperatorTok{,}\NormalTok{ r}\OperatorTok{=}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ m}\OperatorTok{=}\NormalTok{strlen}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}=}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{l}\OperatorTok{+}\NormalTok{r}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ cmp }\OperatorTok{=}\NormalTok{ strncmp}\OperatorTok{(}\NormalTok{t}\OperatorTok{+}\NormalTok{sa}\OperatorTok{[}\NormalTok{mid}\OperatorTok{],}\NormalTok{ p}\OperatorTok{,}\NormalTok{ m}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cmp}\OperatorTok{==}\DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ sa}\OperatorTok{[}\NormalTok{mid}\OperatorTok{];}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cmp}\OperatorTok{\textless{}}\DecValTok{0}\OperatorTok{)}\NormalTok{ l}\OperatorTok{=}\NormalTok{mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ r}\OperatorTok{=}\NormalTok{mid}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{6. Summary}\label{summary-22}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Concept & Purpose & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Suffix Array & Sorted suffix indices & ( O\(n \log n\) ) \\
LCP Array & Adjacent suffix overlap & ( O(n) ) \\
Suffix Tree & Compressed trie of suffixes & ( O(n) ) \\
\end{longtable}

Together they form the core of advanced string algorithms.

\subsubsection{Why It Matters}\label{why-it-matters-62}

Suffix structures reveal hidden order in strings. They turn raw text
into searchable, analyzable data , ideal for compression, search
engines, and DNA analysis.

\begin{quote}
``All suffixes, perfectly sorted , the DNA of text.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-62}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build suffix array for \texttt{banana\$} by hand.
\item
  Write code to compute LCP and longest repeated substring.
\item
  Search multiple patterns using binary search on SA.
\item
  Count distinct substrings from SA + LCP.
\item
  Compare SA-based vs.~tree-based search performance.
\end{enumerate}

Mastering suffix structures equips you to tackle problems that were once
``too big'' for brute force , now solvable with elegance and order.

\subsection{64. Palindromes and Periodicity
(Manacher)}\label{palindromes-and-periodicity-manacher}

Palindromes are symmetric strings that read the same forwards and
backwards , like ``level'', ``racecar'', or ``madam''. They arise
naturally in text analysis, bioinformatics, and even in data
compression.

This section introduces efficient algorithms to detect and analyze
palindromic structure and periodicity in strings, including the
legendary Manacher's Algorithm, which finds all palindromic substrings
in linear time.

\subsubsection{1. What Is a Palindrome?}\label{what-is-a-palindrome}

A string ( S ) is a palindrome if: \[
S[i] = S[n - i + 1] \quad \text{for all } i
\]

Examples:

\begin{itemize}
\tightlist
\item
  \texttt{"abba"} is even-length palindrome- \texttt{"aba"} is
  odd-length palindrome A string may contain many palindromic substrings
  , our goal is to find all centers efficiently.
\end{itemize}

\subsubsection{2. Naive Approach}\label{naive-approach}

For each center (between characters or at characters), expand outward
while characters match.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each center c}\OperatorTok{:}
\NormalTok{    expand left}\OperatorTok{,}\NormalTok{ right }\ControlFlowTok{while}\NormalTok{ S}\OperatorTok{[}\NormalTok{l}\OperatorTok{]} \OperatorTok{==}\NormalTok{ S}\OperatorTok{[}\NormalTok{r}\OperatorTok{]}
\end{Highlighting}
\end{Shaded}

Complexity: ( O\(n^2\) ) , too slow for large strings.

We need something faster , that's where Manacher's Algorithm steps in.

\subsubsection{3. Manacher's Algorithm
(O(n))}\label{manachers-algorithm-on}

Manacher's Algorithm finds the radius of the longest palindrome centered
at each position in linear time.

It cleverly reuses previous computations using mirror symmetry and a
current right boundary.

\subsubsection{Step-by-Step}\label{step-by-step}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Preprocess string to handle even-length palindromes: Insert
  \texttt{\#} between characters.

  Example:

\begin{verbatim}
S = "abba"
T = "^#a#b#b#a#$"
\end{verbatim}

  (\texttt{\^{}} and \texttt{\$} are sentinels)
\item
  Maintain:

  \begin{itemize}
  \tightlist
  \item
    \texttt{C}: center of rightmost palindrome - \texttt{R}: right
    boundary - \texttt{P{[}i{]}}: palindrome radius at \texttt{i}
  \end{itemize}
\item
  For each position \texttt{i}:

  \begin{itemize}
  \tightlist
  \item
    mirror position \texttt{mirror\ =\ 2*C\ -\ i} - initialize
    \texttt{P{[}i{]}\ =\ min(R\ -\ i,\ P{[}mirror{]})} - expand around
    \texttt{i} while characters match - if new palindrome extends past
    \texttt{R}, update \texttt{C} and \texttt{R}
  \end{itemize}
\item
  The \textbf{maximum value of \texttt{P{[}i{]}}} gives the longest
  palindrome.
\end{enumerate}

\subsubsection{Example}\label{example-6}

\begin{verbatim}
S = "abba"
T = "^#a#b#b#a#$"
P = [0,0,1,0,3,0,3,0,1,0,0]
Longest radius = 3 → "abba"
\end{verbatim}

Tiny Code (C Implementation)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ manacher}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
    \DataTypeTok{char}\NormalTok{ t}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{n }\OperatorTok{+} \DecValTok{3}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ p}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{n }\OperatorTok{+} \DecValTok{3}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}\^{}\textquotesingle{}}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}\#\textquotesingle{}}\OperatorTok{;}
\NormalTok{        t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}\#\textquotesingle{}}\OperatorTok{;}\NormalTok{ t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}$\textquotesingle{}}\OperatorTok{;}
\NormalTok{    t}\OperatorTok{[}\NormalTok{m}\OperatorTok{]} \OperatorTok{=} \CharTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}0}\CharTok{\textquotesingle{}}\OperatorTok{;}
    
    \DataTypeTok{int}\NormalTok{ c }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ r }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ maxLen }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\NormalTok{m}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mirror }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{c }\OperatorTok{{-}}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{)}
\NormalTok{            p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{r }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ p}\OperatorTok{[}\NormalTok{mirror}\OperatorTok{])} \OperatorTok{?} \OperatorTok{(}\NormalTok{r }\OperatorTok{{-}}\NormalTok{ i}\OperatorTok{)} \OperatorTok{:}\NormalTok{ p}\OperatorTok{[}\NormalTok{mirror}\OperatorTok{];}
        \ControlFlowTok{else}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{t}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1} \OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{==}\NormalTok{ t}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]])}
\NormalTok{            p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]++;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            c }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{            r }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ maxLen}\OperatorTok{)}\NormalTok{ maxLen }\OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ maxLen}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O(n) ) Space: ( O(n) )

\subsubsection{4. Periodicity and
Repetition}\label{periodicity-and-repetition}

A string ( S ) has a period ( p ) if: \[
S[i] = S[i + p] \text{ for all valid } i
\]

Example: \texttt{abcabcabc} has period 3 (\texttt{abc}).

Checking Periodicity:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build prefix function (as in KMP).
\item
  Let ( n = \textbar S\textbar{} ), \(p = n - \pi[n-1]\).
\item
  If \(n \mod p = 0\), period = ( p ).
\end{enumerate}

Example:

\begin{verbatim}
S = "ababab"
π = [0,0,1,2,3,4]
p = 6 - 4 = 2
6 mod 2 = 0 → periodic
\end{verbatim}

Tiny Code (Check Periodicity)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ period}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{s}\OperatorTok{),}\NormalTok{ pi}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{    pi}\OperatorTok{[}\DecValTok{0}\OperatorTok{]=}\DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{,}\NormalTok{k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)\{}
        \ControlFlowTok{while}\OperatorTok{(}\NormalTok{k}\OperatorTok{\textgreater{}}\DecValTok{0} \OperatorTok{\&\&}\NormalTok{ s}\OperatorTok{[}\NormalTok{k}\OperatorTok{]!=}\NormalTok{s}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{=}\NormalTok{pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{if}\OperatorTok{(}\NormalTok{s}\OperatorTok{[}\NormalTok{k}\OperatorTok{]==}\NormalTok{s}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
\NormalTok{        pi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]=}\NormalTok{k}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ p }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ pi}\OperatorTok{[}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%}\NormalTok{ p }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{?}\NormalTok{ p }\OperatorTok{:}\NormalTok{ n}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Applications}\label{applications-10}

\begin{itemize}
\tightlist
\item
  Palindrome Queries: is substring ( S{[}l:r{]} ) palindrome? →
  precompute radii- Longest Palindromic Substring- DNA Symmetry
  Analysis- Pattern Compression / Period Detection- String Regularity
  Tests
\end{itemize}

\subsubsection{6. Summary}\label{summary-23}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Concept & Purpose & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive Expand & Simple palindrome check & ( O\(n^2\) ) \\
Manacher & Longest palindromic substring & ( O(n) ) \\
KMP Prefix & Period detection & ( O(n) ) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-63}

Palindromes reveal hidden symmetries. Manacher's algorithm is a gem , a
linear-time mirror-based solution to a quadratic problem.

\begin{quote}
``In every word, there may hide a reflection.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-63}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run Manacher's algorithm on \texttt{"abacdfgdcaba"}.
\item
  Modify code to print all palindromic substrings.
\item
  Use prefix function to find smallest period.
\item
  Combine both to find palindromic periodic substrings.
\item
  Compare runtime vs.~naive expand method.
\end{enumerate}

Understanding palindromes and periodicity teaches how structure emerges
from repetition , a central theme in all of algorithmic design.

\subsection{65. Edit Distance and
Alignment}\label{edit-distance-and-alignment}

Edit distance measures how different two strings are , the minimal
number of operations needed to turn one into the other. It's a
cornerstone of spell checking, DNA sequence alignment, plagiarism
detection, and fuzzy search.

The most common form is the Levenshtein distance, using:

\begin{itemize}
\tightlist
\item
  Insertion (add a character)- Deletion (remove a character)-
  Substitution (replace a character) We'll also touch on alignment,
  which generalizes this idea with custom scoring and penalties.
\end{itemize}

\subsubsection{1. Problem Definition}\label{problem-definition-1}

Given two strings ( A ) and ( B ), find the minimum number of edits to
convert \(A \to B\).

If ( A = ``kitten'' ) ( B = ``sitting'' )

One optimal sequence:

\begin{verbatim}
kitten → sitten (substitute 'k'→'s')
sitten → sittin (substitute 'e'→'i')
sittin → sitting (insert 'g')
\end{verbatim}

So edit distance = 3.

\subsubsection{2. Dynamic Programming
Solution}\label{dynamic-programming-solution}

Let \(dp[i][j]\) be the minimum edits to convert
\(A[0..i-1] \to B[0..j-1]\).

Recurrence: \[
dp[i][j] =
\begin{cases}
dp[i-1][j-1], & \text{if } A[i-1] = B[j-1], \\
1 + \min\big(dp[i-1][j],\, dp[i][j-1],\, dp[i-1][j-1]\big), & \text{otherwise}
\end{cases}
\]

Where: - \(dp[i-1][j]\): delete from \(A\) - \(dp[i][j-1]\): insert into
\(A\) - \(dp[i-1][j-1]\): substitute

Base cases: \[
dp[0][j] = j,\quad dp[i][0] = i
\]

Time complexity: \(O(|A||B|)\)

\subsubsection{Example}\label{example-7}

A = \texttt{kitten}, B = \texttt{sitting}

\begin{longtable}[]{@{}lllllllll@{}}
\toprule\noalign{}
& ``\,'' & s & i & t & t & i & n & g \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``\,'' & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
k & 1 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
i & 2 & 2 & 1 & 2 & 3 & 4 & 5 & 6 \\
t & 3 & 3 & 2 & 1 & 2 & 3 & 4 & 5 \\
t & 4 & 4 & 3 & 2 & 1 & 2 & 3 & 4 \\
e & 5 & 5 & 4 & 3 & 2 & 2 & 3 & 4 \\
n & 6 & 6 & 5 & 4 & 3 & 3 & 2 & 3 \\
\end{longtable}

Edit distance = 3

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}string.h\textgreater{}}
\PreprocessorTok{\#define MIN3}\OperatorTok{(}\PreprocessorTok{a}\OperatorTok{,}\PreprocessorTok{b}\OperatorTok{,}\PreprocessorTok{c}\OperatorTok{)}\PreprocessorTok{ }\OperatorTok{((}\PreprocessorTok{a}\OperatorTok{\textless{}}\PreprocessorTok{b}\OperatorTok{)?((}\PreprocessorTok{a}\OperatorTok{\textless{}}\PreprocessorTok{c}\OperatorTok{)?}\PreprocessorTok{a}\OperatorTok{:}\PreprocessorTok{c}\OperatorTok{):((}\PreprocessorTok{b}\OperatorTok{\textless{}}\PreprocessorTok{c}\OperatorTok{)?}\PreprocessorTok{b}\OperatorTok{:}\PreprocessorTok{c}\OperatorTok{))}

\DataTypeTok{int}\NormalTok{ edit\_distance}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{A}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{B}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{A}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{B}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}=}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]=}\NormalTok{i}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]=}\NormalTok{j}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}=}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]==}\NormalTok{B}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]=}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]=}\DecValTok{1}\OperatorTok{+}\NormalTok{MIN3}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ edit\_distance}\OperatorTok{(}\StringTok{"kitten"}\OperatorTok{,}\StringTok{"sitting"}\OperatorTok{));} \CommentTok{// 3}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Space Optimization}\label{space-optimization}

We only need the previous row to compute the current row.

So,\\
Space complexity: \(O(\min(|A|, |B|))\)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ edit\_distance\_opt}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{A}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{B}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n}\OperatorTok{=}\NormalTok{strlen}\OperatorTok{(}\NormalTok{A}\OperatorTok{),}\NormalTok{ m}\OperatorTok{=}\NormalTok{strlen}\OperatorTok{(}\NormalTok{B}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ prev}\OperatorTok{[}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{],}\NormalTok{ curr}\OperatorTok{[}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}\NormalTok{ prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{]=}\NormalTok{j}\OperatorTok{;}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}=}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)\{}
\NormalTok{        curr}\OperatorTok{[}\DecValTok{0}\OperatorTok{]=}\NormalTok{i}\OperatorTok{;}
        \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)\{}
            \ControlFlowTok{if}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]==}\NormalTok{B}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ curr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]=}\NormalTok{prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ curr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]=}\DecValTok{1}\OperatorTok{+}\NormalTok{MIN3}\OperatorTok{(}\NormalTok{prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{],}\NormalTok{ curr}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
        \OperatorTok{\}}
\NormalTok{        memcpy}\OperatorTok{(}\NormalTok{prev}\OperatorTok{,}\NormalTok{curr}\OperatorTok{,}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{curr}\OperatorTok{));}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ prev}\OperatorTok{[}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Alignment}\label{alignment}

Alignment shows which characters correspond between two strings. Used in
bioinformatics (e.g., DNA sequence alignment).

Each operation has a cost:

\begin{itemize}
\tightlist
\item
  Match: 0
\item
  Mismatch: 1
\item
  Gap (insert/delete): 1 We fill the DP table similarly, but track
  choices to trace back alignment.
\end{itemize}

\subsubsection{Example Alignment}\label{example-alignment}

\begin{verbatim}
A: kitten-
B: sitt-ing
\end{verbatim}

We can visualize the transformation path by backtracking dp table.

\subsubsection{Scoring Alignment (General
Form)}\label{scoring-alignment-general-form}

We can generalize: \[
dp[i][j] = \min \begin{cases}
dp[i-1][j-1] + cost(A_i,B_j) \
dp[i-1][j] + gap \
dp[i][j-1] + gap
\end{cases}
\]

Used in Needleman-Wunsch (global alignment) and Smith-Waterman (local
alignment).

\subsubsection{5. Variants}\label{variants}

\begin{itemize}
\tightlist
\item
  Damerau-Levenshtein: adds transposition (swap adjacent chars)- Hamming
  Distance: only substitutions, equal-length strings- Weighted Distance:
  different operation costs- Local Alignment: only best matching
  substrings
\end{itemize}

\subsubsection{6. Summary}\label{summary-24}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3678}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2644}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0805}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2874}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Operations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Levenshtein & insert, delete, replace & (O(nm)) & Spell check, fuzzy
search \\
Hamming & substitution only & (O(n)) & DNA, binary strings \\
Alignment (Needleman-Wunsch) & with scoring & (O(nm)) &
Bioinformatics \\
Local Alignment (Smith-Waterman) & best substring & (O(nm)) & DNA
regions \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-64}

Edit distance transforms ``difference'' into data. It quantifies how far
apart two strings are, enabling flexible, robust comparisons.

\begin{quote}
``Similarity isn't perfection , it's the cost of becoming alike.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-64}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute edit distance between ``intention'' and ``execution''.
\item
  Trace back operations to show alignment.
\item
  Modify costs (insertion=2, deletion=1, substitution=2) and compare
  results.
\item
  Implement Hamming distance for equal-length strings.
\item
  Explore Smith-Waterman for longest common substring.
\end{enumerate}

Once you master edit distance, you can build tools that understand
typos, align genomes, and search imperfectly , perfectly.

\subsection{66. Compression (Huffman, Arithmetic, LZ77,
BWT)}\label{compression-huffman-arithmetic-lz77-bwt}

Compression algorithms let us encode information efficiently, reducing
storage or transmission cost without losing meaning. They turn patterns
and redundancy into shorter representations , the essence of data
compression.

This section introduces the key families of lossless compression
algorithms that form the backbone of formats like ZIP, PNG, and GZIP.

We'll explore:

\begin{itemize}
\tightlist
\item
  Huffman Coding (prefix-free variable-length codes)
\item
  Arithmetic Coding (fractional interval encoding)
\item
  LZ77 / LZ78 (dictionary-based methods)
\item
  Burrows-Wheeler Transform (BWT) (reversible sorting transform)
\end{itemize}

\subsubsection{1. Huffman Coding}\label{huffman-coding}

Huffman coding assigns shorter codes to frequent symbols, and longer
codes to rare ones , achieving optimal compression among prefix-free
codes.

\subsubsection{A. Algorithm}\label{a.-algorithm-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Count frequencies of all symbols.
\item
  Build a min-heap of nodes \texttt{(symbol,\ freq)}.
\item
  While heap size \textgreater{} 1:

  \begin{itemize}
  \tightlist
  \item
    Extract two smallest nodes \texttt{a}, \texttt{b}. - Create new node
    with \texttt{freq\ =\ a.freq\ +\ b.freq}. - Push back into heap.4.
    Assign \texttt{0} to left, \texttt{1} to right.
  \end{itemize}
\item
  Traverse tree , collect codes.
\end{enumerate}

Each symbol gets a unique prefix code (no code is prefix of another).

\subsubsection{B. Example}\label{b.-example-7}

Text: \texttt{ABRACADABRA}

Frequencies:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Symbol & Count \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 5 \\
B & 2 \\
R & 2 \\
C & 1 \\
D & 1 \\
\end{longtable}

Building tree gives codes like:

\begin{verbatim}
A: 0  
B: 101  
R: 100  
C: 1110  
D: 1111
\end{verbatim}

Encoded text: \texttt{0\ 101\ 100\ 0\ 1110\ 0\ 1111\ 0\ 101\ 100\ 0}
Compression achieved!

Tiny Code (C, Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{char}\NormalTok{ ch}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ freq}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Use a min-heap (priority queue) to build the tree. Traverse recursively
to print codewords.

Complexity: (O\(n \log n\))

\subsubsection{2. Arithmetic Coding}\label{arithmetic-coding}

Instead of mapping symbols to bit strings, arithmetic coding maps the
entire message to a single number in {[}0,1).

We start with interval ({[}0,1)), and iteratively narrow it based on
symbol probabilities.

\subsubsection{Example}\label{example-8}

Symbols: \{A: 0.5, B: 0.3, C: 0.2\} Message: \texttt{ABC}

Intervals:

\begin{verbatim}
Start: [0, 1)
A → [0, 0.5)
B → [0.25, 0.4)
C → [0.34, 0.37)
\end{verbatim}

Final code = any number in {[}0.34, 0.37) (e.g.~0.35)

Decoding reverses this process.

Advantage: achieves near-optimal entropy compression. Used in: JPEG2000,
H.264

Time Complexity: ( O(n) )

\subsubsection{3. LZ77 (Sliding Window
Compression)}\label{lz77-sliding-window-compression}

LZ77 replaces repeated substrings with back-references
\texttt{(offset,\ length,\ next\_char)} pointing into a sliding window.

\subsubsection{Example}\label{example-9}

Text: \texttt{abcabcabcx}

Window slides; when \texttt{abc} repeats:

\begin{verbatim}
(0,0,'a'), (0,0,'b'), (0,0,'c'),
(3,3,'x')  // "abc" repeats from 3 chars back
\end{verbatim}

So sequence is compressed as references to earlier substrings.

Used in: DEFLATE (ZIP, GZIP), PNG

Time: ( O(n) ), Space: proportional to window size.

\subsubsection{Tiny Code (Conceptual)}\label{tiny-code-conceptual}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Token }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ offset}\OperatorTok{,}\NormalTok{ length}\OperatorTok{;} \DataTypeTok{char}\NormalTok{ next}\OperatorTok{;} \OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Search previous window for longest match before emitting token.

\subsubsection{4. LZ78 (Dictionary-Based)}\label{lz78-dictionary-based}

Instead of sliding window, LZ78 builds an explicit dictionary of
substrings.

Algorithm:

\begin{itemize}
\tightlist
\item
  Start with empty dictionary.- Read input, find longest prefix in
  dictionary.- Output \texttt{(index,\ next\_char)} and insert new
  entry. Example:
\end{itemize}

\begin{verbatim}
Input: ABAABABAABAB
Output: (0,A), (0,B), (1,B), (2,A), (4,A), (3,B)
\end{verbatim}

Used in: LZW (GIF, TIFF)

\subsubsection{5. Burrows-Wheeler Transform
(BWT)}\label{burrows-wheeler-transform-bwt}

BWT is not compression itself , it permutes text to cluster similar
characters, making it more compressible by run-length or Huffman coding.

\subsubsection{Steps}\label{steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate all rotations of string.
\item
  Sort them lexicographically.
\item
  Take last column as output.
\end{enumerate}

Example: \texttt{banana\$}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Rotations & Sorted \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
banana\$ & \(banana |
| anana\)b \\
a\(banan   | na\)bana & \\
\(banana   | nana\)ba & \\
\end{longtable}

Last column: \texttt{annb\$aa} BWT(``banana\(") = "annb\)aa''

Reversible with index of original row.

Used in: bzip2, FM-index (bioinformatics)

\subsubsection{6. Summary}\label{summary-25}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1408}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3944}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1831}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2817}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Huffman & Variable-length prefix codes & (O\(n \log n\)) & General
compression \\
Arithmetic & Interval encoding & (O(n)) & Near-optimal entropy \\
LZ77 & Sliding window matches & (O(n)) & ZIP, PNG \\
LZ78 & Dictionary building & (O(n)) & GIF, TIFF \\
BWT & Permute for clustering & (O\(n \log n\)) & bzip2 \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-65}

Compression algorithms reveal structure in data , they exploit patterns
that humans can't see. They're also a window into information theory,
showing how close we can get to the entropy limit.

\begin{quote}
``To compress is to understand , every bit saved is a pattern found.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-65}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a Huffman tree for \texttt{MISSISSIPPI}.
\item
  Implement a simple LZ77 encoder for repeating patterns.
\item
  Apply BWT and observe clustering of symbols.
\item
  Compare Huffman and Arithmetic outputs on same input.
\item
  Explore DEFLATE format combining LZ77 + Huffman.
\end{enumerate}

Understanding compression means learning to see redundancy , the key to
efficient storage, transmission, and understanding itself.

\subsection{67. Cryptographic Hashes and
Checksums}\label{cryptographic-hashes-and-checksums}

In algorithms, hashing helps us map data to fixed-size values. But when
used for security and verification, hashing becomes a cryptographic
tool. This section explores cryptographic hashes and checksums ,
algorithms that verify integrity, detect corruption, and secure data.

We'll look at:

\begin{itemize}
\tightlist
\item
  Simple checksums (parity, CRC)- Cryptographic hash functions (MD5, SHA
  family, BLAKE3)- Properties like collision resistance and preimage
  resistance- Practical uses in verification, signing, and storage
\end{itemize}

\subsubsection{1. Checksums}\label{checksums}

Checksums are lightweight methods to detect accidental errors in data
(not secure against attackers). They're used in filesystems, networking,
and storage to verify integrity.

\subsubsection{A. Parity Bit}\label{a.-parity-bit}

Adds one bit to make total 1s even or odd. Used in memory or
communication to detect single-bit errors.

Example: Data = \texttt{1011} → has three 1s. Add parity bit \texttt{1}
to make total 4 (even parity).

Limitation: Only detects odd number of bit errors.

\subsubsection{B. Modular Sum (Simple
Checksum)}\label{b.-modular-sum-simple-checksum}

Sum all bytes (mod 256 or 65536).

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{uint8\_t}\NormalTok{ checksum}\OperatorTok{(}\DataTypeTok{uint8\_t} \OperatorTok{*}\NormalTok{data}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{uint32\_t}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ sum }\OperatorTok{+=}\NormalTok{ data}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return} \OperatorTok{(}\DataTypeTok{uint8\_t}\OperatorTok{)(}\NormalTok{sum }\OperatorTok{\%} \DecValTok{256}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use: Simple file or packet validation.

\subsubsection{C. CRC (Cyclic Redundancy
Check)}\label{c.-crc-cyclic-redundancy-check}

CRCs treat bits as coefficients of a polynomial. Divide by a generator
polynomial, remainder = CRC code.

Used in Ethernet, ZIP, and PNG.

Example: CRC-32, CRC-16.

Fast hardware and table-driven implementations available.

Key Property:

\begin{itemize}
\tightlist
\item
  Detects most burst errors- Not cryptographically secure
\end{itemize}

\subsubsection{2. Cryptographic Hash
Functions}\label{cryptographic-hash-functions}

A cryptographic hash function ( h(x) ) maps any input to a fixed-size
output such that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Deterministic: same input → same output
\item
  Fast computation
\item
  Preimage resistance: hard to find ( x ) given ( h(x) )
\item
  Second-preimage resistance: hard to find \(x' \neq x\) with ( h(x') =
  h(x) )
\item
  Collision resistance: hard to find any two distinct inputs with same
  hash
\end{enumerate}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Output (bits) & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MD5 & 128 & Broken (collisions found) \\
SHA-1 & 160 & Deprecated \\
SHA-256 & 256 & Standard (SHA-2 family) \\
SHA-3 & 256 & Keccak-based sponge \\
BLAKE3 & 256 & Fast, parallel, modern \\
\end{longtable}

\subsubsection{Example}\label{example-10}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h("hello") = 2cf24dba5fb0a... (SHA{-}256)}
\end{Highlighting}
\end{Shaded}

Change one letter, hash changes completely (avalanche effect):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h("Hello") = 185f8db32271f... }
\end{Highlighting}
\end{Shaded}

Even small changes → big differences.

\subsubsection{Tiny Code (C, using
pseudo-interface)}\label{tiny-code-c-using-pseudo-interface}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}openssl/sha.h\textgreater{}}

\DataTypeTok{unsigned} \DataTypeTok{char}\NormalTok{ hash}\OperatorTok{[}\NormalTok{SHA256\_DIGEST\_LENGTH}\OperatorTok{];}
\NormalTok{SHA256}\OperatorTok{((}\DataTypeTok{unsigned} \DataTypeTok{char}\OperatorTok{*)}\StringTok{"hello"}\OperatorTok{,} \DecValTok{5}\OperatorTok{,}\NormalTok{ hash}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Print hash as hex string to verify.

\subsubsection{3. Applications}\label{applications-11}

\begin{itemize}
\tightlist
\item
  Data integrity: verify files (e.g., SHA256SUM)- Digital signatures:
  sign hashes, not raw data- Password storage: store hashes, not
  plaintext- Deduplication: detect identical files via hashes-
  Blockchain: link blocks with hash pointers- Git: stores objects via
  SHA-1 identifiers
\end{itemize}

\subsubsection{4. Hash Collisions}\label{hash-collisions}

A collision occurs when ( h(x) = h(y) ) for \(x \neq y\). Good
cryptographic hashes make this computationally infeasible.

By the birthday paradox, collisions appear after \(2^{n/2}\) operations
for an ( n )-bit hash.

Hence, SHA-256 → \textasciitilde{}\(2^{128}\) effort to collide.

\subsubsection{5. Checksums vs Hashes}\label{checksums-vs-hashes}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Checksum & Cryptographic Hash \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Detect errors & Ensure integrity and authenticity \\
Resistance & Low & High \\
Output Size & Small & 128-512 bits \\
Performance & Very fast & Fast but secure \\
Example & CRC32 & SHA-256, BLAKE3 \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-66}

Checksums catch accidental corruption, hashes protect against malicious
tampering. Together, they guard the trustworthiness of data , the
foundation of secure systems.

\begin{quote}
``Integrity is invisible , until it's lost.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-66}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute CRC32 of a text file, flip one bit, and recompute.
\item
  Use \texttt{sha256sum} to verify file integrity.
\item
  Experiment: change one character in input, observe avalanche.
\item
  Compare performance of SHA-256 and BLAKE3.
\item
  Research how Git uses SHA-1 to track versions.
\end{enumerate}

By learning hashes, you master one of the pillars of security , proof
that something hasn't changed, even when everything else does.

\subsection{68. Approximate and Streaming
Matching}\label{approximate-and-streaming-matching}

Exact string matching (like KMP or Boyer-Moore) demands perfect
alignment between pattern and text. But what if errors, noise, or
incomplete data exist?

That's where approximate matching and streaming matching come in. These
algorithms let you search efficiently even when:

\begin{itemize}
\tightlist
\item
  The pattern might contain typos or mutations- The text arrives in a
  stream (too large to store entirely)- You want to match ``close
  enough,'' not ``exactly'' They're crucial in search engines, spell
  checkers, bioinformatics, and real-time monitoring systems.
\end{itemize}

\subsubsection{1. Approximate String
Matching}\label{approximate-string-matching}

Approximate string matching finds occurrences of a pattern in a text
allowing mismatches, insertions, or deletions , often measured by edit
distance.

\subsubsection{A. Dynamic Programming (Levenshtein
Distance)}\label{a.-dynamic-programming-levenshtein-distance}

Given two strings \(A\) and \(B\), the edit distance is the minimum
number of insertions, deletions, or substitutions to turn \(A\) into
\(B\).

We can build a DP table \(dp[i][j]\):

\begin{itemize}
\tightlist
\item
  \(dp[i][0] = i\) (delete all characters)\\
\item
  \(dp[0][j] = j\) (insert all characters)\\
\item
  If \(A[i] = B[j]\), then \(dp[i][j] = dp[i-1][j-1]\)\\
\item
  Else \(dp[i][j] = 1 + \min(dp[i-1][j],\, dp[i][j-1],\, dp[i-1][j-1])\)
\end{itemize}

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ edit\_distance}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{a}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{a}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{fmin}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]),}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This computes Levenshtein distance in ( O(nm) ) time.

\subsubsection{B. Bitap Algorithm
(Shift-Or)}\label{b.-bitap-algorithm-shift-or}

When pattern length is small, Bitap uses bitmasks to track mismatches.
It efficiently supports up to k errors and runs in near linear time for
small patterns.

Used in grep -E, ag, and fuzzy searching systems.

Idea: Maintain a bitmask where 1 = mismatch, 0 = match. Shift and OR
masks as we scan text.

\subsubsection{C. k-Approximate
Matching}\label{c.-k-approximate-matching}

Find all positions where edit distance ≤ k. Efficient for small ( k )
(e.g., spell correction: edit distance ≤ 2).

Applications:

\begin{itemize}
\tightlist
\item
  Typo-tolerant search- DNA sequence matching- Autocomplete systems
\end{itemize}

\subsubsection{2. Streaming Matching}\label{streaming-matching}

In streaming, the text is too large or unbounded, so we must process
input online. We can't store everything , only summaries or sketches.

\subsubsection{A. Rolling Hash (Rabin-Karp
style)}\label{a.-rolling-hash-rabin-karp-style}

Maintains a moving hash of recent characters. When new character
arrives, update hash in ( O(1) ). Compare with pattern's hash for
possible match.

Good for sliding window matching.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hash }\OperatorTok{=} \OperatorTok{(}\NormalTok{base }\OperatorTok{*} \OperatorTok{(}\NormalTok{hash }\OperatorTok{{-}}\NormalTok{ old\_char }\OperatorTok{*}\NormalTok{ base}\OperatorTok{\^{}(}\NormalTok{m}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{))} \OperatorTok{+}\NormalTok{ new\_char}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ mod}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Fingerprinting (Karp-Rabin
Fingerprint)}\label{b.-fingerprinting-karp-rabin-fingerprint}

A compact representation of a substring. If fingerprints match, do full
verification (avoid false positives). Used in streaming algorithms and
chunking.

\subsubsection{C. Sketch-Based Matching}\label{c.-sketch-based-matching}

Algorithms like Count-Min Sketch or SimHash build summaries of large
data. They help approximate similarity between streams.

Applications:

\begin{itemize}
\tightlist
\item
  Near-duplicate detection (SimHash in Google)- Network anomaly
  detection- Real-time log matching
\end{itemize}

\subsubsection{3. Approximate Matching in
Practice}\label{approximate-matching-in-practice}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3492}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Spell Checking & ``recieve'' → ``receive'' & Edit Distance \\
DNA Alignment & Find similar sequences & Smith-Waterman \\
Autocomplete & Suggest close matches & Fuzzy Search \\
Logs \& Streams & Online pattern alerts & Streaming Bitap, Karp-Rabin \\
Near-Duplicate & Detect similar text & SimHash, MinHash \\
\end{longtable}

\subsubsection{4. Complexity}\label{complexity-4}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Levenshtein DP & (O(nm)) & (O(nm)) & Exact distance \\
Bitap & (O(n)) & (O(1)) & For small patterns \\
Rolling Hash & (O(n)) & (O(1)) & Probabilistic match \\
SimHash & (O(n)) & (O(1)) & Approximate similarity \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-67}

Real-world data is messy , typos, noise, loss, corruption. Approximate
matching lets you build algorithms that forgive errors and adapt to
streams. It powers everything from search engines to genomics, ensuring
your algorithms stay practical in an imperfect world.

\subsubsection{Try It Yourself}\label{try-it-yourself-67}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute edit distance between ``kitten'' and ``sitting.''
\item
  Implement fuzzy search that returns words with ≤1 typo.
\item
  Use rolling hash to detect repeated substrings in a stream.
\item
  Experiment with SimHash to compare document similarity.
\item
  Observe how small typos affect fuzzy vs exact search.
\end{enumerate}

\subsection{69. Bioinformatics Alignment (Needleman-Wunsch,
Smith-Waterman)}\label{bioinformatics-alignment-needleman-wunsch-smith-waterman}

In bioinformatics, comparing DNA, RNA, or protein sequences is like
comparing strings , but with biological meaning. Each sequence is made
of letters (A, C, G, T for DNA; amino acids for proteins). To analyze
similarity, scientists use sequence alignment algorithms that handle
insertions, deletions, and substitutions.

Two fundamental methods dominate:

\begin{itemize}
\tightlist
\item
  Needleman-Wunsch for global alignment- Smith-Waterman for local
  alignment
\end{itemize}

\subsubsection{1. Sequence Alignment}\label{sequence-alignment}

Alignment means placing two sequences side by side to maximize matches
and minimize gaps or mismatches.

For example:

\begin{verbatim}
A C G T G A
| | |   | |
A C G A G A
\end{verbatim}

Here, mismatches and gaps may occur, but the alignment finds the best
possible match under a scoring system.

\subsubsection{Scoring System}\label{scoring-system}

Alignment uses scores instead of just counts. Typical scheme:

\begin{itemize}
\tightlist
\item
  Match: +1- Mismatch: -1- Gap (insertion or deletion): -2 You can
  adjust weights depending on the biological context.
\end{itemize}

\subsubsection{2. Needleman-Wunsch (Global
Alignment)}\label{needleman-wunsch-global-alignment}

Used when you want to align entire sequences , from start to end.

It uses dynamic programming to build a score table ( dp{[}i{]}{[}j{]} ),
where each cell represents the best score for aligning prefixes (
A{[}1..i{]} ) and ( B{[}1..j{]} ).

Recurrence:

\[dp[i][j] = \max
\begin{cases}
dp[i-1][j-1] + \text{score}(A_i, B_j) \
dp[i-1][j] + \text{gap penalty} \
dp[i][j-1] + \text{gap penalty}
\end{cases}\]

Base cases: \[
dp[0][j] = j \times \text{gap penalty}, \quad dp[i][0] = i \times \text{gap penalty}
\]

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ max3}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textgreater{}}\NormalTok{ b }\OperatorTok{?} \OperatorTok{(}\NormalTok{a }\OperatorTok{\textgreater{}}\NormalTok{ c }\OperatorTok{?}\NormalTok{ a }\OperatorTok{:}\NormalTok{ c}\OperatorTok{)} \OperatorTok{:} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}}\NormalTok{ c }\OperatorTok{?}\NormalTok{ b }\OperatorTok{:}\NormalTok{ c}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ needleman\_wunsch}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{A}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{B}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ match}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ mismatch}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ gap}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{A}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{B}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i }\OperatorTok{*}\NormalTok{ gap}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j }\OperatorTok{*}\NormalTok{ gap}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ s }\OperatorTok{=} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ B}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])} \OperatorTok{?}\NormalTok{ match }\OperatorTok{:}\NormalTok{ mismatch}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max3}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ s}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ gap}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ gap}\OperatorTok{);}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example:

\begin{verbatim}
A = "ACGT"
B = "AGT"
match = +1, mismatch = -1, gap = -2
\end{verbatim}

Produces optimal alignment:

\begin{verbatim}
A C G T
A - G T
\end{verbatim}

\subsubsection{3. Smith-Waterman (Local
Alignment)}\label{smith-waterman-local-alignment}

Used when sequences may have similar segments, not full-length
similarity. Perfect for finding motifs or conserved regions.

Recurrence is similar, but with local reset to zero:

\[dp[i][j] = \max
\begin{cases}
0, \
dp[i-1][j-1] + \text{score}(A_i, B_j), \
dp[i-1][j] + \text{gap penalty}, \
dp[i][j-1] + \text{gap penalty}
\end{cases}\]

Final answer = maximum value in the table (not necessarily at the end).

It finds the best substring alignment.

\subsubsection{Example}\label{example-11}

\begin{verbatim}
A = "ACGTTG"
B = "CGT"
\end{verbatim}

Smith-Waterman finds best local match:

\begin{verbatim}
A C G T
  | | |
  C G T
\end{verbatim}

Unlike global alignment, extra prefixes or suffixes are ignored.

\subsubsection{4. Variants and
Extensions}\label{variants-and-extensions}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6429}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Needleman-Wunsch & Global & Aligns full sequences \\
Smith-Waterman & Local & Finds similar subsequences \\
Gotoh Algorithm & Global & Uses affine gap penalty (opening +
extension) \\
BLAST & Heuristic & Speeds up search for large databases \\
\end{longtable}

BLAST (Basic Local Alignment Search Tool) uses word seeds and extension,
trading exactness for speed , essential for large genome databases.

\subsubsection{5. Complexity}\label{complexity-5}

Both Needleman-Wunsch and Smith-Waterman run in:

\begin{itemize}
\tightlist
\item
  Time: ( O(nm) )- Space: ( O(nm) ) But optimized versions use banded DP
  or Hirschberg's algorithm to cut memory to ( O(n + m) ).
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-68}

Sequence alignment bridges computer science and biology. It's how we:

\begin{itemize}
\tightlist
\item
  Compare species- Identify genes- Detect mutations- Trace ancestry-
  Build phylogenetic trees The idea of ``minimum edit cost'' echoes
  everywhere , from spell checkers to DNA analysis.
\end{itemize}

\begin{quote}
``In biology, similarity is a story. Alignment is how we read it.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-68}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Needleman-Wunsch for short DNA sequences.
\item
  Change gap penalties , see how alignment shifts.
\item
  Compare outputs from global and local alignment.
\item
  Use real sequences from GenBank to test.
\item
  Explore BLAST online and compare to exact alignment results.
\end{enumerate}

\subsection{70. Text Indexing and Search
Structures}\label{text-indexing-and-search-structures}

When text becomes large , think books, databases, or the entire web ,
searching naively for patterns (O(nm)) is far too slow. We need indexing
structures that let us search fast, often in O(m) or O(log n) time.

This section covers the backbone of search engines and string
processing:

\begin{itemize}
\tightlist
\item
  Suffix Arrays- Suffix Trees- Inverted Indexes- Tries and Prefix Trees-
  Compressed Indexes like FM-Index (Burrows-Wheeler)
\end{itemize}

\subsubsection{1. Why Index?}\label{why-index}

A text index is like a table of contents , it doesn't store the book,
but lets you jump straight to what you want.

If you have a text of length ( n ), and you'll run many queries, it's
worth building an index (even if it costs ( O\(n \log n\) ) to build).

Without indexing: each query takes ( O(nm) ). With indexing: each query
can take ( O(m) ) or less.

\subsubsection{2. Suffix Array}\label{suffix-array}

A suffix array is a sorted array of all suffixes of a string.

For text \texttt{"banana"}, suffixes are:

\begin{verbatim}
0: banana  
1: anana  
2: nana  
3: ana  
4: na  
5: a
\end{verbatim}

Sorted lexicographically:

\begin{verbatim}
5: a  
3: ana  
1: anana  
0: banana  
4: na  
2: nana
\end{verbatim}

Suffix Array = \texttt{{[}5,\ 3,\ 1,\ 0,\ 4,\ 2{]}}

To search, binary search over the suffix array using your pattern , (
O\(m \log n\) ).

Tiny Code (C) (naive construction)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ cmp}\OperatorTok{(}\DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{a}\OperatorTok{,} \DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{b}\OperatorTok{,} \DataTypeTok{void} \OperatorTok{*}\NormalTok{txt}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \OperatorTok{*(}\DataTypeTok{int}\OperatorTok{*)}\NormalTok{a}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \OperatorTok{*(}\DataTypeTok{int}\OperatorTok{*)}\NormalTok{b}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ strcmp}\OperatorTok{((}\DataTypeTok{char}\OperatorTok{*)}\NormalTok{txt }\OperatorTok{+}\NormalTok{ i}\OperatorTok{,} \OperatorTok{(}\DataTypeTok{char}\OperatorTok{*)}\NormalTok{txt }\OperatorTok{+}\NormalTok{ j}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ build\_suffix\_array}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{txt}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[])} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ sa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{    qsort\_r}\OperatorTok{(}\NormalTok{sa}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\DataTypeTok{int}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{,}\NormalTok{ txt}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Modern methods like prefix doubling or radix sort build it in (
O\(n \log n\) ).

Applications:

\begin{itemize}
\tightlist
\item
  Fast substring search- Longest common prefix (LCP) array- Pattern
  matching in DNA sequences- Plagiarism detection
\end{itemize}

\subsubsection{3. Suffix Tree}\label{suffix-tree-1}

A suffix tree is a compressed trie of all suffixes , each edge stores
multiple characters.

For \texttt{"banana"}, you'd build a tree where each leaf corresponds to
a suffix index.

Advantages:

\begin{itemize}
\tightlist
\item
  Pattern search in ( O(m) )- Space ( O(n) ) (with compression) Built
  using Ukkonen's algorithm in ( O(n) ).
\end{itemize}

Use Suffix Array + LCP as a space-efficient alternative.

\subsubsection{4. FM-Index (Burrows-Wheeler
Transform)}\label{fm-index-burrows-wheeler-transform}

Used in compressed full-text search (e.g., Bowtie, BWA). Combines:

\begin{itemize}
\tightlist
\item
  Burrows-Wheeler Transform (BWT)- Rank/select bitvectors Supports
  pattern search in O(m) time with very low memory.
\end{itemize}

Idea: transform text so similar substrings cluster together, enabling
compression and backward search.

Applications:

\begin{itemize}
\tightlist
\item
  DNA alignment- Large text archives- Memory-constrained search
\end{itemize}

\subsubsection{5. Inverted Index}\label{inverted-index}

Used in search engines. Instead of suffixes, it indexes words.

For example, text corpus:

\begin{verbatim}
doc1: quick brown fox  
doc2: quick red fox
\end{verbatim}

Inverted index:

\begin{verbatim}
"quick" → [doc1, doc2]
"brown" → [doc1]
"red"   → [doc2]
"fox"   → [doc1, doc2]
\end{verbatim}

Now searching ``quick fox'' becomes set intersection of lists.

Used with ranking functions (TF-IDF, BM25).

\subsubsection{6. Tries and Prefix Trees}\label{tries-and-prefix-trees}

A trie stores strings character by character. Each node = prefix.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{child}\OperatorTok{[}\DecValTok{26}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ end}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Perfect for:

\begin{itemize}
\tightlist
\item
  Autocomplete- Prefix search- Spell checkers Search: O(m), where m =
  pattern length.
\end{itemize}

Compressed tries (Patricia trees) reduce space.

\subsubsection{7. Comparing Structures}\label{comparing-structures}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Structure & Search Time & Build Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trie & O(m) & O(n) & High & Prefix queries \\
Suffix Array & O(m log n) & O(n log n) & Medium & Sorted suffixes \\
Suffix Tree & O(m) & O(n) & High & Rich structure \\
FM-Index & O(m) & O(n) & Low & Compressed \\
Inverted Index & O(k) & O(N) & Medium & Word-based \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-69}

Text indexing is the backbone of search engines, DNA alignment, and
autocomplete systems. Without it, Google searches, code lookups, or
genome scans would take minutes, not milliseconds.

\begin{quote}
``Indexing turns oceans of text into navigable maps.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-69}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a suffix array for ``banana'' and perform binary search for
  ``ana.''
\item
  Construct a trie for a dictionary and query prefixes.
\item
  Write a simple inverted index for a few documents.
\item
  Compare memory usage of suffix tree vs suffix array.
\item
  Experiment with FM-index using an online demo (like BWT explorer).
\end{enumerate}

\section{Chapter 8. Geometry, Graphics, and Spatial
Algorithms}\label{chapter-8.-geometry-graphics-and-spatial-algorithms-1}

\subsection{71. Convex Hull (Graham, Andrew,
Chan)}\label{convex-hull-graham-andrew-chan}

In computational geometry, the convex hull of a set of points is the
smallest convex polygon that contains all the points. Intuitively,
imagine stretching a rubber band around a set of nails on a board , the
shape the band takes is the convex hull.

Convex hulls are foundational for many geometric algorithms, like
closest pair, Voronoi diagrams, and collision detection.

In this section, we'll explore three classical algorithms:

\begin{itemize}
\tightlist
\item
  Graham Scan - elegant and simple (O(n log n))- Andrew's Monotone Chain
  - robust and practical (O(n log n))- Chan's Algorithm - advanced and
  optimal (O(n log h), where h = number of hull points)
\end{itemize}

\subsubsection{1. Definition}\label{definition-1}

Given a set of points \(P = {p_1, p_2, ..., p_n}\), the convex hull, (
\text{CH}(P) ), is the smallest convex polygon enclosing all points.

Formally: \[
\text{CH}(P) = \bigcap {C \subseteq \mathbb{R}^2 \mid C \text{ is convex and } P \subseteq C }
\]

A polygon is convex if every line segment between two points of the
polygon lies entirely inside it.

\subsubsection{2. Orientation Test}\label{orientation-test}

All convex hull algorithms rely on an orientation test using cross
product: Given three points ( a, b, c ):

\[
\text{cross}(a,b,c) = (b_x - a_x)(c_y - a_y) - (b_y - a_y)(c_x - a_x)
\]

\begin{itemize}
\tightlist
\item
  \texttt{\textgreater{}\ 0} → counter-clockwise turn-
  \texttt{\textless{}\ 0} → clockwise turn- \texttt{=\ 0} → collinear
\end{itemize}

\subsubsection{3. Graham Scan}\label{graham-scan}

One of the earliest convex hull algorithms.

Idea:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Pick the lowest point (and leftmost if tie).
\item
  Sort all other points by polar angle with respect to it.
\item
  Traverse points and maintain a stack:

  \begin{itemize}
  \tightlist
  \item
    Add point - While last three points make a right turn, pop middle
    one4. Remaining points form convex hull in CCW order.
  \end{itemize}
\end{enumerate}

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\DataTypeTok{double}\NormalTok{ cross}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ cmp}\OperatorTok{(}\DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{p1}\OperatorTok{,} \DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{p2}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Point }\OperatorTok{*}\NormalTok{a }\OperatorTok{=} \OperatorTok{(}\NormalTok{Point}\OperatorTok{*)}\NormalTok{p1}\OperatorTok{,} \OperatorTok{*}\NormalTok{b }\OperatorTok{=} \OperatorTok{(}\NormalTok{Point}\OperatorTok{*)}\NormalTok{p2}\OperatorTok{;}
    \CommentTok{// Compare by polar angle or distance}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{a}\OperatorTok{{-}\textgreater{}}\NormalTok{y }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{{-}\textgreater{}}\NormalTok{y}\OperatorTok{)} \OperatorTok{?} \OperatorTok{(}\NormalTok{a}\OperatorTok{{-}\textgreater{}}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{{-}\textgreater{}}\NormalTok{y}\OperatorTok{)} \OperatorTok{:} \OperatorTok{(}\NormalTok{a}\OperatorTok{{-}\textgreater{}}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{{-}\textgreater{}}\NormalTok{x}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ graham\_scan}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,}\NormalTok{ Point hull}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    qsort}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Point}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ top }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{top }\OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&}\NormalTok{ cross}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{top}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{[}\NormalTok{top}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textless{}=} \DecValTok{0}\OperatorTok{)}
\NormalTok{            top}\OperatorTok{{-}{-};}
\NormalTok{        hull}\OperatorTok{[}\NormalTok{top}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ top}\OperatorTok{;} \CommentTok{// number of hull points}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Sorting: ( O\(n \log n\) )- Scanning: ( O(n) ) → Total: O(n log n)
\end{itemize}

\subsubsection{Example}\label{example-12}

Input:

\begin{verbatim}
(0, 0), (1, 1), (2, 2), (2, 0), (0, 2)
\end{verbatim}

Hull (CCW):

\begin{verbatim}
(0,0) → (2,0) → (2,2) → (0,2)
\end{verbatim}

\subsubsection{4. Andrew's Monotone Chain}\label{andrews-monotone-chain}

Simpler and more robust for floating-point coordinates. Builds lower and
upper hulls separately.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points lexicographically (x, then y).
\item
  Build lower hull (left-to-right)
\item
  Build upper hull (right-to-left)
\item
  Concatenate (excluding duplicates)
\end{enumerate}

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ monotone\_chain}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,}\NormalTok{ Point hull}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    qsort}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Point}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \CommentTok{// Lower hull}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&}\NormalTok{ cross}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textless{}=} \DecValTok{0}\OperatorTok{)}\NormalTok{ k}\OperatorTok{{-}{-};}
\NormalTok{        hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \CommentTok{// Upper hull}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{,}\NormalTok{ t }\OperatorTok{=}\NormalTok{ k}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}=}\NormalTok{ t }\OperatorTok{\&\&}\NormalTok{ cross}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textless{}=} \DecValTok{0}\OperatorTok{)}\NormalTok{ k}\OperatorTok{{-}{-};}
\NormalTok{        hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;} \CommentTok{// last point == first point}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log n\) )

\subsubsection{5. Chan's Algorithm}\label{chans-algorithm}

When \(h \ll n\), Chan's method achieves ( O\(n \log h\) ):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Partition points into groups of size ( m ).
\item
  Compute hulls for each group (Graham).
\item
  Merge hulls with Jarvis March (gift wrapping).
\item
  Choose ( m ) cleverly (\(m = 2^k\)) to ensure ( O\(n \log h\) ).
\end{enumerate}

Used in: large-scale geometric processing.

\subsubsection{6. Applications}\label{applications-12}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Computer Graphics & Shape boundary, hitboxes \\
GIS / Mapping & Region boundaries \\
Robotics & Obstacle envelopes \\
Clustering & Outlier detection \\
Data Analysis & Minimal bounding shape \\
\end{longtable}

\subsubsection{7. Complexity Summary}\label{complexity-summary}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Graham Scan & ( O\(n \log n\) ) & ( O(n) ) & Simple, classic \\
Monotone Chain & ( O\(n \log n\) ) & ( O(n) ) & Stable, robust \\
Chan's Algorithm & ( O\(n \log h\) ) & ( O(n) ) & Best asymptotic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-70}

Convex hulls are one of the cornerstones of computational geometry. They
teach sorting, cross products, and geometric reasoning , and form the
basis for many spatial algorithms.

\begin{quote}
``Every scattered set hides a simple shape. The convex hull is that
hidden simplicity.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-70}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Graham Scan for 10 random points.
\item
  Plot the points and verify the hull.
\item
  Compare results with Andrew's Monotone Chain.
\item
  Test with collinear and duplicate points.
\item
  Explore 3D convex hulls (QuickHull, Gift Wrapping) next.
\end{enumerate}

\subsection{72. Closest Pair and Segment
Intersection}\label{closest-pair-and-segment-intersection}

Geometric problems often ask: \emph{what's the shortest distance between
two points?} or \emph{do these segments cross?} These are classic
building blocks in computational geometry , essential for collision
detection, graphics, clustering, and path planning.

This section covers two foundational problems:

\begin{itemize}
\tightlist
\item
  Closest Pair of Points - find two points with minimum Euclidean
  distance- Segment Intersection - determine if (and where) two line
  segments intersect
\end{itemize}

\subsubsection{1. Closest Pair of Points}\label{closest-pair-of-points}

Given ( n ) points in 2D, find a pair with the smallest distance. The
brute force solution is ( O\(n^2\) ), but using Divide and Conquer, we
can solve it in O(n log n).

\subsubsection{A. Divide and Conquer
Algorithm}\label{a.-divide-and-conquer-algorithm}

Idea:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points by x-coordinate.
\item
  Split into left and right halves.
\item
  Recursively find closest pairs in each half (distance = ( d )).
\item
  Merge step: check pairs across the split line within ( d ).
\end{enumerate}

In merge step, we only need to check at most 6 neighbors per point (by
geometric packing).

Tiny Code (C, Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\DataTypeTok{double}\NormalTok{ dist}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ dx }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ dy }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ sqrt}\OperatorTok{(}\NormalTok{dx}\OperatorTok{*}\NormalTok{dx }\OperatorTok{+}\NormalTok{ dy}\OperatorTok{*}\NormalTok{dy}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ brute\_force}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ d }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{            d }\OperatorTok{=}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{d}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{(}\NormalTok{pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{j}\OperatorTok{]));}
    \ControlFlowTok{return}\NormalTok{ d}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Recursive divide and merge:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ closest\_pair}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{3}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ brute\_force}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{double}\NormalTok{ d }\OperatorTok{=}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{closest\_pair}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{),}
\NormalTok{                    closest\_pair}\OperatorTok{(}\NormalTok{pts }\OperatorTok{+}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ mid}\OperatorTok{));}
    \CommentTok{// merge step: check strip points within distance d}
    \CommentTok{// sort by y, check neighbors}
    \ControlFlowTok{return}\NormalTok{ d}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log n\) )

Example:

Points:

\begin{verbatim}
(2,3), (12,30), (40,50), (5,1), (12,10), (3,4)
\end{verbatim}

Closest pair: (2,3) and (3,4), distance = √2

\subsubsection{B. Sweep Line Variant}\label{b.-sweep-line-variant}

Another method uses a line sweep and a balanced tree to keep active
points. As you move from left to right, maintain a window of recent
points within ( d ).

Used in large-scale spatial systems.

\subsubsection{Applications}\label{applications-13}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Clustering & Find nearest neighbors \\
Robotics & Avoid collisions \\
GIS & Nearest city search \\
Networking & Sensor proximity \\
\end{longtable}

\subsubsection{2. Segment Intersection}\label{segment-intersection}

Given two segments ( AB ) and ( CD ), determine whether they intersect.
It's the core of geometry engines and vector graphics systems.

\subsubsection{A. Orientation Test}\label{a.-orientation-test}

We use the cross product (orientation) test again. Two segments ( AB )
and ( CD ) intersect if and only if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The segments straddle each other: \[
  \text{orient}(A, B, C) \neq \text{orient}(A, B, D)
  \]
\end{enumerate}

\[
\text{orient}(C, D, A) \neq \text{orient}(C, D, B)
\] 2. Special cases for collinear points (check bounding boxes).

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ cross}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{\textless{}=}\NormalTok{ c}\OperatorTok{.}\NormalTok{x }\OperatorTok{\&\&}\NormalTok{ c}\OperatorTok{.}\NormalTok{x }\OperatorTok{\textless{}=}\NormalTok{ fmax}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{\&\&}
\NormalTok{           fmin}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{\textless{}=}\NormalTok{ c}\OperatorTok{.}\NormalTok{y }\OperatorTok{\&\&}\NormalTok{ c}\OperatorTok{.}\NormalTok{y }\OperatorTok{\textless{}=}\NormalTok{ fmax}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ intersect}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{,}\NormalTok{ Point d}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ o1 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{);}
    \DataTypeTok{double}\NormalTok{ o2 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ d}\OperatorTok{);}
    \DataTypeTok{double}\NormalTok{ o3 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{ d}\OperatorTok{,}\NormalTok{ a}\OperatorTok{);}
    \DataTypeTok{double}\NormalTok{ o4 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{ d}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o1}\OperatorTok{*}\NormalTok{o2 }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ o3}\OperatorTok{*}\NormalTok{o4 }\OperatorTok{\textless{}} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;} \CommentTok{// general case}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o1 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{b}\OperatorTok{,}\NormalTok{c}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o2 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{b}\OperatorTok{,}\NormalTok{d}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o3 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{d}\OperatorTok{,}\NormalTok{a}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o4 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{d}\OperatorTok{,}\NormalTok{b}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Line Sweep Algorithm
(Bentley-Ottmann)}\label{b.-line-sweep-algorithm-bentley-ottmann}

For multiple segments, check all intersections efficiently. Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort all endpoints by x-coordinate.
\item
  Sweep from left to right.
\item
  Maintain active set (balanced BST).
\item
  Check neighboring segments for intersections.
\end{enumerate}

Time complexity: \(O((n + k) \log n)\), where \(k\) is the number of
intersections.

Used in CAD, map rendering, and collision systems.

\subsubsection{3. Complexity Summary}\label{complexity-summary-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2899}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1884}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2899}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2319}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Naive
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Closest Pair & \(O(n^2)\) & \(O(n \log n)\) & Divide \& Conquer \\
Segment Intersection & \(O(n^2)\) & \(O((n + k) \log n)\) & Sweep
Line \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-71}

Geometric algorithms like these teach how to reason spatially , blending
math, sorting, and logic. They power real-world systems where precision
matters: from self-driving cars to game engines.

\begin{quote}
``Every point has a neighbor; every path may cross another , geometry
finds the truth in space.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-71}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement the closest pair algorithm using divide and conquer.
\item
  Visualize all pairwise distances , see which pairs are minimal.
\item
  Test segment intersection on random pairs.
\item
  Modify for 3D line segments using vector cross products.
\item
  Try building a line sweep visualizer to catch intersections
  step-by-step.
\end{enumerate}

\subsection{73. Line Sweep and Plane Sweep
Algorithms}\label{line-sweep-and-plane-sweep-algorithms}

The sweep line (or plane sweep) technique is one of the most powerful
paradigms in computational geometry. It transforms complex spatial
problems into manageable one-dimensional events , by sweeping a line (or
plane) across the input and maintaining a dynamic set of active
elements.

This method underlies many geometric algorithms:

\begin{itemize}
\tightlist
\item
  Event sorting → handle things in order- Active set maintenance → track
  current structure- Updates and queries → respond as the sweep
  progresses Used for intersection detection, closest pair, rectangle
  union, computational geometry in graphics and GIS.
\end{itemize}

\subsubsection{1. The Core Idea}\label{the-core-idea-3}

Imagine a vertical line sweeping from left to right across the plane. At
each ``event'' (like a point or segment endpoint), we update the set of
objects the line currently touches , the active set.

Each event may trigger queries, insertions, or removals.

This approach works because geometry problems often depend only on local
relationships between nearby elements as the sweep advances.

\subsubsection{A. Sweep Line Template}\label{a.-sweep-line-template}

A general structure looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Event }\OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ type}\OperatorTok{;}\NormalTok{ Object }\OperatorTok{*}\NormalTok{obj}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{sort}\OperatorTok{(}\NormalTok{events}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ events}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}

\NormalTok{ActiveSet S}\OperatorTok{;}

\ControlFlowTok{for} \OperatorTok{(}\NormalTok{Event e }\OperatorTok{:}\NormalTok{ events}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{type }\OperatorTok{==}\NormalTok{ START}\OperatorTok{)}\NormalTok{ S}\OperatorTok{.}\NormalTok{insert}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{obj}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{type }\OperatorTok{==}\NormalTok{ END}\OperatorTok{)}\NormalTok{ S}\OperatorTok{.}\NormalTok{erase}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{obj}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{type }\OperatorTok{==}\NormalTok{ QUERY}\OperatorTok{)}\NormalTok{ handle\_query}\OperatorTok{(}\NormalTok{S}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{obj}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Sorting ensures events are processed in order of increasing x (or
another dimension).

\subsubsection{2. Classic Applications}\label{classic-applications}

Let's explore three foundational problems solvable by sweep techniques.

\subsubsection{A. Segment Intersection
(Bentley-Ottmann)}\label{a.-segment-intersection-bentley-ottmann}

Goal: detect all intersections among ( n ) line segments.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort endpoints by x-coordinate.
\item
  Sweep from left to right.
\item
  Maintain an ordered set of active segments (sorted by y).
\item
  When a new segment starts, check intersection with neighbors above and
  below.
\item
  When segments intersect, record intersection and insert a new event at
  the x-coordinate of intersection.
\end{enumerate}

Complexity: \(O((n + k)\log n)\), where \(k\) is the number of
intersections.

\subsubsection{B. Closest Pair of
Points}\label{b.-closest-pair-of-points}

Sweep line version sorts by x, then slides a vertical line while
maintaining active points within a strip of width ( d ) (current
minimum). Only need to check at most 6-8 nearby points in strip.

Complexity: ( O\(n \log n\) )

\subsubsection{C. Rectangle Union Area}\label{c.-rectangle-union-area}

Given axis-aligned rectangles, compute total area covered.

Idea:

\begin{itemize}
\tightlist
\item
  Treat vertical edges as events (entering/exiting rectangles).- Sweep
  line moves along x-axis.- Maintain y-intervals in active set (using a
  segment tree or interval tree).- At each step, multiply current width
  × height of union of active intervals. Complexity: ( O\(n \log n\) )
\end{itemize}

Tiny Code Sketch (C)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y1}\OperatorTok{,}\NormalTok{ y2}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ type}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Event}\OperatorTok{;}
\NormalTok{Event events}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ n\_events}\OperatorTok{;}

\NormalTok{qsort}\OperatorTok{(}\NormalTok{events}\OperatorTok{,}\NormalTok{ n\_events}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Event}\OperatorTok{),}\NormalTok{ cmp\_by\_x}\OperatorTok{);}

\DataTypeTok{double}\NormalTok{ prev\_x }\OperatorTok{=}\NormalTok{ events}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{x}\OperatorTok{,}\NormalTok{ area }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{SegmentTree T}\OperatorTok{;}

\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n\_events}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ dx }\OperatorTok{=}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ prev\_x}\OperatorTok{;}
\NormalTok{    area }\OperatorTok{+=}\NormalTok{ dx }\OperatorTok{*}\NormalTok{ T}\OperatorTok{.}\NormalTok{total\_length}\OperatorTok{();} \CommentTok{// current union height}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{type }\OperatorTok{==}\NormalTok{ START}\OperatorTok{)}
\NormalTok{        T}\OperatorTok{.}\NormalTok{insert}\OperatorTok{(}\NormalTok{events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y1}\OperatorTok{,}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y2}\OperatorTok{);}
    \ControlFlowTok{else}
\NormalTok{        T}\OperatorTok{.}\NormalTok{remove}\OperatorTok{(}\NormalTok{events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y1}\OperatorTok{,}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y2}\OperatorTok{);}
\NormalTok{    prev\_x }\OperatorTok{=}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Other Applications}\label{other-applications}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2836}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5075}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2090}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
K-closest points & Maintain top \(k\) in active set & \(O(n \log n)\) \\
Union of rectangles & Compute covered area & \(O(n \log n)\) \\
Point location & Locate point in planar subdivision & \(O(\log n)\) \\
Visibility graph & Track visible edges & \(O(n \log n)\) \\
\end{longtable}

\subsubsection{4. Plane Sweep Extensions}\label{plane-sweep-extensions}

While line sweep moves in one dimension (x), plane sweep handles 2D or
higher-dimensional spaces, where:

\begin{itemize}
\tightlist
\item
  Events are 2D cells or regions.- Sweep front is a plane instead of a
  line. Used in 3D collision detection, computational topology, and CAD
  systems.
\end{itemize}

\subsubsection{Conceptual Visualization}\label{conceptual-visualization}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort events by one axis (say, x).
\item
  Maintain structure (set, tree, or heap) of intersecting or active
  elements.
\item
  Update at each event and record desired output (intersection, union,
  coverage).
\end{enumerate}

The key is the locality principle: only neighbors in the sweep structure
can change outcomes.

\subsubsection{5. Complexity}\label{complexity-6}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Phase & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sorting events & \(O(n \log n)\) \\
Processing events & \(O(n \log n)\) \\
Total & \(O(n \log n)\) (typical) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-72}

The sweep line method transforms geometric chaos into order , turning
spatial relationships into sorted sequences. It's the bridge between
geometry and algorithms, blending structure with motion.

\begin{quote}
``A sweep line sees everything , not all at once, but just in time.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-72}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a sweep-line segment intersection finder.
\item
  Compute the union area of 3 rectangles with overlaps.
\item
  Animate the sweep line to visualize event processing.
\item
  Modify for circular or polygonal objects.
\item
  Explore how sweep-line logic applies to time-based events in
  scheduling.
\end{enumerate}

\subsection{74. Delaunay and Voronoi
Diagrams}\label{delaunay-and-voronoi-diagrams}

In geometry and spatial computing, Delaunay triangulations and Voronoi
diagrams are duals , elegant structures that capture proximity,
territory, and connectivity among points.

They're used everywhere: from mesh generation, pathfinding, geospatial
analysis, to computational biology. This section introduces both, their
relationship, and algorithms to construct them efficiently.

\subsubsection{1. Voronoi Diagram}\label{voronoi-diagram}

Given a set of sites (points) \(P = {p_1, p_2, \ldots, p_n}\), the
Voronoi diagram partitions the plane into regions , one per point , so
that every location in a region is closer to its site than to any other.

Formally, the Voronoi cell for \(p_i\) is: \[
V(p_i) = {x \in \mathbb{R}^2 \mid d(x, p_i) \le d(x, p_j), \forall j \neq i }
\]

Each region is convex, and boundaries are formed by perpendicular
bisectors.

\subsubsection{Example}\label{example-13}

For points ( A, B, C ):

\begin{itemize}
\tightlist
\item
  Draw bisectors between each pair.- Intersection points define Voronoi
  vertices.- Resulting polygons cover the plane, one per site. Used to
  model nearest neighbor regions , ``which tower serves which area?''
\end{itemize}

\subsubsection{Properties}\label{properties}

\begin{itemize}
\tightlist
\item
  Every cell is convex.- Neighboring cells share edges.- The diagram's
  vertices are centers of circumcircles through three sites.- Dual graph
  = Delaunay triangulation.
\end{itemize}

\subsubsection{2. Delaunay Triangulation}\label{delaunay-triangulation}

The Delaunay triangulation (DT) connects points so that no point lies
inside the circumcircle of any triangle.

Equivalently, it's the dual graph of the Voronoi diagram.

It tends to avoid skinny triangles , maximizing minimum angles, creating
well-shaped meshes.

\subsubsection{Formal Definition}\label{formal-definition}

A triangulation ( T ) of ( P ) is Delaunay if for every triangle
\(\triangle abc \in T\), no point \(p \in P \setminus {a,b,c}\) lies
inside the circumcircle of \(\triangle abc\).

Why It Matters:

\begin{itemize}
\tightlist
\item
  Avoids sliver triangles.- Used in finite element meshes, terrain
  modeling, and path planning.- Leads to natural neighbor interpolation
  and smooth surfaces.
\end{itemize}

\subsubsection{3. Relationship}\label{relationship}

Voronoi and Delaunay are geometric duals:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Voronoi & Delaunay \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Regions = proximity zones & Triangles = neighbor connections \\
Edges = bisectors & Edges = neighbor pairs \\
Vertices = circumcenters & Faces = circumcircles \\
\end{longtable}

Connecting neighboring Voronoi cells gives Delaunay edges.

\subsubsection{4. Algorithms}\label{algorithms}

Several algorithms can build these diagrams efficiently.

\subsubsection{A. Incremental Insertion}\label{a.-incremental-insertion}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with a super-triangle enclosing all points.
\item
  Insert points one by one.
\item
  Remove triangles whose circumcircle contains the point.
\item
  Re-triangulate the resulting polygonal hole.
\end{enumerate}

Time Complexity: ( O\(n^2\) ), improved to ( O\(n \log n\) ) with
randomization.

\subsubsection{B. Divide and Conquer}\label{b.-divide-and-conquer}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points by x.
\item
  Recursively build DT for left and right halves.
\item
  Merge by finding common tangents.
\end{enumerate}

Time Complexity: ( O\(n \log n\) ) Elegant, structured, and
deterministic.

\subsubsection{C. Fortune's Sweep Line
Algorithm}\label{c.-fortunes-sweep-line-algorithm}

For Voronoi diagrams, Fortune's algorithm sweeps a line from top to
bottom. Maintains a beach line of parabolic arcs and event queue.

Each event (site or circle) updates the structure , building Voronoi
edges incrementally.

Time Complexity: ( O\(n \log n\) )

\subsubsection{D. Bowyer-Watson (Delaunay via Circumcircle
Test)**}\label{d.-bowyer-watson-delaunay-via-circumcircle-test}

A practical incremental version widely used in graphics and simulation.

Steps:

\begin{itemize}
\tightlist
\item
  Start with supertriangle- Insert point- Remove all triangles whose
  circumcircle contains point- Reconnect the resulting cavity
\end{itemize}

Tiny Code (Conceptual)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}\NormalTok{ Point a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Triangle}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ in\_circle}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{,}\NormalTok{ Point p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ A}\OperatorTok{[}\DecValTok{3}\OperatorTok{][}\DecValTok{3}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}
        \OperatorTok{\{}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{,} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)\},}
        \OperatorTok{\{}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{,} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{b}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)\},}
        \OperatorTok{\{}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ c}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{,} \OperatorTok{(}\NormalTok{c}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ c}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{c}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)\}}
    \OperatorTok{\};}
    \ControlFlowTok{return}\NormalTok{ determinant}\OperatorTok{(}\NormalTok{A}\OperatorTok{)} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This test ensures Delaunay property.

\subsubsection{5. Applications}\label{applications-14}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Application \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GIS & Nearest facility, region partition \\
Mesh Generation & Finite element methods \\
Robotics & Visibility graphs, navigation \\
Computer Graphics & Terrain triangulation \\
Clustering & Spatial neighbor structure \\
\end{longtable}

\subsubsection{6. Complexity Summary}\label{complexity-summary-2}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Type & Time & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fortune & Voronoi & ( O\(n \log n\) ) & Sweep line \\
Bowyer-Watson & Delaunay & ( O\(n \log n\) ) & Incremental \\
Divide \& Conquer & Delaunay & ( O\(n \log n\) ) & Recursive \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-73}

Voronoi and Delaunay diagrams reveal natural structure in point sets.
They convert distance into geometry, showing how space is divided and
connected. If geometry is the shape of space, these diagrams are its
skeleton.

\begin{quote}
``Every point claims its territory; every territory shapes its
network.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-73}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw Voronoi regions for 5 random points by hand.
\item
  Build Delaunay triangles (connect neighboring sites).
\item
  Verify the empty circumcircle property.
\item
  Use a library (CGAL / SciPy) to visualize both structures.
\item
  Explore how adding new points reshapes the diagrams.
\end{enumerate}

\subsection{75. Point in Polygon and Polygon
Triangulation}\label{point-in-polygon-and-polygon-triangulation}

Geometry often asks two fundamental questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Is a point inside or outside a polygon?
\item
  How can a complex polygon be broken into triangles for computation?
\end{enumerate}

These are the building blocks of spatial analysis, computer graphics,
and computational geometry.

\subsubsection{1. Point in Polygon (PIP)}\label{point-in-polygon-pip}

Given a polygon defined by vertices ( \(x_1, y_1\), \(x_2, y_2\),
\ldots, \(x_n, y_n\) ) and a test point ( (x, y) ), we want to determine
if the point lies inside, on the boundary, or outside the polygon.

\subsubsection{Methods}\label{methods}

\subsubsection{A. Ray Casting Algorithm}\label{a.-ray-casting-algorithm}

Shoot a ray horizontally to the right of the point. Count how many times
it intersects polygon edges.

\begin{itemize}
\tightlist
\item
  Odd count → Inside- Even count → Outside This is based on the even-odd
  rule.
\end{itemize}

Tiny Code (Ray Casting in C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ point\_in\_polygon}\OperatorTok{(}\NormalTok{Point p}\OperatorTok{,}\NormalTok{ Point poly}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{bool}\NormalTok{ inside }\OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(((}\NormalTok{poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y }\OperatorTok{\textgreater{}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{!=} \OperatorTok{(}\NormalTok{poly}\OperatorTok{[}\NormalTok{j}\OperatorTok{].}\NormalTok{y }\OperatorTok{\textgreater{}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{))} \OperatorTok{\&\&}
            \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{\textless{}} \OperatorTok{(}\NormalTok{poly}\OperatorTok{[}\NormalTok{j}\OperatorTok{].}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x}\OperatorTok{)} \OperatorTok{*} 
                   \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y}\OperatorTok{)} \OperatorTok{/} 
                   \OperatorTok{(}\NormalTok{poly}\OperatorTok{[}\NormalTok{j}\OperatorTok{].}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y}\OperatorTok{)} \OperatorTok{+}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x}\OperatorTok{))}
\NormalTok{            inside }\OperatorTok{=} \OperatorTok{!}\NormalTok{inside}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ inside}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This toggles \texttt{inside} every time a crossing is found.

\subsubsection{B. Winding Number
Algorithm}\label{b.-winding-number-algorithm}

Counts how many times the polygon winds around the point.

\begin{itemize}
\tightlist
\item
  Nonzero winding number → Inside- Zero → Outside More robust for
  complex polygons with holes or self-intersections.
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Time Complexity & Robustness \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ray Casting & (O(n)) & Simple, may fail on edge cases \\
Winding Number & (O(n)) & More accurate for complex shapes \\
\end{longtable}

\subsubsection{Edge Cases}\label{edge-cases}

Handle:

\begin{itemize}
\tightlist
\item
  Points on edges or vertices- Horizontal edges (special treatment to
  avoid double counting) Numerical precision is key.
\end{itemize}

\subsubsection{Applications}\label{applications-15}

\begin{itemize}
\tightlist
\item
  Hit testing in computer graphics- GIS spatial queries- Collision
  detection
\end{itemize}

\subsubsection{2. Polygon Triangulation}\label{polygon-triangulation-1}

A polygon triangulation divides a polygon into non-overlapping triangles
whose union equals the polygon.

Why triangulate?

\begin{itemize}
\tightlist
\item
  Triangles are simple, stable, and efficient for rendering and
  computation.- Used in graphics pipelines, area computation, physics,
  and mesh generation.
\end{itemize}

\subsubsection{A. Triangulation Basics}\label{a.-triangulation-basics}

For a simple polygon with ( n ) vertices,

\begin{itemize}
\tightlist
\item
  Always possible- Always yields ( n - 2 ) triangles Goal: Find a
  triangulation efficiently and stably.
\end{itemize}

\subsubsection{B. Ear Clipping
Algorithm}\label{b.-ear-clipping-algorithm}

An intuitive and widely used method for triangulation.

\subsubsection{Idea}\label{idea-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find an ear: a triangle formed by three consecutive vertices (
  \(v_{i-1}, v_i, v_{i+1}\) ) such that:

  \begin{itemize}
  \tightlist
  \item
    It is convex - Contains no other vertex inside
  \end{itemize}
\item
  Clip the ear (remove vertex \(v_i\))
\item
  Repeat until only one triangle remains
\end{enumerate}

Time Complexity: ( O\(n^2\) )

Tiny Code (Ear Clipping Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textgreater{}} \DecValTok{3}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_ear}\OperatorTok{(}\NormalTok{i}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{            add\_triangle}\OperatorTok{(}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ i}\OperatorTok{+}\DecValTok{1}\OperatorTok{);}
\NormalTok{            remove\_vertex}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
            \ControlFlowTok{break}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Helper \texttt{is\_ear()} checks convexity and emptiness.

\subsubsection{C. Dynamic Programming for Convex
Polygons}\label{c.-dynamic-programming-for-convex-polygons}

If the polygon is convex, use DP triangulation:

\[
dp[i][j] = \min_{k \in (i,j)} dp[i][k] + dp[k][j] + cost(i, j, k)
\]

Cost: perimeter or area (for minimum-weight triangulation)

Time Complexity: ( O\(n^3\) ) Space: ( O\(n^2\) )

\subsubsection{D. Divide and Conquer}\label{d.-divide-and-conquer}

Recursively split polygon and triangulate sub-polygons. Useful for
convex or near-convex shapes.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Time & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ear Clipping & (O\(n^2\)) & Simple polygons \\
DP Triangulation & (O\(n^3\)) & Weighted cost \\
Convex Polygon & (O(n)) & Straightforward \\
\end{longtable}

\subsubsection{3. Applications}\label{applications-16}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Usage \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Computer Graphics & Rendering, rasterization \\
Computational Geometry & Area computation, integration \\
Finite Element Analysis & Mesh subdivision \\
Robotics & Path planning, map decomposition \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-74}

Point-in-polygon answers where you are. Triangulation tells you how
space is built. Together, they form the foundation of geometric
reasoning.

\begin{quote}
``From a single point to a thousand triangles, geometry turns space into
structure.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-74}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a non-convex polygon and test random points using the ray casting
  rule.
\item
  Implement the ear clipping algorithm for a simple polygon.
\item
  Visualize how each step removes an ear and simplifies the shape.
\item
  Compare triangulation results for convex vs concave shapes.
\end{enumerate}

\subsection{76. Spatial Data Structures (KD,
R-tree)}\label{spatial-data-structures-kd-r-tree}

When working with geometric data, points, rectangles, or polygons,
efficient lookup and organization are crucial. Spatial data structures
are designed to answer queries like:

\begin{itemize}
\tightlist
\item
  Which objects are near a given point?- Which shapes intersect a
  region?- What's the nearest neighbor? They form the backbone of
  computational geometry, computer graphics, GIS, and search systems.
\end{itemize}

\subsubsection{1. Motivation}\label{motivation-1}

Brute force approaches that check every object have ( O(n) ) or worse
performance. Spatial indexing structures, like KD-Trees and R-Trees,
enable efficient range queries, nearest neighbor searches, and spatial
joins.

\subsubsection{2. KD-Tree (k-dimensional
tree)}\label{kd-tree-k-dimensional-tree}

A KD-tree is a binary tree that recursively partitions space using
axis-aligned hyperplanes.

Each node splits the data by one coordinate axis (x, y, z, \ldots).

\subsubsection{Structure}\label{structure}

\begin{itemize}
\tightlist
\item
  Each node represents a point.- Each level splits by a different axis
  (x, y, x, y, \ldots).- Left child contains points with smaller
  coordinate.- Right child contains larger coordinate.
\end{itemize}

Tiny Code (KD-tree Construction in 2D)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ axis}\OperatorTok{;} \CommentTok{// 0 for x, 1 for y}

\NormalTok{KDNode}\OperatorTok{*}\NormalTok{ build}\OperatorTok{(}\NormalTok{Point points}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ depth}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ NULL}\OperatorTok{;}
\NormalTok{    axis }\OperatorTok{=}\NormalTok{ depth }\OperatorTok{\%} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{    nth\_element}\OperatorTok{(}\NormalTok{points}\OperatorTok{,}\NormalTok{ points }\OperatorTok{+}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ points }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,}\NormalTok{ compare\_by\_axis}\OperatorTok{);}
\NormalTok{    KDNode}\OperatorTok{*}\NormalTok{ node }\OperatorTok{=}\NormalTok{ new\_node}\OperatorTok{(}\NormalTok{points}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]);}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{left  }\OperatorTok{=}\NormalTok{ build}\OperatorTok{(}\NormalTok{points}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ depth }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ build}\OperatorTok{(}\NormalTok{points }\OperatorTok{+}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ depth }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ node}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Search Complexity:

\begin{itemize}
\tightlist
\item
  Average: ( O\(\log n\) )- Worst-case: ( O(n) )
\end{itemize}

\subsubsection{Queries}\label{queries}

\begin{itemize}
\tightlist
\item
  Range query: Find points in a region.- Nearest neighbor: Search
  branches that might contain closer points.- K-nearest neighbors: Use
  priority queues.
\end{itemize}

\subsubsection{Pros \& Cons}\label{pros-cons}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Efficient for static data & Costly updates \\
Good for low dimensions & Degrades with high dimensions \\
\end{longtable}

\subsubsection{Applications}\label{applications-17}

\begin{itemize}
\tightlist
\item
  Nearest neighbor in ML- Collision detection- Clustering (e.g., k-means
  acceleration)
\end{itemize}

\subsubsection{3. R-Tree (Rectangle Tree)}\label{r-tree-rectangle-tree}

An R-tree is a height-balanced tree for rectangular bounding boxes. It's
the spatial analog of a B-tree.

\subsubsection{Idea}\label{idea-2}

\begin{itemize}
\tightlist
\item
  Store objects or bounding boxes in leaf nodes.- Internal nodes store
  MBRs (Minimum Bounding Rectangles) that cover child boxes.- Query by
  traversing overlapping MBRs.
\end{itemize}

Tiny Code (R-Tree Node Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
\NormalTok{    Rectangle mbr}\OperatorTok{;}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ children}\OperatorTok{[}\NormalTok{MAX\_CHILDREN}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ count}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Insertion chooses the child whose MBR expands least to accommodate the
new entry.

\subsubsection{Operations}\label{operations}

\begin{itemize}
\item
  Insert: Choose subtree → Insert → Adjust MBRs- Search: Descend into
  nodes whose MBR intersects query- Split: When full, use heuristics
  (linear, quadratic, R*-Tree) Complexity:
\item
  Query: ( O\(\log n\) )- Insert/Delete: ( O\(\log n\) ) average
\end{itemize}

\subsubsection{Pros \& Cons}\label{pros-cons-1}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Supports dynamic data & Overlaps can degrade performance \\
Ideal for rectangles & Complex split rules \\
\end{longtable}

\subsubsection{Variants}\label{variants-1}

\begin{itemize}
\tightlist
\item
  R*-Tree: Optimized reinsertion, better packing- R+ Tree:
  Non-overlapping partitions- Hilbert R-Tree: Uses space-filling curves
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-24}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & KD-Tree & R-Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data Type & Points & Rectangles / Regions \\
Dimensionality & Low (2-10) & Medium \\
Use Case & NN, range queries & Spatial joins, overlap queries \\
Updates & Expensive & Dynamic-friendly \\
Balance & Recursive median & B-tree-like \\
\end{longtable}

\subsubsection{5. Other Spatial
Structures}\label{other-spatial-structures}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Structure & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Quadtree & Recursive 2D subdivision into 4 quadrants \\
Octree & 3D analog of quadtree \\
BSP Tree & Binary partition using arbitrary planes \\
Grid Index & Divide space into uniform grid cells \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-18}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Usage \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GIS & Region queries, map intersections \\
Graphics & Ray tracing acceleration \\
Robotics & Collision and path planning \\
ML & Nearest neighbor search \\
Databases & Spatial indexing \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-75}

Spatial structures turn geometry into searchable data. They enable
efficient algorithms for where and what's near, vital for real-time
systems.

\begin{quote}
``Divide space wisely, and queries become whispers instead of shouts.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-75}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a KD-tree for 10 random 2D points.
\item
  Implement nearest neighbor search.
\item
  Insert rectangles into a simple R-tree and query intersection with a
  bounding box.
\item
  Compare query time vs brute force.
\end{enumerate}

\subsection{77. Rasterization and Scanline
Techniques}\label{rasterization-and-scanline-techniques}

When you draw shapes on a screen, triangles, polygons, circles, they
must be converted into pixels. This conversion is called rasterization.
It's the bridge between geometric math and visible images.

Rasterization and scanline algorithms are foundational to computer
graphics, game engines, and rendering pipelines.

\subsubsection{1. What Is Rasterization?}\label{what-is-rasterization}

Rasterization transforms vector shapes (continuous lines and surfaces)
into discrete pixels on a grid.

For example, a triangle defined by vertices
\texttt{(x1,\ y1),\ (x2,\ y2),\ (x3,\ y3)} must be filled pixel by
pixel.

\subsubsection{2. Core Idea}\label{core-idea}

Each shape (line, polygon, circle) is sampled over a grid. The algorithm
decides which pixels are inside, on, or outside the shape.

A rasterizer answers:

\begin{itemize}
\tightlist
\item
  Which pixels should be lit?- What color or depth should each pixel
  have?
\end{itemize}

\subsubsection{3. Line Rasterization (Bresenham's
Algorithm)}\label{line-rasterization-bresenhams-algorithm}

A classic method for drawing straight lines with integer arithmetic.

Key Idea: Move from one pixel to the next, choosing the pixel closest to
the true line path.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ draw\_line}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x0}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ y0}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x1}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ y1}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dx }\OperatorTok{=}\NormalTok{ abs}\OperatorTok{(}\NormalTok{x1 }\OperatorTok{{-}}\NormalTok{ x0}\OperatorTok{),}\NormalTok{ dy }\OperatorTok{=}\NormalTok{ abs}\OperatorTok{(}\NormalTok{y1 }\OperatorTok{{-}}\NormalTok{ y0}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ sx }\OperatorTok{=} \OperatorTok{(}\NormalTok{x0 }\OperatorTok{\textless{}}\NormalTok{ x1}\OperatorTok{)} \OperatorTok{?} \DecValTok{1} \OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ sy }\OperatorTok{=} \OperatorTok{(}\NormalTok{y0 }\OperatorTok{\textless{}}\NormalTok{ y1}\OperatorTok{)} \OperatorTok{?} \DecValTok{1} \OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ err }\OperatorTok{=}\NormalTok{ dx }\OperatorTok{{-}}\NormalTok{ dy}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        plot}\OperatorTok{(}\NormalTok{x0}\OperatorTok{,}\NormalTok{ y0}\OperatorTok{);} \CommentTok{// draw pixel}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x0 }\OperatorTok{==}\NormalTok{ x1 }\OperatorTok{\&\&}\NormalTok{ y0 }\OperatorTok{==}\NormalTok{ y1}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ e2 }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ err}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e2 }\OperatorTok{\textgreater{}} \OperatorTok{{-}}\NormalTok{dy}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ err }\OperatorTok{{-}=}\NormalTok{ dy}\OperatorTok{;}\NormalTok{ x0 }\OperatorTok{+=}\NormalTok{ sx}\OperatorTok{;} \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e2 }\OperatorTok{\textless{}}\NormalTok{ dx}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ err }\OperatorTok{+=}\NormalTok{ dx}\OperatorTok{;}\NormalTok{ y0 }\OperatorTok{+=}\NormalTok{ sy}\OperatorTok{;} \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Why it works: Bresenham avoids floating-point math and keeps the line
visually continuous.

\subsubsection{4. Polygon Rasterization}\label{polygon-rasterization}

To fill shapes, we need scanline algorithms, they sweep a horizontal
line (y-axis) across the shape and fill pixels in between edges.

\subsubsection{Scanline Fill Steps}\label{scanline-fill-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort edges by their y-coordinates.
\item
  Scan each line (y).
\item
  Find intersections with polygon edges.
\item
  Fill between intersection pairs.
\end{enumerate}

This guarantees correct filling for convex and concave polygons.

\subsubsection{Example (Simple Triangle
Rasterization)}\label{example-simple-triangle-rasterization}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ y }\OperatorTok{=}\NormalTok{ y\_min}\OperatorTok{;}\NormalTok{ y }\OperatorTok{\textless{}=}\NormalTok{ y\_max}\OperatorTok{;}\NormalTok{ y}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    find all x}\OperatorTok{{-}}\NormalTok{intersections with polygon edges}\OperatorTok{;}
\NormalTok{    sort x}\OperatorTok{{-}}\NormalTok{intersections}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ count}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=} \DecValTok{2}\OperatorTok{)}
\NormalTok{        draw\_line}\OperatorTok{(}\NormalTok{x}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ y}\OperatorTok{,}\NormalTok{ x}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{],}\NormalTok{ y}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Circle Rasterization (Midpoint
Algorithm)}\label{circle-rasterization-midpoint-algorithm}

Use symmetry, a circle is symmetric in 8 octants.

Each step calculates the error term to decide whether to move
horizontally or diagonally.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ draw\_circle}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ xc}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ yc}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ x }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ y }\OperatorTok{=}\NormalTok{ r}\OperatorTok{,}\NormalTok{ d }\OperatorTok{=} \DecValTok{3} \OperatorTok{{-}} \DecValTok{2} \OperatorTok{*}\NormalTok{ r}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{y }\OperatorTok{\textgreater{}=}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        plot\_circle\_points}\OperatorTok{(}\NormalTok{xc}\OperatorTok{,}\NormalTok{ yc}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
\NormalTok{        x}\OperatorTok{++;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{d }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ y}\OperatorTok{{-}{-};}\NormalTok{ d }\OperatorTok{+=} \DecValTok{4} \OperatorTok{*} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ y}\OperatorTok{)} \OperatorTok{+} \DecValTok{10}\OperatorTok{;} \OperatorTok{\}}
        \ControlFlowTok{else}\NormalTok{ d }\OperatorTok{+=} \DecValTok{4} \OperatorTok{*}\NormalTok{ x }\OperatorTok{+} \DecValTok{6}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{6. Depth and Shading}\label{depth-and-shading}

In 3D graphics, rasterization includes depth testing (Z-buffer) and
color interpolation. Each pixel stores its depth; new pixels overwrite
only if closer.

Interpolated shading (Gouraud, Phong) computes smooth color transitions
across polygons.

\subsubsection{7. Hardware Rasterization}\label{hardware-rasterization}

Modern GPUs perform rasterization in parallel:

\begin{itemize}
\tightlist
\item
  Vertex Shader → Projection- Rasterizer → Pixel Grid- Fragment Shader →
  Color \& Depth Each pixel is processed in fragment shaders for
  lighting, texture, and effects.
\end{itemize}

\subsubsection{8. Optimizations}\label{optimizations}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Technique & Purpose \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bounding Box Clipping & Skip off-screen regions \\
Early Z-Culling & Discard hidden pixels early \\
Edge Functions & Fast inside-test for triangles \\
Barycentric Coordinates & Interpolate depth/color smoothly \\
\end{longtable}

\subsubsection{9. Why It Matters}\label{why-it-matters-76}

Rasterization turns math into imagery. It's the foundation of all visual
computing, renderers, CAD, games, and GUIs. Even with ray tracing
rising, rasterization remains dominant for real-time rendering.

\begin{quote}
``Every pixel you see began as math, it's just geometry painted by
light.''
\end{quote}

\subsubsection{10. Try It Yourself}\label{try-it-yourself-76}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Bresenham's algorithm for lines.
\item
  Write a scanline polygon fill for triangles.
\item
  Extend it with color interpolation using barycentric coordinates.
\item
  Compare performance vs brute force (looping over all pixels).
\end{enumerate}

\subsection{78. Computer Vision (Canny, Hough,
SIFT)}\label{computer-vision-canny-hough-sift}

Computer vision is where algorithms learn to see, to extract structure,
shape, and meaning from images. Behind every object detector, edge map,
and keypoint matcher lies a handful of powerful geometric algorithms.

In this section, we explore four pillars of classical vision: Canny edge
detection, Hough transform, and SIFT (Scale-Invariant Feature
Transform).

\subsubsection{1. The Vision Pipeline}\label{the-vision-pipeline}

Most vision algorithms follow a simple pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Input: Raw pixels (grayscale or color)
\item
  Preprocess: Smoothing or filtering
\item
  Feature extraction: Edges, corners, blobs
\item
  Detection or matching: Shapes, keypoints
\item
  Interpretation: Object recognition, tracking
\end{enumerate}

Canny, Hough, and SIFT live in the feature extraction and detection
stages.

\subsubsection{2. Canny Edge Detector}\label{canny-edge-detector}

Edges mark places where intensity changes sharply, the outlines of
objects. The Canny algorithm (1986) is one of the most robust and widely
used edge detectors.

\subsubsection{Steps}\label{steps-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Smoothing: Apply Gaussian blur to reduce noise.
\item
  Gradient computation:

  \begin{itemize}
  \tightlist
  \item
    Compute \(G_x\) and \(G_y\) via Sobel filters\\
  \item
    Gradient magnitude: \(G = \sqrt{G_x^2 + G_y^2}\)\\
  \item
    Gradient direction: \(\theta = \tan^{-1}\frac{G_y}{G_x}\)
  \end{itemize}
\item
  Non-maximum suppression:

  \begin{itemize}
  \tightlist
  \item
    Keep only local maxima along the gradient direction
  \end{itemize}
\item
  Double thresholding:

  \begin{itemize}
  \tightlist
  \item
    Strong edges (high gradient)\\
  \item
    Weak edges (connected to strong ones)
  \end{itemize}
\item
  Edge tracking by hysteresis:

  \begin{itemize}
  \tightlist
  \item
    Connect weak edges linked to strong edges
  \end{itemize}
\end{enumerate}

\subsubsection{Tiny Code (Pseudocode)}\label{tiny-code-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Image canny}\OperatorTok{(}\NormalTok{Image input}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Image smoothed }\OperatorTok{=}\NormalTok{ gaussian\_blur}\OperatorTok{(}\NormalTok{input}\OperatorTok{);}
\NormalTok{    Gradient grad }\OperatorTok{=}\NormalTok{ sobel}\OperatorTok{(}\NormalTok{smoothed}\OperatorTok{);}
\NormalTok{    Image suppressed }\OperatorTok{=}\NormalTok{ non\_max\_suppression}\OperatorTok{(}\NormalTok{grad}\OperatorTok{);}
\NormalTok{    Image edges }\OperatorTok{=}\NormalTok{ hysteresis\_threshold}\OperatorTok{(}\NormalTok{suppressed}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ edges}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why Canny Works}\label{why-canny-works}

Canny maximizes three criteria:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Good detection (low false negatives)
\item
  Good localization (edges close to true edges)
\item
  Single response (no duplicates)
\end{enumerate}

It's a careful balance between sensitivity and stability.

\subsubsection{3. Hough Transform}\label{hough-transform}

Canny finds edge points, Hough connects them into shapes.

The Hough transform detects lines, circles, and other parametric shapes
using voting in parameter space.

\subsubsection{Line Detection}\label{line-detection}

Equation of a line: \[
\rho = x\cos\theta + y\sin\theta
\]

Each edge point votes for all (\(\rho, \theta\)) combinations it could
belong to. Peaks in the accumulator array correspond to strong lines.

Tiny Code (Hough Transform)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each edge point }\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{):}
  \ControlFlowTok{for}\NormalTok{ theta in }\OperatorTok{[}\DecValTok{0}\OperatorTok{,} \DecValTok{180}\OperatorTok{):}
\NormalTok{    rho }\OperatorTok{=}\NormalTok{ x}\OperatorTok{*}\NormalTok{cos}\OperatorTok{(}\NormalTok{theta}\OperatorTok{)} \OperatorTok{+}\NormalTok{ y}\OperatorTok{*}\NormalTok{sin}\OperatorTok{(}\NormalTok{theta}\OperatorTok{);}
\NormalTok{    accumulator}\OperatorTok{[}\NormalTok{rho}\OperatorTok{,}\NormalTok{ theta}\OperatorTok{]++;}
\end{Highlighting}
\end{Shaded}

Then pick (\(\rho, \theta\)) with highest votes.

\subsubsection{Circle Detection}\label{circle-detection}

Use 3D accumulator \(center_x, center_y, radius\). Each edge pixel votes
for possible circle centers.

\subsubsection{Applications}\label{applications-19}

\begin{itemize}
\tightlist
\item
  Lane detection in self-driving- Shape recognition (circles, ellipses)-
  Document analysis (lines, grids)
\end{itemize}

\subsubsection{4. SIFT (Scale-Invariant Feature
Transform)}\label{sift-scale-invariant-feature-transform}

SIFT finds keypoints that remain stable under scale, rotation, and
illumination changes.

It's widely used for image matching, panoramas, 3D reconstruction, and
object recognition.

\subsubsection{Steps}\label{steps-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Scale-space extrema detection

  \begin{itemize}
  \item
    Use Difference of Gaussians (DoG) across scales. - Detect
    maxima/minima in space-scale neighborhood.2. Keypoint localization
  \item
    Refine keypoint position and discard unstable ones.3. Orientation
    assignment
  \item
    Assign dominant gradient direction.4. Descriptor generation
  \item
    Build a 128D histogram of gradient orientations in a local patch.
  \end{itemize}
\end{enumerate}

Tiny Code (Outline)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each octave}\OperatorTok{:}
\NormalTok{  build scale}\OperatorTok{{-}}\NormalTok{space pyramid}
\NormalTok{  find DoG extrema}
\NormalTok{  localize keypoints}
\NormalTok{  assign orientations}
\NormalTok{  compute }\DecValTok{128}\ErrorTok{D}\NormalTok{ descriptor}
\end{Highlighting}
\end{Shaded}

\subsubsection{Properties}\label{properties-1}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Property & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scale Invariant & Detects features at multiple scales \\
Rotation Invariant & Uses local orientation \\
Robust & Handles lighting, noise, affine transforms \\
\end{longtable}

\subsubsection{5. Comparison}\label{comparison-25}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1268}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2394}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3099}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3239}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Robustness
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Canny & Edge detection & Binary edge map & Sensitive to thresholds \\
Hough & Shape detection & Lines, circles & Needs clean edges \\
SIFT & Feature detection & Keypoints, descriptors & Very robust \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-20}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use Case \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Robotics & Visual SLAM, localization \\
AR / VR & Marker tracking \\
Search & Image matching \\
Medical & Edge segmentation \\
Industry & Quality inspection \\
\end{longtable}

\subsubsection{7. Modern Successors}\label{modern-successors}

\begin{itemize}
\tightlist
\item
  ORB (FAST + BRIEF): Efficient for real-time- SURF: Faster SIFT
  alternative- Harris / FAST: Corner detectors- Deep features: CNN-based
  descriptors
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-77}

These algorithms gave machines their first eyes, before deep learning,
they were how computers recognized structure. Even today, they're used
in preprocessing, embedded systems, and hybrid pipelines.

\begin{quote}
``Before neural nets could dream, vision began with gradients, geometry,
and votes.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-77}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Canny using Sobel and hysteresis.
\item
  Use Hough transform to detect lines in a synthetic image.
\item
  Try OpenCV SIFT to match keypoints between two rotated images.
\item
  Compare edge maps before and after Gaussian blur.
\end{enumerate}

\subsection{79. Pathfinding in Space (A*, RRT,
PRM)}\label{pathfinding-in-space-a-rrt-prm}

When navigating a maze, driving an autonomous car, or moving a robot
arm, the question is the same: How do we find a path from start to goal
efficiently and safely?

Pathfinding algorithms answer this question, balancing optimality,
speed, and adaptability. In this section, we explore three foundational
families:

\begin{itemize}
\tightlist
\item
  A*: Heuristic search in grids and graphs- RRT (Rapidly-Exploring
  Random Tree): Sampling-based exploration- PRM (Probabilistic Roadmap):
  Precomputed navigation networks
\end{itemize}

\subsubsection{1. The Pathfinding
Problem}\label{the-pathfinding-problem}

Given:

\begin{itemize}
\tightlist
\item
  A space (grid, graph, or continuous)- A start node and goal node- A
  cost function (distance, time, energy)- Optional obstacles Find a
  collision-free, low-cost path.
\end{itemize}

\subsubsection{2. A* (A-star) Search}\label{a-a-star-search}

A* combines Dijkstra's algorithm with a heuristic that estimates
remaining cost. It's the most popular graph-based pathfinding algorithm.

\subsubsection{Key Idea}\label{key-idea}

Each node ( n ) has: \[
f(n) = g(n) + h(n)
\]

\begin{itemize}
\tightlist
\item
  ( g(n) ): cost so far- ( h(n) ): estimated cost to goal- ( f(n) ):
  total estimated cost
\end{itemize}

Algorithm

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize priority queue with start node
\item
  While queue not empty:

  \begin{itemize}
  \tightlist
  \item
    Pop node with smallest ( f(n) ) - If goal reached → return path -
    For each neighbor:

    \begin{itemize}
    \tightlist
    \item
      Compute new ( g ), ( f ) - Update queue if better
    \end{itemize}
  \end{itemize}
\end{enumerate}

Tiny Code (Grid A*)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \DataTypeTok{double}\NormalTok{ g}\OperatorTok{,}\NormalTok{ f}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\DataTypeTok{double}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{Node a}\OperatorTok{,}\NormalTok{ Node b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ fabs}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fabs}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{);} \CommentTok{// Manhattan}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ a\_star}\OperatorTok{(}\NormalTok{Node start}\OperatorTok{,}\NormalTok{ Node goal}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    PriorityQueue open}\OperatorTok{;}
\NormalTok{    push}\OperatorTok{(}\NormalTok{open}\OperatorTok{,}\NormalTok{ start}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{empty}\OperatorTok{(}\NormalTok{open}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        Node cur }\OperatorTok{=}\NormalTok{ pop\_min}\OperatorTok{(}\NormalTok{open}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cur }\OperatorTok{==}\NormalTok{ goal}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ reconstruct\_path}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Node n }\OperatorTok{:}\NormalTok{ neighbors}\OperatorTok{(}\NormalTok{cur}\OperatorTok{))} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ tentative\_g }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{.}\NormalTok{g }\OperatorTok{+}\NormalTok{ dist}\OperatorTok{(}\NormalTok{cur}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{tentative\_g }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{.}\NormalTok{g}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                n}\OperatorTok{.}\NormalTok{g }\OperatorTok{=}\NormalTok{ tentative\_g}\OperatorTok{;}
\NormalTok{                n}\OperatorTok{.}\NormalTok{f }\OperatorTok{=}\NormalTok{ n}\OperatorTok{.}\NormalTok{g }\OperatorTok{+}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\NormalTok{                push}\OperatorTok{(}\NormalTok{open}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Complexity}\label{complexity-7}

\begin{itemize}
\tightlist
\item
  Time: ( O\(E \log V\) )- Space: ( O(V) )- Optimal if ( h(n) ) is
  admissible (never overestimates)
\end{itemize}

\subsubsection{Variants}\label{variants-2}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Variant & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Dijkstra & A* with ( h(n) = 0 ) \\
Greedy Best-First & Uses ( h(n) ) only \\
Weighted A* & Speeds up with tradeoff on optimality \\
Jump Point Search & Optimized for uniform grids \\
\end{longtable}

\subsubsection{3. RRT (Rapidly-Exploring Random
Tree)}\label{rrt-rapidly-exploring-random-tree}

A* struggles in continuous or high-dimensional spaces (e.g.~robot arms).
RRT tackles this with randomized exploration.

\subsubsection{Core Idea}\label{core-idea-1}

\begin{itemize}
\tightlist
\item
  Grow a tree from the start by randomly sampling points.- Extend tree
  toward each sample (step size \(\epsilon\)).- Stop when near the goal.
\end{itemize}

Tiny Code (RRT Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Tree T }\OperatorTok{=} \OperatorTok{\{}\NormalTok{start}\OperatorTok{\};}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ MAX\_ITERS}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    Point q\_rand }\OperatorTok{=}\NormalTok{ random\_point}\OperatorTok{();}
\NormalTok{    Point q\_near }\OperatorTok{=}\NormalTok{ nearest}\OperatorTok{(}\NormalTok{T}\OperatorTok{,}\NormalTok{ q\_rand}\OperatorTok{);}
\NormalTok{    Point q\_new }\OperatorTok{=}\NormalTok{ steer}\OperatorTok{(}\NormalTok{q\_near}\OperatorTok{,}\NormalTok{ q\_rand}\OperatorTok{,}\NormalTok{ step\_size}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{collision\_free}\OperatorTok{(}\NormalTok{q\_near}\OperatorTok{,}\NormalTok{ q\_new}\OperatorTok{))}
\NormalTok{        add\_edge}\OperatorTok{(}\NormalTok{T}\OperatorTok{,}\NormalTok{ q\_near}\OperatorTok{,}\NormalTok{ q\_new}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{distance}\OperatorTok{(}\NormalTok{q\_new}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ eps}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ path}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros \& Cons}\label{pros-cons-2}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Works in continuous space & Paths are suboptimal \\
Handles high dimensions & Randomness may miss narrow passages \\
Simple and fast & Needs post-processing (smoothing) \\
\end{longtable}

\subsubsection{Variants}\label{variants-3}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Variant & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
RRT* & Asymptotically optimal \\
Bi-RRT & Grow from both start and goal \\
Informed RRT* & Focus on promising regions \\
\end{longtable}

\subsubsection{4. PRM (Probabilistic
Roadmap)}\label{prm-probabilistic-roadmap}

PRM builds a graph of feasible configurations, a roadmap, then searches
it.

\subsubsection{Steps}\label{steps-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sample random points in free space
\item
  Connect nearby points with collision-free edges
\item
  Search roadmap (e.g., with A*)
\end{enumerate}

Tiny Code (PRM Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Graph G }\OperatorTok{=} \OperatorTok{\{\};}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    Point p }\OperatorTok{=}\NormalTok{ random\_free\_point}\OperatorTok{();}
\NormalTok{    G}\OperatorTok{.}\NormalTok{add\_vertex}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
\OperatorTok{\}}
\ControlFlowTok{for}\NormalTok{ each p in G}\OperatorTok{:}
    \ControlFlowTok{for}\NormalTok{ each q near p}\OperatorTok{:}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{collision\_free}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ q}\OperatorTok{))}
\NormalTok{            G}\OperatorTok{.}\NormalTok{add\_edge}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
\NormalTok{path }\OperatorTok{=}\NormalTok{ a\_star}\OperatorTok{(}\NormalTok{G}\OperatorTok{,}\NormalTok{ start}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros \& Cons}\label{pros-cons-3}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Precomputes reusable roadmap & Needs many samples for coverage \\
Good for multiple queries & Poor for single-query planning \\
Works in high-dim spaces & May need post-smoothing \\
\end{longtable}

\subsubsection{5. Comparison}\label{comparison-26}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1806}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3472}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Nature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A* & Discrete & Deterministic & Yes & Grids, graphs \\
RRT & Continuous & Randomized & No (RRT* = Yes) & Robotics, motion
planning \\
PRM & Continuous & Randomized & Approx. & Multi-query planning \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-21}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use Case \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Robotics & Arm motion, mobile navigation \\
Games & NPC pathfinding, AI navigation mesh \\
Autonomous vehicles & Route planning \\
Aerospace & Drone and spacecraft trajectory \\
Logistics & Warehouse robot movement \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-78}

Pathfinding is decision-making in space, it gives agents the ability to
move, explore, and act purposefully. From Pac-Man to Mars rovers, every
journey starts with an algorithm.

\begin{quote}
``To move with purpose, one must first see the paths that are
possible.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-78}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement A* on a 2D grid with walls.
\item
  Generate an RRT in a 2D obstacle field.
\item
  Build a PRM for a continuous space and run A* on the roadmap.
\item
  Compare speed and path smoothness across methods.
\end{enumerate}

\subsection{80. Computational Geometry Variants and
Applications}\label{computational-geometry-variants-and-applications}

Computational geometry is the study of algorithms on geometric data,
points, lines, polygons, circles, and higher-dimensional shapes. By now,
you've seen core building blocks: convex hulls, intersections, nearest
neighbors, triangulations, and spatial indexing.

This final section brings them together through variants,
generalizations, and real-world applications, showing how geometry
quietly powers modern computing.

\subsubsection{1. Beyond the Plane}\label{beyond-the-plane}

Most examples so far assumed 2D geometry. But real systems often live in
3D or N-D spaces.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1098}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5732}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3171}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Problems
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Uses
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2D & Convex hull, polygon area, line sweep & GIS, CAD, mapping \\
3D & Convex polyhedra, mesh intersection, visibility & Graphics,
simulation \\
N-D & Voronoi in high-D, KD-trees, optimization & ML, robotics, data
science \\
\end{longtable}

Higher dimensions add complexity (and sometimes impossibility):

\begin{itemize}
\tightlist
\item
  Exact geometry often replaced by approximations.- Volume, distance,
  and intersection tests become more expensive.
\end{itemize}

\subsubsection{2. Approximate and Robust
Geometry}\label{approximate-and-robust-geometry}

Real-world geometry faces numerical errors (floating point) and
degenerate cases (collinear, overlapping). To handle this, algorithms
adopt robustness and approximation strategies.

\begin{itemize}
\tightlist
\item
  Epsilon comparisons: treat values within tolerance as equal-
  Orientation tests: robustly compute turn direction via cross product-
  Exact arithmetic: rational or symbolic computation- Grid snapping:
  quantize space for stability Approximate geometry accepts small error
  for large speed-up, essential in graphics and machine learning.
\end{itemize}

\subsubsection{3. Geometric Duality}\label{geometric-duality}

A powerful tool for reasoning about problems: map points to lines, lines
to points. For example:

\begin{itemize}
\item
  A point ( (a, b) ) maps to line ( y = ax - b ).- A line ( y = mx + c )
  maps to point ( (m, -c) ). Applications:
\item
  Transforming line intersection problems into point location problems-
  Simplifying half-plane intersections- Enabling arrangement algorithms
  in computational geometry Duality is a common trick: turn geometry
  upside-down to make it simpler.
\end{itemize}

\subsubsection{4. Geometric Data
Structures}\label{geometric-data-structures}

Recap of core spatial structures and what they're best at:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3284}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2388}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2537}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stores
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Queries
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
KD-Tree & Points & NN, range & Low-D search \\
R-Tree & Rectangles & Overlaps & Spatial DB \\
Quad/Octree & Space partitions & Point lookup & Graphics, GIS \\
BSP Tree & Polygons & Visibility & Rendering \\
Delaunay Triangulation & Points & Neighbors & Mesh generation \\
Segment Tree & Intervals & Range & Sweep-line events \\
\end{longtable}

\subsubsection{5. Randomized Geometry}\label{randomized-geometry}

Randomness simplifies deterministic geometry:

\begin{itemize}
\tightlist
\item
  Randomized incremental construction (Convex Hulls, Delaunay)- Random
  sampling for approximation (ε-nets, VC dimension)- Monte Carlo
  geometry for probabilistic intersection and coverage Example:
  randomized incremental convex hull builds expected ( O\(n \log n\) )
  structures with elegant proofs.
\end{itemize}

\subsubsection{6. Computational Topology}\label{computational-topology}

Beyond geometry lies shape connectivity, studied by topology. Algorithms
compute connected components, holes, homology, and Betti numbers.

Applications include:

\begin{itemize}
\tightlist
\item
  3D printing (watertightness)- Data analysis (persistent homology)-
  Robotics (free space topology) Geometry meets topology in
  alpha-shapes, simplicial complexes, and manifold reconstruction.
\end{itemize}

\subsubsection{7. Geometry Meets Machine
Learning}\label{geometry-meets-machine-learning}

Many ML methods are geometric at heart:

\begin{itemize}
\tightlist
\item
  Nearest neighbor → Voronoi diagram- SVM → hyperplane separation-
  K-means → Voronoi partitioning- Manifold learning → low-dim geometry-
  Convex optimization → geometric feasibility Visualization tools
  (t-SNE, UMAP) rely on spatial embedding and distance geometry.
\end{itemize}

\subsubsection{8. Applications Across
Fields}\label{applications-across-fields}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1875}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3438}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4688}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Field
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Geometric Core
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Graphics & Rendering, collision & Triangulation, ray tracing \\
GIS & Maps, roads & Polygons, point-in-region \\
Robotics & Path planning & Obstacles, configuration space \\
Architecture & Modeling & Mesh operations \\
Vision & Object boundaries & Contours, convexity \\
AI & Clustering, similarity & Distance metrics \\
Physics & Simulation & Particle collision \\
Databases & Spatial joins & R-Trees, indexing \\
\end{longtable}

Geometry underpins structure, position, and relationship, the backbone
of spatial reasoning.

\subsubsection{9. Complexity and Open
Problems}\label{complexity-and-open-problems}

Some problems still challenge efficient solutions:

\begin{itemize}
\tightlist
\item
  Point location in dynamic settings- Visibility graphs in complex
  polygons- Motion planning in high dimensions- Geometric median /
  center problems- Approximation guarantees in robust settings These
  remain active areas in computational geometry research.
\end{itemize}

\subsubsection{Tiny Code (Point-in-Polygon via Ray
Casting)}\label{tiny-code-point-in-polygon-via-ray-casting}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ inside}\OperatorTok{(}\NormalTok{Point p}\OperatorTok{,}\NormalTok{ Polygon poly}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ cnt }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ poly}\OperatorTok{.}\NormalTok{n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        Point a }\OperatorTok{=}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ b }\OperatorTok{=}\NormalTok{ poly}\OperatorTok{[(}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ poly}\OperatorTok{.}\NormalTok{n}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{intersect\_ray}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{))}\NormalTok{ cnt}\OperatorTok{++;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ cnt }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\OperatorTok{;} \CommentTok{// odd crossings = inside}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This small routine appears everywhere, maps, games, GUIs, and physics
engines.

\subsubsection{10. Why It Matters}\label{why-it-matters-79}

Computational geometry is more than shape, it's the mathematics of
space, powering visual computing, spatial data, and intelligent systems.
Everywhere something moves, collides, maps, or recognizes form, geometry
is the invisible hand guiding it.

\begin{quote}
``All computation lives somewhere, and geometry is how we understand the
where.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-79}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement point-in-polygon and test on convex vs concave shapes.
\item
  Visualize a Delaunay triangulation and its Voronoi dual.
\item
  Experiment with KD-trees for nearest neighbor queries.
\item
  Write a small convex hull in 3D using incremental insertion.
\item
  Sketch an RRT path over a geometric map.
\end{enumerate}

\section{Chapter 9. Systems, Databases, and Distributed
Algorithms}\label{chapter-9.-systems-databases-and-distributed-algorithms-1}

\subsection{81. Concurrency Control (2PL, MVCC,
OCC)}\label{concurrency-control-2pl-mvcc-occ}

In multi-user or multi-threaded systems, many operations want to read or
write shared data at the same time. Without discipline, this leads to
chaos, lost updates, dirty reads, or even inconsistent states.

Concurrency control ensures correctness under parallelism, so that the
result is as if each transaction ran alone (a property called
serializability).

This section introduces three foundational techniques:

\begin{itemize}
\tightlist
\item
  2PL - Two-Phase Locking- MVCC - Multi-Version Concurrency Control- OCC
  - Optimistic Concurrency Control
\end{itemize}

\subsubsection{1. The Goal:
Serializability}\label{the-goal-serializability}

We want transactions to behave as if executed in some serial order, even
though they're interleaved.

A schedule is \emph{serializable} if it yields the same result as some
serial order of transactions.

Concurrency control prevents problems like:

\begin{itemize}
\tightlist
\item
  Lost Update: Two writes overwrite each other.- Dirty Read: Read
  uncommitted data.- Non-repeatable Read: Data changes mid-transaction.-
  Phantom Read: New rows appear after a query.
\end{itemize}

\subsubsection{2. Two-Phase Locking (2PL)}\label{two-phase-locking-2pl}

Idea: Use locks to coordinate access. Each transaction has two phases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Growing phase: acquire locks (shared or exclusive)
\item
  Shrinking phase: release locks (no new locks allowed after release)
\end{enumerate}

This ensures conflict-serializability.

\subsubsection{Lock Types}\label{lock-types}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Type & Operation & Shared? & Exclusive? \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Shared (S) & Read & Yes & No \\
Exclusive (X) & Write & No & No \\
\end{longtable}

If a transaction needs to read: request S-lock. If it needs to write:
request X-lock.

Tiny Code (Lock Manager Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ acquire\_lock}\OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{T}\OperatorTok{,}\NormalTok{ Item }\OperatorTok{*}\NormalTok{X}\OperatorTok{,}\NormalTok{ LockType type}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{conflict\_exists}\OperatorTok{(}\NormalTok{X}\OperatorTok{,}\NormalTok{ type}\OperatorTok{))}
\NormalTok{        wait}\OperatorTok{();}
\NormalTok{    add\_lock}\OperatorTok{(}\NormalTok{X}\OperatorTok{,}\NormalTok{ T}\OperatorTok{,}\NormalTok{ type}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ release\_all}\OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{T}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Lock }\OperatorTok{*}\NormalTok{l in T}\OperatorTok{{-}\textgreater{}}\NormalTok{locks}\OperatorTok{)}
\NormalTok{        unlock}\OperatorTok{(}\NormalTok{l}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Example}\label{example-14}

\begin{verbatim}
T1: read(A); write(A)
T2: read(A); write(A)
\end{verbatim}

Without locks → race condition. With 2PL → one must wait → consistent.

\subsubsection{Variants}\label{variants-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2703}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7297}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strict 2PL & Holds all locks until commit → avoids cascading aborts \\
Rigorous 2PL & Same as Strict, all locks released at end \\
Conservative 2PL & Acquires all locks before execution \\
\end{longtable}

\subsubsection{Pros \& Cons}\label{pros-cons-4}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Guarantees serializability & Can cause deadlocks \\
Simple concept & Blocking, contention under load \\
\end{longtable}

\subsubsection{3. Multi-Version Concurrency Control
(MVCC)}\label{multi-version-concurrency-control-mvcc}

Idea: Readers don't block writers, and writers don't block readers. Each
write creates a new version of data with a timestamp.

Transactions read from a consistent snapshot based on their start time.

\subsubsection{Snapshot Isolation}\label{snapshot-isolation}

\begin{itemize}
\item
  Readers see the latest committed version at transaction start.-
  Writers produce new versions; conflicts detected at commit time. Each
  record stores:
\item
  \texttt{value}- \texttt{created\_at}- \texttt{deleted\_at} (if
  applicable)
\end{itemize}

Tiny Code (Version Chain)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Version }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ value}\OperatorTok{;}
\NormalTok{    Timestamp created}\OperatorTok{;}
\NormalTok{    Timestamp deleted}\OperatorTok{;}
\NormalTok{    Version }\OperatorTok{*}\NormalTok{next}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Read finds version with
\texttt{created\ \textless{}=\ tx.start\ \&\&\ deleted\ \textgreater{}\ tx.start}.

\subsubsection{Pros \& Cons}\label{pros-cons-5}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
No read locks & Higher memory (multiple versions) \\
Readers never block & Write conflicts at commit \\
Great for OLTP systems & GC of old versions needed \\
\end{longtable}

\subsubsection{Used In}\label{used-in}

\begin{itemize}
\tightlist
\item
  PostgreSQL- Oracle- MySQL (InnoDB)- Spanner
\end{itemize}

\subsubsection{4. Optimistic Concurrency Control
(OCC)}\label{optimistic-concurrency-control-occ}

Idea: Assume conflicts are rare. Let transactions run without locks. At
commit time, validate, if conflicts exist, rollback.

\subsubsection{Phases}\label{phases}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Read phase - execute, read data, buffer writes.
\item
  Validation phase - check if conflicts occurred.
\item
  Write phase - apply changes if valid, else abort.
\end{enumerate}

Tiny Code (OCC Validation)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ validate}\OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{T}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{U in committed\_since}\OperatorTok{(}\NormalTok{T}\OperatorTok{.}\NormalTok{start}\OperatorTok{))}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{conflict}\OperatorTok{(}\NormalTok{T}\OperatorTok{,}\NormalTok{ U}\OperatorTok{))}
            \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros \& Cons}\label{pros-cons-6}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
No locks → no deadlocks & High abort rate under contention \\
Great for low-conflict workloads & Wasted work on abort \\
\end{longtable}

\subsubsection{Used In}\label{used-in-1}

\begin{itemize}
\tightlist
\item
  In-memory DBs- Distributed systems- STM (Software Transactional
  Memory)
\end{itemize}

\subsubsection{5. Choosing a Strategy}\label{choosing-a-strategy}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
System Type & Preferred Control \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
OLTP (many reads/writes) & MVCC \\
OLAP (read-heavy) & MVCC or OCC \\
Real-time systems & 2PL (predictable) \\
Low contention & OCC \\
High contention & 2PL / MVCC \\
\end{longtable}

\subsubsection{6. Why It Matters}\label{why-it-matters-80}

Concurrency control is the backbone of consistency in databases,
distributed systems, and even multi-threaded programs. It enforces
correctness amid chaos, ensuring your data isn't silently corrupted.

\begin{quote}
``Without order, parallelism is noise. Concurrency control is its
conductor.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-80}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate 2PL with two transactions updating shared data.
\item
  Implement a toy MVCC table with version chains.
\item
  Write an OCC validator for three concurrent transactions.
\item
  Experiment: under high conflict, which model performs best?
\end{enumerate}

\subsection{82. Logging, Recovery, and Commit
Protocols}\label{logging-recovery-and-commit-protocols}

No matter how elegant your algorithms or how fast your storage, failures
happen. Power cuts, crashes, and network splits are inevitable. What
matters is recovery, restoring the system to a consistent state without
losing committed work.

Logging, recovery, and commit protocols form the backbone of reliable
transactional systems, ensuring durability and correctness in the face
of crashes.

\subsubsection{1. The Problem}\label{the-problem-2}

We need to guarantee the ACID properties:

\begin{itemize}
\tightlist
\item
  Atomicity - all or nothing- Consistency - valid before and after-
  Isolation - no interference- Durability - once committed, always safe
  If a crash occurs mid-transaction, how do we roll back or redo
  correctly?
\end{itemize}

The answer: Log everything, then replay or undo after failure.

\subsubsection{2. Write-Ahead Logging
(WAL)}\label{write-ahead-logging-wal}

The golden rule:

\begin{quote}
``Write log entries before modifying the database.''
\end{quote}

Every action is recorded in a sequential log on disk, ensuring the
system can reconstruct the state.

\subsubsection{Log Record Format}\label{log-record-format}

Each log entry typically includes:

\begin{itemize}
\tightlist
\item
  \texttt{LSN} (Log Sequence Number)- \texttt{Transaction\ ID}-
  \texttt{Operation} (update, insert, delete)- \texttt{Before\ image}
  (old value)- \texttt{After\ image} (new value)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ LogEntry }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ lsn}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ tx\_id}\OperatorTok{;}
    \DataTypeTok{char}\NormalTok{ op}\OperatorTok{[}\DecValTok{10}\OperatorTok{];}
\NormalTok{    Value before}\OperatorTok{,}\NormalTok{ after}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

When a transaction commits, the system first flushes logs to disk
(\texttt{fsync}). Only then is the commit acknowledged.

\subsubsection{3. Recovery Actions}\label{recovery-actions}

When the system restarts, it reads logs and applies a recovery
algorithm.

\subsubsection{Three Phases (ARIES
Model)}\label{three-phases-aries-model}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Analysis - determine state at crash (active vs committed)
\item
  Redo - repeat all actions from last checkpoint
\item
  Undo - rollback incomplete transactions
\end{enumerate}

ARIES (Algorithm for Recovery and Isolation Exploiting Semantics) is the
most widely used approach (IBM DB2, PostgreSQL, SQL Server).

\subsubsection{Redo Rule}\label{redo-rule}

If the system committed before crash → redo all updates so data is
preserved.

\subsubsection{Undo Rule}\label{undo-rule}

If the system didn't commit → undo to maintain atomicity.

Tiny Code (Simplified Recovery Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ recover}\OperatorTok{(}\NormalTok{Log log}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Entry e }\OperatorTok{:}\NormalTok{ log}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{committed}\OperatorTok{)}
\NormalTok{            apply}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{after}\OperatorTok{);}
        \ControlFlowTok{else}
\NormalTok{            apply}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{before}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Checkpointing}\label{checkpointing}

Instead of replaying the entire log, systems take checkpoints, periodic
snapshots marking a safe state.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2985}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7015}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sharp checkpoint & Stop all transactions briefly, flush data + log \\
Fuzzy checkpoint & Mark consistent LSN; continue running \\
\end{longtable}

Checkpoints reduce recovery time: only replay after the last checkpoint.

\subsubsection{5. Commit Protocols}\label{commit-protocols}

In distributed systems, multiple nodes must agree to commit or abort
together. This is handled by atomic commit protocols.

\subsubsection{Two-Phase Commit (2PC)}\label{two-phase-commit-2pc}

Goal: All participants either commit or abort in unison.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Prepare phase (voting):

  \begin{itemize}
  \item
    Coordinator asks all participants to ``prepare'' - Each replies
    yes/no2. Commit phase (decision):
  \item
    If all say yes → commit - Else → abort
  \end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Coordinator: PREPARE  }
\NormalTok{Participants: VOTE YES / NO  }
\NormalTok{Coordinator: COMMIT / ABORT}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

If the coordinator crashes after prepare, participants must wait →
blocking protocol.

Tiny Code (2PC Pseudocode)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ two\_phase\_commit}\OperatorTok{(}\NormalTok{Participants P}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for}\NormalTok{ each p in P}\OperatorTok{:}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{p}\OperatorTok{.}\NormalTok{prepare}\OperatorTok{())} \ControlFlowTok{return}\NormalTok{ abort\_all}\OperatorTok{();}
    \ControlFlowTok{for}\NormalTok{ each p in P}\OperatorTok{:}
\NormalTok{        p}\OperatorTok{.}\NormalTok{commit}\OperatorTok{();}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Three-Phase Commit (3PC)}\label{three-phase-commit-3pc}

Improves on 2PC by adding an intermediate phase to avoid indefinite
blocking. More complex, used in systems with reliable failure detection.

\subsubsection{6. Logging in Distributed
Systems}\label{logging-in-distributed-systems}

Each participant maintains its own WAL. To recover globally:

\begin{itemize}
\tightlist
\item
  Use coordinated checkpoints- Maintain global commit logs-
  Consensus-based protocols (Paxos Commit, Raft) can replace 2PC for
  high availability
\end{itemize}

\subsubsection{7. Example Timeline}\label{example-timeline}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Action \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
T1 updates record A & WAL entry written \\
T1 updates record B & WAL entry written \\
T1 commits & WAL flush, commit record \\
Crash! & Disk may be inconsistent \\
Restart & Recovery scans log, redoes T1 \\
\end{longtable}

\subsubsection{8. Pros and Cons}\label{pros-and-cons}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Approach & Strength & Weakness \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
WAL & Simple, durable & Write overhead \\
Checkpointing & Faster recovery & I/O spikes \\
2PC & Global atomicity & Blocking \\
3PC / Consensus & Non-blocking & Complex, slower \\
\end{longtable}

\subsubsection{9. Real Systems}\label{real-systems}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
System & Strategy \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
PostgreSQL & WAL + ARIES + Checkpoint \\
MySQL (InnoDB) & WAL + Fuzzy checkpoint \\
Spanner & WAL + 2PC + TrueTime \\
Kafka & WAL for durability \\
RocksDB & WAL + LSM checkpoints \\
\end{longtable}

\subsubsection{10. Why It Matters}\label{why-it-matters-81}

Logging and commit protocols make data survive crashes and stay
consistent across machines. Without them, every failure risks
corruption.

\begin{quote}
``Persistence is not about never failing, it's about remembering how to
stand back up.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-81}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a toy WAL system that logs before writes.
\item
  Simulate a crash mid-transaction and replay the log.
\item
  Implement a simple 2PC coordinator with two participants.
\item
  Compare recovery time with vs without checkpoints.
\end{enumerate}

\subsection{83. Scheduling (Round Robin, EDF,
Rate-Monotonic)}\label{scheduling-round-robin-edf-rate-monotonic}

In operating systems and real-time systems, scheduling determines the
order in which tasks or processes run. Since resources like CPU time are
limited, a good scheduler aims to balance fairness, efficiency, and
responsiveness.

\subsubsection{1. The Goal of Scheduling}\label{the-goal-of-scheduling}

Every system has tasks competing for the CPU. Scheduling decides:

\begin{itemize}
\tightlist
\item
  Which task runs next- How long it runs- When it yields or preempts
  Different goals apply in different domains:
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Objective \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
General-purpose OS & Fairness, responsiveness \\
Real-time systems & Meeting deadlines \\
Embedded systems & Predictability \\
High-performance servers & Throughput, latency balance \\
\end{longtable}

A scheduler's policy can be preemptive (interrupts tasks) or
non-preemptive (waits for voluntary yield).

\subsubsection{2. Round Robin Scheduling}\label{round-robin-scheduling}

Round Robin (RR) is one of the simplest preemptive schedulers. Each
process gets a fixed time slice (quantum) and runs in a circular queue.

If a process doesn't finish, it's put back at the end of the queue.

\subsubsection{Tiny Code: Round Robin
(Pseudocode)}\label{tiny-code-round-robin-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{queue processes}\OperatorTok{;}
\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{empty}\OperatorTok{(}\NormalTok{processes}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{    process }\OperatorTok{=}\NormalTok{ dequeue}\OperatorTok{(}\NormalTok{processes}\OperatorTok{);}
\NormalTok{    run\_for\_quantum}\OperatorTok{(}\NormalTok{process}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{process}\OperatorTok{.}\NormalTok{finished}\OperatorTok{)}
\NormalTok{        enqueue}\OperatorTok{(}\NormalTok{processes}\OperatorTok{,}\NormalTok{ process}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Characteristics}\label{characteristics}

\begin{itemize}
\tightlist
\item
  Fair: Every process gets CPU time.- Responsive: Short tasks don't
  starve.- Downside: Context switching overhead if quantum is too small.
  \#\#\#\# Example
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Process & Burst Time & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
P1 & 4 & \\
P2 & 3 & \\
P3 & 2 & \\
\end{longtable}

Quantum = 1 Order: P1, P2, P3, P1, P2, P3, P1, P2 → all finish fairly.

\subsubsection{3. Priority Scheduling}\label{priority-scheduling}

Each task has a priority. The scheduler always picks the
highest-priority ready task.

\begin{itemize}
\item
  Preemptive: A higher-priority task can interrupt a lower one.-
  Non-preemptive: The CPU is released voluntarily. \#\#\#\# Problems
\item
  Starvation: Low-priority tasks may never run.- Solution: Aging -
  gradually increase waiting task priority.
\end{itemize}

\subsubsection{4. Earliest Deadline First
(EDF)}\label{earliest-deadline-first-edf}

EDF is a dynamic priority scheduler for real-time systems. Each task has
a deadline, and the task with the earliest deadline runs first.

\subsubsection{Rule}\label{rule}

At any time, run the ready task with the closest deadline.

\subsubsection{Example}\label{example-15}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Task & Execution Time & Deadline \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
T1 & 1 & 3 \\
T2 & 2 & 5 \\
T3 & 1 & 2 \\
\end{longtable}

Order: T3 → T1 → T2

EDF is optimal for preemptive scheduling of independent tasks on a
single processor.

\subsubsection{5. Rate-Monotonic Scheduling
(RMS)}\label{rate-monotonic-scheduling-rms}

In periodic real-time systems, tasks repeat at fixed intervals. RMS
assigns higher priority to tasks with shorter periods.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Task & Period & Priority \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
T1 & 2 ms & High \\
T2 & 5 ms & Medium \\
T3 & 10 ms & Low \\
\end{longtable}

It's static (priorities don't change) and optimal among fixed-priority
schedulers.

\subsubsection{Utilization Bound}\label{utilization-bound}

For n tasks, RMS is guaranteed schedulable if:

\[
U = \sum_{i=1}^{n} \frac{C_i}{T_i} \le n(2^{1/n} - 1)
\]

For example, for 3 tasks, \(U \le 0.78\).

\subsubsection{6. Shortest Job First
(SJF)}\label{shortest-job-first-sjf}

Run the task with the shortest burst time first.

\begin{itemize}
\tightlist
\item
  Non-preemptive SJF: Once started, runs to completion.- Preemptive SJF
  (Shortest Remaining Time First): Preempts if a shorter job arrives.
  Advantage: Minimizes average waiting time. Disadvantage: Needs
  knowledge of future job lengths.
\end{itemize}

\subsubsection{7. Multilevel Queue
Scheduling}\label{multilevel-queue-scheduling}

Divide processes into classes (interactive, batch, system). Each class
has its own queue with own policy, e.g.:

\begin{itemize}
\tightlist
\item
  Queue 1: System → RR (quantum = 10ms)- Queue 2: Interactive → RR
  (quantum = 50ms)- Queue 3: Batch → FCFS (First-Come-First-Serve) CPU
  is assigned based on queue priority.
\end{itemize}

\subsubsection{8. Multilevel Feedback Queue
(MLFQ)}\label{multilevel-feedback-queue-mlfq}

Processes move between queues based on behavior.

\begin{itemize}
\tightlist
\item
  CPU-bound → move down (lower priority)- I/O-bound → move up (higher
  priority) Goal: Adaptive scheduling that rewards interactive tasks.
\end{itemize}

Used in modern OS kernels (Linux, Windows).

\subsubsection{9. Scheduling Metrics}\label{scheduling-metrics}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Metric & Meaning \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Turnaround Time & Completion − Arrival \\
Waiting Time & Time spent in ready queue \\
Response Time & Time from arrival to first execution \\
Throughput & Completed tasks per unit time \\
CPU Utilization & \% of time CPU is busy \\
\end{longtable}

Schedulers balance these based on design goals.

\subsubsection{10. Why It Matters}\label{why-it-matters-82}

Schedulers shape how responsive, efficient, and fair a system feels. In
operating systems, they govern multitasking. In real-time systems, they
ensure deadlines are met. In servers, they keep latency low and
throughput high.

\begin{quote}
``Scheduling is not just about time. It's about fairness, foresight, and
flow.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-82}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate Round Robin with quantum = 2, compare average waiting time.
\item
  Implement EDF for a set of periodic tasks with deadlines.
\item
  Check schedulability under RMS for 3 periodic tasks.
\item
  Explore Linux CFS (Completely Fair Scheduler) source code.
\item
  Compare SJF and RR for CPU-bound vs I/O-bound workloads.
\end{enumerate}

\subsection{84. Caching and Replacement (LRU, LFU,
CLOCK)}\label{caching-and-replacement-lru-lfu-clock}

Caching is the art of remembering the past to speed up the future. In
computing, caches store recently used or frequently accessed data to
reduce latency and load on slower storage (like disks or networks). The
challenge: caches have limited capacity, so when full, we must decide
what to evict. That's where replacement policies come in.

\subsubsection{1. The Need for Caching}\label{the-need-for-caching}

Caches appear everywhere:

\begin{itemize}
\item
  CPU: L1, L2, L3 caches speed up memory access- Databases: query
  results or index pages- Web browsers / CDNs: recently fetched pages-
  Operating systems: page cache for disk blocks The principle guiding
  all caches is locality:
\item
  Temporal locality: recently used items are likely used again soon-
  Spatial locality: nearby items are likely needed next
\end{itemize}

\subsubsection{2. Cache Replacement
Problem}\label{cache-replacement-problem}

When the cache is full, which item should we remove?

We want to minimize cache misses (requests not found in cache).

Formally:

\begin{quote}
Given a sequence of accesses, find a replacement policy that minimizes
misses.
\end{quote}

Theoretical optimal policy (OPT): always evict the item used farthest in
the future. But OPT requires future knowledge, so we rely on heuristics
like LRU, LFU, CLOCK.

\subsubsection{3. Least Recently Used
(LRU)}\label{least-recently-used-lru}

LRU evicts the least recently accessed item. It assumes recently used =
likely to be used again.

\subsubsection{Implementation
Approaches}\label{implementation-approaches}

\begin{itemize}
\tightlist
\item
  Stack (list): move item to top on access- Hash map + doubly linked
  list: \texttt{O(1)} insert, delete, lookup \#\#\#\# Tiny Code: LRU
  (Simplified)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{prev}\OperatorTok{,} \OperatorTok{*}\NormalTok{next}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{HashMap cache}\OperatorTok{;}
\NormalTok{List lru\_list}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ access}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{in\_cache}\OperatorTok{(}\NormalTok{key}\OperatorTok{))}\NormalTok{ move\_to\_front}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{else} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cache\_full}\OperatorTok{())}\NormalTok{ remove\_lru}\OperatorTok{();}
\NormalTok{        insert\_front}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros}\label{pros}

\begin{itemize}
\item
  Good for workloads with strong temporal locality \#\#\#\# Cons
\item
  Costly in hardware or massive caches (metadata overhead)
\end{itemize}

\subsubsection{4. Least Frequently Used
(LFU)}\label{least-frequently-used-lfu}

LFU evicts the least frequently accessed item.

Tracks usage count for each item:

\begin{itemize}
\tightlist
\item
  Increment on each access- Evict lowest-count item \#\#\#\# Example
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Item & Accesses & Frequency \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 3 & 3 \\
B & 1 & 1 \\
C & 2 & 2 \\
\end{longtable}

Evict B.

\subsubsection{Variants}\label{variants-5}

\begin{itemize}
\item
  LFU with aging: gradually reduce counts to adapt to new trends-
  Approximate LFU: counters in ranges (for memory efficiency) \#\#\#\#
  Pros
\item
  Great for stable, repetitive workloads \#\#\#\# Cons
\item
  Poor for workloads with shifting popularity (slow adaptation)
\end{itemize}

\subsubsection{5. FIFO (First In First
Out)}\label{fifo-first-in-first-out}

Simple but naive:

\begin{itemize}
\tightlist
\item
  Evict the oldest item, ignoring usage Used in simple hardware caches.
  Good when access pattern is cyclic, bad otherwise.
\end{itemize}

\subsubsection{6. Random Replacement (RR)}\label{random-replacement-rr}

Evict a random entry.

Surprisingly competitive in some high-concurrency systems, and trivial
to implement. Used in memcached (as an option).

\subsubsection{7. CLOCK Algorithm}\label{clock-algorithm}

A practical approximation of LRU, widely used in OS page replacement.

Each page has a reference bit (R). Pages form a circular list.

Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clock hand sweeps over pages.
\item
  If \texttt{R\ =\ 0}, evict page.
\item
  If \texttt{R\ =\ 1}, set \texttt{R\ =\ 0} and skip.
\end{enumerate}

This mimics LRU with O(1) cost and low overhead.

\subsubsection{8. Second-Chance and Enhanced
CLOCK}\label{second-chance-and-enhanced-clock}

Second-Chance: give recently used pages a ``second chance'' before
eviction. Enhanced CLOCK: also uses modify bit (M) to prefer clean
pages.

Used in Linux's page replacement (with Active/Inactive lists).

\subsubsection{9. Adaptive Algorithms}\label{adaptive-algorithms}

Modern systems use hybrid or adaptive policies:

\begin{itemize}
\tightlist
\item
  ARC (Adaptive Replacement Cache) - balances recency and frequency- CAR
  (Clock with Adaptive Replacement) - CLOCK-style adaptation- TinyLFU -
  frequency sketch + admission policy- Hyperbolic caching - popularity
  decay for large-scale systems These adapt dynamically to changing
  workloads.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-83}

Caching is the backbone of system speed:

\begin{itemize}
\tightlist
\item
  OS uses it for paging- Databases for buffer pools- CPUs for memory
  hierarchies- CDNs for global acceleration Choosing the right eviction
  policy can mean orders of magnitude improvement in latency and
  throughput.
\end{itemize}

\begin{quote}
``A good cache remembers what matters, and forgets what no longer
does.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-83}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate a cache of size 3 with sequence: A B C A B D A B C D Compare
  LRU, LFU, and FIFO miss counts.
\item
  Implement LRU with a doubly-linked list and hash map in C.
\item
  Try CLOCK with reference bits, simulate a sweep.
\item
  Experiment with ARC and TinyLFU for dynamic workloads.
\item
  Measure hit ratios for different access patterns (sequential, random,
  looping).
\end{enumerate}

\subsection{85. Networking (Routing, Congestion
Control)}\label{networking-routing-congestion-control}

Networking algorithms make sure data finds its way through vast,
connected systems, efficiently, reliably, and fairly. Two core pillars
of network algorithms are routing (deciding \emph{where} packets go) and
congestion control (deciding \emph{how fast} to send them).

Together, they ensure the internet functions under heavy load, dynamic
topology, and unpredictable demand.

\subsubsection{1. The Goals of Networking
Algorithms}\label{the-goals-of-networking-algorithms}

\begin{itemize}
\tightlist
\item
  Correctness: all destinations are reachable if paths exist-
  Efficiency: use minimal resources (bandwidth, latency, hops)-
  Scalability: support large, dynamic networks- Robustness: recover from
  failures- Fairness: avoid starving flows
\end{itemize}

\subsubsection{2. Types of Routing}\label{types-of-routing}

Routing decides paths packets should follow through a graph-like
network.

\subsubsection{Static vs Dynamic
Routing}\label{static-vs-dynamic-routing}

\begin{itemize}
\item
  Static: fixed routes, manual configuration (good for small networks)-
  Dynamic: routes adjust automatically as topology changes
  (internet-scale) \#\#\#\# Unicast, Multicast, Broadcast
\item
  Unicast: one-to-one (most traffic)- Multicast: one-to-many (video
  streaming, gaming)- Broadcast: one-to-all (local networks)
\end{itemize}

\subsubsection{3. Shortest Path Routing}\label{shortest-path-routing}

Most routing relies on shortest path algorithms:

\subsubsection{Dijkstra's Algorithm}\label{dijkstras-algorithm-1}

\begin{itemize}
\item
  Builds shortest paths from one source- Complexity:
  \texttt{O(E\ log\ V)} with priority queue Used in:
\item
  OSPF (Open Shortest Path First)- IS-IS (Intermediate System to
  Intermediate System) \#\#\#\# Bellman-Ford Algorithm
\item
  Handles negative edges- Basis for Distance-Vector routing (RIP)
  \#\#\#\# Tiny Code: Dijkstra for Routing
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define INF }\FloatTok{1e9}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ visited}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ dijkstra}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dist}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\DecValTok{0}\OperatorTok{,}\NormalTok{ s}\OperatorTok{\});}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{().}\NormalTok{second}\OperatorTok{;}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
\NormalTok{                pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{{-}}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ v}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Distance-Vector vs
Link-State}\label{distance-vector-vs-link-state}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Distance-Vector (RIP) & Link-State (OSPF) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Info Shared & Distance to neighbors & Full topology map \\
Convergence & Slower (loops possible) & Fast (SPF computation) \\
Complexity & Lower & Higher \\
Examples & RIP, BGP (conceptually) & OSPF, IS-IS \\
\end{longtable}

RIP uses Bellman-Ford. OSPF floods link-state updates, runs Dijkstra at
each node.

\subsubsection{5. Hierarchical Routing}\label{hierarchical-routing}

Large-scale networks (like the Internet) use hierarchical routing:

\begin{itemize}
\tightlist
\item
  Routers grouped into Autonomous Systems (AS)- Intra-AS routing: OSPF,
  IS-IS- Inter-AS routing: BGP (Border Gateway Protocol) BGP exchanges
  reachability info, not shortest paths, and prefers policy-based
  routing (e.g., cost, contracts, peering).
\end{itemize}

\subsubsection{6. Congestion Control}\label{congestion-control}

Even with good routes, we can't flood links. Congestion control ensures
fair and efficient use of bandwidth.

Implemented primarily at the transport layer (TCP).

\subsubsection{TCP Congestion Control}\label{tcp-congestion-control}

Key components:

\begin{itemize}
\item
  Additive Increase, Multiplicative Decrease (AIMD)- Slow Start: probe
  capacity- Congestion Avoidance: grow cautiously- Fast Retransmit /
  Recovery Modern variants:
\item
  TCP Reno: classic AIMD- TCP Cubic: non-linear growth for high-speed
  networks- BBR (Bottleneck Bandwidth + RTT): model-based control
  \#\#\#\# Algorithm Sketch (AIMD)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{On ACK: cwnd += 1/cwnd  // increase slowly}
\NormalTok{On loss: cwnd /= 2      // halve window}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Queue Management}\label{queue-management}

Routers maintain queues. Too full? =\textgreater{} Packet loss, latency
spikes, tail drop.

Solutions:

\begin{itemize}
\tightlist
\item
  RED (Random Early Detection) - drop packets early- CoDel (Controlled
  Delay) - monitor queue delay, drop adaptively These prevent
  bufferbloat, improving latency for real-time traffic.
\end{itemize}

\subsubsection{8. Flow Control vs Congestion
Control}\label{flow-control-vs-congestion-control}

\begin{itemize}
\tightlist
\item
  Flow Control: prevent sender from overwhelming receiver- Congestion
  Control: prevent sender from overwhelming network TCP uses both:
  receive window (rwnd) and congestion window (cwnd). Actual sending
  rate = \texttt{min(rwnd,\ cwnd)}.
\end{itemize}

\subsubsection{9. Data Plane vs Control
Plane}\label{data-plane-vs-control-plane}

\begin{itemize}
\item
  Control Plane: decides routes (OSPF, BGP)- Data Plane: forwards
  packets (fast path) Modern networking (e.g.~SDN, Software Defined
  Networking) separates these:
\item
  Controller computes routes- Switches act on flow rules
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-84}

Routing and congestion control shape the performance of:

\begin{itemize}
\tightlist
\item
  The Internet backbone- Data center networks (with load balancing)-
  Cloud services and microservice meshes- Content delivery networks
  (CDNs) Every packet's journey, from your laptop to a global data
  center, relies on these ideas.
\end{itemize}

\begin{quote}
``Networking is not magic. It's algorithms moving data through time and
space.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-84}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Dijkstra's algorithm for a small network graph.
\item
  Simulate RIP (Distance Vector): each node updates from neighbors.
\item
  Model TCP AIMD window growth; visualize with Python.
\item
  Try RED: drop packets when queue length \textgreater{} threshold.
\item
  Compare TCP Reno, Cubic, BBR throughput in simulation.
\end{enumerate}

\subsection{86. Distributed Consensus (Paxos, Raft,
PBFT)}\label{distributed-consensus-paxos-raft-pbft}

In a distributed system, multiple nodes must agree on a single value,
for example, the state of a log, a database entry, or a blockchain
block. This agreement process is called consensus.

Consensus algorithms let distributed systems act as one reliable system,
even when some nodes fail, crash, or lie (Byzantine faults).

\subsubsection{1. Why Consensus?}\label{why-consensus}

Imagine a cluster managing a shared log (like in databases or Raft).
Each node might:

\begin{itemize}
\tightlist
\item
  See different requests,- Fail and recover,- Communicate over
  unreliable links. We need all non-faulty nodes to agree on the same
  order of operations.
\end{itemize}

A valid consensus algorithm must satisfy:

\begin{itemize}
\tightlist
\item
  Agreement: all correct nodes choose the same value- Validity: the
  chosen value was proposed by a node- Termination: every correct node
  eventually decides- Fault Tolerance: works despite failures
\end{itemize}

\subsubsection{2. The FLP Impossibility}\label{the-flp-impossibility}

The FLP theorem (Fischer, Lynch, Paterson, 1985) says:

\begin{quote}
In an asynchronous system with even one faulty process, no deterministic
algorithm can guarantee consensus.
\end{quote}

So practical algorithms use:

\begin{itemize}
\tightlist
\item
  Randomization, or- Partial synchrony (timeouts, retries)
\end{itemize}

\subsubsection{3. Paxos: The Classical
Algorithm}\label{paxos-the-classical-algorithm}

Paxos, by Leslie Lamport, is the theoretical foundation for distributed
consensus.

It revolves around three roles:

\begin{itemize}
\tightlist
\item
  Proposers: suggest values- Acceptors: vote on proposals- Learners:
  learn the final decision Consensus proceeds in two phases.
\end{itemize}

\subsubsection{Phase 1 (Prepare)}\label{phase-1-prepare}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Proposer picks a proposal number \texttt{n} and sends
  \texttt{(Prepare,\ n)} to acceptors.
\item
  Acceptors respond with their highest accepted proposal (if any).
\end{enumerate}

\subsubsection{Phase 2 (Accept)}\label{phase-2-accept}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If proposer receives a majority of responses, it sends
  \texttt{(Accept,\ n,\ v)} with value \texttt{v} (highest seen or new).
\item
  Acceptors accept if they haven't promised higher \texttt{n}.
\end{enumerate}

When a majority accept, value \texttt{v} is chosen.

\subsubsection{Guarantees}\label{guarantees}

\begin{itemize}
\item
  Safety: no two different values chosen- Liveness: possible under
  stable leadership \#\#\#\# Drawbacks
\item
  Complex to implement correctly- High messaging overhead \textgreater{}
  ``Paxos is for theorists; Raft is for engineers.''
\end{itemize}

\subsubsection{4. Raft: Understandable
Consensus}\label{raft-understandable-consensus}

Raft was designed to be simpler and more practical than Paxos, focusing
on replicated logs.

\subsubsection{Roles}\label{roles}

\begin{itemize}
\tightlist
\item
  Leader: coordinates all changes- Followers: replicate leader's log-
  Candidates: during elections \#\#\#\# Workflow
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Leader Election

  \begin{itemize}
  \item
    Timeout triggers candidate election. - Each follower votes; majority
    wins.2. Log Replication
  \item
    Leader appends entries, sends \texttt{AppendEntries} RPCs. -
    Followers acknowledge; leader commits when majority ack.3. Safety
  \item
    Logs are consistent across majority. - Followers accept only valid
    prefixes. Raft ensures:
  \end{itemize}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  At most one leader per term- Committed entries never lost- Logs stay
  consistent \#\#\#\# Pseudocode Sketch
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{on timeout }\OperatorTok{{-}\textgreater{}}\NormalTok{ become\_candidate}\OperatorTok{()}
\NormalTok{send RequestVote}\OperatorTok{(}\NormalTok{term}\OperatorTok{,}\NormalTok{ id}\OperatorTok{)}
\ControlFlowTok{if}\NormalTok{ majority\_votes }\OperatorTok{{-}\textgreater{}}\NormalTok{ become\_leader}\OperatorTok{()}

\NormalTok{on AppendEntries}\OperatorTok{(}\NormalTok{term}\OperatorTok{,}\NormalTok{ entries}\OperatorTok{):}
    \ControlFlowTok{if}\NormalTok{ term }\OperatorTok{\textgreater{}=}\NormalTok{ current\_term}\OperatorTok{:}
\NormalTok{        append}\OperatorTok{(}\NormalTok{entries}\OperatorTok{)}
\NormalTok{        reply success}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. PBFT: Byzantine Fault
Tolerance}\label{pbft-byzantine-fault-tolerance}

Paxos and Raft assume crash faults (nodes stop, not lie). For Byzantine
faults (arbitrary behavior), we use PBFT (Practical Byzantine Fault
Tolerance).

Tolerates up to \texttt{f} faulty nodes out of \texttt{3f\ +\ 1} total.

\subsubsection{Phases}\label{phases-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pre-Prepare: Leader proposes value
\item
  Prepare: Nodes broadcast proposal hashes
\item
  Commit: Nodes confirm receipt by 2f+1 votes
\end{enumerate}

Used in blockchains and critical systems (space, finance).

\subsubsection{6. Quorum Concept}\label{quorum-concept}

Consensus often relies on quorums (majorities):

\begin{itemize}
\item
  Two quorums always intersect, ensuring consistency.- Write quorum +
  read quorum ≥ total nodes. In Raft/Paxos:
\item
  Majority = \texttt{N/2\ +\ 1}- Guarantees overlap even if some nodes
  fail.
\end{itemize}

\subsubsection{7. Log Replication and State
Machines}\label{log-replication-and-state-machines}

Consensus underlies Replicated State Machines (RSM):

\begin{itemize}
\item
  Every node applies the same commands in the same order.- Guarantees
  deterministic, identical states. This model powers:
\item
  Databases (etcd, Spanner, TiKV)- Coordination systems (ZooKeeper,
  Consul)- Kubernetes control planes
\end{itemize}

\subsubsection{8. Leader Election}\label{leader-election}

All practical consensus systems need leaders:

\begin{itemize}
\item
  Simplifies coordination- Reduces conflicts- Heartbeats detect
  failures- New elections restore progress Algorithms:
\item
  Raft Election (random timeouts)- Bully Algorithm- Chang-Roberts Ring
  Election
\end{itemize}

\subsubsection{9. Performance and
Optimization}\label{performance-and-optimization}

\begin{itemize}
\item
  Batching: amortize RPC overhead- Pipeline: parallelize appends-
  Read-only optimizations: serve from followers (stale reads)- Witness
  nodes: participate in quorum without full data Advanced:
\item
  Multi-Paxos: reuse leader, fewer rounds- Fast Paxos: shortcut some
  phases- Viewstamped Replication: Paxos-like log replication
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-85}

Consensus is the backbone of reliability in modern distributed systems.
Every consistent database, service registry, or blockchain depends on
it.

Systems using consensus:

\begin{itemize}
\tightlist
\item
  etcd, Consul, ZooKeeper - cluster coordination- Raft in Kubernetes -
  leader election- PBFT in blockchains - fault-tolerant ledgers-
  Spanner, TiDB - consistent databases \textgreater{} ``Consensus is how
  machines learn to agree, and trust.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-85}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Raft leader election in C or Python.
\item
  Simulate Paxos on 5 nodes with message drops.
\item
  Explore PBFT: try failing nodes and Byzantine behavior.
\item
  Compare performance of Raft vs Paxos under load.
\item
  Build a replicated key-value store with Raft.
\end{enumerate}

\subsection{87. Load Balancing and Rate
Limiting}\label{load-balancing-and-rate-limiting}

When systems scale, no single server can handle all requests alone. Load
balancing distributes incoming traffic across multiple servers to
improve throughput, reduce latency, and prevent overload. Meanwhile,
rate limiting protects systems by controlling how often requests are
allowed, ensuring fairness, stability, and security.

These two ideas, spreading the load and controlling the flow, are
cornerstones of modern distributed systems and APIs.

\subsubsection{1. Why Load Balancing
Matters}\label{why-load-balancing-matters}

Imagine a web service receiving thousands of requests per second. If
every request went to one machine, it would crash. A load balancer (LB)
acts as a traffic director, spreading requests across many backends.

Goals:

\begin{itemize}
\tightlist
\item
  Efficiency - fully utilize servers- Reliability - no single point of
  failure- Scalability - handle growing workloads- Flexibility -
  add/remove servers dynamically
\end{itemize}

\subsubsection{2. Types of Load
Balancers}\label{types-of-load-balancers}

\subsubsection{1. Layer 4 (Transport
Layer)}\label{layer-4-transport-layer}

Balances based on IP and port. Fast and protocol-agnostic (works for
TCP/UDP).

Example: Linux IPVS, Envoy, HAProxy

\subsubsection{2. Layer 7 (Application
Layer)}\label{layer-7-application-layer}

Understands protocols like HTTP. Can route by URL path, headers,
cookies.

Example: Nginx, Envoy, AWS ALB

\subsubsection{3. Load Balancing
Algorithms}\label{load-balancing-algorithms}

\subsubsection{Round Robin}\label{round-robin}

Cycles through backends in order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Req1 → ServerA  }
\NormalTok{Req2 → ServerB  }
\NormalTok{Req3 → ServerC}
\end{Highlighting}
\end{Shaded}

Simple, fair (if all nodes equal).

\subsubsection{Weighted Round Robin}\label{weighted-round-robin}

Assigns weights to reflect capacity. Example: ServerA(2x), ServerB(1x)

\subsubsection{Least Connections}\label{least-connections}

Send request to server with fewest active connections.

\subsubsection{Least Response Time}\label{least-response-time}

Select backend with lowest latency (monitored dynamically).

\subsubsection{Hash-Based (Consistent
Hashing)}\label{hash-based-consistent-hashing}

Deterministically route based on request key (like user ID).

\begin{itemize}
\tightlist
\item
  Keeps cache locality- Used in CDNs, distributed caches
  (e.g.~memcached) \#\#\#\# Random
\end{itemize}

Pick a random backend, surprisingly effective under uniform load.

\subsubsection{4. Consistent Hashing (In
Depth)}\label{consistent-hashing-in-depth}

Used for sharding and sticky sessions.

Key idea:

\begin{itemize}
\tightlist
\item
  Map servers to a hash ring- A request's key is hashed onto the ring-
  Assigned to next clockwise server When servers join/leave, only small
  fraction of keys move.
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  CDNs- Distributed caches (Redis Cluster, DynamoDB)- Load-aware systems
\end{itemize}

\subsubsection{5. Health Checks and
Failover}\label{health-checks-and-failover}

A smart LB monitors health of each server:

\begin{itemize}
\tightlist
\item
  Heartbeat pings (HTTP/TCP)- Auto-remove unhealthy servers- Rebalance
  traffic instantly Example: If ServerB fails, remove from rotation:
\end{itemize}

\begin{verbatim}
Healthy: [ServerA, ServerC]
\end{verbatim}

Also supports active-passive failover: hot standby servers take over
when active fails.

\subsubsection{6. Global Load Balancing}\label{global-load-balancing}

Across regions or data centers:

\begin{itemize}
\tightlist
\item
  GeoDNS: route to nearest region- Anycast: advertise same IP globally;
  routing picks nearest- Latency-based routing: measure and pick lowest
  RTT Used by CDNs, cloud services, multi-region apps
\end{itemize}

\subsubsection{7. Rate Limiting: The Other
Side}\label{rate-limiting-the-other-side}

If load balancing spreads the work, rate limiting keeps total work
reasonable.

It prevents:

\begin{itemize}
\item
  Abuse (bots, DDoS)- Overload (too many requests)- Fairness issues (no
  user dominates resources) Policies:
\item
  Per-user, per-IP, per-API-key- Global or per-endpoint
\end{itemize}

\subsubsection{8. Rate Limiting
Algorithms}\label{rate-limiting-algorithms}

\subsubsection{Token Bucket}\label{token-bucket}

\begin{itemize}
\tightlist
\item
  Bucket holds tokens (capacity = burst limit)- Each request consumes 1
  token- Tokens refill at constant rate (rate limit)- If empty → reject
  or delay Good for bursty traffic.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{tokens }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    tokens}\OperatorTok{{-}{-};}
\NormalTok{    allow}\OperatorTok{();}
\OperatorTok{\}} \ControlFlowTok{else}\NormalTok{ reject}\OperatorTok{();}
\end{Highlighting}
\end{Shaded}

\subsubsection{Leaky Bucket}\label{leaky-bucket}

\begin{itemize}
\tightlist
\item
  Requests flow into a bucket, drain at fixed rate- Excess = overflow =
  dropped Smooths bursts; used for shaping.
\end{itemize}

\subsubsection{Fixed Window Counter}\label{fixed-window-counter}

\begin{itemize}
\item
  Count requests in fixed interval (e.g.~1s)- Reset every window- Simple
  but unfair around boundaries \#\#\#\# Sliding Window Log / Sliding
  Window Counter
\item
  Maintain timestamps of requests- Remove old ones beyond time window-
  More accurate and fair
\end{itemize}

\subsubsection{9. Combining Both}\label{combining-both}

A full system might:

\begin{itemize}
\tightlist
\item
  Use rate limiting per user or service- Use load balancing across
  nodes- Apply circuit breakers when overload persists Together, they
  form resilient architectures that stay online even under spikes.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-86}

These techniques make large-scale systems:

\begin{itemize}
\item
  Scalable - handle millions of users- Stable - prevent cascading
  failures- Fair - each client gets a fair share- Resilient - recover
  gracefully from spikes or node loss Used in:
\item
  API Gateways (Kong, Envoy, Nginx)- Cloud Load Balancers (AWS ALB, GCP
  LB)- Kubernetes Ingress and Service Meshes- Distributed Caches and
  Databases \textgreater{} ``Balance keeps systems alive. Limits keep
  them sane.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-86}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate Round Robin and Least Connections balancing across 3 servers.
\item
  Implement a Token Bucket rate limiter in C or Python.
\item
  Test burst traffic, observe drops or delays.
\item
  Combine Consistent Hashing with Token Bucket for user-level control.
\item
  Visualize how load balancing + rate limiting keep system latency low.
\end{enumerate}

\subsection{88. Search and Indexing (Inverted, BM25,
WAND)}\label{search-and-indexing-inverted-bm25-wand}

Search engines, whether web-scale like Google or local like SQLite's
FTS, rely on efficient indexing and ranking to answer queries fast.
Instead of scanning all documents, they use indexes (structured lookup
tables) to quickly find relevant matches.

This section explores inverted indexes, ranking algorithms (TF-IDF,
BM25), and efficient retrieval techniques like WAND.

\subsubsection{1. The Search Problem}\label{the-search-problem}

Given:

\begin{itemize}
\item
  A corpus of documents- A query (e.g., ``machine learning algorithms'')
  We want to return:
\item
  Relevant documents- Ranked by importance and similarity Naive search →
  O(N × M) comparisons Inverted indexes → O(K log N), where K = terms in
  query
\end{itemize}

\subsubsection{2. Inverted Index: The Heart of
Search}\label{inverted-index-the-heart-of-search}

An inverted index maps terms → documents containing them.

\subsubsection{Example}\label{example-16}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Term & Postings List \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``data'' & {[}1, 4, 5{]} \\
``algorithm'' & {[}2, 3, 5{]} \\
``machine'' & {[}1, 2{]} \\
\end{longtable}

Each posting may include:

\begin{itemize}
\tightlist
\item
  docID- term frequency (tf)- positions (for phrase search) \#\#\#\#
  Construction Steps
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Tokenize documents → words
\item
  Normalize (lowercase, stemming, stopword removal)
\item
  Build postings: term → {[}docIDs, tf, positions{]}
\item
  Sort \& compress for storage efficiency
\end{enumerate}

Used by:

\begin{itemize}
\tightlist
\item
  Elasticsearch, Lucene, Whoosh, Solr
\end{itemize}

\subsubsection{3. Boolean Retrieval}\label{boolean-retrieval}

Simplest model:

\begin{itemize}
\tightlist
\item
  Query = Boolean expression
  e.g.~\texttt{(machine\ AND\ learning)\ OR\ AI}
\end{itemize}

Use set operations on postings:

\begin{itemize}
\tightlist
\item
  AND → intersection- OR → union- NOT → difference Fast intersection
  uses merge algorithm on sorted lists.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ intersect}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ A}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ B}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ B}\OperatorTok{[}\NormalTok{j}\OperatorTok{])} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}\NormalTok{ i}\OperatorTok{++;}\NormalTok{ j}\OperatorTok{++;} \OperatorTok{\}}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ B}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ i}\OperatorTok{++;}
        \ControlFlowTok{else}\NormalTok{ j}\OperatorTok{++;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

But Boolean search doesn't rank results, so we need scoring models.

\subsubsection{4. Vector Space Model}\label{vector-space-model}

Represent documents and queries as term vectors. Each dimension = term
weight (tf-idf).

\begin{itemize}
\tightlist
\item
  tf: term frequency in document- idf: inverse document frequency
  \(idf = \log\frac{N}{df_t}\)
\end{itemize}

Cosine similarity measures relevance: \[
\text{score}(q, d) = \frac{q \cdot d}{|q| |d|}
\]

Simple, interpretable, forms basis of BM25 and modern embeddings.

\subsubsection{5. BM25: The Classic Ranking
Function}\label{bm25-the-classic-ranking-function}

BM25 (Best Match 25) is the de facto standard in information retrieval.

\[
\text{score}(q, d) = \sum_{t \in q} IDF(t) \cdot \frac{f(t, d) \cdot (k_1 + 1)}{f(t, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}
\]

Where:

\begin{itemize}
\item
  ( f(t, d) ): term frequency- ( \textbar d\textbar{} ): doc length- (
  avgdl ): average doc length- \(k_1, b\): tunable params (typ. 1.2-2.0,
  0.75) \#\#\#\# Advantages
\item
  Balances term frequency, document length, and rarity- Fast and
  effective baseline- Still used in Elasticsearch, Lucene, OpenSearch
\end{itemize}

\subsubsection{6. Efficiency Tricks: WAND, Block-Max
WAND}\label{efficiency-tricks-wand-block-max-wand}

Ranking involves merging multiple postings. We can skip irrelevant
documents early with WAND (Weak AND).

\subsubsection{WAND Principle}\label{wand-principle}

\begin{itemize}
\tightlist
\item
  Each term has upper-bound score- Maintain pointers in each posting-
  Compute potential max score- If max \textless{} current threshold,
  skip doc Improves latency for top-k retrieval.
\end{itemize}

Variants:

\begin{itemize}
\tightlist
\item
  BMW (Block-Max WAND) - uses block-level score bounds- MaxScore -
  simpler thresholding- Dynamic pruning - skip unpromising candidates
\end{itemize}

\subsubsection{7. Index Compression}\label{index-compression}

Postings lists are long, compression is crucial.

Common schemes:

\begin{itemize}
\tightlist
\item
  Delta encoding: store gaps between docIDs- Variable-byte (VB) or Gamma
  coding- Frame of Reference (FOR) and SIMD-BP128 for vectorized
  decoding Goal: smaller storage + faster decompression
\end{itemize}

\subsubsection{8. Advanced Retrieval}\label{advanced-retrieval}

\subsubsection{Proximity Search}\label{proximity-search}

Require words appear near each other. Use positional indexes.

\subsubsection{Phrase Search}\label{phrase-search}

Match exact sequences using positions: ``machine learning'' ≠ ``learning
machine''

\subsubsection{Fuzzy / Approximate
Search}\label{fuzzy-approximate-search}

Allow typos: Use Levenshtein automata, n-grams, or k-approximate
matching

\subsubsection{Fielded Search}\label{fielded-search}

Score per field (title, body, tags) Weighted combination

\subsubsection{9. Learning-to-Rank and Semantic
Search}\label{learning-to-rank-and-semantic-search}

Modern search adds ML-based re-ranking:

\begin{itemize}
\tightlist
\item
  Learning to Rank (LTR): use features (tf, idf, BM25, clicks)- Neural
  re-ranking: BERT-style embeddings for semantic similarity- Hybrid
  retrieval: combine BM25 + dense vectors (e.g.~ColBERT, RRF) Also: ANN
  (Approximate Nearest Neighbor) for vector-based search.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-87}

Efficient search powers:

\begin{itemize}
\tightlist
\item
  Web search engines- IDE symbol lookup- Log search, code search-
  Database full-text search- AI retrieval pipelines (RAG) It's where
  algorithms meet language and scale.
\end{itemize}

\begin{quote}
``Search is how we connect meaning to memory.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-87}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a tiny inverted index in C or Python.
\item
  Implement Boolean AND and OR queries.
\item
  Compute TF-IDF and BM25 scores for a toy dataset.
\item
  Add WAND pruning for top-k retrieval.
\item
  Compare BM25 vs semantic embeddings for relevance.
\end{enumerate}

\subsection{89. Compression and Encoding in
Systems}\label{compression-and-encoding-in-systems}

Compression and encoding algorithms are the quiet workhorses of
computing, shrinking data to save space, bandwidth, and time. They allow
systems to store more, transmit faster, and process efficiently. From
files and databases to networks and logs, compression shapes nearly
every layer of system design.

\subsubsection{1. Why Compression
Matters}\label{why-compression-matters}

Compression is everywhere:

\begin{itemize}
\item
  Databases - column stores, indexes, logs- Networks - HTTP, TCP, QUIC
  payloads- File systems - ZFS, NTFS, btrfs compression- Streaming -
  video/audio codecs- Logs \& telemetry - reduce I/O and storage cost
  Benefits:
\item
  Smaller data = faster I/O- Less storage = lower cost- Less transfer =
  higher throughput Trade-offs:
\item
  CPU overhead (compression/decompression)- Latency (especially for
  small data)- Suitability (depends on entropy and structure)
\end{itemize}

\subsubsection{2. Key Concepts}\label{key-concepts}

\subsubsection{Entropy}\label{entropy}

Minimum bits needed to represent data (Shannon). High entropy → less
compressible.

\subsubsection{Redundancy}\label{redundancy}

Compression exploits repetition and patterns.

\subsubsection{Lossless vs Lossy}\label{lossless-vs-lossy}

\begin{itemize}
\tightlist
\item
  Lossless: reversible (ZIP, PNG, LZ4)- Lossy: approximate (JPEG, MP3,
  H.264) In system contexts, lossless dominates.
\end{itemize}

\subsubsection{3. Common Lossless Compression
Families}\label{common-lossless-compression-families}

\subsubsection{Huffman Coding}\label{huffman-coding-1}

\begin{itemize}
\tightlist
\item
  Prefix-free variable-length codes- Frequent symbols = short codes-
  Optimal under symbol-level model Used in: DEFLATE, JPEG, MP3
\end{itemize}

\subsubsection{Arithmetic Coding}\label{arithmetic-coding-1}

\begin{itemize}
\item
  Encodes sequence as fractional interval- More efficient than Huffman
  for skewed distributions- Used in: H.264, bzip2, AV1 \#\#\#\#
  Dictionary-Based (LZ77, LZ78)
\item
  Replace repeated substrings with references- Core of ZIP, gzip, zlib,
  LZMA, Snappy \#\#\#\# LZ77 Sketch
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{not EOF}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    find longest match in sliding window}\OperatorTok{;}
\NormalTok{    output }\OperatorTok{(}\NormalTok{offset}\OperatorTok{,}\NormalTok{ length}\OperatorTok{,}\NormalTok{ next\_char}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Variants:

\begin{itemize}
\item
  LZ4 - fast, lower ratio- Snappy - optimized for speed- Zstandard
  (Zstd) - tunable speed/ratio, dictionary support \#\#\#\#
  Burrows-Wheeler Transform (BWT)
\item
  Reorders data to group similar symbols- Followed by Move-To-Front +
  Huffman- Used in bzip2, BWT-based compressors \#\#\#\# Run-Length
  Encoding (RLE)
\item
  Replace consecutive repeats with (symbol, count)- Great for structured
  or sparse data Example: \texttt{AAAAABBBCC} → \texttt{(A,5)(B,3)(C,2)}
\end{itemize}

\subsubsection{4. Specialized Compression in
Systems}\label{specialized-compression-in-systems}

\subsubsection{Columnar Databases}\label{columnar-databases}

Compress per column:

\begin{itemize}
\tightlist
\item
  Dictionary encoding - map strings → ints- Run-length encoding - good
  for sorted columns- Delta encoding - store differences (time series)-
  Bit-packing - fixed-width integers in minimal bits Combine multiple
  for optimal ratio.
\end{itemize}

Example (time deltas):

\begin{verbatim}
[100, 102, 103, 107] → [100, +2, +1, +4]
\end{verbatim}

\subsubsection{Log and Telemetry
Compression}\label{log-and-telemetry-compression}

\begin{itemize}
\item
  Structured formats → fieldwise encoding- Often Snappy or LZ4 for fast
  decode- Aggregators (Fluentd, Loki, Kafka) rely heavily on them
  \#\#\#\# Data Lakes and Files
\item
  Parquet, ORC, Arrow → columnar + compressed- Choose codec per column:
  LZ4 for speed, Zstd for ratio
\end{itemize}

\subsubsection{5. Streaming and Chunked
Compression}\label{streaming-and-chunked-compression}

Large data often processed in chunks:

\begin{itemize}
\tightlist
\item
  Enables random access and parallelism- Needed for network streams,
  distributed files Example: \texttt{zlib} block, \texttt{Zstd} frame,
  \texttt{gzip} chunk
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  HTTP chunked encoding- Kafka log segments- MapReduce shuffle
\end{itemize}

\subsubsection{6. Encoding Schemes}\label{encoding-schemes}

Compression ≠ encoding. Encoding ensures safe transport.

\subsubsection{Base64}\label{base64}

\begin{itemize}
\item
  Maps 3 bytes → 4 chars- 33\% overhead- Used for binary → text (emails,
  JSON APIs) \#\#\#\# URL Encoding
\item
  Escape unsafe chars with \texttt{\%xx} \#\#\#\# Delta Encoding
\item
  Store differences, not full values \#\#\#\# Varint / Zigzag Encoding
\item
  Compact integers (e.g.~protobufs)- Smaller numbers → fewer bytes
  Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{x }\OperatorTok{\textgreater{}=} \BaseNTok{0x80}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ emit}\OperatorTok{((}\NormalTok{x }\OperatorTok{\&} \BaseNTok{0x7F}\OperatorTok{)} \OperatorTok{|} \BaseNTok{0x80}\OperatorTok{);}\NormalTok{ x }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{7}\OperatorTok{;} \OperatorTok{\}}
\NormalTok{emit}\OperatorTok{(}\NormalTok{x}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Adaptive and Context
Models}\label{adaptive-and-context-models}

Modern compressors adapt to local patterns:

\begin{itemize}
\tightlist
\item
  PPM (Prediction by Partial Matching)- Context mixing (PAQ)- Zstd uses
  FSE (Finite State Entropy) coding Balance between speed, memory, and
  compression ratio.
\end{itemize}

\subsubsection{8. Hardware Acceleration}\label{hardware-acceleration}

Compression can be offloaded to:

\begin{itemize}
\tightlist
\item
  CPUs with SIMD (AVX2, SSE4.2)- GPUs (parallel encode/decode)- NICs /
  SmartNICs- ASICs (e.g., Intel QAT) Critical for high-throughput
  databases, network appliances, storage systems.
\end{itemize}

\subsubsection{9. Design Trade-offs}\label{design-trade-offs}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Goal & Best Choice \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Max speed & LZ4, Snappy \\
Max ratio & Zstd, LZMA \\
Balance & Zstd (tunable) \\
Column store & RLE, Delta, Dict \\
Logs / telemetry & Snappy, LZ4 \\
Archival & bzip2, xz \\
Real-time & LZ4, Brotli (fast mode) \\
\end{longtable}

Choose based on CPU budget, I/O cost, latency tolerance.

\subsubsection{10. Why It Matters}\label{why-it-matters-88}

Compression is a first-class optimization:

\begin{itemize}
\tightlist
\item
  Saves petabytes in data centers- Boosts throughput across networks-
  Powers cloud storage (S3, BigQuery, Snowflake)- Enables efficient
  analytics and ML pipelines \textgreater{} ``Every byte saved is time
  earned.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-88}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compress text using Huffman coding (build frequency table).
\item
  Compare gzip, Snappy, and Zstd on a 1GB dataset.
\item
  Implement delta encoding and RLE for numeric data.
\item
  Try dictionary encoding on repetitive strings.
\item
  Measure compression ratio, speed, and CPU usage trade-offs.
\end{enumerate}

\subsection{90. Fault Tolerance and
Replication}\label{fault-tolerance-and-replication}

Modern systems must survive hardware crashes, network partitions, or
data loss without stopping. Fault tolerance ensures that a system
continues to function, even when parts fail. Replication underpins this
resilience, duplicating data or computation across multiple nodes for
redundancy, performance, and consistency.

Together, they form the backbone of reliability in distributed systems.

\subsubsection{1. Why Fault Tolerance?}\label{why-fault-tolerance}

No system is perfect:

\begin{itemize}
\tightlist
\item
  Servers crash- Disks fail- Networks partition- Power goes out The
  question isn't \emph{if} failure happens, but \emph{when}.
  Fault-tolerant systems detect, contain, and recover from failure
  automatically.
\end{itemize}

Goals:

\begin{itemize}
\tightlist
\item
  Availability - keep serving requests- Durability - never lose data-
  Consistency - stay correct across replicas
\end{itemize}

\subsubsection{2. Failure Models}\label{failure-models}

\subsubsection{Crash Faults}\label{crash-faults}

Node stops responding but doesn't misbehave. Handled by restarts or
replication (Raft, Paxos).

\subsubsection{Omission Faults}\label{omission-faults}

Lost messages or dropped updates. Handled with retries and
acknowledgments.

\subsubsection{Byzantine Faults}\label{byzantine-faults}

Arbitrary/malicious behavior. Handled by Byzantine Fault Tolerance
(PBFT), expensive but robust.

\subsubsection{3. Redundancy: The Core
Strategy}\label{redundancy-the-core-strategy}

Fault tolerance = redundancy + detection + recovery

Redundancy types:

\begin{itemize}
\tightlist
\item
  Hardware: multiple power supplies, disks (RAID)- Software: replicated
  services, retries- Data: multiple copies, erasure codes- Temporal:
  retry or checkpoint and replay
\end{itemize}

\subsubsection{4. Replication Models}\label{replication-models}

\subsubsection{1. Active Replication}\label{active-replication}

All replicas process requests in parallel (lockstep). Results must
match. Used in real-time and Byzantine systems.

\subsubsection{2. Passive
(Primary-Backup)}\label{passive-primary-backup}

One leader (primary) handles requests. Backups replicate log, take over
on failure. Used in Raft, ZooKeeper, PostgreSQL streaming.

\subsubsection{3. Quorum Replication}\label{quorum-replication}

Writes and reads contact majority of replicas. Ensures overlap →
consistency. Used in Cassandra, DynamoDB, Etcd.

\subsubsection{5. Consistency Models}\label{consistency-models}

Replication introduces a trade-off between consistency and availability
(CAP theorem).

\subsubsection{Strong Consistency}\label{strong-consistency}

All clients see the same value immediately. Example: Raft, Etcd,
Spanner.

\subsubsection{Eventual Consistency}\label{eventual-consistency}

Replicas converge over time. Example: DynamoDB, Cassandra.

\subsubsection{Causal Consistency}\label{causal-consistency}

Preserves causal order of events. Example: Vector clocks, CRDTs.

Choice depends on workload:

\begin{itemize}
\tightlist
\item
  Banking → strong- Social feeds → eventual- Collaborative editing →
  causal
\end{itemize}

\subsubsection{6. Checkpointing and
Recovery}\label{checkpointing-and-recovery}

To recover after crash:

\begin{itemize}
\tightlist
\item
  Periodically checkpoint state- On restart, replay log of missed events
  Example: Databases → Write-Ahead Log (WAL) Stream systems → Kafka
  checkpoints
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{1. Save state to disk}
\NormalTok{2. Record latest log position}
\NormalTok{3. On restart → reload + replay}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Erasure Coding}\label{erasure-coding}

Instead of full copies, store encoded fragments. With ( k ) data blocks,
( m ) parity blocks → tolerate ( m ) failures.

Example: Reed-Solomon (used in HDFS, Ceph)

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
k & m & Total & Fault Tolerance \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
4 & 2 & 6 & 2 failures \\
\end{longtable}

Better storage efficiency than 3× replication.

\subsubsection{8. Failure Detection}\label{failure-detection}

Detecting failure is tricky in distributed systems (because of latency).
Common techniques:

\begin{itemize}
\tightlist
\item
  Heartbeats - periodic ``I'm alive'' messages- Timeouts - suspect node
  if no heartbeat- Gossip protocols - share failure info among peers
  Used in Consul, Cassandra, Kubernetes health checks.
\end{itemize}

\subsubsection{9. Self-Healing Systems}\label{self-healing-systems}

After failure:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Detect it
\item
  Isolate faulty component
\item
  Replace or restart
\item
  Rebalance load or re-replicate data
\end{enumerate}

Patterns:

\begin{itemize}
\tightlist
\item
  Supervisor trees (Erlang/Elixir)- Self-healing clusters (Kubernetes)-
  Rebalancing (Cassandra ring repair) ``Never trust a single machine,
  trust the system.''
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-89}

Fault tolerance turns fragile infrastructure into reliable services.

Used in:

\begin{itemize}
\tightlist
\item
  Databases (replication + WAL)- Distributed storage (HDFS, Ceph, S3)-
  Orchestration (Kubernetes controllers)- Streaming systems (Kafka,
  Flink) Without replication and fault tolerance, large-scale systems
  would collapse under failure.
\end{itemize}

\begin{quote}
``Resilience is built, not assumed.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-89}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a primary-backup key-value store: leader writes, follower
  replicates.
\item
  Add heartbeat + timeout detection to trigger failover.
\item
  Simulate partition: explore behavior under strong vs eventual
  consistency.
\item
  Implement checkpoint + replay recovery for a small app.
\item
  Compare 3× replication vs Reed-Solomon (4+2) for space and
  reliability.
\end{enumerate}

\section{Chapter 10. AI, ML and
Optimization}\label{chapter-10.-ai-ml-and-optimization-1}

\subsection{91. Classical ML (k-means, Naive Bayes, SVM, Decision
Trees)}\label{classical-ml-k-means-naive-bayes-svm-decision-trees}

Classical machine learning is built on interpretable mathematics and
solid optimization foundations. Long before deep learning, these
algorithms powered search engines, spam filters, and recommendation
systems. They're still used today, fast, explainable, and easy to
deploy.

This section covers the four pillars of classical ML:

\begin{itemize}
\tightlist
\item
  k-means - unsupervised clustering- Naive Bayes - probabilistic
  classification- SVM - margin-based classification- Decision Trees -
  rule-based learning
\end{itemize}

\subsubsection{1. The Essence of Classical
ML}\label{the-essence-of-classical-ml}

Classical ML is about learning from data using statistical principles,
often without huge compute. Given dataset ( D = \{\(x_i, y_i\)\} ), the
task is to:

\begin{itemize}
\tightlist
\item
  Predict ( y ) from ( x )- Generalize beyond seen data- Balance bias
  and variance
\end{itemize}

\subsubsection{2. k-means Clustering}\label{k-means-clustering}

Goal: partition data into ( k ) groups (clusters) such that
intra-cluster distance is minimized.

\subsubsection{Objective}\label{objective}

\[
\min_{C} \sum_{i=1}^k \sum_{x \in C_i} |x - \mu_i|^2
\] Where \(\mu_i\) = centroid of cluster ( i ).

\subsubsection{Algorithm}\label{algorithm}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose ( k ) random centroids
\item
  Assign each point to nearest centroid
\item
  Recompute centroids
\item
  Repeat until stable
\end{enumerate}

\subsubsection{Tiny Code (C-style)}\label{tiny-code-c-style}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{iter }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ iter }\OperatorTok{\textless{}}\NormalTok{ max\_iter}\OperatorTok{;}\NormalTok{ iter}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    assign\_points\_to\_clusters}\OperatorTok{();}
\NormalTok{    recompute\_centroids}\OperatorTok{();}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros}\label{pros-1}

\begin{itemize}
\item
  Simple, fast (( O(nkd) ))- Works well for spherical clusters \#\#\#\#
  Cons
\item
  Requires ( k )- Sensitive to initialization, outliers Variants:
\item
  k-means++ (better initialization)- Mini-batch k-means (scalable)
\end{itemize}

\subsubsection{3. Naive Bayes Classifier}\label{naive-bayes-classifier}

A probabilistic model using Bayes' theorem under independence
assumptions.

\[
P(y|x) \propto P(y) \prod_{i=1}^n P(x_i | y)
\]

\subsubsection{Algorithm}\label{algorithm-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute prior ( P(y) )
\item
  Compute likelihood ( P\(x_i | y\) )
\item
  Predict class with max posterior
\end{enumerate}

\subsubsection{Types}\label{types}

\begin{itemize}
\tightlist
\item
  Multinomial NB - text (bag of words)- Gaussian NB - continuous
  features- Bernoulli NB - binary features \#\#\#\# Example (Spam
  Detection)
\end{itemize}

\begin{verbatim}
P(spam | "win money") ∝ P(spam) * P("win"|spam) * P("money"|spam)
\end{verbatim}

\subsubsection{Pros}\label{pros-2}

\begin{itemize}
\item
  Fast, works well for text- Needs little data- Probabilistic
  interpretation \#\#\#\# Cons
\item
  Assumes feature independence- Poor for correlated features
\end{itemize}

\subsubsection{4. Support Vector Machines
(SVM)}\label{support-vector-machines-svm}

SVM finds the max-margin hyperplane separating classes.

\subsubsection{Objective}\label{objective-1}

Maximize margin = distance between boundary and nearest points.

\[
\min_{w, b} \frac{1}{2} |w|^2 \quad \text{s.t.} \quad y_i(w \cdot x_i + b) \ge 1
\]

Can be solved via Quadratic Programming.

\subsubsection{Intuition}\label{intuition}

\begin{itemize}
\tightlist
\item
  Each data point → vector- Hyperplane: \(w \cdot x + b = 0\)- Support
  vectors = boundary points \#\#\#\# Kernel Trick
\end{itemize}

Transform input via kernel ( K\(x_i, x_j\) = \phi\(x_i\)
\cdot \phi\(x_j\) ):

\begin{itemize}
\item
  Linear: dot product- Polynomial: ( \(x_i \cdot x_j + c\)\^{}d )- RBF:
  \(e^{-\gamma |x_i - x_j|^2}\) \#\#\#\# Pros
\item
  Effective in high dimensions- Can model nonlinear boundaries- Few
  hyperparameters \#\#\#\# Cons
\item
  Slow on large data- Harder to tune kernel parameters
\end{itemize}

\subsubsection{5. Decision Trees}\label{decision-trees}

If-else structure for classification/regression.

At each node:

\begin{itemize}
\item
  Pick feature ( f ) and threshold ( t )- Split to maximize information
  gain \#\#\#\# Metrics
\item
  Entropy: \(H = -\sum p_i \log p_i\)- Gini: \(G = 1 - \sum p_i^2\)
  \#\#\#\# Pseudocode
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{feature }\OperatorTok{\textless{}}\NormalTok{ threshold}\OperatorTok{)}
\NormalTok{    go left}\OperatorTok{;}
\ControlFlowTok{else}
\NormalTok{    go right}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Build recursively until:

\begin{itemize}
\item
  Max depth- Min samples per leaf- Pure nodes \#\#\#\# Pros
\item
  Interpretable- Handles mixed data- No scaling needed \#\#\#\# Cons
\item
  Prone to overfitting- Unstable (small data changes) Fixes:
\item
  Pruning (reduce depth)- Ensembles: Random Forests, Gradient Boosting
\end{itemize}

\subsubsection{6. Bias-Variance Tradeoff}\label{bias-variance-tradeoff}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Bias & Variance \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
k-means & High & Low \\
Naive Bayes & High & Low \\
SVM & Low & Medium \\
Decision Tree & Low & High \\
\end{longtable}

Balancing both = good generalization.

\subsubsection{7. Evaluation Metrics}\label{evaluation-metrics}

For classification:

\begin{itemize}
\item
  Accuracy, Precision, Recall, F1-score- ROC-AUC, Confusion Matrix For
  clustering:
\item
  Inertia, Silhouette Score Always use train/test split or
  cross-validation.
\end{itemize}

\subsubsection{8. Scaling to Large Data}\label{scaling-to-large-data}

Techniques:

\begin{itemize}
\item
  Mini-batch training- Online updates (SGD)- Dimensionality reduction
  (PCA)- Approximation (Random Projections) Libraries:
\item
  scikit-learn (Python)- liblinear, libsvm (C/C++)- MLlib (Spark)
\end{itemize}

\subsubsection{9. When to Use What}\label{when-to-use-what}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Task & Recommended Algorithm \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Text classification & Naive Bayes \\
Clustering & k-means \\
Nonlinear classification & SVM (RBF) \\
Tabular data & Decision Tree \\
Quick baseline & Logistic Regression / NB \\
\end{longtable}

\subsubsection{10. Why It Matters}\label{why-it-matters-90}

These algorithms are fast, interpretable, and theoretical foundations of
modern ML. They remain the go-to choice for:

\begin{itemize}
\tightlist
\item
  Small to medium datasets- Real-time classification- Explainable AI
  \textgreater{} ``Classical ML is the art of solving problems with math
  you can still write on a whiteboard.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-90}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cluster 2D points with k-means, plot centroids.
\item
  Train Naive Bayes on a spam/ham dataset.
\item
  Classify linearly separable data with SVM.
\item
  Build a Decision Tree from scratch (entropy, Gini).
\item
  Compare models' accuracy and interpretability.
\end{enumerate}

\subsection{92. Ensemble Methods (Bagging, Boosting, Random
Forests)}\label{ensemble-methods-bagging-boosting-random-forests}

Ensemble methods combine multiple weak learners to build a strong
predictor. Instead of relying on one model, ensembles vote, average, or
boost multiple models, improving stability and accuracy.

They are the bridge between classical and modern ML , simple models,
combined smartly, become powerful.

\subsubsection{1. The Core Idea}\label{the-core-idea-4}

\begin{quote}
``Many weak learners, when combined, can outperform a single strong
one.''
\end{quote}

Mathematically, if \(f_1, f_2, \ldots, f_k\) are weak learners, an
ensemble predictor is:

\[
F(x) = \frac{1}{k}\sum_{i=1}^k f_i(x)
\]

For classification, combine via majority vote. For regression, combine
via average.

\subsubsection{2. Bagging (Bootstrap
Aggregating)}\label{bagging-bootstrap-aggregating}

Bagging reduces variance by training models on different samples.

\subsubsection{Steps}\label{steps-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw ( B ) bootstrap samples from dataset ( D ).
\item
  Train one model per sample.
\item
  Aggregate predictions by averaging or voting.
\end{enumerate}

\[
\hat{f}*{bag}(x) = \frac{1}{B} \sum*{b=1}^B f_b(x)
\]

Each \(f_b\) is trained on a random subset (with replacement).

\subsubsection{Example}\label{example-17}

\begin{itemize}
\tightlist
\item
  Base learner: Decision Tree- Ensemble: Bagged Trees- Famous instance:
  Random Forest \#\#\#\# Tiny Code (C-style Pseudocode)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ b }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ b }\OperatorTok{\textless{}}\NormalTok{ B}\OperatorTok{;}\NormalTok{ b}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    D\_b }\OperatorTok{=}\NormalTok{ bootstrap\_sample}\OperatorTok{(}\NormalTok{D}\OperatorTok{);}
\NormalTok{    model}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ train\_tree}\OperatorTok{(}\NormalTok{D\_b}\OperatorTok{);}
\OperatorTok{\}}
\NormalTok{prediction }\OperatorTok{=}\NormalTok{ average\_predictions}\OperatorTok{(}\NormalTok{model}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros}\label{pros-3}

\begin{itemize}
\item
  Reduces variance- Works well with high-variance learners-
  Parallelizable \#\#\#\# Cons
\item
  Increases computation- Doesn't reduce bias
\end{itemize}

\subsubsection{3. Random Forest}\label{random-forest}

A bagging-based ensemble of decision trees with feature randomness.

\subsubsection{Key Ideas}\label{key-ideas}

\begin{itemize}
\tightlist
\item
  Each tree trained on bootstrap sample.- At each split, consider random
  subset of features.- Final prediction = majority vote or average. This
  decorrelates trees, improving generalization.
\end{itemize}

\[
F(x) = \frac{1}{B} \sum_{b=1}^{B} T_b(x)
\]

\subsubsection{Pros}\label{pros-4}

\begin{itemize}
\item
  Handles large feature sets- Low overfitting- Good default for tabular
  data \#\#\#\# Cons
\item
  Less interpretable- Slower on huge datasets OOB (Out-of-Bag) error =
  internal validation from unused samples.
\end{itemize}

\subsubsection{4. Boosting}\label{boosting}

Boosting focuses on reducing bias by sequentially training models , each
one corrects errors from the previous.

\subsubsection{Steps}\label{steps-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with weak learner ( f\_1(x) )
\item
  Train next learner ( f\_2(x) ) on residuals/errors
\item
  Combine with weighted sum
\end{enumerate}

\[
F_m(x) = F_{m-1}(x) + \alpha_m f_m(x)
\]

Weights \(\alpha_m\) focus on difficult examples.

\subsubsection{Tiny Code (Conceptual)}\label{tiny-code-conceptual-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{F }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ m }\OperatorTok{\textless{}}\NormalTok{ M}\OperatorTok{;}\NormalTok{ m}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    residual }\OperatorTok{=}\NormalTok{ y }\OperatorTok{{-}}\NormalTok{ predict}\OperatorTok{(}\NormalTok{F}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\NormalTok{    f\_m }\OperatorTok{=}\NormalTok{ train\_weak\_learner}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ residual}\OperatorTok{);}
\NormalTok{    F }\OperatorTok{+=}\NormalTok{ alpha}\OperatorTok{[}\NormalTok{m}\OperatorTok{]} \OperatorTok{*}\NormalTok{ f\_m}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. AdaBoost (Adaptive
Boosting)}\label{adaboost-adaptive-boosting}

AdaBoost adapts weights on samples after each iteration.

\subsubsection{Algorithm}\label{algorithm-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize weights: \(w_i = \frac{1}{n}\)
\item
  Train weak classifier \(f_t\)
\item
  Compute error: \(\epsilon_t\)
\item
  Update weights: \[
  w_i \leftarrow w_i \cdot e^{\alpha_t \cdot I(y_i \ne f_t(x_i))}
  \] where
  \(\alpha_t = \frac{1}{2} \ln\left(\frac{1 - \epsilon_t}{\epsilon_t}\right)\)
\item
  Normalize weights
\end{enumerate}

Final classifier: \[
F(x) = \text{sign}\left( \sum_t \alpha_t f_t(x) \right)
\]

\subsubsection{Pros}\label{pros-5}

\begin{itemize}
\item
  High accuracy on clean data- Simple and interpretable weights \#\#\#\#
  Cons
\item
  Sensitive to outliers- Sequential → not easily parallelizable
\end{itemize}

\subsubsection{6. Gradient Boosting}\label{gradient-boosting}

A modern version of boosting using gradient descent on loss.

At each step, fit new model to negative gradient of loss function.

\subsubsection{Objective}\label{objective-2}

\[
F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)
\]

where \(h_m(x) \approx -\frac{\partial L(y, F(x))}{\partial F(x)}\)

\subsubsection{Common Libraries}\label{common-libraries}

\begin{itemize}
\item
  XGBoost
\item
  LightGBM
\item
  CatBoost \#\#\#\# Pros
\item
  High performance on tabular data- Flexible (custom loss)- Handles
  mixed feature types \#\#\#\# Cons
\item
  Slower to train- Sensitive to hyperparameters
\end{itemize}

\subsubsection{7. Stacking (Stacked
Generalization)}\label{stacking-stacked-generalization}

Combine multiple models (base learners) via a meta-model.

\subsubsection{Steps}\label{steps-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train base models (SVM, Tree, NB, etc.)
\item
  Collect their predictions
\item
  Train meta-model (e.g.~Logistic Regression) on outputs
\end{enumerate}

\[
\hat{y} = f_{meta}(f_1(x), f_2(x), \ldots, f_k(x))
\]

\subsubsection{8. Bagging vs Boosting}\label{bagging-vs-boosting}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Bagging & Boosting \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strategy & Parallel & Sequential \\
Goal & Reduce variance & Reduce bias \\
Weighting & Uniform & Adaptive \\
Example & Random Forest & AdaBoost, XGBoost \\
\end{longtable}

\subsubsection{9. Bias-Variance Behavior}\label{bias-variance-behavior}

\begin{itemize}
\tightlist
\item
  Bagging: ↓ variance- Boosting: ↓ bias- Random Forest: balanced-
  Stacking: flexible but complex
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-91}

Ensemble methods are the workhorses of classical ML competitions and
real-world tabular problems. They blend interpretability, flexibility,
and predictive power.

\begin{quote}
``One tree may fall, but a forest stands strong.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-91}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train a Random Forest on the Iris dataset.
\item
  Implement AdaBoost from scratch using decision stumps.
\item
  Compare Bagging vs Boosting accuracy.
\item
  Try XGBoost with different learning rates.
\item
  Visualize feature importance across models.
\end{enumerate}

\subsection{93. Gradient Methods (SGD, Adam,
RMSProp)}\label{gradient-methods-sgd-adam-rmsprop}

Gradient-based optimization is the heartbeat of machine learning. These
methods update parameters iteratively by following the negative gradient
of the loss function. They power everything from linear regression to
deep neural networks.

\subsubsection{1. The Core Idea}\label{the-core-idea-5}

We want to minimize a loss function ( L\(\theta\) ). Starting from some
initial parameters \(\theta_0\), we move in the opposite direction of
the gradient:

\[
\theta_{t+1} = \theta_t - \eta \cdot \nabla_\theta L(\theta_t)
\]

where \(\eta\) is the learning rate (step size).

The gradient tells us which way the function increases fastest , we move
the other way.

\subsubsection{2. Batch Gradient Descent}\label{batch-gradient-descent}

Uses the entire dataset to compute the gradient.

\[
\nabla_\theta L(\theta) = \frac{1}{N} \sum_{i=1}^N \nabla_\theta \ell_i(\theta)
\]

\begin{itemize}
\tightlist
\item
  Accurate but slow for large ( N )- Each update is expensive Tiny Code
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    grad }\OperatorTok{=}\NormalTok{ compute\_full\_gradient}\OperatorTok{(}\NormalTok{data}\OperatorTok{,}\NormalTok{ theta}\OperatorTok{);}
\NormalTok{    theta }\OperatorTok{=}\NormalTok{ theta }\OperatorTok{{-}}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ grad}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Good for: small datasets or convex problems

\subsubsection{3. Stochastic Gradient Descent
(SGD)}\label{stochastic-gradient-descent-sgd}

Instead of full data, use one random sample per step.

\[
\theta_{t+1} = \theta_t - \eta \cdot \nabla_\theta \ell_i(\theta_t)
\]

\begin{itemize}
\tightlist
\item
  Noisy but faster updates- Can escape local minima- Great for online
  learning Tiny Code
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each sample }\OperatorTok{(}\NormalTok{x\_i}\OperatorTok{,}\NormalTok{ y\_i}\OperatorTok{):}
\NormalTok{    grad }\OperatorTok{=}\NormalTok{ grad\_loss}\OperatorTok{(}\NormalTok{theta}\OperatorTok{,}\NormalTok{ x\_i}\OperatorTok{,}\NormalTok{ y\_i}\OperatorTok{);}
\NormalTok{    theta }\OperatorTok{{-}=}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ grad}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Pros

\begin{itemize}
\item
  Fast convergence- Works on large datasets Cons
\item
  Noisy updates- Requires learning rate tuning
\end{itemize}

\subsubsection{4. Mini-Batch Gradient
Descent}\label{mini-batch-gradient-descent}

Compromise between batch and stochastic.

Use small subset (mini-batch) of samples:

\[
\theta_{t+1} = \theta_t - \eta \cdot \frac{1}{m} \sum_{i=1}^m \nabla_\theta \ell_i(\theta_t)
\]

Usually batch size = 32 or 64. Faster, more stable updates.

\subsubsection{5. Momentum}\label{momentum}

Adds velocity to smooth oscillations.

\[
v_t = \beta v_{t-1} + (1 - \beta) \nabla_\theta L(\theta_t)
\]

\[
\theta_{t+1} = \theta_t - \eta v_t
\]

This accumulates past gradients to speed movement in consistent
directions.

Think of it like a heavy ball rolling down a hill.

\subsubsection{6. Nesterov Accelerated Gradient
(NAG)}\label{nesterov-accelerated-gradient-nag}

Improves momentum by looking ahead:

\[
v_t = \beta v_{t-1} + \eta \nabla_\theta L(\theta_t - \beta v_{t-1})
\]

It anticipates the future position before computing the gradient.

Faster convergence in convex settings.

\subsubsection{7. RMSProp}\label{rmsprop}

Adjusts learning rate per parameter using exponential average of squared
gradients:

\[
E[g^2]*t = \rho E[g^2]*{t-1} + (1 - \rho) g_t^2
\]

\[
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t
\]

This helps when gradients vary in magnitude.

Good for: non-stationary objectives, deep networks

\subsubsection{8. Adam (Adaptive Moment
Estimation)}\label{adam-adaptive-moment-estimation}

Combines momentum + RMSProp:

\[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
\]

\[
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
\]

Bias-corrected estimates:

\[
\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
\]

Update rule:

\[
\theta_{t+1} = \theta_t - \frac{\eta \cdot \hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
\]

Tiny Code (Conceptual)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ v }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ grad}\OperatorTok{(}\NormalTok{theta}\OperatorTok{);}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ beta1 }\OperatorTok{*}\NormalTok{ m }\OperatorTok{+} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ beta1}\OperatorTok{)} \OperatorTok{*}\NormalTok{ g}\OperatorTok{;}
\NormalTok{    v }\OperatorTok{=}\NormalTok{ beta2 }\OperatorTok{*}\NormalTok{ v }\OperatorTok{+} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ beta2}\OperatorTok{)} \OperatorTok{*}\NormalTok{ g }\OperatorTok{*}\NormalTok{ g}\OperatorTok{;}
\NormalTok{    m\_hat }\OperatorTok{=}\NormalTok{ m }\OperatorTok{/} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ pow}\OperatorTok{(}\NormalTok{beta1}\OperatorTok{,}\NormalTok{ t}\OperatorTok{));}
\NormalTok{    v\_hat }\OperatorTok{=}\NormalTok{ v }\OperatorTok{/} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ pow}\OperatorTok{(}\NormalTok{beta2}\OperatorTok{,}\NormalTok{ t}\OperatorTok{));}
\NormalTok{    theta }\OperatorTok{{-}=}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ m\_hat }\OperatorTok{/} \OperatorTok{(}\NormalTok{sqrt}\OperatorTok{(}\NormalTok{v\_hat}\OperatorTok{)} \OperatorTok{+}\NormalTok{ eps}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pros

\begin{itemize}
\item
  Works well out of the box- Adapts learning rate- Great for deep
  learning Cons
\item
  May not converge exactly- Needs decay schedule for stability
\end{itemize}

\subsubsection{9. Learning Rate
Schedules}\label{learning-rate-schedules}

Control \(\eta\) over time:

\begin{itemize}
\tightlist
\item
  Step decay: \(\eta_t = \eta_0 \cdot \gamma^{\lfloor t/s \rfloor}\)-
  Exponential decay: \(\eta_t = \eta_0 e^{-\lambda t}\)- Cosine
  annealing: smooth periodic decay- Warm restarts: reset learning rate
  periodically
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-92}

All modern deep learning is built on gradients. Choosing the right
optimizer can mean faster training and better accuracy.

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Optimizer & Adaptive & Momentum & Common Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
SGD & No & Optional & Simple tasks \\
SGD + Momentum & No & Yes & ConvNets \\
RMSProp & Yes & No & RNNs \\
Adam & Yes & Yes & Transformers, DNNs \\
\end{longtable}

\begin{quote}
``Optimization is the art of taking small steps in the right direction ,
many times over.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-92}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement SGD and Adam on a linear regression task.
\item
  Compare training curves for SGD, Momentum, RMSProp, and Adam.
\item
  Experiment with learning rate schedules.
\item
  Visualize optimization paths on a 2D contour plot.
\end{enumerate}

\subsection{94. Deep Learning (Backpropagation, Dropout,
Normalization)}\label{deep-learning-backpropagation-dropout-normalization}

Deep learning is about stacking layers of computation so that the
network can learn hierarchical representations. From raw pixels to
abstract features, deep nets build meaning through composition of
functions.

At the core of this process are three ideas: backpropagation,
regularization (dropout), and normalization.

\subsubsection{1. The Essence of Deep
Learning}\label{the-essence-of-deep-learning}

A neural network is a chain of functions:

\[
f(x; \theta) = f_L(f_{L-1}(\cdots f_1(x)))
\]

Each layer transforms its input and passes it on.

Training involves finding parameters \(\theta\) that minimize a loss (
L(f\(x; \theta\), y) ).

\subsubsection{2. Backpropagation}\label{backpropagation}

Backpropagation is the algorithm that teaches neural networks.

It uses the chain rule of calculus to efficiently compute gradients
layer by layer.

For each layer ( i ):

\[
\frac{\partial L}{\partial \theta_i} = \frac{\partial L}{\partial a_i} \cdot \frac{\partial a_i}{\partial \theta_i}
\]

and propagate backward:

\[
\frac{\partial L}{\partial a_{i-1}} = \frac{\partial L}{\partial a_i} \cdot \frac{\partial a_i}{\partial a_{i-1}}
\]

So every neuron learns how much it contributed to the error.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Pseudocode for 2{-}layer network}
\NormalTok{forward}\OperatorTok{:}
\NormalTok{    z1 }\OperatorTok{=}\NormalTok{ W1}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ b1}\OperatorTok{;}
\NormalTok{    a1 }\OperatorTok{=}\NormalTok{ relu}\OperatorTok{(}\NormalTok{z1}\OperatorTok{);}
\NormalTok{    z2 }\OperatorTok{=}\NormalTok{ W2}\OperatorTok{*}\NormalTok{a1 }\OperatorTok{+}\NormalTok{ b2}\OperatorTok{;}
\NormalTok{    y\_hat }\OperatorTok{=}\NormalTok{ softmax}\OperatorTok{(}\NormalTok{z2}\OperatorTok{);}
\NormalTok{    loss }\OperatorTok{=}\NormalTok{ cross\_entropy}\OperatorTok{(}\NormalTok{y\_hat}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}

\NormalTok{backward}\OperatorTok{:}
\NormalTok{    dz2 }\OperatorTok{=}\NormalTok{ y\_hat }\OperatorTok{{-}}\NormalTok{ y}\OperatorTok{;}
\NormalTok{    dW2 }\OperatorTok{=}\NormalTok{ dz2 }\OperatorTok{*}\NormalTok{ a1}\OperatorTok{.}\NormalTok{T}\OperatorTok{;}
\NormalTok{    db2 }\OperatorTok{=}\NormalTok{ sum}\OperatorTok{(}\NormalTok{dz2}\OperatorTok{);}
\NormalTok{    da1 }\OperatorTok{=}\NormalTok{ W2}\OperatorTok{.}\NormalTok{T }\OperatorTok{*}\NormalTok{ dz2}\OperatorTok{;}
\NormalTok{    dz1 }\OperatorTok{=}\NormalTok{ da1 }\OperatorTok{*}\NormalTok{ relu\_grad}\OperatorTok{(}\NormalTok{z1}\OperatorTok{);}
\NormalTok{    dW1 }\OperatorTok{=}\NormalTok{ dz1 }\OperatorTok{*}\NormalTok{ x}\OperatorTok{.}\NormalTok{T}\OperatorTok{;}
\NormalTok{    db1 }\OperatorTok{=}\NormalTok{ sum}\OperatorTok{(}\NormalTok{dz1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Each gradient is computed by local differentiation and multiplied back.

\subsubsection{3. Activation Functions}\label{activation-functions}

Nonlinear activations let networks approximate nonlinear functions.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Function & Formula & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ReLU & \(\max(0, x)\) & Default, fast \\
Sigmoid & \(\frac{1}{1 + e^{-x}}\) & Probabilities \\
Tanh & \(\tanh(x)\) & Centered activations \\
GELU & \(x \, \Phi(x)\) & Modern transformers \\
\end{longtable}

Without nonlinearity, stacking layers is just one big linear
transformation.

\subsubsection{4. Dropout}\label{dropout}

Dropout is a regularization technique that prevents overfitting. During
training, randomly turn off neurons:

\[
\tilde{a}_i = a_i \cdot m_i, \quad m_i \sim \text{Bernoulli}(p)
\]

At inference, scale activations by ( p ) (keep probability).

It forces the network to not rely on any single path.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rand\_uniform}\OperatorTok{()} \OperatorTok{\textless{}}\NormalTok{ p}\OperatorTok{)}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{else}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/=}\NormalTok{ p}\OperatorTok{;} \CommentTok{// scaling}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Normalization}\label{normalization}

Normalization stabilizes and speeds up training by reducing internal
covariate shift.

\subsubsection{Batch Normalization}\label{batch-normalization}

Normalize activations per batch:

\[
\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
\]

\[
y = \gamma \hat{x} + \beta
\]

Learnable parameters \(\gamma, \beta\) restore flexibility.

Benefits:

\begin{itemize}
\tightlist
\item
  Smooth gradients- Allows higher learning rates- Acts as regularizer
  \#\#\#\# Layer Normalization
\end{itemize}

Used in transformers (normalizes across features, not batch).

\subsubsection{6. Initialization}\label{initialization}

Proper initialization helps gradients flow.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Scheme & Formula & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Xavier & \(\text{Var}(W) = \frac{1}{n_{in}}\) & Tanh \\
He & \(\text{Var}(W) = \frac{2}{n_{in}}\) & ReLU \\
\end{longtable}

Poor initialization can lead to vanishing or exploding gradients.

\subsubsection{7. Training Pipeline}\label{training-pipeline}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize weights
\item
  Forward pass
\item
  Compute loss
\item
  Backward pass (backprop)
\item
  Update weights (e.g.~with Adam)
\end{enumerate}

Repeat until convergence.

\subsubsection{8. Deep Architectures}\label{deep-architectures}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Model & Key Idea & Typical Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MLP & Fully connected & Tabular data \\
CNN & Convolutions & Images \\
RNN & Sequential recurrence & Time series, text \\
Transformer & Self-attention & Language, vision \\
\end{longtable}

Each architecture stacks linear operations and nonlinearities in
different ways.

\subsubsection{9. Overfitting and
Regularization}\label{overfitting-and-regularization}

Common fixes:

\begin{itemize}
\tightlist
\item
  Dropout- Weight decay (\(L_2\) regularization)- Data augmentation-
  Early stopping The key is to improve generalization, not just minimize
  training loss.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-93}

Backpropagation turned neural networks from theory to practice.
Normalization made them train faster. Dropout made them generalize
better.

Together, they unlocked the deep learning revolution.

\begin{quote}
``Depth gives power, but gradients give life.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-93}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a 2-layer network with ReLU and softmax.
\item
  Add dropout and batch normalization.
\item
  Visualize training with and without dropout.
\item
  Compare performance on MNIST with and without normalization.
\end{enumerate}

\subsection{95. Sequence Models (Viterbi, Beam Search,
CTC)}\label{sequence-models-viterbi-beam-search-ctc}

Sequence models process data where order matters, text, speech, DNA,
time series. They capture dependencies across positions, predicting the
next step from context.

This section explores three fundamental tools: Viterbi, Beam Search, and
CTC (Connectionist Temporal Classification).

\subsubsection{1. The Nature of Sequential
Data}\label{the-nature-of-sequential-data}

Sequential data has temporal or structural order. Each element \(x_t\)
depends on past inputs \(x_{1:t-1}\).

Common sequence tasks:

\begin{itemize}
\tightlist
\item
  Tagging (POS tagging, named entity recognition)- Transcription (speech
  → text)- Decoding (translation, path reconstruction) To handle such
  problems, we need models that remember.
\end{itemize}

\subsubsection{2. Hidden Markov Models
(HMMs)}\label{hidden-markov-models-hmms}

A Hidden Markov Model assumes:

\begin{itemize}
\tightlist
\item
  A sequence of hidden states \(z_1, z_2, \ldots, z_T\)- Each state
  emits an observation \(x_t\)- Transition and emission probabilities
  govern the process \[
  P(z_t | z_{t-1}) = A_{z_{t-1}, z_t}, \quad P(x_t | z_t) = B_{z_t}(x_t)
  \]
\end{itemize}

Goal: find the most likely sequence of hidden states given observations.

\subsubsection{3. The Viterbi Algorithm}\label{the-viterbi-algorithm}

Viterbi is a dynamic programming algorithm to decode the most probable
path:

\[
\delta_t(i) = \max_{z_{1:t-1}} P(z_{1:t-1}, z_t = i, x_{1:t})
\]

Recurrence:

\[
\delta_t(i) = \max_j \big( \delta_{t-1}(j) \cdot A_{j,i} \big) \cdot B_i(x_t)
\]

Track backpointers to reconstruct the best sequence.

Time complexity: \(O(T \cdot N^2)\),\\
where \(N\) = number of states, \(T\) = sequence length.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{t }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ best }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{INF}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ argmax }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ score }\OperatorTok{=}\NormalTok{ delta}\OperatorTok{[}\NormalTok{t}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{score }\OperatorTok{\textgreater{}}\NormalTok{ best}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ best }\OperatorTok{=}\NormalTok{ score}\OperatorTok{;}\NormalTok{ argmax }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;} \OperatorTok{\}}
        \OperatorTok{\}}
\NormalTok{        delta}\OperatorTok{[}\NormalTok{t}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ best }\OperatorTok{*}\NormalTok{ B}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{x}\OperatorTok{[}\NormalTok{t}\OperatorTok{]];}
\NormalTok{        backptr}\OperatorTok{[}\NormalTok{t}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ argmax}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use \texttt{backptr} to trace back the optimal path.

\subsubsection{4. Beam Search}\label{beam-search}

For many sequence models (e.g.~neural machine translation), exhaustive
search is impossible. Beam search keeps only the top-k best hypotheses
at each step.

Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with an empty sequence and score 0
\item
  At each step, expand each candidate with all possible next tokens
\item
  Keep only k best sequences (beam size)
\item
  Stop when all sequences end or reach max length
\end{enumerate}

Beam size controls trade-off:

\begin{itemize}
\tightlist
\item
  Larger beam → better accuracy, slower- Smaller beam → faster, riskier
\end{itemize}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{step }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ step }\OperatorTok{\textless{}}\NormalTok{ max\_len}\OperatorTok{;}\NormalTok{ step}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\NormalTok{Candidate}\OperatorTok{\textgreater{}}\NormalTok{ new\_beam}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{c in beam}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        probs }\OperatorTok{=}\NormalTok{ model\_next}\OperatorTok{(}\NormalTok{c}\OperatorTok{.}\NormalTok{seq}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{token}\OperatorTok{,}\NormalTok{ p in probs}\OperatorTok{)}
\NormalTok{            new\_beam}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{c}\OperatorTok{.}\NormalTok{seq }\OperatorTok{+}\NormalTok{ token}\OperatorTok{,}\NormalTok{ c}\OperatorTok{.}\NormalTok{score }\OperatorTok{+}\NormalTok{ log}\OperatorTok{(}\NormalTok{p}\OperatorTok{)\});}
    \OperatorTok{\}}
\NormalTok{    beam }\OperatorTok{=}\NormalTok{ top\_k}\OperatorTok{(}\NormalTok{new\_beam}\OperatorTok{,}\NormalTok{ k}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use log probabilities to avoid underflow.

\subsubsection{5. Connectionist Temporal Classification
(CTC)}\label{connectionist-temporal-classification-ctc}

Used in speech recognition and handwriting recognition where input and
output lengths differ.

CTC learns to align input frames with output symbols without explicit
alignment.

Add a special blank symbol (∅) to allow flexible alignment.

Example (CTC decoding):

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Frame & Output & After Collapse \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A ∅ A A & A ∅ A & A A \\
H ∅ ∅ H & H H & H \\
\end{longtable}

Loss: \[
P(y | x) = \sum_{\pi \in \text{Align}(x, y)} P(\pi | x)
\] where \(\pi\) are all alignments that reduce to ( y ).

CTC uses dynamic programming to compute forward-backward probabilities.

\subsubsection{6. Comparing Methods}\label{comparing-methods}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1594}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2319}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2609}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Used In
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handles Alignment?
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Viterbi & HMMs & Most probable state path & Yes \\
Beam Search & Neural decoders & Approximate search & Implicit \\
CTC & Speech / seq2seq & Sum over alignments & Yes \\
\end{longtable}

\subsubsection{7. Use Cases}\label{use-cases}

\begin{itemize}
\tightlist
\item
  Viterbi: POS tagging, speech decoding- Beam Search: translation, text
  generation- CTC: ASR, OCR, gesture recognition
\end{itemize}

\subsubsection{8. Implementation Tips}\label{implementation-tips}

\begin{itemize}
\tightlist
\item
  Use log-space for probabilities- In beam search, apply length
  normalization- In CTC, use dynamic programming tables- Combine CTC +
  beam search for speech decoding
\end{itemize}

\subsubsection{9. Common Pitfalls}\label{common-pitfalls}

\begin{itemize}
\tightlist
\item
  Viterbi assumes Markov property (limited memory)- Beam Search can miss
  global optimum- CTC can confuse repeated characters without blanks
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-94}

Sequence models are the bridge between structure and time. They show how
to decode hidden meaning in ordered data.

From decoding Morse code to transcribing speech, these algorithms give
machines the gift of sequence understanding.

\subsubsection{Try It Yourself}\label{try-it-yourself-94}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Viterbi for a 3-state HMM.
\item
  Compare greedy decoding vs beam search on a toy language model.
\item
  Build a CTC loss table for a short sequence (like ``HELLO'').
\end{enumerate}

\subsection{96. Metaheuristics (GA, SA, PSO,
ACO)}\label{metaheuristics-ga-sa-pso-aco}

Metaheuristics are general-purpose optimization strategies that search
through vast, complex spaces when exact methods are too slow or
infeasible. They don't guarantee the perfect answer but often find
good-enough solutions fast.

This section covers four classics:

\begin{itemize}
\tightlist
\item
  GA (Genetic Algorithm)- SA (Simulated Annealing)- PSO (Particle Swarm
  Optimization)- ACO (Ant Colony Optimization)
\end{itemize}

\subsubsection{1. The Metaheuristic
Philosophy}\label{the-metaheuristic-philosophy}

Metaheuristics draw inspiration from nature and physics. They combine
exploration (searching widely) and exploitation (refining promising
spots).

They're ideal for:

\begin{itemize}
\tightlist
\item
  NP-hard problems (TSP, scheduling)- Continuous optimization (parameter
  tuning)- Black-box functions (no gradients) They trade mathematical
  guarantees for practical power.
\end{itemize}

\subsubsection{2. Genetic Algorithm (GA)}\label{genetic-algorithm-ga}

Inspired by natural selection, GAs evolve a population of solutions.

\subsubsection{Core Steps}\label{core-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize population randomly
\item
  Evaluate fitness of each
\item
  Select parents
\item
  Crossover to produce offspring
\item
  Mutate to add variation
\item
  Replace worst with new candidates
\end{enumerate}

Repeat until convergence.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{gen }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ gen }\OperatorTok{\textless{}}\NormalTok{ max\_gen}\OperatorTok{;}\NormalTok{ gen}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    evaluate}\OperatorTok{(}\NormalTok{pop}\OperatorTok{);}
\NormalTok{    parents }\OperatorTok{=}\NormalTok{ select\_best}\OperatorTok{(}\NormalTok{pop}\OperatorTok{);}
\NormalTok{    offspring }\OperatorTok{=}\NormalTok{ crossover}\OperatorTok{(}\NormalTok{parents}\OperatorTok{);}
\NormalTok{    mutate}\OperatorTok{(}\NormalTok{offspring}\OperatorTok{);}
\NormalTok{    pop }\OperatorTok{=}\NormalTok{ select\_survivors}\OperatorTok{(}\NormalTok{pop}\OperatorTok{,}\NormalTok{ offspring}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Operators

\begin{itemize}
\tightlist
\item
  Selection: tournament, roulette-wheel- Crossover: one-point, uniform-
  Mutation: bit-flip, Gaussian Strengths: global search, diverse
  exploration Weakness: may converge slowly
\end{itemize}

\subsubsection{3. Simulated Annealing
(SA)}\label{simulated-annealing-sa}

Mimics cooling of metals, start hot (high randomness), slowly cool.

At each step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Propose random neighbor
\item
  Accept if better
\item
  If worse, accept with probability \[
  P = e^{-\frac{\Delta E}{T}}
  \]
\item
  Gradually lower ( T )
\end{enumerate}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OperatorTok{=}\NormalTok{ T\_init}\OperatorTok{;}
\NormalTok{state }\OperatorTok{=}\NormalTok{ random\_state}\OperatorTok{();}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{T }\OperatorTok{\textgreater{}}\NormalTok{ T\_min}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    next }\OperatorTok{=}\NormalTok{ neighbor}\OperatorTok{(}\NormalTok{state}\OperatorTok{);}
\NormalTok{    dE }\OperatorTok{=}\NormalTok{ cost}\OperatorTok{(}\NormalTok{next}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ cost}\OperatorTok{(}\NormalTok{state}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dE }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ exp}\OperatorTok{({-}}\NormalTok{dE}\OperatorTok{/}\NormalTok{T}\OperatorTok{)} \OperatorTok{\textgreater{}}\NormalTok{ rand\_uniform}\OperatorTok{())}
\NormalTok{        state }\OperatorTok{=}\NormalTok{ next}\OperatorTok{;}
\NormalTok{    T }\OperatorTok{*=}\NormalTok{ alpha}\OperatorTok{;} \CommentTok{// cooling rate}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Strengths: escapes local minima Weakness: sensitive to cooling schedule

\subsubsection{4. Particle Swarm Optimization
(PSO)}\label{particle-swarm-optimization-pso}

Inspired by bird flocking. Each particle adjusts velocity based on:

\begin{itemize}
\tightlist
\item
  Its own best position- The global best found \[
  v_i \leftarrow w v_i + c_1 r_1 (p_i - x_i) + c_2 r_2 (g - x_i)
  \]
\end{itemize}

\[
x_i \leftarrow x_i + v_i
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each particle i}\OperatorTok{:}
\NormalTok{    v}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ w}\OperatorTok{*}\NormalTok{v}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ c1}\OperatorTok{*}\NormalTok{r1}\OperatorTok{*(}\NormalTok{pbest}\OperatorTok{[}\NormalTok{i}\OperatorTok{]{-}}\NormalTok{x}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{+}\NormalTok{ c2}\OperatorTok{*}\NormalTok{r2}\OperatorTok{*(}\NormalTok{gbest}\OperatorTok{{-}}\NormalTok{x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\NormalTok{    x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ v}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{    update\_best}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Strengths: continuous domains, easy Weakness: premature convergence

\subsubsection{5. Ant Colony Optimization
(ACO)}\label{ant-colony-optimization-aco}

Inspired by ant foraging, ants deposit pheromones on paths. The stronger
the trail, the more likely others follow.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize pheromone on all edges
\item
  Each ant builds a solution (prob. ∝ pheromone)
\item
  Evaluate paths
\item
  Evaporate pheromone
\item
  Reinforce good paths
\end{enumerate}

\[
\tau_{ij} \leftarrow (1 - \rho)\tau_{ij} + \sum_k \Delta\tau_{ij}^k
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each iteration}\OperatorTok{:}
    \ControlFlowTok{for}\NormalTok{ each ant}\OperatorTok{:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ build\_solution}\OperatorTok{(}\NormalTok{pheromone}\OperatorTok{);}
\NormalTok{        score }\OperatorTok{=}\NormalTok{ evaluate}\OperatorTok{(}\NormalTok{path}\OperatorTok{);}
\NormalTok{    evaporate}\OperatorTok{(}\NormalTok{pheromone}\OperatorTok{);}
\NormalTok{    deposit}\OperatorTok{(}\NormalTok{pheromone}\OperatorTok{,}\NormalTok{ best\_paths}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Strengths: combinatorial problems (TSP) Weakness: parameter tuning,
slower convergence

\subsubsection{6. Comparing the Four}\label{comparing-the-four}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0870}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2029}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2754}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4348}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Inspiration
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GA & Evolution & Discrete search & Selection, crossover, mutation \\
SA & Thermodynamics & Local optima escape & Cooling + randomness \\
PSO & Swarm behavior & Continuous search & Local + global attraction \\
ACO & Ant foraging & Graph paths & Pheromone reinforcement \\
\end{longtable}

\subsubsection{7. Design Patterns}\label{design-patterns}

Common metaheuristic pattern:

\begin{itemize}
\tightlist
\item
  Represent solution- Define fitness / cost function- Define neighbor /
  mutation operators- Balance randomness and greediness Tuning
  parameters often matters more than equations.
\end{itemize}

\subsubsection{8. Hybrid Metaheuristics}\label{hybrid-metaheuristics}

Combine strengths:

\begin{itemize}
\tightlist
\item
  GA + SA: evolve population, fine-tune locally- PSO + DE: use swarm +
  differential evolution- ACO + Local Search: reinforce with
  hill-climbing These hybrids often outperform single methods.
\end{itemize}

\subsubsection{9. Common Pitfalls}\label{common-pitfalls-1}

\begin{itemize}
\tightlist
\item
  Poor representation → weak search- Over-exploitation → stuck in local
  optima- Bad parameters → chaotic or stagnant behavior Always visualize
  progress (fitness over time).
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-95}

Metaheuristics give us adaptive intelligence, searching without
gradients, equations, or complete knowledge. They reflect nature's way
of solving complex puzzles: iterate, adapt, survive.

\begin{quote}
``Optimization is not about perfection. It's about progress guided by
curiosity.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-95}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Simulated Annealing for the Traveling Salesman Problem.
\item
  Create a Genetic Algorithm for knapsack optimization.
\item
  Tune PSO parameters to fit a function \(f(x) = x^2 + 10\sin x\).
\item
  Compare ACO paths for TSP at different evaporation rates.
\end{enumerate}

\subsection{97. Reinforcement Learning (Q-learning, Policy
Gradients)}\label{reinforcement-learning-q-learning-policy-gradients}

Reinforcement Learning (RL) is about learning through interaction , an
agent explores an environment, takes actions, and learns from rewards.
Unlike supervised learning (where correct labels are given), RL learns
what to do by trial and error.

This section introduces two core approaches:

\begin{itemize}
\tightlist
\item
  Q-learning (value-based)- Policy Gradient (policy-based)
\end{itemize}

\subsubsection{1. The Reinforcement Learning
Setting}\label{the-reinforcement-learning-setting}

An RL problem is modeled as a Markov Decision Process (MDP):

\begin{itemize}
\tightlist
\item
  States \(S\)
\item
  Actions \(A\)
\item
  Transition \(P(s' \mid s, a)\)
\item
  Reward \(R(s, a)\)
\item
  Discount factor \(\gamma\)
\end{itemize}

The agent's goal is to find a policy \(\pi(a \mid s)\) that maximizes
expected return:

\[
G_t = \sum_{k=0}^\infty \gamma^k R_{t+k+1}
\]

\subsubsection{2. Value Functions}\label{value-functions}

The value function measures how good a state (or state-action pair) is.

\begin{itemize}
\item
  State-value: \[
  V^\pi(s) = \mathbb{E}_\pi[G_t | S_t = s]
  \]
\item
  Action-value (Q-function): \[
  Q^\pi(s, a) = \mathbb{E}_\pi[G_t | S_t = s, A_t = a]
  \]
\end{itemize}

\subsubsection{3. Bellman Equation}\label{bellman-equation}

The Bellman equation relates a state's value to its neighbors:

\[
Q^*(s,a) = R(s,a) + \gamma \max_{a'} Q^*(s',a')
\]

This recursive definition drives value iteration and Q-learning.

\subsubsection{4. Q-Learning}\label{q-learning}

Q-learning learns the optimal action-value function off-policy
(independent of behavior policy):

Update Rule: \[
Q(s,a) \leftarrow Q(s,a) + \alpha \big[ r + \gamma \max_{a'} Q(s',a') - Q(s,a) \big]
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Q}\OperatorTok{[}\NormalTok{s}\OperatorTok{][}\NormalTok{a}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ alpha }\OperatorTok{*} \OperatorTok{(}\NormalTok{r }\OperatorTok{+}\NormalTok{ gamma }\OperatorTok{*}\NormalTok{ max}\OperatorTok{(}\NormalTok{Q}\OperatorTok{[}\NormalTok{s\_next}\OperatorTok{])} \OperatorTok{{-}}\NormalTok{ Q}\OperatorTok{[}\NormalTok{s}\OperatorTok{][}\NormalTok{a}\OperatorTok{]);}
\NormalTok{s }\OperatorTok{=}\NormalTok{ s\_next}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Repeat while exploring (e.g., \(\varepsilon\)-greedy):

\begin{itemize}
\tightlist
\item
  With probability \(\varepsilon\), choose a random action
\item
  With probability \(1 - \varepsilon\), choose the best action
\end{itemize}

Over time, \(Q\) converges to \(Q^*\).

\subsubsection{5. Exploration vs
Exploitation}\label{exploration-vs-exploitation}

RL is a balancing act:

\begin{itemize}
\item
  Exploration: try new actions to gather knowledge- Exploitation: use
  current best knowledge to maximize reward Strategies:
\item
  ε-greedy- Softmax action selection- Upper Confidence Bound (UCB)
\end{itemize}

\subsubsection{6. Policy Gradient
Methods}\label{policy-gradient-methods}

Instead of learning Q-values, learn the policy directly. Represent
policy with parameters \(\theta\):

\[
\pi_\theta(a|s) = P(a | s; \theta)
\]

Goal: maximize expected return \[
J(\theta) = \mathbb{E}*{\pi*\theta}[G_t]
\]

Gradient ascent update: \[
\theta \leftarrow \theta + \alpha \nabla_\theta J(\theta)
\]

REINFORCE Algorithm: \[
\nabla_\theta J(\theta) = \mathbb{E}\big[ G_t \nabla_\theta \log \pi_\theta(a_t|s_t) \big]
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OperatorTok{+=}\NormalTok{ alpha }\OperatorTok{*}\NormalTok{ G\_t }\OperatorTok{*}\NormalTok{ grad\_logpi}\OperatorTok{(}\NormalTok{a\_t}\OperatorTok{,}\NormalTok{ s\_t}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Actor-Critic
Architecture}\label{actor-critic-architecture}

Combines policy gradient (actor) + value estimation (critic).

\begin{itemize}
\tightlist
\item
  Actor: updates policy- Critic: estimates value (baseline) Update: \[
  \theta \leftarrow \theta + \alpha_\theta \delta_t \nabla_\theta \log \pi_\theta(a_t|s_t)
  \]
\end{itemize}

\[
w \leftarrow w + \alpha_w \delta_t \nabla_w V_w(s_t)
\]

with TD error: \[
\delta_t = r + \gamma V(s') - V(s)
\]

\subsubsection{8. Comparing Methods}\label{comparing-methods-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1967}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1148}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2131}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0492}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Learns
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
On/Off Policy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Continuous?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Q-learning & Value-based & Q(s, a) & Off-policy & No & \\
Policy Gradient & Policy-based & π(a & s) & On-policy & Yes \\
Actor-Critic & Hybrid & Both & On-policy & Yes & \\
\end{longtable}

\subsubsection{9. Extensions}\label{extensions}

\begin{itemize}
\tightlist
\item
  Deep Q-Networks (DQN): use neural nets for Q(s, a)- PPO / A3C:
  advanced actor-critic methods- TD(λ): tradeoff between MC and TD
  learning- Double Q-learning: reduce overestimation- Entropy
  regularization: encourage exploration
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-96}

Reinforcement learning powers autonomous agents, game AIs, and control
systems. It's the foundation of AlphaGo, robotics control, and adaptive
decision systems.

\begin{quote}
``An agent learns not from instruction but from experience.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-96}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Q-learning for a grid-world maze.
\item
  Add ε-greedy exploration.
\item
  Visualize the learned policy.
\item
  Try REINFORCE with a simple policy (e.g.~softmax over actions).
\item
  Compare convergence of Q-learning vs Policy Gradient.
\end{enumerate}

\subsection{98. Approximation and Online
Algorithms}\label{approximation-and-online-algorithms}

In the real world, we often can't wait for a perfect solution , data
arrives on the fly, or the problem is too hard to solve exactly. That's
where approximation and online algorithms shine. They aim for
good-enough results, fast and adaptively, under uncertainty.

\subsubsection{1. The Big Picture}\label{the-big-picture-1}

\begin{itemize}
\tightlist
\item
  Approximation algorithms: Solve NP-hard problems with provable
  bounds.- Online algorithms: Make immediate decisions without knowing
  the future. Both trade optimality for efficiency or adaptability.
\end{itemize}

\subsubsection{2. Approximation
Algorithms}\label{approximation-algorithms}

An approximation algorithm finds a solution within a factor \(\rho\) of
the optimal.

If ( C ) is cost of the algorithm, and \(C^*\) is optimal cost:

\[
\rho = \max\left(\frac{C}{C^*}, \frac{C^*}{C}\right)
\]

Example: \(\rho = 2\) → solution at most twice worse than optimal.

\subsubsection{3. Example: Vertex Cover}\label{example-vertex-cover}

Problem: Given graph ( G(V,E) ), choose smallest set of vertices
covering all edges.

Algorithm (2-approximation):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize cover = ∅
\item
  While edges remain:

  \begin{itemize}
  \tightlist
  \item
    Pick any edge (u, v) - Add both u, v to cover - Remove all edges
    incident on u or v Guarantee: At most 2× optimal size.
  \end{itemize}
\end{enumerate}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cover }\OperatorTok{=} \OperatorTok{\{\};}
\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{edges}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
    \OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{)} \OperatorTok{=}\NormalTok{ edges}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{    cover}\OperatorTok{.}\NormalTok{add}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
\NormalTok{    cover}\OperatorTok{.}\NormalTok{add}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{    remove\_incident\_edges}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Example: Metric TSP (Triangle
Inequality)}\label{example-metric-tsp-triangle-inequality}

Algorithm (Christofides):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find MST
\item
  Find odd-degree vertices
\item
  Find min perfect matching
\item
  Combine + shortcut to get tour
\end{enumerate}

Guarantee: ≤ 1.5 × optimal.

\subsubsection{5. Greedy Approximation: Set
Cover}\label{greedy-approximation-set-cover}

Goal: Cover universe ( U ) with minimum sets \(S_i\).

Greedy Algorithm: Pick set covering most uncovered elements each time.
Guarantee: \(H_n \approx \ln n\) factor approximation.

\subsubsection{6. Online Algorithms}\label{online-algorithms}

Online algorithms must decide now, before future input is known.

Goal: Minimize competitive ratio:

\[
\text{CR} = \max_{\text{input}} \frac{\text{Cost}*{\text{online}}}{\text{Cost}*{\text{optimal offline}}}
\]

Lower CR → better adaptability.

\subsubsection{7. Classic Example: Online
Paging}\label{classic-example-online-paging}

You have k pages in cache, sequence of page requests.

\begin{itemize}
\item
  If page in cache → hit- Else → miss, must evict one page Strategies:
\item
  LRU (Least Recently Used): evict oldest- FIFO: evict first loaded-
  Random: pick randomly Competitive Ratio:
\item
  LRU: ≤ ( k )- Random: ≤ ( 2k-1 )
\end{itemize}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cache }\OperatorTok{=}\NormalTok{ LRUCache}\OperatorTok{(}\NormalTok{k}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{page in requests}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{cache}\OperatorTok{.}\NormalTok{contains}\OperatorTok{(}\NormalTok{page}\OperatorTok{))}
\NormalTok{        cache}\OperatorTok{.}\NormalTok{evict\_oldest}\OperatorTok{();}
\NormalTok{    cache}\OperatorTok{.}\NormalTok{add}\OperatorTok{(}\NormalTok{page}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Online Bipartite Matching
(Karp-Vazirani-Vazirani)}\label{online-bipartite-matching-karp-vazirani-vazirani}

Given offline set U and online set V (arrives one by one), match
greedily. Competitive ratio: \(1 - \frac{1}{e}\)

Used in ad allocation and resource assignment.

\subsubsection{9. Approximation + Online
Together}\label{approximation-online-together}

Modern algorithms blend both:

\begin{itemize}
\tightlist
\item
  Streaming algorithms: One pass, small memory (Count-Min, reservoir
  sampling)- Online learning: Update models incrementally (SGD,
  perceptron)- Approximate dynamic programming: RL and heuristic search
  These are approximate online solvers , both quick and adaptive.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-97}

Approximation algorithms give us provable near-optimal answers. Online
algorithms give us real-time adaptivity. Together, they model
intelligence under limits , when time and information are scarce.

\begin{quote}
``Sometimes, good and on time beats perfect and late.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-97}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement 2-approx vertex cover on a small graph.
\item
  Simulate online paging with LRU vs Random.
\item
  Build a greedy set cover solver.
\item
  Measure competitive ratio on test sequences.
\item
  Combine ideas: streaming + approximation for big data filtering.
\end{enumerate}

\subsection{99. Fairness, Causal Inference, and Robust
Optimization}\label{fairness-causal-inference-and-robust-optimization}

As algorithms increasingly shape decisions , from hiring to lending to
healthcare , we must ensure they're fair, causally sound, and robust to
uncertainty. This section blends ideas from ethics, statistics, and
optimization to make algorithms not just efficient, but responsible and
reliable.

\subsubsection{1. Why Fairness Matters}\label{why-fairness-matters}

Machine learning systems often inherit biases from data. Without
intervention, they can amplify inequality or discrimination.

Fairness-aware algorithms explicitly measure and correct these effects.

Common sources of bias:

\begin{itemize}
\tightlist
\item
  Historical bias (biased data)- Measurement bias (imprecise features)-
  Selection bias (skewed samples) The goal: equitable treatment across
  sensitive groups (gender, race, region, etc.)
\end{itemize}

\subsubsection{2. Formal Fairness
Criteria}\label{formal-fairness-criteria}

Several fairness notions exist, often conflicting:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1705}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2636}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3721}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0465}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1473}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Criterion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Demographic Parity & ( P\(\hat{Y}=1                      | A=a\) =
P\(\hat{Y}=1                               | A=b\) ) & Equal positive
rate & & \\
Equal Opportunity & Equal true positive rates & Same recall for all
groups & & \\
Equalized Odds & Equal TPR \& FPR & Balanced errors & & \\
Calibration & Same predicted probability meaning & If model says 70\%,
all groups should achieve 70\% & & \\
\end{longtable}

No single measure fits all , fairness depends on context and trade-offs.

\subsubsection{3. Algorithmic Fairness
Techniques}\label{algorithmic-fairness-techniques}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Pre-processing Rebalance or reweight data before training. Example:
  reweighing, sampling.
\item
  In-processing Add fairness constraints to loss function. Example:
  adversarial debiasing.
\item
  Post-processing Adjust predictions after training. Example: threshold
  shifting.
\end{enumerate}

Tiny Code (Adversarial Debiasing Skeleton)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ x, a, y }\KeywordTok{in}\NormalTok{ data:}
\NormalTok{    y\_pred }\OperatorTok{=}\NormalTok{ model(x)}
\NormalTok{    loss\_main }\OperatorTok{=}\NormalTok{ loss\_fn(y\_pred, y)}
\NormalTok{    loss\_adv }\OperatorTok{=}\NormalTok{ adv\_fn(y\_pred, a)}
\NormalTok{    loss\_total }\OperatorTok{=}\NormalTok{ loss\_main }\OperatorTok{{-}}\NormalTok{ λ }\OperatorTok{*}\NormalTok{ loss\_adv}
\NormalTok{    update(loss\_total)}
\end{Highlighting}
\end{Shaded}

Here, the adversary tries to predict sensitive attribute, encouraging
invariance.

\subsubsection{4. Causal Inference
Basics}\label{causal-inference-basics}

Correlation ≠ causation. To reason about fairness and robustness, we
need causal understanding , what \emph{would} happen if we changed
something.

Causal inference models relationships via Directed Acyclic Graphs
(DAGs):

\begin{itemize}
\tightlist
\item
  Nodes: variables- Edges: causal influence
\end{itemize}

\subsubsection{5. Counterfactual
Reasoning}\label{counterfactual-reasoning}

A counterfactual asks:

\begin{quote}
``What would the outcome be if we intervened differently?''
\end{quote}

Formally: \[
P(Y_{do(X=x)})
\]

Used in:

\begin{itemize}
\tightlist
\item
  Fairness (counterfactual fairness)- Policy evaluation- Robust decision
  making
\end{itemize}

\subsubsection{6. Counterfactual
Fairness}\label{counterfactual-fairness}

An algorithm is counterfactually fair if prediction stays the same under
hypothetical changes to sensitive attributes.

\[
\hat{Y}*{A \leftarrow a}(U) = \hat{Y}*{A \leftarrow a'}(U)
\]

This requires causal models , not just data.

\subsubsection{7. Robust Optimization}\label{robust-optimization}

In uncertain environments, we want solutions that hold up under
worst-case conditions.

Formulation: \[
\min_x \max_{\xi \in \Xi} f(x, \xi)
\]

where \(\Xi\) is the uncertainty set.

Example: Design a portfolio that performs well under varying market
conditions.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ robust\_objective}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{[],}\NormalTok{ Scenario Xi}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ N}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ worst }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\NormalTok{N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        worst }\OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{worst}\OperatorTok{,}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ Xi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]));}
    \ControlFlowTok{return}\NormalTok{ worst}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This searches for a solution minimizing worst-case loss.

\subsubsection{8. Distributional
Robustness}\label{distributional-robustness}

Instead of worst-case instances, protect against worst-case
distributions:

\[
\min_\theta \sup_{Q \in \mathcal{B}(P)} \mathbb{E}_{x \sim Q}[L(\theta, x)]
\]

Used in adversarial training and domain adaptation.

Example: Add noise or perturbations to improve resilience:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_adv }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+}\NormalTok{ ε }\OperatorTok{*}\NormalTok{ sign(grad(loss, x))}
\end{Highlighting}
\end{Shaded}

\subsubsection{9. Balancing Fairness, Causality, and
Robustness}\label{balancing-fairness-causality-and-robustness}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1408}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4930}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3662}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Goal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fairness & Parity, Adversarial, Counterfactual & Competing
definitions \\
Causality & DAGs, do-calculus, SCMs & Identifying true structure \\
Robustness & Min-max, DRO, Adversarial Training & Trade-off with
accuracy \\
\end{longtable}

Real-world design involves balancing trade-offs.

Sometimes improving fairness reduces accuracy, or robustness increases
conservatism.

\subsubsection{10. Why It Matters}\label{why-it-matters-98}

Algorithms don't exist in isolation , they affect people. Embedding
fairness, causality, and robustness ensures systems are trustworthy,
interpretable, and just.

\begin{quote}
``The goal is not just intelligent algorithms , but responsible ones.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-98}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train a simple classifier on biased data.
\item
  Apply reweighing or adversarial debiasing.
\item
  Draw a causal DAG of your data features.
\item
  Compute counterfactual fairness for a sample.
\item
  Implement a robust loss using adversarial perturbations.
\end{enumerate}

\subsection{100. AI Planning, Search, and Learning
Systems}\label{ai-planning-search-and-learning-systems}

AI systems are not just pattern recognizers , they are decision makers.
They plan, search, and learn in structured environments, choosing
actions that lead to long-term goals. This section explores how modern
AI combines planning, search, and learning to solve complex tasks.

\subsubsection{1. What Is AI Planning?}\label{what-is-ai-planning}

AI planning is about finding a sequence of actions that transforms an
initial state into a goal state.

Formally, a planning problem consists of:

\begin{itemize}
\tightlist
\item
  States ( S )- Actions ( A )- Transition function ( T(s, a) \to s' )-
  Goal condition \(G \subseteq S\)- Cost function ( c(a) ) The
  objective: Find a plan \(\pi = [a_1, a_2, \ldots, a_n]\) minimizing
  total cost or maximizing reward.
\end{itemize}

\subsubsection{2. Search-Based Planning}\label{search-based-planning}

At the heart of planning lies search. Search explores possible action
sequences, guided by heuristics.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Type & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS & Uninformed & Deep exploration, no guarantee \\
BFS & Uninformed & Finds shortest path \\
Dijkstra & Weighted & Optimal if costs ≥ 0 \\
A* & Heuristic & Combines cost + heuristic \\
\end{longtable}

A* Search Formula: \[
f(n) = g(n) + h(n)
\] where:

\begin{itemize}
\tightlist
\item
  ( g(n) ): cost so far- ( h(n) ): heuristic estimate to goal If ( h )
  is admissible, A* is optimal.
\end{itemize}

Tiny Code (A* Skeleton)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{priority\_queue}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{\textgreater{}}\NormalTok{ open}\OperatorTok{;}
\NormalTok{g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{open}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{start}\OperatorTok{,}\NormalTok{ h}\OperatorTok{(}\NormalTok{start}\OperatorTok{)\});}

\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{open}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
\NormalTok{    n }\OperatorTok{=}\NormalTok{ open}\OperatorTok{.}\NormalTok{pop\_min}\OperatorTok{();}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{goal}\OperatorTok{(}\NormalTok{n}\OperatorTok{))} \ControlFlowTok{break}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{a in actions}\OperatorTok{(}\NormalTok{n}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ step}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ a}\OperatorTok{);}
\NormalTok{        cost }\OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{+}\NormalTok{ c}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ a}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cost }\OperatorTok{\textless{}}\NormalTok{ g}\OperatorTok{[}\NormalTok{s}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            g}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=}\NormalTok{ cost}\OperatorTok{;}
\NormalTok{            f}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{+}\NormalTok{ h}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
\NormalTok{            open}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{s}\OperatorTok{,}\NormalTok{ f}\OperatorTok{[}\NormalTok{s}\OperatorTok{]\});}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Heuristics and
Admissibility}\label{heuristics-and-admissibility}

A heuristic ( h(s) ) estimates distance to the goal.

\begin{itemize}
\item
  Admissible: never overestimates- Consistent: satisfies triangle
  inequality Examples:
\item
  Manhattan distance (grids)- Euclidean distance (geometry)- Pattern
  databases (puzzles) Good heuristics = faster convergence.
\end{itemize}

\subsubsection{4. Classical Planning
(STRIPS)}\label{classical-planning-strips}

In symbolic AI, states are represented by facts (predicates), and
actions have preconditions and effects.

Example:

\begin{verbatim}
Action: Move(x, y)
Precondition: At(x), Clear(y)
Effect: ¬At(x), At(y)
\end{verbatim}

Search happens in logical state space.

Planners:

\begin{itemize}
\tightlist
\item
  Forward search (progression)- Backward search (regression)- Heuristic
  planners (FF, HSP)
\end{itemize}

\subsubsection{5. Hierarchical Planning}\label{hierarchical-planning}

Break complex goals into subgoals.

\begin{itemize}
\tightlist
\item
  HTN (Hierarchical Task Networks): Define high-level tasks broken into
  subtasks.
\end{itemize}

Example: ``Make dinner'' → {[}Cook rice, Stir-fry vegetables, Set
table{]}

Hierarchy makes planning modular and interpretable.

\subsubsection{6. Probabilistic Planning}\label{probabilistic-planning}

When actions are uncertain:

\begin{itemize}
\tightlist
\item
  MDPs: full observability, stochastic transitions- POMDPs: partial
  observability Use value iteration, policy iteration, or Monte Carlo
  planning.
\end{itemize}

\subsubsection{7. Learning to Plan}\label{learning-to-plan}

Combine learning with search:

\begin{itemize}
\tightlist
\item
  Learned heuristics: neural networks approximate ( h(s) )-
  AlphaZero-style planning: learn value + policy, guide tree search-
  Imitation learning: mimic expert demonstrations This bridges classical
  AI and modern ML.
\end{itemize}

Tiny Code (Learning-Guided A*)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f }\OperatorTok{=}\NormalTok{ g }\OperatorTok{+}\NormalTok{ alpha }\OperatorTok{*}\NormalTok{ learned\_heuristic(s)}
\end{Highlighting}
\end{Shaded}

Neural net learns ( h\_\theta(s) ) from solved examples.

\subsubsection{8. Integrated Systems}\label{integrated-systems}

Modern AI stacks combine:

\begin{itemize}
\item
  Search (planning backbone)- Learning (policy, heuristic, model)-
  Simulation (data generation) Examples:
\item
  AlphaZero: self-play + MCTS + neural nets- MuZero: learns model +
  value + policy jointly- Large Language Agents: use reasoning + memory
  + search
\end{itemize}

\subsubsection{9. Real-World
Applications}\label{real-world-applications}

\begin{itemize}
\tightlist
\item
  Robotics: motion planning, pathfinding- Games: Go, Chess, strategy
  games- Logistics: route optimization- Autonomy: drones, vehicles, AI
  assistants- Synthesis: program and query generation Each blends
  symbolic reasoning and statistical learning.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-99}

Planning, search, and learning form the triad of intelligence:

\begin{itemize}
\tightlist
\item
  Search explores possibilities- Planning sequences actions toward
  goals- Learning adapts heuristics from experience Together, they power
  systems that think, adapt, and act.
\end{itemize}

\begin{quote}
``Intelligence is not just knowing , it is choosing wisely under
constraints.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-99}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement A* search on a grid maze.
\item
  Add a Manhattan heuristic.
\item
  Extend to probabilistic transitions (simulate noise).
\item
  Build a simple planner with preconditions and effects.
\item
  Train a neural heuristic to guide search on puzzles.
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{The Plan}\label{the-plan}

\section{Chapter 1. Foundations of
Algorithms}\label{chapter-1.-foundations-of-algorithms-2}

\subsection{1. What Is an Algorithm?}\label{what-is-an-algorithm-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0256}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6410}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Euclid's GCD & Oldest known algorithm for greatest common divisor \\
2 & Sieve of Eratosthenes & Generate primes efficiently \\
3 & Binary Search & Divide and conquer search \\
4 & Exponentiation by Squaring & Fast power computation \\
5 & Long Division & Classic step-by-step arithmetic \\
6 & Modular Addition Algorithm & Wrap-around arithmetic \\
7 & Base Conversion Algorithm & Convert between number systems \\
8 & Factorial Computation & Recursive and iterative approaches \\
9 & Fibonacci Sequence & Recursive vs.~dynamic computation \\
10 & Tower of Hanoi & Recursive problem-solving pattern \\
\end{longtable}

\subsection{2. Measuring Time and
Space}\label{measuring-time-and-space-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0317}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4127}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5556}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
11 & Counting Operations & Manual step-counting for complexity \\
12 & Loop Analysis & Evaluate time cost of loops \\
13 & Recurrence Expansion & Analyze recursive costs \\
14 & Amortized Analysis & Average per-operation cost \\
15 & Space Counting & Stack and heap tracking \\
16 & Memory Footprint Estimator & Track per-variable usage \\
17 & Time Complexity Table & Map O(1)\ldots O(n²)\ldots O(2ⁿ) \\
18 & Space-Time Tradeoff & Cache vs.~recomputation \\
19 & Profiling Algorithm & Empirical time measurement \\
20 & Benchmarking Framework & Compare algorithm performance \\
\end{longtable}

\subsection{3. Big-O, Big-Theta,
Big-Omega}\label{big-o-big-theta-big-omega-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0290}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4348}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5362}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
21 & Growth Rate Comparator & Compare asymptotic behaviors \\
22 & Dominant Term Extractor & Simplify runtime expressions \\
23 & Limit-Based Complexity Test & Using limits for asymptotics \\
24 & Summation Simplifier & Sum of arithmetic/geometric sequences \\
25 & Recurrence Tree Method & Visualize recursive costs \\
26 & Master Theorem Evaluator & Solve T(n) recurrences \\
27 & Big-Theta Proof Builder & Bounding upper and lower limits \\
28 & Big-Omega Case Finder & Best-case scenario analysis \\
29 & Empirical Complexity Estimator & Measure via doubling
experiments \\
30 & Complexity Class Identifier & Match runtime to known class \\
\end{longtable}

\subsection{4. Algorithmic Paradigms (Greedy, Divide and Conquer,
DP)}\label{algorithmic-paradigms-greedy-divide-and-conquer-dp-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
31 & Greedy Coin Change & Local optimal step-by-step \\
32 & Huffman Coding & Greedy compression tree \\
33 & Merge Sort & Divide and conquer sort \\
34 & Binary Search & Divide and conquer search \\
35 & Karatsuba Multiplication & Recursive divide \& conquer \\
36 & Matrix Chain Multiplication & DP with substructure \\
37 & Longest Common Subsequence & Classic DP problem \\
38 & Rod Cutting & DP optimization \\
39 & Activity Selection & Greedy scheduling \\
40 & Optimal Merge Patterns & Greedy file merging \\
\end{longtable}

\subsection{5. Recurrence Relations}\label{recurrence-relations-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
41 & Linear Recurrence Solver & Closed-form for linear recurrences \\
42 & Master Theorem & Divide-and-conquer complexity \\
43 & Substitution Method & Inductive proof approach \\
44 & Iteration Method & Expand recurrence step-by-step \\
45 & Generating Functions & Transform recurrences \\
46 & Matrix Exponentiation & Solve linear recurrences fast \\
47 & Recurrence to DP Table & Tabulation approach \\
48 & Divide \& Combine Template & Convert recurrence into algorithm \\
49 & Memoized Recursive Solver & Store overlapping results \\
50 & Characteristic Polynomial & Solve homogeneous recurrence \\
\end{longtable}

\subsection{6. Searching Basics}\label{searching-basics-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
51 & Linear Search & Sequential element scan \\
52 & Binary Search & Midpoint halving \\
53 & Jump Search & Block skip linear \\
54 & Exponential Search & Doubling step size \\
55 & Interpolation Search & Estimate position by value \\
56 & Ternary Search & Divide into thirds \\
57 & Fibonacci Search & Golden ratio search \\
58 & Sentinel Search & Early termination optimization \\
59 & Bidirectional Search & Meet-in-the-middle \\
60 & Search in Rotated Array & Adapted binary search \\
\end{longtable}

\subsection{7. Sorting Basics}\label{sorting-basics-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
61 & Bubble Sort & Adjacent swap sort \\
62 & Selection Sort & Find minimum each pass \\
63 & Insertion Sort & Incremental build sort \\
64 & Shell Sort & Gap-based insertion \\
65 & Merge Sort & Divide-and-conquer \\
66 & Quick Sort & Partition-based \\
67 & Heap Sort & Binary heap order \\
68 & Counting Sort & Integer key distribution \\
69 & Radix Sort & Digit-by-digit \\
70 & Bucket Sort & Group into ranges \\
\end{longtable}

\subsection{8. Data Structures
Overview}\label{data-structures-overview-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
71 & Stack Push/Pop & LIFO operations \\
72 & Queue Enqueue/Dequeue & FIFO operations \\
73 & Singly Linked List & Linear node chain \\
74 & Doubly Linked List & Bidirectional traversal \\
75 & Hash Table Insertion & Key-value indexing \\
76 & Binary Search Tree Insert & Ordered node placement \\
77 & Heapify & Build heap in-place \\
78 & Union-Find Operations & Disjoint-set management \\
79 & Graph Adjacency List Build & Sparse representation \\
80 & Trie Insertion/Search & Prefix tree for strings \\
\end{longtable}

\subsection{9. Graphs and Trees
Overview}\label{graphs-and-trees-overview-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
81 & DFS Traversal & Depth-first exploration \\
82 & BFS Traversal & Level-order exploration \\
83 & Topological Sort & DAG ordering \\
84 & Minimum Spanning Tree & Kruskal/Prim overview \\
85 & Dijkstra's Shortest Path & Weighted graph shortest route \\
86 & Bellman-Ford & Handle negative edges \\
87 & Floyd-Warshall & All-pairs shortest path \\
88 & Union-Find for MST & Edge grouping \\
89 & Tree Traversals & Inorder, Preorder, Postorder \\
90 & LCA (Lowest Common Ancestor) & Common node in tree \\
\end{longtable}

\subsection{10. Algorithm Design
Patterns}\label{algorithm-design-patterns-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
91 & Brute Force & Try all possibilities \\
92 & Greedy Choice & Local optimum per step \\
93 & Divide and Conquer & Break and merge \\
94 & Dynamic Programming & Reuse subproblems \\
95 & Backtracking & Explore with undo \\
96 & Branch and Bound & Prune search space \\
97 & Randomized Algorithm & Inject randomness \\
98 & Approximation Algorithm & Near-optimal solution \\
99 & Online Algorithm & Step-by-step decision \\
100 & Hybrid Strategy & Combine paradigms \\
\end{longtable}

\section{Chapter 2. Sorting and
Searching}\label{chapter-2.-sorting-and-searching-2}

\subsection{11. Elementary Sorting (Bubble, Insertion,
Selection)}\label{elementary-sorting-bubble-insertion-selection-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
101 & Bubble Sort & Swap adjacent out-of-order elements \\
102 & Improved Bubble Sort & Stop early if already sorted \\
103 & Cocktail Shaker Sort & Bidirectional bubble pass \\
104 & Selection Sort & Select smallest element each pass \\
105 & Double Selection Sort & Find both min and max each pass \\
106 & Insertion Sort & Insert each element into correct spot \\
107 & Binary Insertion Sort & Use binary search for position \\
108 & Gnome Sort & Simple insertion-like with swaps \\
109 & Odd-Even Sort & Parallel-friendly comparison sort \\
110 & Stooge Sort & Recursive quirky educational sort \\
\end{longtable}

\subsection{12. Divide-and-Conquer Sorting (Merge, Quick,
Heap)}\label{divide-and-conquer-sorting-merge-quick-heap-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
111 & Merge Sort & Recursive divide and merge \\
112 & Iterative Merge Sort & Bottom-up non-recursive version \\
113 & Quick Sort & Partition-based recursive sort \\
114 & Hoare Partition Scheme & Classic quicksort partition \\
115 & Lomuto Partition Scheme & Simpler but less efficient \\
116 & Randomized Quick Sort & Avoid worst-case pivot \\
117 & Heap Sort & Heapify + extract max repeatedly \\
118 & 3-Way Quick Sort & Handle duplicates efficiently \\
119 & External Merge Sort & Disk-based merge for large data \\
120 & Parallel Merge Sort & Divide work among threads \\
\end{longtable}

\subsection{13. Counting and Distribution Sorts (Counting, Radix,
Bucket)}\label{counting-and-distribution-sorts-counting-radix-bucket-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5781}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
121 & Counting Sort & Count key occurrences \\
122 & Stable Counting Sort & Preserve order of equals \\
123 & Radix Sort (LSD) & Least significant digit first \\
124 & Radix Sort (MSD) & Most significant digit first \\
125 & Bucket Sort & Distribute into buckets \\
126 & Pigeonhole Sort & Simple bucket variant \\
127 & Flash Sort & Distribution with in-place correction \\
128 & Postman Sort & Stable multi-key sort \\
129 & Address Calculation Sort & Hash-like distribution \\
130 & Spread Sort & Hybrid radix/quick strategy \\
\end{longtable}

\subsection{14. Hybrid Sorts (IntroSort,
Timsort)}\label{hybrid-sorts-introsort-timsort-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
131 & IntroSort & Quick + Heap fallback \\
132 & TimSort & Merge + Insertion + Runs \\
133 & Dual-Pivot QuickSort & Modern quicksort optimization \\
134 & SmoothSort & Heap-like adaptive sort \\
135 & Block Merge Sort & Cache-efficient merge variant \\
136 & Adaptive Merge Sort & Adjusts to partially sorted data \\
137 & PDQSort & Pattern-defeating quicksort \\
138 & WikiSort & Stable in-place merge \\
139 & GrailSort & In-place stable mergesort \\
140 & Adaptive Hybrid Sort & Dynamically selects strategy \\
\end{longtable}

\subsection{15. Special Sorts (Cycle, Gnome, Comb,
Pancake)}\label{special-sorts-cycle-gnome-comb-pancake-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
141 & Cycle Sort & Minimal writes \\
142 & Comb Sort & Shrinking gap bubble \\
143 & Gnome Sort & Insertion-like with swaps \\
144 & Cocktail Sort & Two-way bubble \\
145 & Pancake Sort & Flip-based sorting \\
146 & Bitonic Sort & Parallel network sorting \\
147 & Odd-Even Merge Sort & Sorting network design \\
148 & Sleep Sort & Uses timing as order key \\
149 & Bead Sort & Simulates gravity \\
150 & Bogo Sort & Randomly permute until sorted \\
\end{longtable}

\subsection{16. Linear and Binary
Search}\label{linear-and-binary-search-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
151 & Linear Search & Scan sequentially \\
152 & Linear Search (Sentinel) & Guard element at end \\
153 & Binary Search (Iterative) & Halve interval each loop \\
154 & Binary Search (Recursive) & Halve interval via recursion \\
155 & Binary Search (Lower Bound) & First \textgreater= target \\
156 & Binary Search (Upper Bound) & First \textgreater{} target \\
157 & Exponential Search & Double step size \\
158 & Jump Search & Jump fixed steps then linear \\
159 & Fibonacci Search & Golden-ratio style jumps \\
160 & Uniform Binary Search & Avoid recomputing midpoints \\
\end{longtable}

\subsection{17. Interpolation and Exponential
Search}\label{interpolation-and-exponential-search-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
161 & Interpolation Search & Estimate index by value \\
162 & Recursive Interpolation Search & Divide by estimated midpoint \\
163 & Exponential Search & Double and binary refine \\
164 & Doubling Search & Generic exponential pattern \\
165 & Galloping Search & Used in TimSort merges \\
166 & Unbounded Binary Search & Find bounds dynamically \\
167 & Root-Finding Bisection & Search zero-crossing \\
168 & Golden Section Search & Optimize unimodal function \\
169 & Fibonacci Search (Optimum) & Similar to golden search \\
170 & Jump + Binary Hybrid & Combined probing strategy \\
\end{longtable}

\subsection{18. Selection Algorithms (Quickselect, Median of
Medians)}\label{selection-algorithms-quickselect-median-of-medians-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
171 & Quickselect & Partition-based selection \\
172 & Median of Medians & Deterministic pivot \\
173 & Randomized Select & Random pivot version \\
174 & Binary Search on Answer & Range-based selection \\
175 & Order Statistics Tree & BST with rank queries \\
176 & Tournament Tree Selection & Hierarchical comparison \\
177 & Heap Select (Min-Heap) & Maintain top-k elements \\
178 & Partial QuickSort & Sort partial prefix \\
179 & BFPRT Algorithm & Linear-time selection \\
180 & Kth Largest Stream & Streaming selection \\
\end{longtable}

\subsection{19. Range Searching and Nearest
Neighbor}\label{range-searching-and-nearest-neighbor-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
181 & Binary Search Range & Find lower and upper bounds \\
182 & Segment Tree Query & Sum/min/max over interval \\
183 & Fenwick Tree Query & Efficient prefix sums \\
184 & Interval Tree Search & Overlap queries \\
185 & KD-Tree Search & Spatial nearest neighbor \\
186 & R-Tree Query & Range search in geometry \\
187 & Range Minimum Query (RMQ) & Sparse table approach \\
188 & Mo's Algorithm & Offline query reordering \\
189 & Sweep Line Range Search & Sort + scan technique \\
190 & Ball Tree Nearest Neighbor & Metric-space search \\
\end{longtable}

\subsection{20. Search Optimizations and
Variants}\label{search-optimizations-and-variants-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
191 & Binary Search with Tolerance & For floating values \\
192 & Ternary Search & Unimodal optimization \\
193 & Hash-Based Search & O(1) expected lookup \\
194 & Bloom Filter Lookup & Probabilistic membership \\
195 & Cuckoo Hash Search & Dual-hash relocation \\
196 & Robin Hood Hashing & Equalize probe lengths \\
197 & Jump Consistent Hashing & Stable hash assignment \\
198 & Prefix Search in Trie & Auto-completion lookup \\
199 & Pattern Search in Suffix Array & Fast substring lookup \\
200 & Search in Infinite Array & Dynamic bound finding \\
\end{longtable}

\section{Chapter 3. Data Structures in
Action}\label{chapter-3.-data-structures-in-action-1}

\subsection{21. Arrays, Linked Lists, Stacks,
Queues}\label{arrays-linked-lists-stacks-queues-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0441}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4706}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4853}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
201 & Dynamic Array Resize & Doubling strategy for capacity \\
202 & Circular Array Implementation & Wrap-around indexing \\
203 & Singly Linked List Insert/Delete & Basic node manipulation \\
204 & Doubly Linked List Insert/Delete & Two-way linkage \\
205 & Stack Push/Pop & LIFO structure \\
206 & Queue Enqueue/Dequeue & FIFO structure \\
207 & Deque Implementation & Double-ended queue \\
208 & Circular Queue & Fixed-size queue with wrap-around \\
209 & Stack via Queue & Implement stack using two queues \\
210 & Queue via Stack & Implement queue using two stacks \\
\end{longtable}

\subsection{22. Hash Tables and Variants (Cuckoo, Robin Hood,
Consistent)}\label{hash-tables-and-variants-cuckoo-robin-hood-consistent-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
211 & Hash Table Insertion & Key-value pair with modulo \\
212 & Linear Probing & Resolve collisions sequentially \\
213 & Quadratic Probing & Nonlinear probing sequence \\
214 & Double Hashing & Alternate hash on collision \\
215 & Cuckoo Hashing & Two-table relocation strategy \\
216 & Robin Hood Hashing & Equalize probe length fairness \\
217 & Chained Hash Table & Linked list buckets \\
218 & Perfect Hashing & No-collision mapping \\
219 & Consistent Hashing & Stable distribution across nodes \\
220 & Dynamic Rehashing & Resize on load factor threshold \\
\end{longtable}

\subsection{23. Heaps (Binary, Fibonacci,
Pairing)}\label{heaps-binary-fibonacci-pairing-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
221 & Binary Heap Insert & Bubble-up maintenance \\
222 & Binary Heap Delete & Heapify-down maintenance \\
223 & Build Heap (Heapify) & Bottom-up O(n) build \\
224 & Heap Sort & Extract max repeatedly \\
225 & Min Heap Implementation & For smallest element access \\
226 & Max Heap Implementation & For largest element access \\
227 & Fibonacci Heap Insert/Delete & Amortized efficient operations \\
228 & Pairing Heap Merge & Lightweight mergeable heap \\
229 & Binomial Heap Merge & Merge trees of equal order \\
230 & Leftist Heap Merge & Maintain rank-skewed heap \\
\end{longtable}

\subsection{24. Balanced Trees (AVL, Red-Black, Splay,
Treap)}\label{balanced-trees-avl-red-black-splay-treap-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
231 & AVL Tree Insert & Rotate to maintain balance \\
232 & AVL Tree Delete & Balance after deletion \\
233 & Red-Black Tree Insert & Color fix and rotations \\
234 & Red-Black Tree Delete & Maintain invariants \\
235 & Splay Tree Access & Move accessed node to root \\
236 & Treap Insert & Priority-based rotation \\
237 & Treap Delete & Randomized balance \\
238 & Weight Balanced Tree & Maintain subtree weights \\
239 & Scapegoat Tree Rebuild & Rebalance on size threshold \\
240 & AA Tree & Simplified red-black variant \\
\end{longtable}

\subsection{25. Segment Trees and Fenwick
Trees}\label{segment-trees-and-fenwick-trees-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
241 & Build Segment Tree & Recursive construction \\
242 & Range Sum Query & Recursive or iterative query \\
243 & Range Update & Lazy propagation technique \\
244 & Point Update & Modify single element \\
245 & Fenwick Tree Build & Incremental binary index \\
246 & Fenwick Update & Update cumulative sums \\
247 & Fenwick Query & Prefix sum retrieval \\
248 & Segment Tree Merge & Combine child results \\
249 & Persistent Segment Tree & Maintain history of versions \\
250 & 2D Segment Tree & For matrix range queries \\
\end{longtable}

\subsection{26. Disjoint Set Union
(Union-Find)}\label{disjoint-set-union-union-find-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
251 & Make-Set & Initialize each element \\
252 & Find & Locate representative \\
253 & Union & Merge two sets \\
254 & Union by Rank & Attach smaller tree to larger \\
255 & Path Compression & Flatten tree structure \\
256 & DSU with Rollback & Support undo operations \\
257 & DSU on Tree & Track subtree connectivity \\
258 & Kruskal's MST & Edge selection with DSU \\
259 & Connected Components & Group graph nodes \\
260 & Offline Query DSU & Handle dynamic unions \\
\end{longtable}

\subsection{27. Probabilistic Data Structures (Bloom, Count-Min,
HyperLogLog)}\label{probabilistic-data-structures-bloom-count-min-hyperloglog-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
261 & Bloom Filter Insert & Hash to bit array \\
262 & Bloom Filter Query & Probabilistic membership check \\
263 & Counting Bloom Filter & Support deletions via counters \\
264 & Cuckoo Filter & Space-efficient alternative \\
265 & Count-Min Sketch & Approximate frequency table \\
266 & HyperLogLog & Cardinality estimation \\
267 & Flajolet-Martin & Early probabilistic counting \\
268 & MinHash & Estimate Jaccard similarity \\
269 & Reservoir Sampling & Random k-sample stream \\
270 & Skip Bloom Filter & Range queries on Bloom \\
\end{longtable}

\subsection{28. Skip Lists and B-Trees}\label{skip-lists-and-b-trees-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
271 & Skip List Insert & Probabilistic layered list \\
272 & Skip List Delete & Adjust pointers \\
273 & Skip List Search & Jump via tower levels \\
274 & B-Tree Insert & Split on overflow \\
275 & B-Tree Delete & Merge on underflow \\
276 & B+ Tree Search & Leaf-based sequential scan \\
277 & B+ Tree Range Query & Efficient ordered access \\
278 & B* Tree & More space-efficient variant \\
279 & Adaptive Radix Tree & Byte-wise branching \\
280 & Trie Compression & Path compression optimization \\
\end{longtable}

\subsection{29. Persistent and Functional Data
Structures}\label{persistent-and-functional-data-structures-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
281 & Persistent Stack & Keep all versions \\
282 & Persistent Array & Copy-on-write segments \\
283 & Persistent Segment Tree & Versioned updates \\
284 & Persistent Linked List & Immutable nodes \\
285 & Functional Queue & Amortized reverse lists \\
286 & Finger Tree & Fast concat and split \\
287 & Zipper Structure & Localized mutation \\
288 & Red-Black Persistent Tree & Immutable balanced tree \\
289 & Trie with Versioning & Historical string lookup \\
290 & Persistent Union-Find & Time-travel connectivity \\
\end{longtable}

\subsection{30. Advanced Trees and Range
Queries}\label{advanced-trees-and-range-queries-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
291 & Sparse Table Build & Static range min/max \\
292 & Cartesian Tree & RMQ to LCA transformation \\
293 & Segment Tree Beats & Handle complex queries \\
294 & Merge Sort Tree & Range count queries \\
295 & Wavelet Tree & Rank/select by value \\
296 & KD-Tree & Multidimensional queries \\
297 & Range Tree & Orthogonal range queries \\
298 & Fenwick 2D Tree & Matrix prefix sums \\
299 & Treap Split/Merge & Range-based treap ops \\
300 & Mo's Algorithm on Tree & Offline subtree queries \\
\end{longtable}

\section{Chapter 4. Graph
Algorithms}\label{chapter-4.-graph-algorithms-2}

\subsection{31. Traversals (DFS, BFS, Iterative
Deepening)}\label{traversals-dfs-bfs-iterative-deepening-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4795}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4795}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
301 & Depth-First Search (Recursive) & Explore deeply before
backtracking \\
302 & Depth-First Search (Iterative) & Stack-based exploration \\
303 & Breadth-First Search (Queue) & Level-order traversal \\
304 & Iterative Deepening DFS & Combine depth-limit + completeness \\
305 & Bidirectional BFS & Search from both ends \\
306 & DFS on Grid & Maze solving / connected components \\
307 & BFS on Grid & Shortest path in unweighted graph \\
308 & Multi-Source BFS & Parallel layer expansion \\
309 & Topological Sort (DFS-based) & DAG ordering \\
310 & Topological Sort (Kahn's Algorithm) & In-degree tracking \\
\end{longtable}

\subsection{32. Strongly Connected Components (Tarjan,
Kosaraju)}\label{strongly-connected-components-tarjan-kosaraju-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
311 & Kosaraju's Algorithm & Two-pass DFS \\
312 & Tarjan's Algorithm & Low-link discovery \\
313 & Gabow's Algorithm & Stack pair tracking \\
314 & SCC DAG Construction & Condensed component graph \\
315 & SCC Online Merge & Incremental condensation \\
316 & Component Label Propagation & Iterative labeling \\
317 & Path-Based SCC & DFS with path stack \\
318 & Kosaraju Parallel Version & SCC via parallel DFS \\
319 & Dynamic SCC Maintenance & Add/remove edges \\
320 & SCC for Weighted Graph & Combine with edge weights \\
\end{longtable}

\subsection{33. Shortest Paths (Dijkstra, Bellman-Ford, A*,
Johnson)}\label{shortest-paths-dijkstra-bellman-ford-a-johnson-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
321 & Dijkstra (Binary Heap) & Greedy edge relaxation \\
322 & Dijkstra (Fibonacci Heap) & Improved priority queue \\
323 & Bellman-Ford & Negative weights support \\
324 & SPFA (Queue Optimization) & Faster average Bellman-Ford \\
325 & A* Search & Heuristic-guided path \\
326 & Floyd--Warshall & All-pairs shortest path \\
327 & Johnson's Algorithm & All-pairs using reweighting \\
328 & 0-1 BFS & Deque-based shortest path \\
329 & Dial's Algorithm & Integer weight buckets \\
330 & Multi-Source Dijkstra & Multiple starting points \\
\end{longtable}

\subsection{34. Shortest Path Variants (0--1 BFS, Bidirectional,
Heuristic
A*)}\label{shortest-path-variants-01-bfs-bidirectional-heuristic-a}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4219}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5312}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
331 & 0--1 BFS & For edges with weight 0 or 1 \\
332 & Bidirectional Dijkstra & Meet in the middle \\
333 & A* with Euclidean Heuristic & Spatial shortest path \\
334 & ALT Algorithm & A* landmarks + triangle inequality \\
335 & Contraction Hierarchies & Preprocessing for road networks \\
336 & CH Query Algorithm & Shortcut-based routing \\
337 & Bellman-Ford Queue Variant & Early termination \\
338 & Dijkstra with Early Stop & Halt on target \\
339 & Goal-Directed Search & Restrict expansion direction \\
340 & Yen's K Shortest Paths & Enumerate multiple best paths \\
\end{longtable}

\subsection{35. Minimum Spanning Trees (Kruskal, Prim,
Borůvka)}\label{minimum-spanning-trees-kruskal-prim-borux16fvka-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
341 & Kruskal's Algorithm & Sort edges + union-find \\
342 & Prim's Algorithm (Heap) & Grow MST from seed \\
343 & Prim's Algorithm (Adj Matrix) & Dense graph variant \\
344 & Borůvka's Algorithm & Component merging \\
345 & Reverse-Delete MST & Remove heavy edges \\
346 & MST via Dijkstra Trick & For positive weights \\
347 & Dynamic MST Maintenance & Handle edge updates \\
348 & Minimum Bottleneck Spanning Tree & Max edge minimization \\
349 & Manhattan MST & Grid graph optimization \\
350 & Euclidean MST (Kruskal + Geometry) & Use Delaunay graph \\
\end{longtable}

\subsection{36. Flows (Ford--Fulkerson, Edmonds--Karp,
Dinic)}\label{flows-fordfulkerson-edmondskarp-dinic}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5079}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
351 & Ford--Fulkerson & Augmenting path method \\
352 & Edmonds--Karp & BFS-based Ford--Fulkerson \\
353 & Dinic's Algorithm & Level graph + blocking flow \\
354 & Push--Relabel & Local preflow push \\
355 & Capacity Scaling & Speed-up with capacity tiers \\
356 & Cost Scaling & Min-cost optimization \\
357 & Min-Cost Max-Flow (Bellman-Ford) & Costed augmenting paths \\
358 & Min-Cost Max-Flow (SPFA) & Faster average \\
359 & Circulation with Demands & Generalized flow formulation \\
360 & Successive Shortest Path & Incremental min-cost updates \\
\end{longtable}

\subsection{37. Cuts (Stoer--Wagner, Karger,
Gomory--Hu)}\label{cuts-stoerwagner-karger-gomoryhu}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
361 & Stoer--Wagner Minimum Cut & Global min cut \\
362 & Karger's Randomized Cut & Contract edges randomly \\
363 & Karger--Stein & Recursive randomized cut \\
364 & Gomory--Hu Tree & All-pairs min-cut \\
365 & Max-Flow Min-Cut & Duality theorem application \\
366 & Stoer--Wagner Repeated Phase & Multiple passes \\
367 & Dynamic Min Cut & Maintain on edge update \\
368 & Minimum s--t Cut (Edmonds--Karp) & Based on flow \\
369 & Approximate Min Cut & Random sampling \\
370 & Min k-Cut & Partition graph into k parts \\
\end{longtable}

\subsection{38. Matchings (Hopcroft--Karp, Hungarian,
Blossom)}\label{matchings-hopcroftkarp-hungarian-blossom}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
371 & Bipartite Matching (DFS) & Simple augmenting path \\
372 & Hopcroft--Karp & O(E√V) bipartite matching \\
373 & Hungarian Algorithm & Weighted assignment \\
374 & Kuhn--Munkres & Max-weight matching \\
375 & Blossom Algorithm & General graph matching \\
376 & Edmonds' Blossom Shrinking & Odd cycle contraction \\
377 & Greedy Matching & Fast approximate \\
378 & Stable Marriage (Gale--Shapley) & Stable pairing \\
379 & Weighted b-Matching & Capacity-constrained \\
380 & Maximal Matching & Local greedy maximal set \\
\end{longtable}

\subsection{39. Tree Algorithms (LCA, HLD, Centroid
Decomposition)}\label{tree-algorithms-lca-hld-centroid-decomposition-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
381 & Euler Tour LCA & Flatten tree to array \\
382 & Binary Lifting LCA & Jump powers of two \\
383 & Tarjan's LCA (Offline DSU) & Query via union-find \\
384 & Heavy-Light Decomposition & Decompose paths \\
385 & Centroid Decomposition & Recursive split on centroid \\
386 & Tree Diameter (DFS Twice) & Farthest pair \\
387 & Tree DP & Subtree-based optimization \\
388 & Rerooting DP & Compute all roots' answers \\
389 & Binary Search on Tree & Edge weight constraints \\
390 & Virtual Tree & Build on query subset \\
\end{longtable}

\subsection{40. Advanced Graph Algorithms and
Tricks}\label{advanced-graph-algorithms-and-tricks-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5224}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
391 & Topological DP & DP on DAG order \\
392 & SCC Condensed Graph DP & Meta-graph processing \\
393 & Eulerian Path & Trail covering all edges \\
394 & Hamiltonian Path & NP-complete exploration \\
395 & Chinese Postman & Eulerian circuit with repeats \\
396 & Hierholzer's Algorithm & Construct Eulerian circuit \\
397 & Johnson's Cycle Finding & Enumerate all cycles \\
398 & Transitive Closure (Floyd--Warshall) & Reachability matrix \\
399 & Graph Coloring (Backtracking) & Constraint satisfaction \\
400 & Articulation Points \& Bridges & Critical structure detection \\
\end{longtable}

\section{Chapter 5. Dynamic
Programming}\label{chapter-5.-dynamic-programming-2}

\subsection{41. DP Basics and State
Transitions}\label{dp-basics-and-state-transitions-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0435}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5072}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4493}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
401 & Fibonacci DP & Classic top-down vs bottom-up \\
402 & Climbing Stairs & Count paths with small steps \\
403 & Grid Paths & DP over 2D lattice \\
404 & Min Cost Path & Accumulate minimal sums \\
405 & Coin Change (Count Ways) & Combinatorial sums \\
406 & Coin Change (Min Coins) & Minimize step count \\
407 & Knapsack 0/1 & Select items under weight limit \\
408 & Knapsack Unbounded & Repeatable items \\
409 & Longest Increasing Subsequence (DP) & Subsequence optimization \\
410 & Edit Distance (Levenshtein) & Measure similarity step-by-step \\
\end{longtable}

\subsection{42. Classic Problems (Knapsack, Subset Sum, Coin
Change)}\label{classic-problems-knapsack-subset-sum-coin-change-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
411 & 0/1 Knapsack & Value maximization under capacity \\
412 & Subset Sum & Boolean feasibility DP \\
413 & Equal Partition & Divide set into equal halves \\
414 & Count of Subsets with Sum & Counting variant \\
415 & Target Sum & DP with +/- transitions \\
416 & Unbounded Knapsack & Reuse items \\
417 & Fractional Knapsack & Greedy + DP comparison \\
418 & Coin Change (Min Coins) & DP shortest path \\
419 & Coin Change (Count Ways) & Combinatorial counting \\
420 & Multi-Dimensional Knapsack & Capacity in multiple dimensions \\
\end{longtable}

\subsection{43. Sequence Problems (LIS, LCS, Edit
Distance)}\label{sequence-problems-lis-lcs-edit-distance-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5224}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
421 & Longest Increasing Subsequence & O(n²) DP \\
422 & LIS (Patience Sorting) & O(n log n) optimized \\
423 & Longest Common Subsequence & Two-sequence DP \\
424 & Edit Distance (Levenshtein) & Transform operations \\
425 & Longest Palindromic Subsequence & Symmetric DP \\
426 & Shortest Common Supersequence & Merge sequences \\
427 & Longest Repeated Subsequence & DP with overlap \\
428 & String Interleaving & Merge with order preservation \\
429 & Sequence Alignment (Bioinformatics) & Gap penalties \\
430 & Diff Algorithm (Myers/DP) & Minimal edit path \\
\end{longtable}

\subsection{44. Matrix and Chain
Problems}\label{matrix-and-chain-problems-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
431 & Matrix Chain Multiplication & Parenthesization cost \\
432 & Boolean Parenthesization & Count true outcomes \\
433 & Burst Balloons & Interval DP \\
434 & Optimal BST & Weighted search cost \\
435 & Polygon Triangulation & DP over partitions \\
436 & Matrix Path Sum & DP on 2D grid \\
437 & Largest Square Submatrix & Dynamic growth check \\
438 & Max Rectangle in Binary Matrix & Histogram + DP \\
439 & Submatrix Sum Queries & Prefix sum DP \\
440 & Palindrome Partitioning & DP with cuts \\
\end{longtable}

\subsection{45. Bitmask DP and Traveling
Salesman}\label{bitmask-dp-and-traveling-salesman-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
441 & Traveling Salesman (TSP) & Visit all cities \\
442 & Subset DP & Over subsets of states \\
443 & Hamiltonian Path DP & State compression \\
444 & Assignment Problem DP & Mask over tasks \\
445 & Partition into Two Sets & Balanced load \\
446 & Count Hamiltonian Cycles & Bitmask enumeration \\
447 & Steiner Tree DP & Minimal connection of terminals \\
448 & SOS DP (Sum Over Subsets) & Precompute sums \\
449 & Bitmask Knapsack & State compression \\
450 & Bitmask Independent Set & Graph subset optimization \\
\end{longtable}

\subsection{46. Digit DP and SOS DP}\label{digit-dp-and-sos-dp-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
451 & Count Numbers with Property & Digit-state transitions \\
452 & Count Without Adjacent Duplicates & Adjacent constraints \\
453 & Sum of Digits in Range & Carry-dependent states \\
454 & Count with Mod Condition & DP over digit sum mod M \\
455 & Count of Increasing Digits & Ordered constraint \\
456 & Count with Forbidden Digits & Exclusion transitions \\
457 & SOS DP Subset Sum & Sum over bitmask subsets \\
458 & SOS DP Superset Sum & Sum over supersets \\
459 & XOR Basis DP & Combine digit and bit DP \\
460 & Digit DP for Palindromes & Symmetric digit state \\
\end{longtable}

\subsection{47. DP Optimizations (Divide \& Conquer, Convex Hull Trick,
Knuth)}\label{dp-optimizations-divide-conquer-convex-hull-trick-knuth-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
461 & Divide \& Conquer DP & Monotone decision property \\
462 & Knuth Optimization & DP with quadrangle inequality \\
463 & Convex Hull Trick & Linear recurrence min queries \\
464 & Li Chao Tree & Segment-based hull maintenance \\
465 & Slope Trick & Piecewise-linear optimization \\
466 & Monotonic Queue Optimization & Sliding DP state \\
467 & Bitset DP & Speed via bit-parallel \\
468 & Offline DP Queries & Preprocessing state \\
469 & DP + Segment Tree & Range-based optimization \\
470 & Divide \& Conquer Knapsack & Split-space DP \\
\end{longtable}

\subsection{48. Tree DP and Rerooting}\label{tree-dp-and-rerooting-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
471 & Subtree Sum DP & Aggregate values \\
472 & Diameter DP & Max path via child states \\
473 & Independent Set DP & Choose or skip nodes \\
474 & Vertex Cover DP & Tree constraint problem \\
475 & Path Counting DP & Count root-leaf paths \\
476 & DP on Rooted Tree & Bottom-up aggregation \\
477 & Rerooting Technique & Compute for all roots \\
478 & Distance Sum Rerooting & Efficient recomputation \\
479 & Tree Coloring DP & Combinatorial counting \\
480 & Binary Search on Tree DP & Monotonic transitions \\
\end{longtable}

\subsection{49. DP Reconstruction and
Traceback}\label{dp-reconstruction-and-traceback-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
481 & Reconstruct LCS & Backtrack table \\
482 & Reconstruct LIS & Track predecessors \\
483 & Reconstruct Knapsack & Recover selected items \\
484 & Edit Distance Alignment & Trace insert/delete/substitute \\
485 & Matrix Chain Parentheses & Rebuild parenthesization \\
486 & Coin Change Reconstruction & Backtrack last used coin \\
487 & Path Reconstruction DP & Trace minimal route \\
488 & Sequence Reconstruction & Rebuild from states \\
489 & Multi-Choice Reconstruction & Combine best subpaths \\
490 & Traceback Visualization & Visual DP backtrack tool \\
\end{longtable}

\subsection{50. Meta-DP and Optimization
Templates}\label{meta-dp-and-optimization-templates-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
491 & State Compression Template & Represent subsets compactly \\
492 & Transition Optimization Template & Precompute transitions \\
493 & Space Optimization Template & Rolling arrays \\
494 & Multi-Dimensional DP Template & Nested loops version \\
495 & Decision Monotonicity & Optimization hint \\
496 & Monge Array Optimization & Matrix property leverage \\
497 & Divide \& Conquer Template & Half-split recursion \\
498 & Rerooting Template & Generalized tree DP \\
499 & Iterative DP Pattern & Bottom-up unrolling \\
500 & Memoization Template & Recursive caching skeleton \\
\end{longtable}

\section{Chapter 6. Mathematics for
Algorithms}\label{chapter-6.-mathematics-for-algorithms-1}

\subsection{51. Number Theory (GCD, Modular Arithmetic,
CRT)}\label{number-theory-gcd-modular-arithmetic-crt-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
501 & Euclidean Algorithm & Compute gcd(a, b) \\
502 & Extended Euclidean Algorithm & Solve ax + by = gcd(a, b) \\
503 & Modular Addition & Add under modulo M \\
504 & Modular Multiplication & Multiply under modulo M \\
505 & Modular Exponentiation & Fast power mod M \\
506 & Modular Inverse & Compute a⁻¹ mod M \\
507 & Chinese Remainder Theorem & Combine modular systems \\
508 & Binary GCD (Stein's Algorithm) & Bitwise gcd \\
509 & Modular Reduction & Normalize residues \\
510 & Modular Linear Equation Solver & Solve ax ≡ b (mod m) \\
\end{longtable}

\subsection{52. Primality and Factorization (Miller--Rabin, Pollard
Rho)}\label{primality-and-factorization-millerrabin-pollard-rho}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
511 & Trial Division & Simple prime test \\
512 & Sieve of Eratosthenes & Generate primes up to n \\
513 & Sieve of Atkin & Faster sieve variant \\
514 & Miller--Rabin Primality Test & Probabilistic primality \\
515 & Fermat Primality Test & Modular power check \\
516 & Pollard's Rho & Randomized factorization \\
517 & Pollard's p−1 Method & Factor using smoothness \\
518 & Wheel Factorization & Skip known composites \\
519 & AKS Primality Test & Deterministic polynomial test \\
520 & Segmented Sieve & Prime generation for large n \\
\end{longtable}

\subsection{53. Combinatorics (Permutations, Combinations,
Subsets)}\label{combinatorics-permutations-combinations-subsets-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
521 & Factorial Precomputation & Build n! table \\
522 & nCr Computation & Use Pascal's or factorials \\
523 & Pascal's Triangle & Binomial coefficients \\
524 & Multiset Combination & Repetition allowed \\
525 & Permutation Generation & Lexicographic order \\
526 & Next Permutation & STL-style increment \\
527 & Subset Generation & Bitmask or recursion \\
528 & Gray Code Generation & Single-bit flips \\
529 & Catalan Number DP & Count valid parentheses \\
530 & Stirling Numbers & Partition counting \\
\end{longtable}

\subsection{54. Probability and Randomized
Algorithms}\label{probability-and-randomized-algorithms-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
531 & Monte Carlo Simulation & Approximate via randomness \\
532 & Las Vegas Algorithm & Always correct, variable time \\
533 & Reservoir Sampling & Uniform sampling from stream \\
534 & Randomized QuickSort & Expected O(n log n) \\
535 & Randomized QuickSelect & Random pivot \\
536 & Birthday Paradox Simulation & Probability collision \\
537 & Random Hashing & Reduce collision chance \\
538 & Random Walk Simulation & State transitions \\
539 & Coupon Collector Estimation & Expected trials \\
540 & Markov Chain Simulation & Transition matrix sampling \\
\end{longtable}

\subsection{55. Sieve Methods and Modular
Math}\label{sieve-methods-and-modular-math-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0455}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4545}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
541 & Sieve of Eratosthenes & Base prime sieve \\
542 & Linear Sieve & O(n) sieve variant \\
543 & Segmented Sieve & Range prime generation \\
544 & SPF (Smallest Prime Factor) Table & Factorization via sieve \\
545 & Möbius Function Sieve & Multiplicative function calc \\
546 & Euler's Totient Sieve & Compute φ(n) for all n \\
547 & Divisor Count Sieve & Count divisors efficiently \\
548 & Modular Precomputation & Store inverses, factorials \\
549 & Fermat Little Theorem & a\^{}(p−1) ≡ 1 mod p \\
550 & Wilson's Theorem & Prime test via factorial mod p \\
\end{longtable}

\subsection{56. Linear Algebra (Gaussian Elimination, LU,
SVD)}\label{linear-algebra-gaussian-elimination-lu-svd-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
551 & Gaussian Elimination & Solve Ax = b \\
552 & Gauss-Jordan Elimination & Reduced row echelon \\
553 & LU Decomposition & Factor A into L·U \\
554 & Cholesky Decomposition & A = L·Lᵀ for SPD \\
555 & QR Decomposition & Orthogonal factorization \\
556 & Matrix Inversion (Gauss-Jordan) & Find A⁻¹ \\
557 & Determinant by Elimination & Product of pivots \\
558 & Rank of Matrix & Count non-zero rows \\
559 & Eigenvalue Power Method & Approximate dominant eigenvalue \\
560 & Singular Value Decomposition & A = UΣVᵀ \\
\end{longtable}

\subsection{57. FFT and NTT (Fast
Transforms)}\label{fft-and-ntt-fast-transforms-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5079}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
561 & Discrete Fourier Transform (DFT) & O(n²) baseline \\
562 & Fast Fourier Transform (FFT) & O(n log n) convolution \\
563 & Cooley--Tukey FFT & Recursive divide and conquer \\
564 & Iterative FFT & In-place bit reversal \\
565 & Inverse FFT & Recover time-domain \\
566 & Convolution via FFT & Polynomial multiplication \\
567 & Number Theoretic Transform (NTT) & Modulo prime FFT \\
568 & Inverse NTT & Modular inverse transform \\
569 & Bluestein's Algorithm & FFT of arbitrary size \\
570 & FFT-Based Multiplication & Big integer product \\
\end{longtable}

\subsection{58. Numerical Methods (Newton, Simpson,
Runge--Kutta)}\label{numerical-methods-newton-simpson-rungekutta}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
571 & Newton--Raphson & Root finding via tangent \\
572 & Bisection Method & Interval halving \\
573 & Secant Method & Approximate derivative \\
574 & Fixed-Point Iteration & x = f(x) convergence \\
575 & Gaussian Quadrature & Weighted integration \\
576 & Simpson's Rule & Piecewise quadratic integral \\
577 & Trapezoidal Rule & Linear interpolation integral \\
578 & Runge--Kutta (RK4) & ODE solver \\
579 & Euler's Method & Step-by-step ODE \\
580 & Gradient Descent (1D) & Numerical optimization \\
\end{longtable}

\subsection{59. Mathematical Optimization (Simplex, Gradient,
Convex)}\label{mathematical-optimization-simplex-gradient-convex-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
581 & Simplex Method & Linear programming solver \\
582 & Dual Simplex Method & Solve dual constraints \\
583 & Interior-Point Method & Convex optimization \\
584 & Gradient Descent & Unconstrained optimization \\
585 & Stochastic Gradient Descent & Sample-based updates \\
586 & Newton's Method (Multivariate) & Quadratic convergence \\
587 & Conjugate Gradient & Solve SPD systems \\
588 & Lagrange Multipliers & Constrained optimization \\
589 & KKT Conditions Solver & Convex constraint handling \\
590 & Coordinate Descent & Sequential variable updates \\
\end{longtable}

\subsection{60. Algebraic Tricks and Transform
Techniques}\label{algebraic-tricks-and-transform-techniques-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
591 & Polynomial Multiplication (FFT) & Fast convolution \\
592 & Polynomial Inversion & Newton iteration \\
593 & Polynomial Derivative & Term-wise multiply by index \\
594 & Polynomial Integration & Divide by index+1 \\
595 & Formal Power Series Composition & Substitute series \\
596 & Exponentiation by Squaring & Fast powering \\
597 & Modular Exponentiation & Fast power mod M \\
598 & Fast Walsh--Hadamard Transform & XOR convolution \\
599 & Zeta Transform & Subset summation \\
600 & Möbius Inversion & Recover original from sums \\
\end{longtable}

\section{Chapter 7. Strings and Text
Algorithms}\label{chapter-7.-strings-and-text-algorithms-2}

\subsection{61. String Matching (KMP, Z, Rabin--Karp,
Boyer--Moore)}\label{string-matching-kmp-z-rabinkarp-boyermoore}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
601 & Naive String Matching & Compare every position \\
602 & Knuth--Morris--Pratt (KMP) & Prefix function skipping \\
603 & Z-Algorithm & Match using Z-values \\
604 & Rabin--Karp & Rolling hash comparison \\
605 & Boyer--Moore & Backward skip based on mismatch \\
606 & Boyer--Moore--Horspool & Simplified shift table \\
607 & Sunday Algorithm & Last-character shift \\
608 & Finite Automaton Matching & DFA-based matching \\
609 & Bitap Algorithm & Bitmask approximate matching \\
610 & Two-Way Algorithm & Optimal linear matching \\
\end{longtable}

\subsection{62. Multi-Pattern Search
(Aho--Corasick)}\label{multi-pattern-search-ahocorasick}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
611 & Aho--Corasick Automaton & Trie + failure links \\
612 & Trie Construction & Prefix tree build \\
613 & Failure Link Computation & BFS for transitions \\
614 & Output Link Management & Handle overlapping patterns \\
615 & Multi-Pattern Search & Find all keywords \\
616 & Dictionary Matching & Find multiple substrings \\
617 & Dynamic Aho--Corasick & Add/remove patterns \\
618 & Parallel AC Search & Multi-threaded traversal \\
619 & Compressed AC Automaton & Memory-optimized \\
620 & Extended AC with Wildcards & Flexible matching \\
\end{longtable}

\subsection{63. Suffix Structures (Suffix Array, Suffix Tree,
LCP)}\label{suffix-structures-suffix-array-suffix-tree-lcp-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
621 & Suffix Array (Naive) & Sort all suffixes \\
622 & Suffix Array (Doubling) & O(n log n) rank-based \\
623 & Kasai's LCP Algorithm & Longest common prefix \\
624 & Suffix Tree (Ukkonen) & Linear-time online \\
625 & Suffix Automaton & Minimal DFA of substrings \\
626 & SA-IS Algorithm & O(n) suffix array \\
627 & LCP RMQ Query & Range minimum for substring \\
628 & Generalized Suffix Array & Multiple strings \\
629 & Enhanced Suffix Array & Combine SA + LCP \\
630 & Sparse Suffix Tree & Space-efficient variant \\
\end{longtable}

\subsection{64. Palindromes and Periodicity
(Manacher)}\label{palindromes-and-periodicity-manacher-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4932}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4658}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
631 & Naive Palindrome Check & Expand around center \\
632 & Manacher's Algorithm & O(n) longest palindrome \\
633 & Longest Palindromic Substring & Center expansion \\
634 & Palindrome DP Table & Substring boolean matrix \\
635 & Palindromic Tree (Eertree) & Track distinct palindromes \\
636 & Prefix Function Periodicity & Detect repetition patterns \\
637 & Z-Function Periodicity & Identify periodic suffix \\
638 & KMP Prefix Period Check & Shortest repeating unit \\
639 & Lyndon Factorization & Decompose string into Lyndon words \\
640 & Minimal Rotation (Booth's Algorithm) & Lexicographically minimal
shift \\
\end{longtable}

\subsection{65. Edit Distance and
Alignment}\label{edit-distance-and-alignment-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
641 & Levenshtein Distance & Insert/delete/replace cost \\
642 & Damerau--Levenshtein & Swap included \\
643 & Hamming Distance & Count differing bits \\
644 & Needleman--Wunsch & Global alignment \\
645 & Smith--Waterman & Local alignment \\
646 & Hirschberg's Algorithm & Memory-optimized alignment \\
647 & Edit Script Reconstruction & Backtrack operations \\
648 & Affine Gap Penalty DP & Varying gap cost \\
649 & Myers Bit-Vector Algorithm & Fast edit distance \\
650 & Longest Common Subsequence & Alignment by inclusion \\
\end{longtable}

\subsection{66. Compression (Huffman, Arithmetic, LZ77,
BWT)}\label{compression-huffman-arithmetic-lz77-bwt-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
651 & Huffman Coding & Optimal prefix tree \\
652 & Canonical Huffman & Deterministic ordering \\
653 & Arithmetic Coding & Interval probability coding \\
654 & Shannon--Fano Coding & Early prefix method \\
655 & Run-Length Encoding (RLE) & Repeat compression \\
656 & LZ77 & Sliding-window match \\
657 & LZ78 & Dictionary building \\
658 & LZW & Variant used in GIF \\
659 & Burrows--Wheeler Transform & Block reordering \\
660 & Move-to-Front Encoding & Locality boosting transform \\
\end{longtable}

\subsection{67. Cryptographic Hashes and
Checksums}\label{cryptographic-hashes-and-checksums-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
661 & Rolling Hash & Polynomial mod-based \\
662 & CRC32 & Cyclic redundancy check \\
663 & Adler-32 & Lightweight checksum \\
664 & MD5 & Legacy cryptographic hash \\
665 & SHA-1 & Deprecated hash function \\
666 & SHA-256 & Secure hash standard \\
667 & SHA-3 (Keccak) & Sponge construction \\
668 & HMAC & Keyed message authentication \\
669 & Merkle Tree & Hierarchical hashing \\
670 & Hash Collision Detection & Birthday bound simulation \\
\end{longtable}

\subsection{68. Approximate and Streaming
Matching}\label{approximate-and-streaming-matching-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
671 & K-Approximate Matching & Allow k mismatches \\
672 & Bitap Algorithm & Bitwise dynamic programming \\
673 & Landau--Vishkin Algorithm & Edit distance ≤ k \\
674 & Filtering Algorithm & Fast approximate search \\
675 & Wu--Manber & Multi-pattern approximate search \\
676 & Streaming KMP & Online prefix updates \\
677 & Rolling Hash Sketch & Sliding window hashing \\
678 & Sketch-based Similarity & MinHash / LSH variants \\
679 & Weighted Edit Distance & Weighted operations \\
680 & Online Levenshtein & Dynamic stream update \\
\end{longtable}

\subsection{69. Bioinformatics Alignment (Needleman--Wunsch,
Smith--Waterman)}\label{bioinformatics-alignment-needlemanwunsch-smithwaterman}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
681 & Needleman--Wunsch & Global sequence alignment \\
682 & Smith--Waterman & Local alignment \\
683 & Gotoh Algorithm & Affine gap penalties \\
684 & Hirschberg Alignment & Linear-space alignment \\
685 & Multiple Sequence Alignment (MSA) & Progressive methods \\
686 & Profile Alignment & Align sequence to profile \\
687 & Hidden Markov Model Alignment & Probabilistic alignment \\
688 & BLAST & Heuristic local search \\
689 & FASTA & Word-based alignment \\
690 & Pairwise DP Alignment & General DP framework \\
\end{longtable}

\subsection{70. Text Indexing and Search
Structures}\label{text-indexing-and-search-structures-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5397}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4127}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
691 & Inverted Index Build & Word-to-document mapping \\
692 & Positional Index & Store word positions \\
693 & TF-IDF Weighting & Importance scoring \\
694 & BM25 Ranking & Modern ranking formula \\
695 & Trie Index & Prefix search structure \\
696 & Suffix Array Index & Substring search \\
697 & Compressed Suffix Array & Space-optimized \\
698 & FM-Index & BWT-based compressed index \\
699 & DAWG (Directed Acyclic Word Graph) & Shared suffix graph \\
700 & Wavelet Tree for Text & Rank/select on sequences \\
\end{longtable}

\section{Chapter 8. Geometry, Graphics, and Spatial
Algorithms}\label{chapter-8.-geometry-graphics-and-spatial-algorithms-2}

\subsection{71. Convex Hull (Graham, Andrew,
Chan)}\label{convex-hull-graham-andrew-chan-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3944}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5634}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
701 & Gift Wrapping (Jarvis March) & Wrap hull one point at a time \\
702 & Graham Scan & Sort by angle, maintain stack \\
703 & Andrew's Monotone Chain & Sort by x, upper + lower hull \\
704 & Chan's Algorithm & Output-sensitive O(n log h) \\
705 & QuickHull & Divide-and-conquer hull \\
706 & Incremental Convex Hull & Add points one by one \\
707 & Divide \& Conquer Hull & Merge two partial hulls \\
708 & 3D Convex Hull & Extend to 3D geometry \\
709 & Dynamic Convex Hull & Maintain hull with inserts \\
710 & Rotating Calipers & Compute diameter, width, antipodal pairs \\
\end{longtable}

\subsection{72. Closest Pair and Segment
Intersection}\label{closest-pair-and-segment-intersection-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4921}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4603}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
711 & Closest Pair (Divide \& Conquer) & Split, merge minimal
distance \\
712 & Closest Pair (Sweep Line) & Maintain active window \\
713 & Brute Force Closest Pair & Check all O(n²) pairs \\
714 & Bentley--Ottmann & Find all line intersections \\
715 & Segment Intersection Test & Cross product orientation \\
716 & Line Sweep for Segments & Event-based intersection \\
717 & Intersection via Orientation & CCW test \\
718 & Circle Intersection & Geometry of two circles \\
719 & Polygon Intersection & Clip overlapping polygons \\
720 & Nearest Neighbor Pair & Combine KD-tree + search \\
\end{longtable}

\subsection{73. Line Sweep and Plane Sweep
Algorithms}\label{line-sweep-and-plane-sweep-algorithms-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5205}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4384}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
721 & Sweep Line for Events & Process sorted events \\
722 & Interval Scheduling & Select non-overlapping intervals \\
723 & Rectangle Union Area & Sweep edges to count area \\
724 & Segment Intersection (Bentley--Ottmann) & Detect all crossings \\
725 & Skyline Problem & Merge height profiles \\
726 & Closest Pair Sweep & Maintain active set \\
727 & Circle Arrangement & Sweep and count regions \\
728 & Sweep for Overlapping Rectangles & Detect collisions \\
729 & Range Counting & Count points in rectangle \\
730 & Plane Sweep for Triangles & Polygon overlay computation \\
\end{longtable}

\subsection{74. Delaunay and Voronoi
Diagrams}\label{delaunay-and-voronoi-diagrams-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5070}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4507}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
731 & Delaunay Triangulation (Incremental) & Add points, maintain
Delaunay \\
732 & Delaunay (Divide \& Conquer) & Merge triangulations \\
733 & Delaunay (Fortune's Sweep) & O(n log n) construction \\
734 & Voronoi Diagram (Fortune's) & Sweep line beachline \\
735 & Incremental Voronoi & Update on insertion \\
736 & Bowyer--Watson & Empty circle criterion \\
737 & Duality Transform & Convert between Voronoi/Delaunay \\
738 & Power Diagram & Weighted Voronoi \\
739 & Lloyd's Relaxation & Smooth Voronoi cells \\
740 & Voronoi Nearest Neighbor & Region-based lookup \\
\end{longtable}

\subsection{75. Point in Polygon and Polygon
Triangulation}\label{point-in-polygon-and-polygon-triangulation-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5846}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3692}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
741 & Ray Casting & Count edge crossings \\
742 & Winding Number & Angle sum method \\
743 & Convex Polygon Point Test & Orientation checks \\
744 & Ear Clipping Triangulation & Remove ears iteratively \\
745 & Monotone Polygon Triangulation & Sweep line triangulation \\
746 & Delaunay Triangulation & Optimal triangle quality \\
747 & Convex Decomposition & Split into convex parts \\
748 & Polygon Area (Shoelace Formula) & Signed area computation \\
749 & Minkowski Sum & Add shapes geometrically \\
750 & Polygon Intersection (Weiler--Atherton) & Clip overlapping
shapes \\
\end{longtable}

\subsection{76. Spatial Data Structures (KD,
R-tree)}\label{spatial-data-structures-kd-r-tree-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
751 & KD-Tree Build & Recursive median split \\
752 & KD-Tree Search & Axis-aligned query \\
753 & Range Search KD-Tree & Orthogonal query \\
754 & Nearest Neighbor KD-Tree & Closest point search \\
755 & R-Tree Build & Bounding box hierarchy \\
756 & R*-Tree & Optimized split strategy \\
757 & Quad Tree & Spatial decomposition \\
758 & Octree & 3D spatial decomposition \\
759 & BSP Tree (Binary Space Partition) & Split by planes \\
760 & Morton Order (Z-Curve) & Spatial locality index \\
\end{longtable}

\subsection{77. Rasterization and Scanline
Techniques}\label{rasterization-and-scanline-techniques-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
761 & Bresenham's Line Algorithm & Efficient integer drawing \\
762 & Midpoint Circle Algorithm & Circle rasterization \\
763 & Scanline Fill & Polygon interior fill \\
764 & Edge Table Fill & Sort edges by y \\
765 & Z-Buffer Algorithm & Hidden surface removal \\
766 & Painter's Algorithm & Sort by depth \\
767 & Gouraud Shading & Vertex interpolation shading \\
768 & Phong Shading & Normal interpolation \\
769 & Anti-Aliasing (Supersampling) & Smooth jagged edges \\
770 & Scanline Polygon Clipping & Efficient clipping \\
\end{longtable}

\subsection{78. Computer Vision (Canny, Hough,
SIFT)}\label{computer-vision-canny-hough-sift-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5479}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4110}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
771 & Canny Edge Detector & Gradient + hysteresis \\
772 & Sobel Operator & Gradient magnitude filter \\
773 & Hough Transform (Lines) & Accumulator for line detection \\
774 & Hough Transform (Circles) & Radius-based accumulator \\
775 & Harris Corner Detector & Eigenvalue-based corners \\
776 & FAST Corner Detector & Intensity circle test \\
777 & SIFT (Scale-Invariant Feature Transform) & Keypoint detection \\
778 & SURF (Speeded-Up Robust Features) & Faster descriptor \\
779 & ORB (Oriented FAST + BRIEF) & Binary robust feature \\
780 & RANSAC & Robust model fitting \\
\end{longtable}

\subsection{79. Pathfinding in Space (A*, RRT,
PRM)}\label{pathfinding-in-space-a-rrt-prm-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5224}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
781 & A* Search & Heuristic pathfinding \\
782 & Dijkstra for Grid & Weighted shortest path \\
783 & Theta* & Any-angle pathfinding \\
784 & Jump Point Search & Grid acceleration \\
785 & RRT (Rapidly-Exploring Random Tree) & Random sampling tree \\
786 & RRT* & Optimal variant with rewiring \\
787 & PRM (Probabilistic Roadmap) & Graph sampling planner \\
788 & Visibility Graph & Connect visible vertices \\
789 & Potential Field Pathfinding & Gradient-based navigation \\
790 & Bug Algorithms & Simple obstacle avoidance \\
\end{longtable}

\subsection{80. Computational Geometry Variants and
Applications}\label{computational-geometry-variants-and-applications-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
791 & Convex Polygon Intersection & Clip convex sets \\
792 & Minkowski Sum & Shape convolution \\
793 & Rotating Calipers & Closest/farthest pair \\
794 & Half-Plane Intersection & Feasible region \\
795 & Line Arrangement & Count regions \\
796 & Point Location (Trapezoidal Map) & Query region lookup \\
797 & Voronoi Nearest Facility & Region query \\
798 & Delaunay Mesh Generation & Triangulation refinement \\
799 & Smallest Enclosing Circle & Welzl's algorithm \\
800 & Collision Detection (SAT) & Separating axis theorem \\
\end{longtable}

\section{Chapter 9. Systems, Databases, and Distributed
Algorithms}\label{chapter-9.-systems-databases-and-distributed-algorithms-2}

\subsection{81. Concurrency Control (2PL, MVCC,
OCC)}\label{concurrency-control-2pl-mvcc-occ-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5493}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4085}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
801 & Two-Phase Locking (2PL) & Acquire-then-release locks \\
802 & Strict 2PL & Hold locks until commit \\
803 & Conservative 2PL & Prevent deadlocks via prelock \\
804 & Timestamp Ordering & Schedule by timestamps \\
805 & Multiversion Concurrency Control (MVCC) & Snapshot isolation \\
806 & Optimistic Concurrency Control (OCC) & Validate at commit \\
807 & Serializable Snapshot Isolation & Merge read/write sets \\
808 & Lock-Free Algorithm & Atomic CAS updates \\
809 & Wait-Die / Wound-Wait & Deadlock prevention policies \\
810 & Deadlock Detection (Wait-for Graph) & Cycle detection in waits \\
\end{longtable}

\subsection{82. Logging, Recovery, and Commit
Protocols}\label{logging-recovery-and-commit-protocols-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
811 & Write-Ahead Logging (WAL) & Log before commit \\
812 & ARIES Recovery & Re-do/undo with LSNs \\
813 & Shadow Paging & Copy-on-write persistence \\
814 & Two-Phase Commit (2PC) & Coordinator-driven commit \\
815 & Three-Phase Commit (3PC) & Non-blocking variant \\
816 & Checkpointing & Save state for recovery \\
817 & Undo Logging & Rollback uncommitted \\
818 & Redo Logging & Reapply committed \\
819 & Quorum Commit & Majority agreement \\
820 & Consensus Commit & Combine 2PC + Paxos \\
\end{longtable}

\subsection{83. Scheduling (Round Robin, EDF,
Rate-Monotonic)}\label{scheduling-round-robin-edf-rate-monotonic-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
821 & First-Come First-Served (FCFS) & Sequential job order \\
822 & Shortest Job First (SJF) & Optimal average wait \\
823 & Round Robin (RR) & Time-slice fairness \\
824 & Priority Scheduling & Weighted selection \\
825 & Multilevel Queue & Tiered priority queues \\
826 & Earliest Deadline First (EDF) & Real-time optimal \\
827 & Rate Monotonic Scheduling (RMS) & Fixed periodic priority \\
828 & Lottery Scheduling & Probabilistic fairness \\
829 & Multilevel Feedback Queue & Adaptive behavior \\
830 & Fair Queuing (FQ) & Flow-based proportional sharing \\
\end{longtable}

\subsection{84. Caching and Replacement (LRU, LFU,
CLOCK)}\label{caching-and-replacement-lru-lfu-clock-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5672}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3881}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
831 & LRU (Least Recently Used) & Evict oldest used \\
832 & LFU (Least Frequently Used) & Evict lowest frequency \\
833 & FIFO Cache & Simple queue eviction \\
834 & CLOCK Algorithm & Approximate LRU \\
835 & ARC (Adaptive Replacement Cache) & Mix of recency + frequency \\
836 & Two-Queue (2Q) & Separate recent/frequent \\
837 & LIRS (Low Inter-reference Recency Set) & Predict reuse distance \\
838 & TinyLFU & Frequency sketch admission \\
839 & Random Replacement & Simple stochastic policy \\
840 & Belady's Optimal & Evict farthest future use \\
\end{longtable}

\subsection{85. Networking (Routing, Congestion
Control)}\label{networking-routing-congestion-control-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5938}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3594}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
841 & Dijkstra's Routing & Shortest path routing \\
842 & Bellman--Ford Routing & Distance-vector routing \\
843 & Link-State Routing (OSPF) & Global view routing \\
844 & Distance-Vector Routing (RIP) & Local neighbor updates \\
845 & Path Vector (BGP) & Route advertisement \\
846 & Flooding & Broadcast to all nodes \\
847 & Spanning Tree Protocol & Loop-free topology \\
848 & Congestion Control (AIMD) & TCP window control \\
849 & Random Early Detection (RED) & Queue preemptive drop \\
850 & ECN (Explicit Congestion Notification) & Mark packets early \\
\end{longtable}

\subsection{86. Distributed Consensus (Paxos, Raft,
PBFT)}\label{distributed-consensus-paxos-raft-pbft-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0385}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5385}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4231}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
851 & Basic Paxos & Majority consensus \\
852 & Multi-Paxos & Sequence of agreements \\
853 & Raft & Log replication + leader election \\
854 & Viewstamped Replication & Alternative consensus design \\
855 & PBFT (Practical Byzantine Fault Tolerance) & Byzantine safety \\
856 & Zab (Zookeeper Atomic Broadcast) & Broadcast + ordering \\
857 & EPaxos & Leaderless fast path \\
858 & VRR (Virtual Ring Replication) & Log around ring \\
859 & Two-Phase Commit with Consensus & Transactional commit \\
860 & Chain Replication & Ordered state replication \\
\end{longtable}

\subsection{87. Load Balancing and Rate
Limiting}\label{load-balancing-and-rate-limiting-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
861 & Round Robin Load Balancing & Sequential distribution \\
862 & Weighted Round Robin & Proportional to weight \\
863 & Least Connections & Pick least loaded node \\
864 & Consistent Hashing & Map requests stably \\
865 & Power of Two Choices & Sample and choose lesser load \\
866 & Random Load Balancing & Simple uniform random \\
867 & Token Bucket & Rate-based limiter \\
868 & Leaky Bucket & Steady flow shaping \\
869 & Sliding Window Counter & Rolling time window \\
870 & Fixed Window Counter & Resettable counter limiter \\
\end{longtable}

\subsection{88. Search and Indexing (Inverted, BM25,
WAND)}\label{search-and-indexing-inverted-bm25-wand-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
871 & Inverted Index Construction & Word → document list \\
872 & Positional Index Build & Store term positions \\
873 & TF-IDF Scoring & Term frequency weighting \\
874 & BM25 Ranking & Modern scoring model \\
875 & Boolean Retrieval & Logical AND/OR/NOT \\
876 & WAND Algorithm & Efficient top-k retrieval \\
877 & Block-Max WAND (BMW) & Early skipping optimization \\
878 & Impact-Ordered Indexing & Sort by contribution \\
879 & Tiered Indexing & Prioritize high-score docs \\
880 & DAAT vs SAAT Evaluation & Document vs score-at-a-time \\
\end{longtable}

\subsection{89. Compression and Encoding in
Systems}\label{compression-and-encoding-in-systems-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
881 & Run-Length Encoding (RLE) & Simple repetition encoding \\
882 & Huffman Coding & Optimal variable-length code \\
883 & Arithmetic Coding & Fractional interval coding \\
884 & Delta Encoding & Store differences \\
885 & Variable Byte Encoding & Compact integers \\
886 & Elias Gamma Coding & Prefix integer encoding \\
887 & Rice Coding & Unary + remainder scheme \\
888 & Snappy & Fast block compression \\
889 & Zstandard (Zstd) & Modern adaptive codec \\
890 & LZ4 & High-speed dictionary compressor \\
\end{longtable}

\subsection{90. Fault Tolerance and
Replication}\label{fault-tolerance-and-replication-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
891 & Primary--Backup Replication & One leader, one standby \\
892 & Quorum Replication & Majority write/read rule \\
893 & Chain Replication & Ordered consistency \\
894 & Gossip Protocol & Epidemic state exchange \\
895 & Anti-Entropy Repair & Periodic reconciliation \\
896 & Erasure Coding & Redundant data blocks \\
897 & Checksum Verification & Detect corruption \\
898 & Heartbeat Monitoring & Liveness detection \\
899 & Leader Election (Bully) & Highest ID wins \\
900 & Leader Election (Ring) & Token-based rotation \\
\end{longtable}

\section{Chapter 10. AI, ML, and
Optimization}\label{chapter-10.-ai-ml-and-optimization-2}

\subsection{91. Classical ML (k-means, Naive Bayes, SVM, Decision
Trees)}\label{classical-ml-k-means-naive-bayes-svm-decision-trees-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4789}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4789}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
901 & k-Means Clustering & Partition by centroid iteration \\
902 & k-Medoids (PAM) & Cluster by exemplars \\
903 & Gaussian Mixture Model (EM) & Soft probabilistic clustering \\
904 & Naive Bayes Classifier & Probabilistic feature independence \\
905 & Logistic Regression & Sigmoid linear classifier \\
906 & Perceptron & Online linear separator \\
907 & Decision Tree (CART) & Recursive partition by impurity \\
908 & ID3 Algorithm & Information gain splitting \\
909 & k-Nearest Neighbors (kNN) & Distance-based classification \\
910 & Linear Discriminant Analysis (LDA) & Projection for separation \\
\end{longtable}

\subsection{92. Ensemble Methods (Bagging, Boosting, Random
Forests)}\label{ensemble-methods-bagging-boosting-random-forests-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
911 & Bagging & Bootstrap aggregation \\
912 & Random Forest & Ensemble of decision trees \\
913 & AdaBoost & Weighted error correction \\
914 & Gradient Boosting & Sequential residual fitting \\
915 & XGBoost & Optimized gradient boosting \\
916 & LightGBM & Histogram-based leaf growth \\
917 & CatBoost & Ordered boosting for categoricals \\
918 & Stacking & Meta-model ensemble \\
919 & Voting Classifier & Majority aggregation \\
920 & Snapshot Ensemble & Averaged checkpoints \\
\end{longtable}

\subsection{93. Gradient Methods (SGD, Adam,
RMSProp)}\label{gradient-methods-sgd-adam-rmsprop-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5238}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
921 & Gradient Descent & Batch full-gradient step \\
922 & Stochastic Gradient Descent (SGD) & Sample-wise updates \\
923 & Mini-Batch SGD & Tradeoff speed and variance \\
924 & Momentum & Add velocity to descent \\
925 & Nesterov Accelerated Gradient & Lookahead correction \\
926 & AdaGrad & Adaptive per-parameter rate \\
927 & RMSProp & Exponential moving average \\
928 & Adam & Momentum + adaptive rate \\
929 & AdamW & Decoupled weight decay \\
930 & L-BFGS & Limited-memory quasi-Newton \\
\end{longtable}

\subsection{94. Deep Learning (Backpropagation, Dropout,
Normalization)}\label{deep-learning-backpropagation-dropout-normalization-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
931 & Backpropagation & Gradient chain rule \\
932 & Xavier/He Initialization & Scaled variance init \\
933 & Dropout & Random neuron deactivation \\
934 & Batch Normalization & Normalize per batch \\
935 & Layer Normalization & Normalize per feature \\
936 & Gradient Clipping & Prevent explosion \\
937 & Early Stopping & Prevent overfitting \\
938 & Weight Decay & Regularization via penalty \\
939 & Learning Rate Scheduling & Dynamic LR adjustment \\
940 & Residual Connections & Skip layer improvement \\
\end{longtable}

\subsection{95. Sequence Models (Viterbi, Beam Search,
CTC)}\label{sequence-models-viterbi-beam-search-ctc-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0405}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5811}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3784}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
941 & Hidden Markov Model (Forward--Backward) & Probabilistic sequence
model \\
942 & Viterbi Algorithm & Most probable path \\
943 & Baum--Welch & EM training for HMMs \\
944 & Beam Search & Top-k path exploration \\
945 & Greedy Decoding & Fast approximate decoding \\
946 & Connectionist Temporal Classification (CTC) & Unaligned sequence
training \\
947 & Attention Mechanism & Weighted context aggregation \\
948 & Transformer Decoder & Self-attention stack \\
949 & Seq2Seq with Attention & Encoder-decoder framework \\
950 & Pointer Network & Output index selection \\
\end{longtable}

\subsection{96. Metaheuristics (GA, SA, PSO,
ACO)}\label{metaheuristics-ga-sa-pso-aco-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0455}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4545}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
951 & Genetic Algorithm (GA) & Evolutionary optimization \\
952 & Simulated Annealing (SA) & Temperature-controlled search \\
953 & Tabu Search & Memory of forbidden moves \\
954 & Particle Swarm Optimization (PSO) & Velocity-based search \\
955 & Ant Colony Optimization (ACO) & Pheromone-guided path \\
956 & Differential Evolution (DE) & Vector-based mutation \\
957 & Harmony Search & Music-inspired improvisation \\
958 & Firefly Algorithm & Brightness-attraction movement \\
959 & Bee Colony Optimization & Explore-exploit via scouts \\
960 & Hill Climbing & Local incremental improvement \\
\end{longtable}

\subsection{97. Reinforcement Learning (Q-learning, Policy
Gradients)}\label{reinforcement-learning-q-learning-policy-gradients-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5312}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4219}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
961 & Monte Carlo Control & Average returns \\
962 & Temporal Difference (TD) Learning & Bootstrap updates \\
963 & SARSA & On-policy TD learning \\
964 & Q-Learning & Off-policy TD learning \\
965 & Double Q-Learning & Reduce overestimation \\
966 & Deep Q-Network (DQN) & Neural Q approximator \\
967 & REINFORCE & Policy gradient by sampling \\
968 & Actor--Critic & Value-guided policy update \\
969 & PPO (Proximal Policy Optimization) & Clipped surrogate
objective \\
970 & DDPG / SAC & Continuous action RL \\
\end{longtable}

\subsection{98. Approximation and Online
Algorithms}\label{approximation-and-online-algorithms-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4384}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5205}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
971 & Greedy Set Cover & ln(n)-approximation \\
972 & Vertex Cover Approximation & Double-matching heuristic \\
973 & Traveling Salesman Approximation & MST-based 2-approx \\
974 & k-Center Approximation & Farthest-point heuristic \\
975 & Online Paging (LRU) & Competitive analysis \\
976 & Online Matching (Ranking) & Adversarial input resilience \\
977 & Online Knapsack & Ratio-based acceptance \\
978 & Competitive Ratio Evaluation & Bound worst-case performance \\
979 & PTAS / FPTAS Schemes & Polynomial approximation \\
980 & Primal--Dual Method & Approximate combinatorial optimization \\
\end{longtable}

\subsection{99. Fairness, Causal Inference, and Robust
Optimization}\label{fairness-causal-inference-and-robust-optimization-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0441}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4265}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
981 & Reweighting for Fairness & Adjust sample weights \\
982 & Demographic Parity Constraint & Equalize positive rates \\
983 & Equalized Odds & Align error rates \\
984 & Adversarial Debiasing & Learn fair representations \\
985 & Causal DAG Discovery & Graphical causal inference \\
986 & Propensity Score Matching & Estimate treatment effect \\
987 & Instrumental Variable Estimation & Handle confounders \\
988 & Robust Optimization & Worst-case aware optimization \\
989 & Distributionally Robust Optimization & Minimax over uncertainty
sets \\
990 & Counterfactual Fairness & Simulate do-interventions \\
\end{longtable}

\subsection{100. AI Planning, Search, and Learning
Systems}\label{ai-planning-search-and-learning-systems-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4844}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4531}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
991 & Breadth-First Search (BFS) & Uninformed search \\
992 & Depth-First Search (DFS) & Backtracking search \\
993 & A* Search & Heuristic guided \\
994 & Iterative Deepening A* (IDA*) & Memory-bounded heuristic \\
995 & Uniform Cost Search & Expand by path cost \\
996 & Monte Carlo Tree Search (MCTS) & Exploration vs exploitation \\
997 & Minimax & Game tree evaluation \\
998 & Alpha--Beta Pruning & Prune unneeded branches \\
999 & STRIPS Planning & Action-based state transition \\
1000 & Hierarchical Task Network (HTN) & Structured AI planning \\
\end{longtable}




\end{document}
