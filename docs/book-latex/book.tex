% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={The Little Book of Algorithms},
  pdfauthor={Duc-Tam Nguyen},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{The Little Book of Algorithms}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Version 0.3.1}
\author{Duc-Tam Nguyen}
\date{2025-10-08}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter{Content}\label{content}

\emph{A Friendly Guide from Numbers to Neural Networks}

\begin{itemize}
\tightlist
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.pdf}{Download
  PDF} - print-ready
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.epub}{Download
  EPUB} - e-reader friendly
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.tex}{View
  LaTex} - \texttt{.tex} source
\item
  \href{https://github.com/little-book-of/algorithms}{Source code
  (Github)} - Markdown source
\item
  \href{https://little-book-of.github.io/algorithms}{Read on GitHub
  Pages} - view online
\end{itemize}

Licensed under \textbf{CC BY-NC-SA 4.0}.

\subsubsection{Chapter 1. Foundations of
Algorithms}\label{chapter-1.-foundations-of-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    What Is an Algorithm?\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{1}
  \tightlist
  \item
    Measuring Time and Space\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2}
  \tightlist
  \item
    Big-O, Big-Theta, Big-Omega\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{3}
  \tightlist
  \item
    Algorithmic Paradigms (Greedy, Divide and Conquer, DP)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{4}
  \tightlist
  \item
    Recurrence Relations\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{5}
  \tightlist
  \item
    Searching Basics\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{6}
  \tightlist
  \item
    Sorting Basics\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{7}
  \tightlist
  \item
    Data Structures Overview\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{8}
  \tightlist
  \item
    Graphs and Trees Overview\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{9}
  \tightlist
  \item
    Algorithm Design Patterns
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 2. Sorting and
Searching}\label{chapter-2.-sorting-and-searching}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{10}
  \tightlist
  \item
    Elementary Sorting (Bubble, Insertion, Selection)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{11}
  \tightlist
  \item
    Divide-and-Conquer Sorting (Merge, Quick, Heap)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{12}
  \tightlist
  \item
    Counting and Distribution Sorts (Counting, Radix, Bucket)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{13}
  \tightlist
  \item
    Hybrid Sorts (IntroSort, Timsort)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{14}
  \tightlist
  \item
    Special Sorts (Cycle, Gnome, Comb, Pancake)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{15}
  \tightlist
  \item
    Linear and Binary Search\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{16}
  \tightlist
  \item
    Interpolation and Exponential Search\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{17}
  \tightlist
  \item
    Selection Algorithms (Quickselect, Median of Medians)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{18}
  \tightlist
  \item
    Range Searching and Nearest Neighbor\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{19}
  \tightlist
  \item
    Search Optimizations and Variants
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 3. Data Structures in
Action}\label{chapter-3.-data-structures-in-action}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{20}
  \tightlist
  \item
    Arrays, Linked Lists, Stacks, Queues\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{21}
  \tightlist
  \item
    Hash Tables and Variants (Cuckoo, Robin Hood, Consistent)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{22}
  \tightlist
  \item
    Heaps (Binary, Fibonacci, Pairing)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{23}
  \tightlist
  \item
    Balanced Trees (AVL, Red-Black, Splay, Treap)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{24}
  \tightlist
  \item
    Segment Trees and Fenwick Trees\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{25}
  \tightlist
  \item
    Disjoint Set Union (Union-Find)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{26}
  \tightlist
  \item
    Probabilistic Data Structures (Bloom, Count-Min, HyperLogLog)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{27}
  \tightlist
  \item
    Skip Lists and B-Trees\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{28}
  \tightlist
  \item
    Persistent and Functional Data Structures\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{29}
  \tightlist
  \item
    Advanced Trees and Range Queries
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 4. Graph
Algorithms}\label{chapter-4.-graph-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{30}
  \tightlist
  \item
    Traversals (DFS, BFS, Iterative Deepening)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{31}
  \tightlist
  \item
    Strongly Connected Components (Tarjan, Kosaraju)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{32}
  \tightlist
  \item
    Shortest Paths (Dijkstra, Bellman-Ford, A*, Johnson)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{33}
  \tightlist
  \item
    Shortest Path Variants (0--1 BFS, Bidirectional, Heuristic A*)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{34}
  \tightlist
  \item
    Minimum Spanning Trees (Kruskal, Prim, Borůvka)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{35}
  \tightlist
  \item
    Flows (Ford--Fulkerson, Edmonds--Karp, Dinic)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{36}
  \tightlist
  \item
    Cuts (Stoer--Wagner, Karger, Gomory--Hu)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{37}
  \tightlist
  \item
    Matchings (Hopcroft--Karp, Hungarian, Blossom)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{38}
  \tightlist
  \item
    Tree Algorithms (LCA, HLD, Centroid Decomposition)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{39}
  \tightlist
  \item
    Advanced Graph Algorithms and Tricks
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 5. Dynamic
Programming}\label{chapter-5.-dynamic-programming}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{40}
  \tightlist
  \item
    DP Basics and State Transitions\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{41}
  \tightlist
  \item
    Classic Problems (Knapsack, Subset Sum, Coin Change)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{42}
  \tightlist
  \item
    Sequence Problems (LIS, LCS, Edit Distance)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{43}
  \tightlist
  \item
    Matrix and Chain Problems\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{44}
  \tightlist
  \item
    Bitmask DP and Traveling Salesman\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{45}
  \tightlist
  \item
    Digit DP and SOS DP\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{46}
  \tightlist
  \item
    DP Optimizations (Divide \& Conquer, Convex Hull Trick, Knuth)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{47}
  \tightlist
  \item
    Tree DP and Rerooting\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{48}
  \tightlist
  \item
    DP Reconstruction and Traceback\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{49}
  \tightlist
  \item
    Meta-DP and Optimization Templates
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 6. Mathematics for
Algorithms}\label{chapter-6.-mathematics-for-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{50}
  \tightlist
  \item
    Number Theory (GCD, Modular Arithmetic, CRT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{51}
  \tightlist
  \item
    Primality and Factorization (Miller--Rabin, Pollard Rho)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{52}
  \tightlist
  \item
    Combinatorics (Permutations, Combinations, Subsets)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{53}
  \tightlist
  \item
    Probability and Randomized Algorithms\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{54}
  \tightlist
  \item
    Sieve Methods and Modular Math\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{55}
  \tightlist
  \item
    Linear Algebra (Gaussian Elimination, LU, SVD)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{56}
  \tightlist
  \item
    FFT and NTT (Fast Transforms)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{57}
  \tightlist
  \item
    Numerical Methods (Newton, Simpson, Runge--Kutta)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{58}
  \tightlist
  \item
    Mathematical Optimization (Simplex, Gradient, Convex)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{59}
  \tightlist
  \item
    Algebraic Tricks and Transform Techniques
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 7. Strings and Text
Algorithms}\label{chapter-7.-strings-and-text-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{60}
  \tightlist
  \item
    String Matching (KMP, Z, Rabin--Karp, Boyer--Moore)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{61}
  \tightlist
  \item
    Multi-Pattern Search (Aho--Corasick)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{62}
  \tightlist
  \item
    Suffix Structures (Suffix Array, Suffix Tree, LCP)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{63}
  \tightlist
  \item
    Palindromes and Periodicity (Manacher)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{64}
  \tightlist
  \item
    Edit Distance and Alignment\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{65}
  \tightlist
  \item
    Compression (Huffman, Arithmetic, LZ77, BWT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{66}
  \tightlist
  \item
    Cryptographic Hashes and Checksums\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{67}
  \tightlist
  \item
    Approximate and Streaming Matching\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{68}
  \tightlist
  \item
    Bioinformatics Alignment (Needleman--Wunsch, Smith--Waterman)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{69}
  \tightlist
  \item
    Text Indexing and Search Structures
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 8. Geometry, Graphics, and Spatial
Algorithms}\label{chapter-8.-geometry-graphics-and-spatial-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{70}
  \tightlist
  \item
    Convex Hull (Graham, Andrew, Chan)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{71}
  \tightlist
  \item
    Closest Pair and Segment Intersection\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{72}
  \tightlist
  \item
    Line Sweep and Plane Sweep Algorithms\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{73}
  \tightlist
  \item
    Delaunay and Voronoi Diagrams\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{74}
  \tightlist
  \item
    Point in Polygon and Polygon Triangulation\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{75}
  \tightlist
  \item
    Spatial Data Structures (KD, R-tree)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{76}
  \tightlist
  \item
    Rasterization and Scanline Techniques\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{77}
  \tightlist
  \item
    Computer Vision (Canny, Hough, SIFT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{78}
  \tightlist
  \item
    Pathfinding in Space (A*, RRT, PRM)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{79}
  \tightlist
  \item
    Computational Geometry Variants and Applications
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 9. Systems, Databases, and Distributed
Algorithms}\label{chapter-9.-systems-databases-and-distributed-algorithms}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{80}
  \tightlist
  \item
    Concurrency Control (2PL, MVCC, OCC)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{81}
  \tightlist
  \item
    Logging, Recovery, and Commit Protocols\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{82}
  \tightlist
  \item
    Scheduling (Round Robin, EDF, Rate-Monotonic)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{83}
  \tightlist
  \item
    Caching and Replacement (LRU, LFU, CLOCK)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{84}
  \tightlist
  \item
    Networking (Routing, Congestion Control)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{85}
  \tightlist
  \item
    Distributed Consensus (Paxos, Raft, PBFT)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{86}
  \tightlist
  \item
    Load Balancing and Rate Limiting\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{87}
  \tightlist
  \item
    Search and Indexing (Inverted, BM25, WAND)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{88}
  \tightlist
  \item
    Compression and Encoding in Systems\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{89}
  \tightlist
  \item
    Fault Tolerance and Replication
  \end{enumerate}
\end{itemize}

\subsubsection{Chapter 10. AI, ML, and
Optimization}\label{chapter-10.-ai-ml-and-optimization}

\begin{itemize}
\tightlist
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{90}
  \tightlist
  \item
    Classical ML (k-means, Naive Bayes, SVM, Decision Trees)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{91}
  \tightlist
  \item
    Ensemble Methods (Bagging, Boosting, Random Forests)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{92}
  \tightlist
  \item
    Gradient Methods (SGD, Adam, RMSProp)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{93}
  \tightlist
  \item
    Deep Learning (Backpropagation, Dropout, Normalization)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{94}
  \tightlist
  \item
    Sequence Models (Viterbi, Beam Search, CTC)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{95}
  \tightlist
  \item
    Metaheuristics (GA, SA, PSO, ACO)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{96}
  \tightlist
  \item
    Reinforcement Learning (Q-learning, Policy Gradients)\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{97}
  \tightlist
  \item
    Approximation and Online Algorithms\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{98}
  \tightlist
  \item
    Fairness, Causal Inference, and Robust Optimization\\
  \end{enumerate}
\item
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{99}
  \tightlist
  \item
    AI Planning, Search, and Learning Systems
  \end{enumerate}
\end{itemize}

\bookmarksetup{startatroot}

\chapter{The Cheatsheet}\label{the-cheatsheet}

\subsection{Page 1. Big Picture and
Complexity}\label{page-1.-big-picture-and-complexity}

A quick reference for understanding algorithms, efficiency, and growth
rates. Keep this sheet beside you as you read or code.

\subsubsection{What Is an Algorithm?}\label{what-is-an-algorithm}

An algorithm is a clear, step-by-step process that solves a problem.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Property & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Precise & Each step is unambiguous \\
Finite & Must stop after a certain number of steps \\
Effective & Every step is doable by machine or human \\
Deterministic & Same input, same output (usually) \\
\end{longtable}

Think of it like a recipe:

\begin{itemize}
\tightlist
\item
  Input: ingredients
\item
  Steps: instructions
\item
  Output: final dish
\end{itemize}

\subsubsection{Core Qualities}\label{core-qualities}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Concept & Question to Ask \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Correctness & Does it always solve the problem \\
Termination & Does it eventually stop \\
Complexity & How much time and space it needs \\
Clarity & Is it easy to understand and implement \\
\end{longtable}

\subsubsection{Why Complexity Matters}\label{why-complexity-matters}

Different algorithms grow differently as input size \(n\) increases.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Growth Rate & Example Algorithm & Effect When \(n\) Doubles \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(O(1)\) & Hash lookup & No change \\
\(O(\log n)\) & Binary search & Slight increase \\
\(O(n)\) & Linear scan & Doubled \\
\(O(n\log n)\) & Merge sort & Slightly more than 2× \\
\(O(n^2)\) & Bubble sort & Quadrupled \\
\(O(2^n)\) & Subset generation & Explodes \\
\(O(n!)\) & Brute-force permutations & Unusable beyond \(n=10\) \\
\end{longtable}

\subsubsection{Measuring Time and Space}\label{measuring-time-and-space}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1839}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4943}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3218}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Measure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Time Complexity & Number of operations & Loop from 1 to \(n\):
\(O(n)\) \\
Space Complexity & Memory usage (stack, heap, data structures) &
Recursive call depth: \(O(n)\) \\
\end{longtable}

Simple rules:

\begin{itemize}
\tightlist
\item
  Sequential steps: sum of costs
\item
  Nested loops: product of sizes
\item
  Recursion: use recurrence relations
\end{itemize}

\subsubsection{Common Patterns}\label{common-patterns}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Pattern & Cost Formula & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Single Loop (1 to \(n\)) & \(T(n) = n\) & \(O(n)\) \\
Nested Loops (\(n \times n\)) & \(T(n) = n^2\) & \(O(n^2)\) \\
Halving Each Step & \(T(n) = \log_2 n\) & \(O(\log n)\) \\
Divide and Conquer (2 halves) & \(T(n) = 2T(n/2) + n\) &
\(O(n\log n)\) \\
\end{longtable}

\subsubsection{Doubling Rule}\label{doubling-rule}

Run algorithm for \(n\) and \(2n\):

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Observation & Likely Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Constant time & \(O(1)\) \\
Time doubles & \(O(n)\) \\
Time quadruples & \(O(n^2)\) \\
Time × log factor & \(O(n\log n)\) \\
\end{longtable}

\subsubsection{Tiny Code: Binary Search}\label{tiny-code-binary-search}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ binary\_search(arr, x):}
\NormalTok{    lo, hi }\OperatorTok{=} \DecValTok{0}\NormalTok{, }\BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ lo }\OperatorTok{\textless{}=}\NormalTok{ hi:}
\NormalTok{        mid }\OperatorTok{=}\NormalTok{ (lo }\OperatorTok{+}\NormalTok{ hi) }\OperatorTok{//} \DecValTok{2}
        \ControlFlowTok{if}\NormalTok{ arr[mid] }\OperatorTok{==}\NormalTok{ x:}
            \ControlFlowTok{return}\NormalTok{ mid}
        \ControlFlowTok{elif}\NormalTok{ arr[mid] }\OperatorTok{\textless{}}\NormalTok{ x:}
\NormalTok{            lo }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            hi }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

Complexity: \[T(n) = T(n/2) + 1 \Rightarrow O(\log n)\]

\subsubsection{Common Pitfalls}\label{common-pitfalls}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3788}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6212}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Issue
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Tip
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Off-by-one error & Check loop bounds carefully \\
Infinite loop & Ensure termination condition is reachable \\
Midpoint overflow (C/C++) & Use
\texttt{mid\ =\ lo\ +\ (hi\ -\ lo)\ /\ 2} \\
Unsorted data in search & Binary search only works on sorted input \\
\end{longtable}

\subsubsection{Quick Growth Summary}\label{quick-growth-summary}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Type & Formula Example & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Constant & \(1\) & Fixed time \\
Logarithmic & \(\log n\) & Divide each time \\
Linear & \(n\) & Step through all items \\
Linearithmic & \(n \log n\) & Sort-like complexity \\
Quadratic & \(n^2\) & Double loop \\
Cubic & \(n^3\) & Triple nested loops \\
Exponential & \(2^n\) & All subsets \\
Factorial & \(n!\) & All permutations \\
\end{longtable}

\subsubsection{Simple Rule of Thumb}\label{simple-rule-of-thumb}

Trace small examples by hand. Count steps, memory, and recursion depth.
You'll see how growth behaves before running code.

\subsection{Page 2. Recurrences and Master
Theorem}\label{page-2.-recurrences-and-master-theorem}

This page helps you break down recursive algorithms and estimate their
runtime using recurrences.

\subsubsection{What Is a Recurrence?}\label{what-is-a-recurrence}

A recurrence relation expresses a problem's cost \(T(n)\) in terms of
smaller subproblems.

Typical structure:

\[
T(n) = a , T\left(\frac{n}{b}\right) + f(n)
\]

where:

\begin{itemize}
\tightlist
\item
  \(a\) = number of subproblems
\item
  \(b\) = factor by which input shrinks
\item
  \(f(n)\) = extra work per call (merge, combine, etc.)
\end{itemize}

\subsubsection{Common Recurrences}\label{common-recurrences}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Recurrence Form & Solution \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Search & \(T(n)=T(n/2)+1\) & \(O(\log n)\) \\
Merge Sort & \(T(n)=2T(n/2)+n\) & \(O(n\log n)\) \\
Quick Sort (avg) & \(T(n)=2T(n/2)+O(n)\) & \(O(n\log n)\) \\
Quick Sort (worst) & \(T(n)=T(n-1)+O(n)\) & \(O(n^2)\) \\
Matrix Multiply & \(T(n)=8T(n/2)+O(n^2)\) & \(O(n^3)\) \\
Karatsuba & \(T(n)=3T(n/2)+O(n)\) & \(O(n^{\log_2 3})\) \\
\end{longtable}

\subsubsection{Solving Recurrences}\label{solving-recurrences}

There are several methods to solve them:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2188}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2812}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Iteration & Expand step by step & Simple recurrences \\
Substitution & Guess and prove with induction & Verification \\
Recursion Tree & Visualize total work per level & Divide and conquer \\
Master Theorem & Shortcut for \(T(n)=aT(n/b)+f(n)\) & Standard forms \\
\end{longtable}

\subsubsection{The Master Theorem}\label{the-master-theorem}

Given \[T(n) = aT(n/b) + f(n)\]

Let \[n^{\log_b a}\] be the ``critical term''

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0357}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5982}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3661}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Condition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Result
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & If \(f(n) = O(n^{\log_b a - \varepsilon})\) &
\(T(n) = \Theta(n^{\log_b a})\) \\
2 & If \(f(n) = \Theta(n^{\log_b a}\log^k n)\) &
\(T(n) = \Theta(n^{\log_b a}\log^{k+1} n)\) \\
3 & If \(f(n) = \Omega(n^{\log_b a + \varepsilon})\) and regularity
holds & \(T(n) = \Theta(f(n))\) \\
\end{longtable}

\subsubsection{Examples}\label{examples}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0545}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0545}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1091}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.4000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(a\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(b\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(f(n)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(T(n)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Merge Sort & 2 & 2 & \(n\) & 2 & \(\Theta(n\log n)\) \\
Binary Search & 1 & 2 & \(1\) & 1 & \(\Theta(\log n)\) \\
Strassen Multiply & 7 & 2 & \(n^2\) & 2 & \(\Theta(n^{\log_2 7})\) \\
Quick Sort (avg) & 2 & 2 & \(n\) & 2 & \(\Theta(n\log n)\) \\
\end{longtable}

\subsubsection{Recursion Tree
Visualization}\label{recursion-tree-visualization}

Break cost into levels:

Example: \(T(n)=2T(n/2)+n\)

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Level & \#Nodes & Work per Node & Total Work \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 & \(n\) & \(n\) \\
1 & 2 & \(n/2\) & \(n\) \\
2 & 4 & \(n/4\) & \(n\) \\
\ldots{} & \ldots{} & \ldots{} & \ldots{} \\
\end{longtable}

Sum across \(\log_2 n\) levels:

\[T(n) = n \log_2 n\]

\subsubsection{Tiny Code: Fast
Exponentiation}\label{tiny-code-fast-exponentiation}

Compute \(a^n\) efficiently.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ power(a, n):}
\NormalTok{    res }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ n }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{:}
\NormalTok{            res }\OperatorTok{*=}\NormalTok{ a}
\NormalTok{        a }\OperatorTok{*=}\NormalTok{ a}
\NormalTok{        n }\OperatorTok{//=} \DecValTok{2}
    \ControlFlowTok{return}\NormalTok{ res}
\end{Highlighting}
\end{Shaded}

Recurrence:

\[T(n) = T(n/2) + O(1) \Rightarrow O(\log n)\]

\subsubsection{Iteration Method Example}\label{iteration-method-example}

Solve \(T(n)=T(n/2)+n\)

Expand:

\[
\begin{aligned}
T(n) &= T(n/2) + n \
&= T(n/4) + n/2 + n \
&= T(n/8) + n/4 + n/2 + n \
&= \ldots + n(1 + 1/2 + 1/4 + \ldots) \
&= O(n)
\end{aligned}
\]

\subsubsection{Common Forms}\label{common-forms}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Form & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n)=T(n-1)+O(1)\) & \(O(n)\) \\
\(T(n)=T(n/2)+O(1)\) & \(O(\log n)\) \\
\(T(n)=2T(n/2)+O(1)\) & \(O(n)\) \\
\(T(n)=2T(n/2)+O(n)\) & \(O(n\log n)\) \\
\(T(n)=T(n/2)+O(n)\) & \(O(n)\) \\
\end{longtable}

\subsubsection{Quick Checklist}\label{quick-checklist}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify \(a\), \(b\), and \(f(n)\)
\item
  Compare \(f(n)\) to \(n^{\log_b a}\)
\item
  Apply correct case
\item
  Confirm assumptions (regularity)
\item
  State final complexity
\end{enumerate}

Understanding recurrences helps you estimate performance before coding.
Always look for subproblem count, size, and merge cost.

\subsection{Page 3. Sorting at a
Glance}\label{page-3.-sorting-at-a-glance}

Sorting is one of the most common algorithmic tasks. This page helps you
quickly compare sorting methods, their complexity, stability, and when
to use them.

\subsubsection{Why Sorting Matters}\label{why-sorting-matters}

Sorting organizes data so that searches, merges, and analyses become
efficient. Many problems become simpler once the input is sorted.

\subsubsection{Quick Comparison Table}\label{quick-comparison-table}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1359}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1068}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0583}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.0777}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.2718}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-Place
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & \(O(n)\) & \(O(n^2)\) & \(O(n^2)\) & \(O(1)\) & Yes & Yes
& Simple, educational \\
Selection Sort & \(O(n^2)\) & \(O(n^2)\) & \(O(n^2)\) & \(O(1)\) & No &
Yes & Few swaps \\
Insertion Sort & \(O(n)\) & \(O(n^2)\) & \(O(n^2)\) & \(O(1)\) & Yes &
Yes & Great for small/partial sort \\
Merge Sort & \(O(n\log n)\) & \(O(n\log n)\) & \(O(n\log n)\) & \(O(n)\)
& Yes & No & Stable, divide and conquer \\
Quick Sort & \(O(n\log n)\) & \(O(n\log n)\) & \(O(n^2)\) &
\(O(\log n)\) & No & Yes & Fast average, in place \\
Heap Sort & \(O(n\log n)\) & \(O(n\log n)\) & \(O(n\log n)\) & \(O(1)\)
& No & Yes & Not stable \\
Counting Sort & \(O(n+k)\) & \(O(n+k)\) & \(O(n+k)\) & \(O(n+k)\) & Yes
& No & Integer keys only \\
Radix Sort & \(O(d(n+k))\) & \(O(d(n+k))\) & \(O(d(n+k))\) & \(O(n+k)\)
& Yes & No & Sort by digits \\
Bucket Sort & \(O(n+k)\) & \(O(n+k)\) & \(O(n^2)\) & \(O(n)\) & Yes & No
& Uniform distribution needed \\
\end{longtable}

\subsubsection{Choosing a Sorting
Algorithm}\label{choosing-a-sorting-algorithm}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Situation & Best Choice \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Small array or nearly sorted data & Insertion Sort \\
Stable required, general case & Merge Sort or Timsort \\
In-place and fast on average & Quick Sort \\
Guarantee worst-case \(O(n\log n)\) & Heap Sort \\
Small integer keys or limited range & Counting or Radix \\
External sorting (large data) & External Merge Sort \\
\end{longtable}

\subsubsection{Tiny Code: Insertion
Sort}\label{tiny-code-insertion-sort}

Simple and intuitive for beginners.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ insertion\_sort(a):}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(a)):}
\NormalTok{        key }\OperatorTok{=}\NormalTok{ a[i]}
\NormalTok{        j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ a[j] }\OperatorTok{\textgreater{}}\NormalTok{ key:}
\NormalTok{            a[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ a[j]}
\NormalTok{            j }\OperatorTok{{-}=} \DecValTok{1}
\NormalTok{        a[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ key}
    \ControlFlowTok{return}\NormalTok{ a}
\end{Highlighting}
\end{Shaded}

Complexity: \[T(n) = O(n^2)\] average, \[O(n)\] best (already sorted)

\subsubsection{Divide and Conquer Sorts}\label{divide-and-conquer-sorts}

\paragraph{Merge Sort}\label{merge-sort}

Splits list, sorts halves, merges results.

Recurrence: \[T(n) = 2T(n/2) + O(n) = O(n\log n)\]

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ merge\_sort(a):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(a) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ a}
\NormalTok{    mid }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(a)}\OperatorTok{//}\DecValTok{2}
\NormalTok{    L }\OperatorTok{=}\NormalTok{ merge\_sort(a[:mid])}
\NormalTok{    R }\OperatorTok{=}\NormalTok{ merge\_sort(a[mid:])}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}
\NormalTok{    res }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(L) }\KeywordTok{and}\NormalTok{ j }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(R):}
        \ControlFlowTok{if}\NormalTok{ L[i] }\OperatorTok{\textless{}=}\NormalTok{ R[j]:}
\NormalTok{            res.append(L[i])}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            res.append(R[j])}\OperatorTok{;}\NormalTok{ j }\OperatorTok{+=} \DecValTok{1}
\NormalTok{    res.extend(L[i:])}\OperatorTok{;}\NormalTok{ res.extend(R[j:])}
    \ControlFlowTok{return}\NormalTok{ res}
\end{Highlighting}
\end{Shaded}

\paragraph{Quick Sort}\label{quick-sort}

Pick pivot, partition, sort subarrays.

Recurrence: \[T(n) = T(k) + T(n-k-1) + O(n)\] Average case:
\[O(n\log n)\] Worst case: \[O(n^2)\]

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ quick\_sort(a):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(a) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ a}
\NormalTok{    pivot }\OperatorTok{=}\NormalTok{ a[}\BuiltInTok{len}\NormalTok{(a)}\OperatorTok{//}\DecValTok{2}\NormalTok{]}
\NormalTok{    left  }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ a }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}}\NormalTok{ pivot]}
\NormalTok{    mid   }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ a }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{==}\NormalTok{ pivot]}
\NormalTok{    right }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ a }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}}\NormalTok{ pivot]}
    \ControlFlowTok{return}\NormalTok{ quick\_sort(left) }\OperatorTok{+}\NormalTok{ mid }\OperatorTok{+}\NormalTok{ quick\_sort(right)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Stable vs Unstable}\label{stable-vs-unstable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1270}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5397}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Stable & Equal elements keep original order & Merge Sort, Insertion \\
Unstable & May reorder equal elements & Quick, Heap \\
\end{longtable}

\subsubsection{Visualization Tips}\label{visualization-tips}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pattern & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble & Compare and swap adjacent \\
Selection & Select min each pass \\
Insertion & Grow sorted region step by step \\
Merge & Divide, conquer, merge \\
Quick & Partition and recurse \\
Heap & Build heap, extract repeatedly \\
\end{longtable}

\subsubsection{Summary Table}\label{summary-table}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2295}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2951}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1967}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1475}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1311}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Category
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Simple & Bubble, Selection & \(O(n^2)\) & Varies & \(O(1)\) \\
Insertion & Incremental & \(O(n^2)\) & Yes & \(O(1)\) \\
Divide/Conquer & Merge, Quick & \(O(n\log n)\) & Merge yes & Merge no \\
Distribution & Counting, Radix & \(O(n+k)\) & Yes & \(O(n+k)\) \\
Hybrid & Timsort, IntroSort & \(O(n\log n)\) & Yes & Varies \\
\end{longtable}

When in doubt, start with Timsort (Python) or std::sort (C++) which
adapt dynamically.

\subsection{Page 4. Searching and
Selection}\label{page-4.-searching-and-selection}

Searching means finding what you need from a collection. Selection means
picking specific elements such as the smallest, largest, or k-th
element. This page summarizes both.

\subsubsection{Searching Basics}\label{searching-basics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4074}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1975}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2346}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Requirement
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & Check one by one & None & \(O(n)\) \\
Binary Search & Divide range by 2 each step & Sorted & \(O(\log n)\) \\
Jump Search & Skip ahead fixed steps & Sorted & \(O(\sqrt n)\) \\
Interpolation & Guess position based on value & Sorted, uniform &
\(O(\log\log n)\) avg \\
Exponential & Expand window, then binary search & Sorted &
\(O(\log n)\) \\
\end{longtable}

\subsubsection{Linear Search}\label{linear-search}

Simple but slow for large inputs.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ linear\_search(a, x):}
    \ControlFlowTok{for}\NormalTok{ i, v }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(a):}
        \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{==}\NormalTok{ x:}
            \ControlFlowTok{return}\NormalTok{ i}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

Complexity: \[T(n) = O(n)\]

\subsubsection{Binary Search}\label{binary-search}

Fast on sorted lists.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ binary\_search(a, x):}
\NormalTok{    lo, hi }\OperatorTok{=} \DecValTok{0}\NormalTok{, }\BuiltInTok{len}\NormalTok{(a) }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ lo }\OperatorTok{\textless{}=}\NormalTok{ hi:}
\NormalTok{        mid }\OperatorTok{=}\NormalTok{ (lo }\OperatorTok{+}\NormalTok{ hi) }\OperatorTok{//} \DecValTok{2}
        \ControlFlowTok{if}\NormalTok{ a[mid] }\OperatorTok{==}\NormalTok{ x:}
            \ControlFlowTok{return}\NormalTok{ mid}
        \ControlFlowTok{elif}\NormalTok{ a[mid] }\OperatorTok{\textless{}}\NormalTok{ x:}
\NormalTok{            lo }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            hi }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

Complexity: \[T(n) = T(n/2) + 1 \Rightarrow O(\log n)\]

\subsubsection{Binary Search Variants}\label{binary-search-variants}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1594}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4348}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4058}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Goal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Return Value
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Lower Bound & First index where \(a[i] \ge x\) & Position of first ≥
x \\
Upper Bound & First index where \(a[i] > x\) & Position of first
\textgreater{} x \\
Count Range & \texttt{upper\_bound\ -\ lower\_bound} & Count of \(x\) in
sorted array \\
\end{longtable}

\subsubsection{Common Binary Search
Pitfalls}\label{common-binary-search-pitfalls}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Problem & Fix \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Infinite loop & Update bounds correctly \\
Off-by-one & Check mid inclusion carefully \\
Unsuitable for unsorted data & Sort or use hash-based search \\
Overflow (C/C++) & \texttt{mid\ =\ lo\ +\ (hi\ -\ lo)\ /\ 2} \\
\end{longtable}

\subsubsection{Exponential Search}\label{exponential-search}

Used for unbounded or large sorted lists.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check positions \(1, 2, 4, 8, ...\) until \(a[i] \ge x\)
\item
  Binary search in last found interval
\end{enumerate}

Complexity: \[O(\log n)\]

\subsubsection{Selection Problems}\label{selection-problems}

Find the \(k\)-th smallest or largest element.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2361}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Min / Max & Smallest / largest element & Linear Scan & \(O(n)\) \\
k-th Smallest & Order statistic & Quickselect & Avg \(O(n)\) \\
Median & Middle element & Quickselect & Avg \(O(n)\) \\
Top-k Elements & Partial sort & Heap / Partition & \(O(n\log k)\) \\
Median of Medians & Worst-case linear selection & Deterministic &
\(O(n)\) \\
\end{longtable}

\subsubsection{Tiny Code: Quickselect (k-th
smallest)}\label{tiny-code-quickselect-k-th-smallest}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ quickselect(a, k):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(a) }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ a[}\DecValTok{0}\NormalTok{]}
\NormalTok{    pivot }\OperatorTok{=}\NormalTok{ random.choice(a)}
\NormalTok{    left  }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ a }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}}\NormalTok{ pivot]}
\NormalTok{    mid   }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ a }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{==}\NormalTok{ pivot]}
\NormalTok{    right }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ a }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}}\NormalTok{ pivot]}

    \ControlFlowTok{if}\NormalTok{ k }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(left):}
        \ControlFlowTok{return}\NormalTok{ quickselect(left, k)}
    \ControlFlowTok{elif}\NormalTok{ k }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(left) }\OperatorTok{+} \BuiltInTok{len}\NormalTok{(mid):}
        \ControlFlowTok{return}\NormalTok{ pivot}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ quickselect(right, k }\OperatorTok{{-}} \BuiltInTok{len}\NormalTok{(left) }\OperatorTok{{-}} \BuiltInTok{len}\NormalTok{(mid))}
\end{Highlighting}
\end{Shaded}

Complexity: Average \(O(n)\), Worst \(O(n^2)\)

\subsubsection{Tiny Code: Lower Bound}\label{tiny-code-lower-bound}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ lower\_bound(a, x):}
\NormalTok{    lo, hi }\OperatorTok{=} \DecValTok{0}\NormalTok{, }\BuiltInTok{len}\NormalTok{(a)}
    \ControlFlowTok{while}\NormalTok{ lo }\OperatorTok{\textless{}}\NormalTok{ hi:}
\NormalTok{        mid }\OperatorTok{=}\NormalTok{ (lo }\OperatorTok{+}\NormalTok{ hi) }\OperatorTok{//} \DecValTok{2}
        \ControlFlowTok{if}\NormalTok{ a[mid] }\OperatorTok{\textless{}}\NormalTok{ x:}
\NormalTok{            lo }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            hi }\OperatorTok{=}\NormalTok{ mid}
    \ControlFlowTok{return}\NormalTok{ lo}
\end{Highlighting}
\end{Shaded}

\subsubsection{Hash-Based Searching}\label{hash-based-searching}

When order does not matter, hashing gives near constant lookup.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Average & Worst \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & \(O(1)\) & \(O(n)\) \\
Search & \(O(1)\) & \(O(n)\) \\
Delete & \(O(1)\) & \(O(n)\) \\
\end{longtable}

Best for large, unsorted collections.

\subsubsection{Summary Table}\label{summary-table-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Scenario & Recommended Approach & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Small array & Linear Search & \(O(n)\) \\
Large, sorted array & Binary Search & \(O(\log n)\) \\
Unbounded range & Exponential Search & \(O(\log n)\) \\
Need k-th smallest element & Quickselect & Avg \(O(n)\) \\
Many lookups & Hash Table & Avg \(O(1)\) \\
\end{longtable}

\subsubsection{Quick Tips}\label{quick-tips}

\begin{itemize}
\tightlist
\item
  Always check whether data is sorted before applying binary search.
\item
  Quickselect is great when you only need the k-th element, not a full
  sort.
\item
  Use hash maps for fast lookups on unsorted data.
\end{itemize}

\subsection{Page 5. Core Data
Structures}\label{page-5.-core-data-structures}

Data structures organize data for efficient access and modification.
Choosing the right one often makes an algorithm simple and fast.

\subsubsection{Arrays and Lists}\label{arrays-and-lists}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1700}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Search
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert End
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert Middle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Static Array & \(O(1)\) & \(O(n)\) & N/A & \(O(n)\) & \(O(n)\) & Fixed
size \\
Dynamic Array & \(O(1)\) & \(O(n)\) & Amortized \(O(1)\) & \(O(n)\) &
\(O(n)\) & Auto-resizing \\
Linked List (S) & \(O(n)\) & \(O(n)\) & \(O(1)\) head & \(O(1)\) if node
known & \(O(1)\) if node known & Sequential access \\
Linked List (D) & \(O(n)\) & \(O(n)\) & \(O(1)\) head/tail & \(O(1)\) if
node known & \(O(1)\) if node known & Two-way traversal \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  Singly linked lists: next pointer only
\item
  Doubly linked lists: next and prev pointers
\item
  Dynamic arrays use \emph{doubling} to grow capacity
\end{itemize}

\subsubsection{Tiny Code: Dynamic Array Resize
(Python-like)}\label{tiny-code-dynamic-array-resize-python-like}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ resize(arr, new\_cap):}
\NormalTok{    new }\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ new\_cap}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(arr)):}
\NormalTok{        new[i] }\OperatorTok{=}\NormalTok{ arr[i]}
    \ControlFlowTok{return}\NormalTok{ new}
\end{Highlighting}
\end{Shaded}

Doubling capacity keeps amortized append \(O(1)\).

\subsubsection{Stacks and Queues}\label{stacks-and-queues}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Structure & Push & Pop & Peek & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Stack (LIFO) & \(O(1)\) & \(O(1)\) & \(O(1)\) & Undo operations,
recursion \\
Queue (FIFO) & \(O(1)\) & \(O(1)\) & \(O(1)\) & Scheduling, BFS \\
Deque & \(O(1)\) & \(O(1)\) & \(O(1)\) & Insert/remove both ends \\
\end{longtable}

\subsubsection{Tiny Code: Stack}\label{tiny-code-stack}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stack }\OperatorTok{=}\NormalTok{ []}
\NormalTok{stack.append(x)   }\CommentTok{\# push}
\NormalTok{x }\OperatorTok{=}\NormalTok{ stack.pop()   }\CommentTok{\# pop}
\end{Highlighting}
\end{Shaded}

\subsubsection{Tiny Code: Queue}\label{tiny-code-queue}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\NormalTok{q }\OperatorTok{=}\NormalTok{ deque()}
\NormalTok{q.append(x)   }\CommentTok{\# enqueue}
\NormalTok{x }\OperatorTok{=}\NormalTok{ q.popleft()  }\CommentTok{\# dequeue}
\end{Highlighting}
\end{Shaded}

\subsubsection{Priority Queue (Heap)}\label{priority-queue-heap}

Stores elements so the smallest (or largest) is always on top.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & \(O(\log n)\) \\
Extract min & \(O(\log n)\) \\
Peek min & \(O(1)\) \\
Build heap & \(O(n)\) \\
\end{longtable}

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ heapq}
\NormalTok{heap }\OperatorTok{=}\NormalTok{ []}
\NormalTok{heapq.heappush(heap, value)}
\NormalTok{x }\OperatorTok{=}\NormalTok{ heapq.heappop(heap)}
\end{Highlighting}
\end{Shaded}

Heaps are used in Dijkstra, Prim, and scheduling.

\subsubsection{Hash Tables}\label{hash-tables}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Average & Worst & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & \(O(1)\) & \(O(n)\) & Hash collisions increase cost \\
Search & \(O(1)\) & \(O(n)\) & Good hash + low load factor helps \\
Delete & \(O(1)\) & \(O(n)\) & Usually open addressing or chaining \\
\end{longtable}

Key ideas:

\begin{itemize}
\tightlist
\item
  Compute index using hash function:
  \texttt{index\ =\ hash(key)\ \%\ capacity}
\item
  Resolve collisions by chaining or probing
\end{itemize}

\subsubsection{Tiny Code: Hash Map
(Simplified)}\label{tiny-code-hash-map-simplified}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table }\OperatorTok{=}\NormalTok{ [[] }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{8}\NormalTok{)]}
\KeywordTok{def}\NormalTok{ put(key, value):}
\NormalTok{    i }\OperatorTok{=} \BuiltInTok{hash}\NormalTok{(key) }\OperatorTok{\%} \BuiltInTok{len}\NormalTok{(table)}
    \ControlFlowTok{for}\NormalTok{ kv }\KeywordTok{in}\NormalTok{ table[i]:}
        \ControlFlowTok{if}\NormalTok{ kv[}\DecValTok{0}\NormalTok{] }\OperatorTok{==}\NormalTok{ key:}
\NormalTok{            kv[}\DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ value}
            \ControlFlowTok{return}
\NormalTok{    table[i].append([key, value])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Sets}\label{sets}

A hash-based collection of unique elements.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation & Average Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Add & \(O(1)\) \\
Search & \(O(1)\) \\
Remove & \(O(1)\) \\
\end{longtable}

Used for membership checks and duplicates removal.

\subsubsection{Union-Find (Disjoint Set)}\label{union-find-disjoint-set}

Keeps track of connected components. Two main operations:

\begin{itemize}
\tightlist
\item
  find(x): get representative of x
\item
  union(a,b): merge sets of a and b
\end{itemize}

With path compression + union by rank → nearly \(O(1)\).

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ DSU:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, n):}
        \VariableTok{self}\NormalTok{.p }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(n))}
        \VariableTok{self}\NormalTok{.r }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\NormalTok{n}
    \KeywordTok{def}\NormalTok{ find(}\VariableTok{self}\NormalTok{, x):}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.p[x] }\OperatorTok{!=}\NormalTok{ x:}
            \VariableTok{self}\NormalTok{.p[x] }\OperatorTok{=} \VariableTok{self}\NormalTok{.find(}\VariableTok{self}\NormalTok{.p[x])}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.p[x]}
    \KeywordTok{def}\NormalTok{ union(}\VariableTok{self}\NormalTok{, a, b):}
\NormalTok{        ra, rb }\OperatorTok{=} \VariableTok{self}\NormalTok{.find(a), }\VariableTok{self}\NormalTok{.find(b)}
        \ControlFlowTok{if}\NormalTok{ ra }\OperatorTok{==}\NormalTok{ rb: }\ControlFlowTok{return}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.r[ra] }\OperatorTok{\textless{}} \VariableTok{self}\NormalTok{.r[rb]: ra, rb }\OperatorTok{=}\NormalTok{ rb, ra}
        \VariableTok{self}\NormalTok{.p[rb] }\OperatorTok{=}\NormalTok{ ra}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.r[ra] }\OperatorTok{==} \VariableTok{self}\NormalTok{.r[rb]:}
            \VariableTok{self}\NormalTok{.r[ra] }\OperatorTok{+=} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\subsubsection{Summary Table}\label{summary-table-2}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Category & Structure & Use Case \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sequence & Array, List & Ordered data \\
LIFO/FIFO & Stack, Queue & Recursion, scheduling \\
Priority & Heap & Best-first selection, PQ problems \\
Hash-based & Hash Table, Set & Fast lookups, uniqueness \\
Connectivity & Union-Find & Graph components, clustering \\
\end{longtable}

\subsubsection{Quick Tips}\label{quick-tips-1}

\begin{itemize}
\tightlist
\item
  Choose array when random access matters.
\item
  Choose list when insertions/deletions frequent.
\item
  Choose stack or queue for control flow.
\item
  Choose heap for priority.
\item
  Choose hash table for constant lookups.
\item
  Choose DSU for disjoint sets or graph merging.
\end{itemize}

\subsection{Page 6. Graphs Quick Use}\label{page-6.-graphs-quick-use}

Graphs model connections between objects. They appear everywhere: maps,
networks, dependencies, and systems. This page gives you a compact view
of common graph algorithms.

\subsubsection{Graph Basics}\label{graph-basics}

A graph has vertices (nodes) and edges (connections).

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Type & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & Edges go both ways \\
Directed (Digraph) & Edges have direction \\
Weighted & Edges carry cost or distance \\
Unweighted & All edges cost 1 \\
\end{longtable}

\subsubsection{Representations}\label{representations}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2254}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1127}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2958}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3662}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Representation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adjacency List & \(O(V+E)\) & Sparse graphs & Common in practice \\
Adjacency Matrix & \(O(V^2)\) & Dense graphs & Constant-time edge
lookup \\
Edge List & \(O(E)\) & Edge-based algorithms & Easy to iterate over
edges \\
\end{longtable}

Adjacency List Example (Python):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \DecValTok{0}\NormalTok{: [(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), (}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{)],}
    \DecValTok{1}\NormalTok{: [(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)],}
    \DecValTok{2}\NormalTok{: []}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Each tuple \texttt{(neighbor,\ weight)} represents an edge.

\subsubsection{Traversals}\label{traversals}

\paragraph{Breadth-First Search (BFS)}\label{breadth-first-search-bfs}

Visits layer by layer (good for shortest paths in unweighted graphs).

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}
\KeywordTok{def}\NormalTok{ bfs(adj, s):}
\NormalTok{    dist }\OperatorTok{=}\NormalTok{ \{s: }\DecValTok{0}\NormalTok{\}}
\NormalTok{    q }\OperatorTok{=}\NormalTok{ deque([s])}
    \ControlFlowTok{while}\NormalTok{ q:}
\NormalTok{        u }\OperatorTok{=}\NormalTok{ q.popleft()}
        \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ adj[u]:}
            \ControlFlowTok{if}\NormalTok{ v }\KeywordTok{not} \KeywordTok{in}\NormalTok{ dist:}
\NormalTok{                dist[v] }\OperatorTok{=}\NormalTok{ dist[u] }\OperatorTok{+} \DecValTok{1}
\NormalTok{                q.append(v)}
    \ControlFlowTok{return}\NormalTok{ dist}
\end{Highlighting}
\end{Shaded}

Complexity: \(O(V+E)\)

\paragraph{Depth-First Search (DFS)}\label{depth-first-search-dfs}

Explores deeply before backtracking.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ dfs(adj, u, visited):}
\NormalTok{    visited.add(u)}
    \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ adj[u]:}
        \ControlFlowTok{if}\NormalTok{ v }\KeywordTok{not} \KeywordTok{in}\NormalTok{ visited:}
\NormalTok{            dfs(adj, v, visited)}
\end{Highlighting}
\end{Shaded}

Complexity: \(O(V+E)\)

\subsubsection{Shortest Path Algorithms}\label{shortest-path-algorithms}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2024}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1905}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2738}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Works On
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Negative Edges
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
BFS & Unweighted & No & \(O(V+E)\) & Shortest hops \\
Dijkstra & Weighted (nonneg) & No & \(O((V+E)\log V)\) & Uses priority
queue \\
Bellman-Ford & Weighted & Yes & \(O(VE)\) & Detects negative cycles \\
Floyd-Warshall & All pairs & Yes & \(O(V^3)\) & DP approach \\
\end{longtable}

\subsubsection{Tiny Code: Dijkstra's
Algorithm}\label{tiny-code-dijkstras-algorithm}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ heapq}

\KeywordTok{def}\NormalTok{ dijkstra(adj, s):}
\NormalTok{    INF }\OperatorTok{=} \DecValTok{1018}
\NormalTok{    dist }\OperatorTok{=}\NormalTok{ [INF] }\OperatorTok{*} \BuiltInTok{len}\NormalTok{(adj)}
\NormalTok{    dist[s] }\OperatorTok{=} \DecValTok{0}
\NormalTok{    pq }\OperatorTok{=}\NormalTok{ [(}\DecValTok{0}\NormalTok{, s)]}
    \ControlFlowTok{while}\NormalTok{ pq:}
\NormalTok{        d, u }\OperatorTok{=}\NormalTok{ heapq.heappop(pq)}
        \ControlFlowTok{if}\NormalTok{ d }\OperatorTok{!=}\NormalTok{ dist[u]: }
            \ControlFlowTok{continue}
        \ControlFlowTok{for}\NormalTok{ v, w }\KeywordTok{in}\NormalTok{ adj[u]:}
\NormalTok{            nd }\OperatorTok{=}\NormalTok{ d }\OperatorTok{+}\NormalTok{ w}
            \ControlFlowTok{if}\NormalTok{ nd }\OperatorTok{\textless{}}\NormalTok{ dist[v]:}
\NormalTok{                dist[v] }\OperatorTok{=}\NormalTok{ nd}
\NormalTok{                heapq.heappush(pq, (nd, v))}
    \ControlFlowTok{return}\NormalTok{ dist}
\end{Highlighting}
\end{Shaded}

\subsubsection{Topological Sort (DAGs
only)}\label{topological-sort-dags-only}

Orders nodes so every edge \((u,v)\) goes from earlier to later.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Idea & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS-based & Post-order stack reversal & \(O(V+E)\) \\
Kahn's Algo & Remove nodes with indegree 0 & \(O(V+E)\) \\
\end{longtable}

\subsubsection{Minimum Spanning Tree
(MST)}\label{minimum-spanning-tree-mst}

Connect all nodes with minimum total weight.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3611}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3472}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Kruskal & Sort edges, use Union-Find & \(O(E\log E)\) & Works well with
edge list \\
Prim & Grow tree using PQ & \(O(E\log V)\) & Starts from any vertex \\
\end{longtable}

\subsubsection{Tiny Code: Kruskal MST}\label{tiny-code-kruskal-mst}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ kruskal(edges, n):}
\NormalTok{    parent }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(n))}
    \KeywordTok{def}\NormalTok{ find(x):}
        \ControlFlowTok{if}\NormalTok{ parent[x] }\OperatorTok{!=}\NormalTok{ x:}
\NormalTok{            parent[x] }\OperatorTok{=}\NormalTok{ find(parent[x])}
        \ControlFlowTok{return}\NormalTok{ parent[x]}
\NormalTok{    res }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ w, u, v }\KeywordTok{in} \BuiltInTok{sorted}\NormalTok{(edges):}
\NormalTok{        ru, rv }\OperatorTok{=}\NormalTok{ find(u), find(v)}
        \ControlFlowTok{if}\NormalTok{ ru }\OperatorTok{!=}\NormalTok{ rv:}
\NormalTok{            res }\OperatorTok{+=}\NormalTok{ w}
\NormalTok{            parent[rv] }\OperatorTok{=}\NormalTok{ ru}
    \ControlFlowTok{return}\NormalTok{ res}
\end{Highlighting}
\end{Shaded}

\subsubsection{Strongly Connected Components
(SCC)}\label{strongly-connected-components-scc}

Subsets where every node can reach every other. Use Kosaraju or Tarjan
algorithm, both \(O(V+E)\).

\subsubsection{Cycle Detection}\label{cycle-detection}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Graph Type & Method & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & DFS with parent & Edge to non-parent visited \\
Directed & DFS with color/state & Back edge found = cycle \\
\end{longtable}

\subsubsection{Summary Table}\label{summary-table-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3377}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2078}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1558}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2987}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Visit all nodes & DFS / BFS & \(O(V+E)\) & Traversal \\
Shortest path (unweighted) & BFS & \(O(V+E)\) & Counts edges \\
Shortest path (weighted) & Dijkstra & \(O(E\log V)\) & No negative
weights \\
Negative edges allowed & Bellman-Ford & \(O(VE)\) & Detects negative
cycles \\
All-pairs shortest path & Floyd-Warshall & \(O(V^3)\) & DP matrix \\
MST & Kruskal / Prim & \(O(E\log V)\) & Minimal connection cost \\
DAG order & Topological Sort & \(O(V+E)\) & Only for DAGs \\
\end{longtable}

\subsubsection{Quick Tips}\label{quick-tips-2}

\begin{itemize}
\tightlist
\item
  Use BFS for shortest path in unweighted graphs.
\item
  Use Dijkstra if weights are nonnegative.
\item
  Use Union-Find for Kruskal MST.
\item
  Use Topological Sort for dependency resolution.
\item
  Always check for negative edges before using Dijkstra.
\end{itemize}

\subsection{Page 7. Dynamic Programming Quick
Use}\label{page-7.-dynamic-programming-quick-use}

Dynamic Programming (DP) is about solving big problems by breaking them
into overlapping subproblems and reusing their solutions. This page
helps you see patterns quickly.

\subsubsection{When to Use DP}\label{when-to-use-dp}

You can usually apply DP if:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Symptom & Meaning \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Optimal Substructure & Best solution uses best of subparts \\
Overlapping Subproblems & Same subresults appear again \\
Decision + Recurrence & State transitions can be defined \\
\end{longtable}

\subsubsection{DP Styles}\label{dp-styles}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2714}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3714}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Style
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Top-down (Memo) & Recursion + cache results & Fibonacci with
memoization \\
Bottom-up (Tabular) & Iterative fill table & Knapsack table \\
Space-optimized & Reuse previous row/state & Rolling arrays \\
\end{longtable}

\subsubsection{Fibonacci Example}\label{fibonacci-example}

Recurrence: \[F(n)=F(n-1)+F(n-2),\quad F(0)=0,F(1)=1\]

\paragraph{Top-down (Memoization)}\label{top-down-memoization}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib(n, memo}\OperatorTok{=}\NormalTok{\{\}):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ n}
    \ControlFlowTok{if}\NormalTok{ n }\KeywordTok{not} \KeywordTok{in}\NormalTok{ memo:}
\NormalTok{        memo[n] }\OperatorTok{=}\NormalTok{ fib(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, memo) }\OperatorTok{+}\NormalTok{ fib(n}\OperatorTok{{-}}\DecValTok{2}\NormalTok{, memo)}
    \ControlFlowTok{return}\NormalTok{ memo[n]}
\end{Highlighting}
\end{Shaded}

\paragraph{Bottom-up (Tabulation)}\label{bottom-up-tabulation}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib(n):}
\NormalTok{    dp }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{        dp.append(dp[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ dp[i}\OperatorTok{{-}}\DecValTok{2}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ dp[n]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Steps to Solve DP
Problems}\label{steps-to-solve-dp-problems}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define State Example: \(dp[i]\) = best answer for first \(i\) items
\item
  Define Transition Example:
  \(dp[i]=\max(dp[i-1], value[i]+dp[i-weight[i]])\)
\item
  Set Base Cases Example: \(dp[0]=0\)
\item
  Choose Order Bottom-up or Top-down
\item
  Return Answer Often \(dp[n]\) or \(dp[target]\)
\end{enumerate}

\subsubsection{Common DP Categories}\label{common-dp-categories}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1268}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4789}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3944}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Category
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Problems
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State Form
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sequence & LIS, LCS, Edit Distance & \(dp[i][j]\) over prefixes \\
Subset & Knapsack, Subset Sum & \(dp[i][w]\) capacity-based \\
Partition & Palindrome Partitioning, Equal Sum & \(dp[i]\) cut-based \\
Grid & Min Path Sum, Unique Paths & \(dp[i][j]\) over cells \\
Counting & Coin Change Count, Stairs & Add ways from subproblems \\
Interval & Matrix Chain, Burst Balloons & \(dp[i][j]\) range
subproblem \\
Bitmask & TSP, Assignment & \(dp[mask][i]\) subset states \\
Digit & Count numbers with constraint & \(dp[pos][tight][sum]\)
digits \\
Tree & Rerooting, Subtree DP & \(dp[u]\) over children \\
\end{longtable}

\subsubsection{Classic Problems}\label{classic-problems}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3434}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3838}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State Definition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Climbing Stairs & \(dp[i]=\) ways to reach step i &
\(dp[i]=dp[i-1]+dp[i-2]\) \\
Coin Change (Count Ways) & \(dp[x]=\) ways to make sum x &
\(dp[x]+=dp[x-coin]\) \\
0/1 Knapsack & \(dp[w]=\) max value under weight w &
\(dp[w]=\max(dp[w],dp[w-w_i]+v_i)\) \\
Longest Increasing Subseq. & \(dp[i]=\) LIS ending at i & if
\(a[j]<a[i]\), \(dp[i]=dp[j]+1\) \\
Edit Distance & \(dp[i][j]=\) edit cost & min(insert,delete,replace) \\
Matrix Chain Multiplication & \(dp[i][j]=\) min cost mult subchain &
\(dp[i][j]=\min_k(dp[i][k]+dp[k+1][j])\) \\
\end{longtable}

\subsubsection{Tiny Code: 0/1 Knapsack (1D
optimized)}\label{tiny-code-01-knapsack-1d-optimized}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ knapsack(weights, values, W):}
\NormalTok{    dp }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\NormalTok{(W}\OperatorTok{+}\DecValTok{1}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(weights)):}
        \ControlFlowTok{for}\NormalTok{ w }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(W, weights[i]}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{):}
\NormalTok{            dp[w] }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(dp[w], dp[w}\OperatorTok{{-}}\NormalTok{weights[i]] }\OperatorTok{+}\NormalTok{ values[i])}
    \ControlFlowTok{return}\NormalTok{ dp[W]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Sequence Alignment
Example}\label{sequence-alignment-example}

Edit Distance Recurrence:

\[
dp[i][j] =
\begin{cases}
dp[i-1][j-1], & \text{if } s[i] = t[j],\\
1 + \min(dp[i-1][j],\ dp[i][j-1],\ dp[i-1][j-1]), & \text{otherwise.}
\end{cases}
\]

\subsubsection{Optimization Techniques}\label{optimization-techniques}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3088}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3529}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3382}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
When to Use
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Space Optimization & 2D → 1D states reuse & Knapsack, LCS \\
Prefix/Suffix Precomp & Range aggregates & Sum/Min queries \\
Divide \& Conquer DP & Monotonic decisions & Matrix Chain \\
Convex Hull Trick & Linear transition minima & DP on lines \\
Bitset DP & Large boolean states & Subset sum optimization \\
\end{longtable}

\subsubsection{Debugging Tips}\label{debugging-tips}

\begin{itemize}
\tightlist
\item
  Print partial \texttt{dp} arrays to see progress.
\item
  Check base cases carefully.
\item
  Ensure loops match transition dependencies.
\item
  Always confirm the recurrence before coding.
\end{itemize}

\subsection{Page 8. Mathematics for Algorithms Quick
Use}\label{page-8.-mathematics-for-algorithms-quick-use}

Mathematics builds the foundation for algorithmic reasoning. This page
collects essential formulas and methods every programmer should know.

\subsubsection{Number Theory Essentials}\label{number-theory-essentials}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2133}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3067}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4800}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Topic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Idea
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GCD (Euclidean) & Greatest common divisor & \(gcd(a,b)=gcd(b,a%b)
\) \\
Extended GCD & Solve \(ax+by=gcd(a,b)\) & Backtrack coefficients \\
LCM & Least common multiple & \(lcm(a,b)=\frac{a\cdot b}{gcd(a,b)}\) \\
Modular Addition & Add under modulo M & \((a+b)\bmod M\) \\
Modular Multiply & Multiply under modulo M & \((a\cdot b)\bmod M\) \\
Modular Inverse & \(a^{-1}\bmod M\) & \(a^{M-2}\bmod M\) if M is
prime \\
Modular Exponent & Fast exponentiation & Square and multiply \\
CRT & Combine congruences & Solve system \(x\equiv a_i\pmod{m_i}\) \\
\end{longtable}

Tiny Code (Modular Exponentiation):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ modpow(a, n, M):}
\NormalTok{    res }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ n:}
        \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\&} \DecValTok{1}\NormalTok{:}
\NormalTok{            res }\OperatorTok{=}\NormalTok{ res }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ M}
\NormalTok{        a }\OperatorTok{=}\NormalTok{ a }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ M}
\NormalTok{        n }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ res}
\end{Highlighting}
\end{Shaded}

\subsubsection{Primality and
Factorization}\label{primality-and-factorization}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2561}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2805}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1951}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2683}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trial Division & Small n & \(O(\sqrt{n})\) & Simple \\
Sieve of Eratosthenes & Generate primes & \(O(n\log\log n)\) & Classic
prime sieve \\
Miller--Rabin & Probabilistic primality & \(O(k\log^3 n)\) & Fast for
big n \\
Pollard Rho & Factor composite & \(O(n^{1/4})\) & Randomized \\
Sieve of Atkin & Faster variant & \(O(n)\) & Complex implementation \\
\end{longtable}

\subsubsection{Combinatorics}\label{combinatorics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7262}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2738}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n! = n\cdot(n-1)\cdots1\) & Factorial \\
\(\binom{n}{k}=\dfrac{n!}{k!(n-k)!}\) & Number of combinations \\
\(P(n,k)=\dfrac{n!}{(n-k)!}\) & Number of permutations \\
Pascal's Rule: \(\binom{n}{k}=\binom{n-1}{k}+\binom{n-1}{k-1}\) & Build
Pascal's Triangle \\
Catalan: \(C_n=\dfrac{1}{n+1}\binom{2n}{n}\) & Parentheses counting \\
\end{longtable}

Tiny Code (nCr with factorials mod M):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ nCr(n, r, fact, inv):}
    \ControlFlowTok{return}\NormalTok{ fact[n]}\OperatorTok{*}\NormalTok{inv[r]}\OperatorTok{\%}\NormalTok{M}\OperatorTok{*}\NormalTok{inv[n}\OperatorTok{{-}}\NormalTok{r]}\OperatorTok{\%}\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\subsubsection{Probability Basics}\label{probability-basics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1414}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4444}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1414}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula or Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Probability & \(P(A)=\frac{\text{favorable}}{\text{total}}\) & & \\
Complement & \(P(\bar{A})=1-P(A)\) & & \\
Union & \(P(A\cup B)=P(A)+P(B)-P(A\cap B)\) & & \\
Conditional &
\(P(A                                         | B)=\frac{P(A\cap B)}{P(B)}\)
& & \\
Bayes' Theorem &
\(P(A                                         | B)=\frac{P(B                | A)P(A)}{P(B)}\)
& & \\
Expected Value & \(E[X]=\sum x_iP(x_i)\) & & \\
Variance & \(Var(X)=E[X^2]-E[X]^2\) & & \\
\end{longtable}

\subsubsection{Linear Algebra Core}\label{linear-algebra-core}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Formula / Method & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gaussian Elimination & Solve \(Ax=b\) & \(O(n^3)\) \\
Determinant & Product of pivots & \(O(n^3)\) \\
Matrix Multiply & \((AB)*{ij}=\sum_kA*{ik}B_{kj}\) & \(O(n^3)\) \\
Transpose & \(A^T_{ij}=A_{ji}\) & \(O(n^2)\) \\
LU Decomposition & \(A=LU\) (lower, upper) & \(O(n^3)\) \\
Cholesky & \(A=LL^T\) (symmetric pos. def.) & \(O(n^3)\) \\
Power Method & Dominant eigenvalue estimation & iterative \\
\end{longtable}

Tiny Code (Gaussian Elimination Skeleton):

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{    pivot }\OperatorTok{=}\NormalTok{ a[i][i]}
    \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(i, n}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        a[i][j] }\OperatorTok{/=}\NormalTok{ pivot}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{if}\NormalTok{ k }\OperatorTok{!=}\NormalTok{ i:}
\NormalTok{            ratio }\OperatorTok{=}\NormalTok{ a[k][i]}
            \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(i, n}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{                a[k][j] }\OperatorTok{{-}=}\NormalTok{ ratio}\OperatorTok{*}\NormalTok{a[i][j]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Fast Transforms}\label{fast-transforms}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Transform & Use Case & Complexity & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
FFT & Polynomial convolution & \(O(n\log n)\) & Complex numbers \\
NTT & Modular convolution & \(O(n\log n)\) & Prime modulus \\
FWT (XOR) & XOR-based convolution & \(O(n\log n)\) & Subset DP \\
\end{longtable}

FFT Equation:

\[
X_k = \sum_{n=0}^{N-1} x_n e^{-2\pi i kn/N}
\]

\subsubsection{Numerical Methods}\label{numerical-methods}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1591}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1932}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6477}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula or Idea
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bisection & Root-finding & Midpoint halve until \(f(x)=0\) \\
Newton--Raphson & Fast convergence &
\(x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)}\) \\
Secant Method & Approx derivative &
\(x_{n+1}=x_n-f(x_n)\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\) \\
Simpson's Rule & Integration &
\(\int_a^bf(x)dx\approx\frac{h}{3}(f(a)+4f(m)+f(b))\) \\
\end{longtable}

\subsubsection{Optimization and
Calculus}\label{optimization-and-calculus}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2564}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7436}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Idea
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Derivative & \(f'(x)=\lim_{h\to0}\frac{f(x+h)-f(x)}{h}\) \\
Gradient Descent & \(x_{k+1}=x_k-\eta\nabla f(x_k)\) \\
Lagrange Multipliers & \(\nabla f=\lambda\nabla g\) \\
Convex Function &
\(f(\lambda x+(1-\lambda)y)\le\lambda f(x)+(1-\lambda)f(y)\) \\
\end{longtable}

Tiny Code (Gradient Descent):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{=}\NormalTok{ x0}
\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1000}\NormalTok{):}
\NormalTok{    grad }\OperatorTok{=}\NormalTok{ df(x)}
\NormalTok{    x }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ grad}
\end{Highlighting}
\end{Shaded}

\subsubsection{Algebraic Tricks}\label{algebraic-tricks}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3627}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2647}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2059}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Topic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Use
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Exponentiation & \(a^n\) via square-multiply & & \\
Polynomial Deriv. & \((ax^n)' = n\cdot a x^{n-1}\) & & \\
Integration & \(\int x^n dx = \frac{x^{n+1}}{n+1}+C\) & & \\
Möbius Inversion &
\(f(n)=\sum_{d                         | n}g(d)\implies g(n)=\sum_{d | n}\mu(d)\cdot f(n/d)\)
& & \\
\end{longtable}

\subsubsection{Quick Reference Table}\label{quick-reference-table}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Must-Know Algorithm \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Number Theory & GCD, Mod Exp, CRT \\
Combinatorics & Pascal, Factorial, Catalan \\
Probability & Bayes, Expected Value \\
Linear Algebra & Gaussian Elimination \\
Transforms & FFT, NTT \\
Optimization & Gradient Descent \\
\end{longtable}

\subsection{Page 9. Strings and Text Algorithms Quick
Use}\label{page-9.-strings-and-text-algorithms-quick-use}

Strings are sequences of characters used in text search, matching, and
transformation. This page gives quick references to classical and modern
string techniques.

\subsubsection{String Fundamentals}\label{string-fundamentals}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5067}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2933}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Alphabet & Set of symbols & \texttt{\{a,\ b,\ c\}} \\
String Length & Number of characters & \texttt{"hello"} → 5 \\
Substring & Continuous part of string & \texttt{"ell"} in
\texttt{"hello"} \\
Subsequence & Ordered subset (not necessarily cont.) & \texttt{"hlo"}
from \texttt{"hello"} \\
Prefix / Suffix & Starts / ends part of string & \texttt{"he"},
\texttt{"lo"} \\
\end{longtable}

Indexing: Most algorithms use 0-based indexing.

\subsubsection{String Search Overview}\label{string-search-overview}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Complexity & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive Search & \(O(nm)\) & Check all positions \\
KMP & \(O(n+m)\) & Prefix-suffix skip table \\
Z-Algorithm & \(O(n+m)\) & Precompute match lengths \\
Rabin--Karp & \(O(n+m)\) avg & Rolling hash check \\
Boyer--Moore & \(O(n/m)\) avg & Backward scan, skip mismatches \\
\end{longtable}

\subsubsection{KMP Prefix Function}\label{kmp-prefix-function}

Compute prefix-suffix matches for pattern.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.1045}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.8955}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(pi[i]\) & Longest proper prefix that is also suffix for
\(pattern[0:i]\) \\
\end{longtable}

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ prefix\_function(p):}
\NormalTok{    pi }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(p)}
\NormalTok{    j }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(p)):}
        \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}} \DecValTok{0} \KeywordTok{and}\NormalTok{ p[i] }\OperatorTok{!=}\NormalTok{ p[j]:}
\NormalTok{            j }\OperatorTok{=}\NormalTok{ pi[j}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ p[i] }\OperatorTok{==}\NormalTok{ p[j]:}
\NormalTok{            j }\OperatorTok{+=} \DecValTok{1}
\NormalTok{        pi[i] }\OperatorTok{=}\NormalTok{ j}
    \ControlFlowTok{return}\NormalTok{ pi}
\end{Highlighting}
\end{Shaded}

Search uses \texttt{pi} to skip mismatches.

\subsubsection{Z-Algorithm}\label{z-algorithm}

Computes length of substring starting at i matching prefix.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Meaning \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(Z[i]\) & Longest substring starting at i matching prefix \\
\end{longtable}

Use
\texttt{\$S\ =\ pattern\ +\ \textquotesingle{}\$\textquotesingle{}\ +\ text\$}
to find pattern occurrences.

\subsubsection{Rabin--Karp Rolling Hash}\label{rabinkarp-rolling-hash}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Idea & Compute hash for window of text, slide, compare \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\end{longtable}

Hash Function: \[
h(s) = (s_0p^{n-1} + s_1p^{n-2} + \dots + s_{n-1}) \bmod M
\]

Update efficiently when sliding one character.

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ rolling\_hash(s, base}\OperatorTok{=}\DecValTok{257}\NormalTok{, mod}\OperatorTok{=}\DecValTok{109}\OperatorTok{+}\DecValTok{7}\NormalTok{):}
\NormalTok{    h }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ ch }\KeywordTok{in}\NormalTok{ s:}
\NormalTok{        h }\OperatorTok{=}\NormalTok{ (h}\OperatorTok{*}\NormalTok{base }\OperatorTok{+} \BuiltInTok{ord}\NormalTok{(ch)) }\OperatorTok{\%}\NormalTok{ mod}
    \ControlFlowTok{return}\NormalTok{ h}
\end{Highlighting}
\end{Shaded}

\subsubsection{Advanced Pattern
Matching}\label{advanced-pattern-matching}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Use Case & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Boyer--Moore & Large alphabet & \(O(n/m)\) avg \\
Sunday & Last char shift heuristic & \(O(n)\) avg \\
Bitap & Approximate match & \(O(nm/w)\) \\
Aho--Corasick & Multi-pattern search & \(O(n+z)\) \\
\end{longtable}

\subsubsection{Aho--Corasick Automaton}\label{ahocorasick-automaton}

Build a trie from patterns and compute failure links.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Build Trie & Add all patterns \\
Failure Link & Fallback to next prefix \\
Output Link & Record pattern match \\
\end{longtable}

Tiny Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\KeywordTok{def}\NormalTok{ build\_ac(patterns):}
\NormalTok{    trie }\OperatorTok{=}\NormalTok{ [\{\}]}
\NormalTok{    fail }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{]}
    \ControlFlowTok{for}\NormalTok{ pat }\KeywordTok{in}\NormalTok{ patterns:}
\NormalTok{        node }\OperatorTok{=} \DecValTok{0}
        \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ pat:}
\NormalTok{            node }\OperatorTok{=}\NormalTok{ trie[node].setdefault(c, }\BuiltInTok{len}\NormalTok{(trie))}
            \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(trie):}
\NormalTok{                trie.append(\{\})}
\NormalTok{                fail.append(}\DecValTok{0}\NormalTok{)}
    \CommentTok{\# compute failure links}
\NormalTok{    q }\OperatorTok{=}\NormalTok{ deque()}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ trie[}\DecValTok{0}\NormalTok{]:}
\NormalTok{        q.append(trie[}\DecValTok{0}\NormalTok{][c])}
    \ControlFlowTok{while}\NormalTok{ q:}
\NormalTok{        u }\OperatorTok{=}\NormalTok{ q.popleft()}
        \ControlFlowTok{for}\NormalTok{ c, v }\KeywordTok{in}\NormalTok{ trie[u].items():}
\NormalTok{            f }\OperatorTok{=}\NormalTok{ fail[u]}
            \ControlFlowTok{while}\NormalTok{ f }\KeywordTok{and}\NormalTok{ c }\KeywordTok{not} \KeywordTok{in}\NormalTok{ trie[f]:}
\NormalTok{                f }\OperatorTok{=}\NormalTok{ fail[f]}
\NormalTok{            fail[v] }\OperatorTok{=}\NormalTok{ trie[f].get(c, }\DecValTok{0}\NormalTok{)}
\NormalTok{            q.append(v)}
    \ControlFlowTok{return}\NormalTok{ trie, fail}
\end{Highlighting}
\end{Shaded}

\subsubsection{Suffix Structures}\label{suffix-structures}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2540}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4921}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2540}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Build Time
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Suffix Array & Sorted list of suffix indices & \(O(n\log n)\) \\
LCP Array & Longest Common Prefix of suffix & \(O(n)\) \\
Suffix Tree & Trie of suffixes & \(O(n)\) (Ukkonen) \\
Suffix Automaton & Minimal DFA of substrings & \(O(n)\) \\
\end{longtable}

Suffix Array Doubling Approach:

\begin{itemize}
\tightlist
\item
  Rank substrings of length \(2^k\)
\item
  Sort and merge using pairs of ranks
\end{itemize}

LCP via Kasai's Algorithm: \[
LCP[i]=\text{common prefix of } S[SA[i]:], S[SA[i-1]:]
\]

\subsubsection{Palindrome Detection}\label{palindrome-detection}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Description & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Manacher's Algorithm & Longest palindromic substring & \(O(n)\) \\
DP Table & Check substring palindrome & \(O(n^2)\) \\
Center Expansion & Expand around center & \(O(n^2)\) \\
\end{longtable}

Manacher's Core:

\begin{itemize}
\tightlist
\item
  Transform with separators (\texttt{\#})
\item
  Track radius of palindrome around each center
\end{itemize}

\subsubsection{Edit Distance Family}\label{edit-distance-family}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2985}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3134}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3881}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Levenshtein Distance & Insert/Delete/Replace & \(O(nm)\) \\
Damerau--Levenshtein & Add transposition & \(O(nm)\) \\
Hirschberg & Space-optimized LCS & \(O(nm)\) time, \(O(n)\) space \\
\end{longtable}

Recurrence: \[
dp[i][j]=\min
\begin{cases}
dp[i-1][j]+1 \
dp[i][j-1]+1 \
dp[i-1][j-1]+(s_i\neq t_j)
\end{cases}
\]

\subsubsection{Compression Techniques}\label{compression-techniques}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2537}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2388}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5075}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Huffman Coding & Prefix code & Shorter codes for frequent chars \\
Arithmetic Coding & Range encoding & Fractional interval
representation \\
LZ77 / LZ78 & Dictionary-based & Reuse earlier substrings \\
BWT + MTF + RLE & Block sorting & Group similar chars before coding \\
\end{longtable}

Huffman Principle: Shorter bit strings assigned to higher frequency
symbols.

\subsubsection{Hashing and Checksums}\label{hashing-and-checksums}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Use Case & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
CRC32 & Error detection & Simple polynomial mod \\
MD5 & Hash (legacy) & Not secure \\
SHA-256 & Secure hash & Cryptographic \\
Rolling Hash & Substring compare & Used in Rabin--Karp \\
\end{longtable}

\subsubsection{Quick Reference}\label{quick-reference}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Task & Algorithm & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Single pattern search & KMP / Z & \(O(n+m)\) \\
Multi-pattern search & Aho--Corasick & \(O(n+z)\) \\
Approximate search & Bitap / Wu--Manber & \(O(kn)\) \\
Substring queries & Suffix Array + LCP & \(O(\log n)\) \\
Palindromes & Manacher & \(O(n)\) \\
Compression & Huffman / LZ77 & variable \\
Edit distance & DP table & \(O(nm)\) \\
\end{longtable}

\subsection{Page 10. Geometry, Graphics, and Spatial Algorithms Quick
Use}\label{page-10.-geometry-graphics-and-spatial-algorithms-quick-use}

Geometry helps us solve problems about shapes, distances, and spatial
relationships. This page summarizes core computational geometry
techniques with simple formulas and examples.

\subsubsection{Coordinate Basics}\label{coordinate-basics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1552}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3793}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0086}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0086}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0086}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0948}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Point Distance & Distance between \((x_1,y_1)\) and \((x_2,y_2)\) &
\(d=\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\) & & & & \\
Midpoint & Between two points &
\((\frac{x_1+x_2}{2}, \frac{y_1+y_2}{2})\) & & & & \\
Dot Product & Angle \& projection &
\(\vec{a}\cdot\vec{b}=                    | a |   | b | \cos\theta\) & &
& & \\
Cross Product (2D) & Signed area, orientation &
\(a\times b = a_xb_y - a_yb_x\) & & & & \\
Orientation Test & CCW, CW, collinear check & \(\text{sign}(a\times b)\)
& & & & \\
\end{longtable}

Tiny Code (Orientation Test):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ orient(a, b, c):}
\NormalTok{    val }\OperatorTok{=}\NormalTok{ (b[}\DecValTok{0}\NormalTok{]}\OperatorTok{{-}}\NormalTok{a[}\DecValTok{0}\NormalTok{])}\OperatorTok{*}\NormalTok{(c[}\DecValTok{1}\NormalTok{]}\OperatorTok{{-}}\NormalTok{a[}\DecValTok{1}\NormalTok{]) }\OperatorTok{{-}}\NormalTok{ (b[}\DecValTok{1}\NormalTok{]}\OperatorTok{{-}}\NormalTok{a[}\DecValTok{1}\NormalTok{])}\OperatorTok{*}\NormalTok{(c[}\DecValTok{0}\NormalTok{]}\OperatorTok{{-}}\NormalTok{a[}\DecValTok{0}\NormalTok{])}
    \ControlFlowTok{return} \DecValTok{0} \ControlFlowTok{if}\NormalTok{ val }\OperatorTok{==} \DecValTok{0} \ControlFlowTok{else}\NormalTok{ (}\DecValTok{1} \ControlFlowTok{if}\NormalTok{ val }\OperatorTok{\textgreater{}} \DecValTok{0} \ControlFlowTok{else} \OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Convex Hull}\label{convex-hull}

Find the smallest convex polygon enclosing all points.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Complexity & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Graham Scan & \(O(n\log n)\) & Sort by angle, use stack \\
Andrew's Monotone & \(O(n\log n)\) & Sort by x, build upper/lower \\
Jarvis March & \(O(nh)\) & Wrap hull, h = hull size \\
Chan's Algorithm & \(O(n\log h)\) & Output-sensitive hull \\
\end{longtable}

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points
\item
  Build lower hull
\item
  Build upper hull
\item
  Concatenate
\end{enumerate}

\subsubsection{Closest Pair of Points}\label{closest-pair-of-points}

Divide-and-conquer approach.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Split by x & Divide points into halves \\
Recurse and merge & Track min distance across strip \\
\end{longtable}

Complexity: \(O(n\log n)\)

Formula: \[
d(p,q)=\sqrt{(x_p-x_q)^2+(y_p-y_q)^2}
\]

\subsubsection{Line Intersection}\label{line-intersection}

Two segments \((p_1,p_2)\) and \((q_1,q_2)\) intersect if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Orientations differ
\item
  Segments overlap on line if collinear
\end{enumerate}

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ intersect(p1, p2, q1, q2):}
\NormalTok{    o1 }\OperatorTok{=}\NormalTok{ orient(p1, p2, q1)}
\NormalTok{    o2 }\OperatorTok{=}\NormalTok{ orient(p1, p2, q2)}
\NormalTok{    o3 }\OperatorTok{=}\NormalTok{ orient(q1, q2, p1)}
\NormalTok{    o4 }\OperatorTok{=}\NormalTok{ orient(q1, q2, p2)}
    \ControlFlowTok{return}\NormalTok{ o1 }\OperatorTok{!=}\NormalTok{ o2 }\KeywordTok{and}\NormalTok{ o3 }\OperatorTok{!=}\NormalTok{ o4}
\end{Highlighting}
\end{Shaded}

\subsubsection{Polygon Area (Shoelace
Formula)}\label{polygon-area-shoelace-formula}

For vertices \((x_i, y_i)\) in order:

\[
A=\frac{1}{2}\left|\sum_{i=0}^{n-1}(x_iy_{i+1}-x_{i+1}y_i)\right|
\]

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ area(poly):}
\NormalTok{    s }\OperatorTok{=} \DecValTok{0}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(poly)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{        x1, y1 }\OperatorTok{=}\NormalTok{ poly[i]}
\NormalTok{        x2, y2 }\OperatorTok{=}\NormalTok{ poly[(i}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{\%}\NormalTok{n]}
\NormalTok{        s }\OperatorTok{+=}\NormalTok{ x1}\OperatorTok{*}\NormalTok{y2 }\OperatorTok{{-}}\NormalTok{ x2}\OperatorTok{*}\NormalTok{y1}
    \ControlFlowTok{return} \BuiltInTok{abs}\NormalTok{(s)}\OperatorTok{/}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\subsubsection{Point in Polygon}\label{point-in-polygon}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Idea & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ray Casting & Count edge crossings & \(O(n)\) \\
Winding Number & Track signed rotations & \(O(n)\) \\
Convex Test & Check all orientations & \(O(n)\) \\
\end{longtable}

Ray Casting: Odd number of crossings → inside.

\subsubsection{Rotating Calipers}\label{rotating-calipers}

Used for:

\begin{itemize}
\tightlist
\item
  Polygon diameter (farthest pair)
\item
  Minimum bounding box
\item
  Width and antipodal pairs
\end{itemize}

Idea: Sweep around convex hull using tangents. Complexity: \(O(n)\)
after hull.

\subsubsection{Sweep Line Techniques}\label{sweep-line-techniques}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Method & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Closest Pair & Active set by y & \(O(n\log n)\) \\
Segment Intersection & Event-based sweeping & \(O((n+k)\log n)\) \\
Rectangle Union Area & Vertical edge events & \(O(n\log n)\) \\
Skyline Problem & Merge by height & \(O(n\log n)\) \\
\end{longtable}

Use balanced trees or priority queues for active sets.

\subsubsection{Circle Geometry}\label{circle-geometry}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Concept & Formula \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Equation & \((x-x_c)^2+(y-y_c)^2=r^2\) \\
Tangent Length & \(\sqrt{d^2-r^2}\) \\
Two-Circle Intersection & Distance-based geometry \\
\end{longtable}

\subsubsection{Spatial Data Structures}\label{spatial-data-structures}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Structure & Use Case & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
KD-Tree & Nearest neighbor search & Axis-aligned splits \\
R-Tree & Range queries & Bounding boxes hierarchy \\
Quadtree & 2D recursive subdivision & Graphics, collision detection \\
Octree & 3D extension & Volumetric partitioning \\
BSP Tree & Planar splits & Rendering, collision \\
\end{longtable}

\subsubsection{Rasterization and
Graphics}\label{rasterization-and-graphics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3385}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4308}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bresenham Line & Draw line integer grid & No floating point \\
Midpoint Circle & Circle rasterization & Symmetry exploitation \\
Scanline Fill & Polygon fill algorithm & Sort edges, horizontal sweep \\
Z-Buffer & Hidden surface removal & Per-pixel depth comparison \\
Phong Shading & Smooth lighting & Interpolate normals \\
\end{longtable}

\subsubsection{Pathfinding in Space}\label{pathfinding-in-space}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Description & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A* & Heuristic shortest path & \(f(n)=g(n)+h(n)\) \\
Theta* & Any-angle path & Shortcut-based \\
RRT / RRT* & Random exploration & Robotics planning \\
PRM & Probabilistic roadmap & Sampled graph \\
Visibility Graph & Connect visible points & Geometric planning \\
\end{longtable}

\subsubsection{Quick Summary}\label{quick-summary}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Task & Algorithm & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Convex Hull & Graham / Andrew & \(O(n\log n)\) \\
Closest Pair & Divide and Conquer & \(O(n\log n)\) \\
Segment Intersection Detection & Sweep Line & \(O(n\log n)\) \\
Point in Polygon & Ray Casting & \(O(n)\) \\
Polygon Area & Shoelace Formula & \(O(n)\) \\
Nearest Neighbor Search & KD-Tree & \(O(\log n)\) \\
Pathfinding & A* & \(O(E\log V)\) \\
\end{longtable}

\subsubsection{Tip}\label{tip}

\begin{itemize}
\tightlist
\item
  Always sort points for geometry preprocessing.
\item
  Use cross product for orientation tests.
\item
  Prefer integer arithmetic when possible to avoid floating errors.
\end{itemize}

\subsection{Page 11. Systems, Databases, and Distributed Algorithms
Quick
Use}\label{page-11.-systems-databases-and-distributed-algorithms-quick-use}

Systems and databases rely on algorithms that manage memory,
concurrency, persistence, and coordination. This page gives an overview
of the most important ones.

\subsubsection{Concurrency Control}\label{concurrency-control}

Ensures correctness when multiple transactions or threads run at once.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2447}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4255}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3298}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Two-Phase Locking (2PL) & Acquire locks, then release after commit &
Guarantees serializability \\
Strict 2PL & Hold all locks until commit & Prevents cascading aborts \\
Conservative 2PL & Lock all before execution & Deadlock-free but less
parallel \\
Timestamp Ordering & Order by timestamps & May abort late
transactions \\
Multiversion CC (MVCC) & Readers get snapshots & Used in PostgreSQL,
InnoDB \\
Optimistic CC (OCC) & Validate at commit & Best for low conflict
workloads \\
\end{longtable}

\subsubsection{Tiny Code: Timestamp
Ordering}\label{tiny-code-timestamp-ordering}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simplified}
\ControlFlowTok{if}\NormalTok{ write\_ts[x] }\OperatorTok{\textgreater{}}\NormalTok{ txn\_ts }\KeywordTok{or}\NormalTok{ read\_ts[x] }\OperatorTok{\textgreater{}}\NormalTok{ txn\_ts:}
\NormalTok{    abort()}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    write\_ts[x] }\OperatorTok{=}\NormalTok{ txn\_ts}
\end{Highlighting}
\end{Shaded}

Each object tracks read and write timestamps.

\subsubsection{Deadlocks}\label{deadlocks}

Circular waits among transactions.

Detection \textbar{} Build Wait-For Graph, detect cycle \textbar{}\\
Prevention \textbar{} Wait-Die (old waits) / Wound-Wait (young aborts)
\textbar{}

Detection Complexity: \(O(V+E)\)

Tiny Code (Wait-For Graph Cycle Check):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ has\_cycle(graph):}
\NormalTok{    visited, stack }\OperatorTok{=} \BuiltInTok{set}\NormalTok{(), }\BuiltInTok{set}\NormalTok{()}
    \KeywordTok{def}\NormalTok{ dfs(u):}
\NormalTok{        visited.add(u)}
\NormalTok{        stack.add(u)}
        \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ graph[u]:}
            \ControlFlowTok{if}\NormalTok{ v }\KeywordTok{not} \KeywordTok{in}\NormalTok{ visited }\KeywordTok{and}\NormalTok{ dfs(v): }\ControlFlowTok{return} \VariableTok{True}
            \ControlFlowTok{if}\NormalTok{ v }\KeywordTok{in}\NormalTok{ stack: }\ControlFlowTok{return} \VariableTok{True}
\NormalTok{        stack.remove(u)}
        \ControlFlowTok{return} \VariableTok{False}
    \ControlFlowTok{return} \BuiltInTok{any}\NormalTok{(dfs(u) }\ControlFlowTok{for}\NormalTok{ u }\KeywordTok{in}\NormalTok{ graph)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Logging and Recovery}\label{logging-and-recovery}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2239}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4030}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3731}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Write-Ahead Log & Log before data & Ensures durability \\
ARIES & Analysis, Redo, Undo phases & Industry standard \\
Checkpointing & Save consistent snapshot & Speeds recovery \\
Shadow Paging & Copy-on-write updates & Simpler but less flexible \\
\end{longtable}

Recovery after crash:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Analysis: find active transactions
\item
  Redo: reapply committed changes
\item
  Undo: revert uncommitted ones
\end{enumerate}

\subsubsection{Indexing}\label{indexing}

Accelerates lookups and range queries.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2344}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3438}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4219}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Index Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
B-Tree / B+Tree & Balanced multiway tree & Disk-friendly \\
Hash Index & Exact match only & No range queries \\
GiST / R-Tree & Spatial data & Bounding box hierarchy \\
Inverted Index & Text search & Maps token to document list \\
\end{longtable}

B+Tree Complexity: \(O(\log_B N)\) (B = branching factor)

Tiny Code (Binary Search in Index):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ search(node, key):}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ bisect\_left(node.keys, key)}
    \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(node.keys) }\KeywordTok{and}\NormalTok{ node.keys[i] }\OperatorTok{==}\NormalTok{ key:}
        \ControlFlowTok{return}\NormalTok{ node.values[i]}
    \ControlFlowTok{if}\NormalTok{ node.is\_leaf:}
        \ControlFlowTok{return} \VariableTok{None}
    \ControlFlowTok{return}\NormalTok{ search(node.children[i], key)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Query Processing}\label{query-processing}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Parsing & Build abstract syntax tree \\
Optimization & Reorder joins, pick indices \\
Execution Plan & Choose algorithm per operator \\
Execution & Evaluate iterators or pipelines \\
\end{longtable}

Common join strategies:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Join Type & Complexity & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Nested Loop & \(O(nm)\) & Simple, slow \\
Hash Join & \(O(n+m)\) & Build + probe \\
Sort-Merge Join & \(O(n\log n+m\log m)\) & Sorted inputs \\
\end{longtable}

\subsubsection{Caching and Replacement}\label{caching-and-replacement}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Policy & Description & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LRU & Evict least recently used & Simple, temporal locality \\
LFU & Evict least frequently used & Good for stable patterns \\
ARC / LIRS & Adaptive hybrid & Handles mixed workloads \\
Random & Random eviction & Simple, fair \\
\end{longtable}

Tiny Code (LRU using OrderedDict):

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ OrderedDict}

\KeywordTok{class}\NormalTok{ LRU:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, cap):}
        \VariableTok{self}\NormalTok{.cap }\OperatorTok{=}\NormalTok{ cap}
        \VariableTok{self}\NormalTok{.cache }\OperatorTok{=}\NormalTok{ OrderedDict()}
    \KeywordTok{def}\NormalTok{ get(}\VariableTok{self}\NormalTok{, k):}
        \ControlFlowTok{if}\NormalTok{ k }\KeywordTok{not} \KeywordTok{in} \VariableTok{self}\NormalTok{.cache: }\ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}
        \VariableTok{self}\NormalTok{.cache.move\_to\_end(k)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.cache[k]}
    \KeywordTok{def}\NormalTok{ put(}\VariableTok{self}\NormalTok{, k, v):}
        \ControlFlowTok{if}\NormalTok{ k }\KeywordTok{in} \VariableTok{self}\NormalTok{.cache: }\VariableTok{self}\NormalTok{.cache.move\_to\_end(k)}
        \VariableTok{self}\NormalTok{.cache[k] }\OperatorTok{=}\NormalTok{ v}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.cache) }\OperatorTok{\textgreater{}} \VariableTok{self}\NormalTok{.cap: }\VariableTok{self}\NormalTok{.cache.popitem(last}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Distributed Systems Core}\label{distributed-systems-core}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Description & Typical Solution \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Consensus & Agree on value across nodes & Paxos, Raft \\
Leader Election & Pick coordinator & Bully, Raft \\
Replication & Maintain copies & Log replication \\
Partitioning & Split data & Consistent hashing \\
Membership & Detect nodes & Gossip protocols \\
\end{longtable}

\subsubsection{Raft Consensus
(Simplified)}\label{raft-consensus-simplified}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Phase & Action \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Election & Nodes vote, elect leader \\
Replication & Leader appends log entries \\
Commitment & Once majority acknowledge \\
\end{longtable}

Safety: Committed entries never change. Liveness: New leader elected on
failure.

Tiny Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ vote\_request.term }\OperatorTok{\textgreater{}}\NormalTok{ term:}
\NormalTok{    term }\OperatorTok{=}\NormalTok{ vote\_request.term}
\NormalTok{    voted\_for }\OperatorTok{=}\NormalTok{ candidate}
\end{Highlighting}
\end{Shaded}

\subsubsection{Consistent Hashing}\label{consistent-hashing}

Distributes keys across nodes smoothly.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hash each node to ring & e.g.~hash(node\_id) \\
Hash each key & Find next node clockwise \\
Add/remove node & Only nearby keys move \\
\end{longtable}

Used in: Dynamo, Cassandra, Memcached.

\subsubsection{Fault Tolerance Patterns}\label{fault-tolerance-patterns}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Pattern & Description & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Replication & Multiple copies & Primary-backup \\
Checkpointing & Save progress periodically & ML training \\
Heartbeats & Liveness detection & Cluster managers \\
Retry + Backoff & Handle transient failures & API calls \\
Quorum Reads/Writes & Require majority agreement & Cassandra \\
\end{longtable}

\subsubsection{Distributed Coordination}\label{distributed-coordination}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Tool / Protocol & Description & Example Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ZooKeeper & Centralized coordination & Locks, config \\
Raft & Distributed consensus & Log replication \\
Etcd & Key-value store on Raft & Cluster metadata \\
\end{longtable}

\subsubsection{Summary Table}\label{summary-table-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1905}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3016}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1746}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Topic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm / Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Locking & 2PL, MVCC, OCC & varies & Transaction isolation \\
Deadlock & Wait-Die, Detection & \(O(V+E)\) & Graph-based check \\
Recovery & ARIES, WAL & varies & Crash recovery \\
Indexing & B+Tree, Hash Index & \(O(\log N)\) & Faster queries \\
Join & Hash / Sort-Merge & varies & Query optimization \\
Cache & LRU, LFU & \(O(1)\) & Data locality \\
Consensus & Raft, Paxos & \(O(n)\) msg & Fault tolerance \\
Partitioning & Consistent Hashing & \(O(1)\) avg & Scalability \\
\end{longtable}

\subsubsection{Quick Tips}\label{quick-tips-3}

\begin{itemize}
\tightlist
\item
  Always ensure serializability in concurrency.
\item
  Use MVCC for read-heavy workloads.
\item
  ARIES ensures durability via WAL.
\item
  For scalability, partition and replicate wisely.
\item
  Consensus is required for shared state correctness.
\end{itemize}

\subsection{Page 12. Algorithms for AI, ML, and Optimization Quick
Use}\label{page-12.-algorithms-for-ai-ml-and-optimization-quick-use}

This page gathers classical algorithms that power modern AI and machine
learning systems, from clustering and classification to gradient-based
learning and metaheuristics.

\subsubsection{Classical Machine Learning
Algorithms}\label{classical-machine-learning-algorithms}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1308}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1963}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5140}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1589}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Category
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Core Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Clustering & k-Means & Assign to nearest centroid, update centers &
\(O(nkt)\) \\
Clustering & k-Medoids (PAM) & Representative points as centers &
\(O(k(n-k)^2)\) \\
Clustering & Gaussian Mixture (EM) & Soft assignments via probabilities
& \(O(nkd)\) per iter \\
Classification & Naive Bayes & Apply Bayes rule with feature
independence & \(O(nd)\) \\
Classification & Logistic Regression & Linear + sigmoid activation &
\(O(nd)\) \\
Classification & SVM (Linear) & Maximize margin via convex optimization
& \(O(nd)\) approx \\
Classification & k-NN & Vote from nearest neighbors & \(O(nd)\) per
query \\
Trees & Decision Tree (CART) & Recursive splitting by impurity &
\(O(nd\log n)\) \\
Projection & LDA / PCA & Find projection maximizing variance or class
separation & \(O(d^3)\) \\
\end{longtable}

\subsubsection{Tiny Code: k-Means}\label{tiny-code-k-means}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random, math}

\KeywordTok{def}\NormalTok{ kmeans(points, k, iters}\OperatorTok{=}\DecValTok{100}\NormalTok{):}
\NormalTok{    centroids }\OperatorTok{=}\NormalTok{ random.sample(points, k)}
    \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iters):}
\NormalTok{        groups }\OperatorTok{=}\NormalTok{ [[] }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(k)]}
        \ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ points:}
\NormalTok{            idx }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(}\BuiltInTok{range}\NormalTok{(k), key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ i: (p[}\DecValTok{0}\NormalTok{]}\OperatorTok{{-}}\NormalTok{centroids[i][}\DecValTok{0}\NormalTok{])}\DecValTok{2} \OperatorTok{+}\NormalTok{ (p[}\DecValTok{1}\NormalTok{]}\OperatorTok{{-}}\NormalTok{centroids[i][}\DecValTok{1}\NormalTok{])}\DecValTok{2}\NormalTok{)}
\NormalTok{            groups[idx].append(p)}
\NormalTok{        new\_centroids }\OperatorTok{=}\NormalTok{ []}
        \ControlFlowTok{for}\NormalTok{ g }\KeywordTok{in}\NormalTok{ groups:}
            \ControlFlowTok{if}\NormalTok{ g:}
\NormalTok{                x }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(p[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ g)}\OperatorTok{/}\BuiltInTok{len}\NormalTok{(g)}
\NormalTok{                y }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(p[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ g)}\OperatorTok{/}\BuiltInTok{len}\NormalTok{(g)}
\NormalTok{                new\_centroids.append((x,y))}
            \ControlFlowTok{else}\NormalTok{:}
\NormalTok{                new\_centroids.append(random.choice(points))}
        \ControlFlowTok{if}\NormalTok{ centroids }\OperatorTok{==}\NormalTok{ new\_centroids: }\ControlFlowTok{break}
\NormalTok{        centroids }\OperatorTok{=}\NormalTok{ new\_centroids}
    \ControlFlowTok{return}\NormalTok{ centroids}
\end{Highlighting}
\end{Shaded}

\subsubsection{Linear Models}\label{linear-models}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2436}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3077}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4487}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Loss Function
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Regression & \(\hat{y}=w^Tx+b\) & MSE:
\(\frac{1}{n}\sum(y-\hat{y})^2\) \\
Logistic Regression & \(\hat{y}=\sigma(w^Tx+b)\) & Cross-Entropy \\
Ridge Regression & Linear + \(L_2\) penalty &
\(L=\text{MSE}+\lambda|w|^2\) \\
Lasso Regression & Linear + \(L_1\) penalty &
\(L=\text{MSE}+\lambda|w|_1\) \\
\end{longtable}

Tiny Code (Gradient Descent for Linear Regression):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ train(X, y, lr}\OperatorTok{=}\FloatTok{0.01}\NormalTok{, epochs}\OperatorTok{=}\DecValTok{1000}\NormalTok{):}
\NormalTok{    w }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(X[}\DecValTok{0}\NormalTok{])}
\NormalTok{    b }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(epochs):}
        \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(y)):}
\NormalTok{            y\_pred }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(w[j]}\OperatorTok{*}\NormalTok{X[i][j] }\ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(w))) }\OperatorTok{+}\NormalTok{ b}
\NormalTok{            err }\OperatorTok{=}\NormalTok{ y\_pred }\OperatorTok{{-}}\NormalTok{ y[i]}
            \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(w)):}
\NormalTok{                w[j] }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ err }\OperatorTok{*}\NormalTok{ X[i][j]}
\NormalTok{            b }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ err}
    \ControlFlowTok{return}\NormalTok{ w, b}
\end{Highlighting}
\end{Shaded}

\subsubsection{Decision Trees and
Ensembles}\label{decision-trees-and-ensembles}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2394}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3803}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3803}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ID3 / C4.5 / CART & Split by info gain or Gini & Recursive,
interpretable \\
Random Forest & Bagging + Decision Trees & Reduces variance \\
Gradient Boosting & Sequential residual fitting & XGBoost, LightGBM,
CatBoost \\
AdaBoost & Weighted weak learners & Sensitive to noise \\
\end{longtable}

Impurity Measures:

\begin{itemize}
\tightlist
\item
  Gini: \(1-\sum p_i^2\)
\item
  Entropy: \(-\sum p_i\log_2p_i\)
\end{itemize}

\subsubsection{Support Vector Machines
(SVM)}\label{support-vector-machines-svm}

Finds a maximum margin hyperplane.

Objective: \[
\min_{w,b} \frac{1}{2}|w|^2 + C\sum\xi_i
\] subject to \(y_i(w^Tx_i+b)\ge1-\xi_i\)

Kernel trick enables nonlinear separation:
\[K(x_i,x_j)=\phi(x_i)\cdot\phi(x_j)\]

\subsubsection{Neural Network
Fundamentals}\label{neural-network-fundamentals}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Component & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Neuron & \(y=\sigma(w\cdot x+b)\) \\
Activation & Sigmoid, ReLU, Tanh \\
Loss & MSE, Cross-Entropy \\
Training & Gradient Descent + Backprop \\
Optimizers & SGD, Adam, RMSProp \\
\end{longtable}

Forward Propagation: \[a^{(l)} = \sigma(W^{(l)}a^{(l-1)}+b^{(l)})\]
Backpropagation computes gradients layer by layer.

\subsubsection{Gradient Descent
Variants}\label{gradient-descent-variants}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Variant & Idea & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Batch & Use all data each step & Stable but slow \\
Stochastic & Update per sample & Noisy, fast \\
Mini-batch & Group updates & Common practice \\
Momentum & Add velocity term & Faster convergence \\
Adam & Adaptive moment estimates & Most popular \\
\end{longtable}

Update Rule: \[
w = w - \eta \cdot \frac{\partial L}{\partial w}
\]

\subsubsection{Unsupervised Learning}\label{unsupervised-learning}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Description & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
PCA & Variance-based projection & Eigen decomposition \\
ICA & Independent components & Signal separation \\
t-SNE & Preserve local structure & Visualization only \\
Autoencoder & NN reconstruction model & Dimensionality red. \\
\end{longtable}

PCA Formula: Covariance \(C=\frac{1}{n}X^TX\), eigenvectors of \(C\) are
principal axes.

\subsubsection{Probabilistic Models}\label{probabilistic-models}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1818}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2727}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2273}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2841}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0341}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive Bayes & Independence assumption &
\(P(y                 | x)\propto P(y)\prod P(x_i | y)\) & & \\
HMM & Sequential hidden states & Viterbi for decoding & & \\
Markov Chains & Transition probabilities &
\(P(x_t               | x_{t-1})\) & & \\
Gaussian Mixture & Soft clustering & EM algorithm & & \\
\end{longtable}

\subsubsection{Optimization and
Metaheuristics}\label{optimization-and-metaheuristics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3016}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2381}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4603}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Category
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gradient Descent & Convex Opt. & Differentiable objectives \\
Newton's Method & Second-order & Uses Hessian \\
Simulated Annealing & Prob. search & Escape local minima \\
Genetic Algorithm & Evolutionary & Population-based search \\
PSO (Swarm) & Collective move & Inspired by flocking behavior \\
Hill Climbing & Greedy search & Local optimization \\
\end{longtable}

\subsubsection{Reinforcement Learning
Core}\label{reinforcement-learning-core}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Concept & Description & Example \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Agent & Learner/decision maker & Robot, policy \\
Environment & Provides states, rewards & Game, simulation \\
Policy & Mapping state → action & \(\pi(s)=a\) \\
Value Function & Expected return & \(V(s)\), \(Q(s,a)\) \\
\end{longtable}

Q-Learning Update: \[
Q(s,a)\leftarrow Q(s,a)+\alpha(r+\gamma\max_{a'}Q(s',a')-Q(s,a))
\]

Tiny Code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Q[s][a] }\OperatorTok{+=}\NormalTok{ alpha }\OperatorTok{*}\NormalTok{ (r }\OperatorTok{+}\NormalTok{ gamma }\OperatorTok{*} \BuiltInTok{max}\NormalTok{(Q[s\_next]) }\OperatorTok{{-}}\NormalTok{ Q[s][a])}
\end{Highlighting}
\end{Shaded}

\subsubsection{AI Search Algorithms}\label{ai-search-algorithms}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1447}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3158}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2105}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3289}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
BFS & Shortest path unweighted & \(O(V+E)\) & Level order search \\
DFS & Deep exploration & \(O(V+E)\) & Backtracking \\
A* Search & Informed, uses heuristic & \(O(E\log V)\) &
\(f(n)=g(n)+h(n)\) \\
IDA* & Iterative deepening A* & Memory efficient & Optimal if \(h\)
admissible \\
Beam Search & Keep best k states & Approximate & NLP decoding \\
\end{longtable}

\subsubsection{Evaluation Metrics}\label{evaluation-metrics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1772}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3418}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4810}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Task
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula / Meaning
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classification & Accuracy, Precision, Recall & \(\frac{TP}{TP+FP}\),
\(\frac{TP}{TP+FN}\) \\
Regression & RMSE, MAE, \(R^2\) & Fit and error magnitude \\
Clustering & Silhouette Score & Cohesion vs separation \\
Ranking & MAP, NDCG & Order-sensitive \\
\end{longtable}

Confusion Matrix:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
& Pred + & Pred - \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Actual + & TP & FN \\
Actual - & FP & TN \\
\end{longtable}

\subsubsection{Summary}\label{summary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2090}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3582}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Category
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Clustering & k-Means, GMM & Unsupervised grouping \\
Classification & Logistic, SVM, Trees & Supervised labeling \\
Regression & Linear, Ridge, Lasso & Predict continuous value \\
Optimization & GD, Adam, Simulated Annealing & Minimize loss \\
Probabilistic & Bayes, HMM, EM & Uncertainty modeling \\
Reinforcement & Q-Learning, SARSA & Reward-based learning \\
\end{longtable}

\bookmarksetup{startatroot}

\chapter{The Book}\label{the-book}

\begin{itemize}
\tightlist
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.pdf}{Download
  PDF} - print-ready
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.epub}{Download
  EPUB} - e-reader friendly
\item
  \href{https://github.com/little-book-of/algorithms/blob/main/releases/book.tex}{View
  LaTex} - \texttt{.tex} source
\item
  \href{https://github.com/little-book-of/algorithms}{Source code
  (Github)} - Markdown source
\item
  \href{https://little-book-of.github.io/algorithms/books/en-US/book.html}{Read
  on GitHub Pages} - view online
\end{itemize}

Licensed under CC BY-NC-SA 4.0.

\section{Chapter 1. Foundations of
algorithms}\label{chapter-1.-foundations-of-algorithms-1}

\subsection{1. What Is an Algorithm?}\label{what-is-an-algorithm-1}

Let's start at the beginning. Before code, data, or performance, we need
a clear idea of what an algorithm really is.

An algorithm is a clear, step-by-step procedure to solve a problem.
Think of it like a recipe: you have inputs (ingredients), a series of
steps (instructions), and an output (the finished dish).

At its core, an algorithm should be:

\begin{itemize}
\tightlist
\item
  Precise: every step is well defined and unambiguous
\item
  Finite: it finishes after a limited number of steps
\item
  Effective: each step is simple enough to carry out
\item
  Deterministic (usually): the same input gives the same output
\end{itemize}

When you write an algorithm, you are describing how to get from question
to answer, not just what the answer is.

\subsubsection{Example: Sum from 1 to
(n)}\label{example-sum-from-1-to-n}

Suppose you want the sum of the numbers from 1 to (n).

Natural language steps

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Set \texttt{total\ =\ 0}
\item
  For each \texttt{i} from \texttt{1} to \texttt{n}, add \texttt{i} to
  \texttt{total}
\item
  Return \texttt{total}
\end{enumerate}

Pseudocode

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Algorithm SumToN(n):}
\NormalTok{    total ← 0}
\NormalTok{    for i ← 1 to n:}
\NormalTok{        total ← total + i}
\NormalTok{    return total}
\end{Highlighting}
\end{Shaded}

C code

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_to\_n}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Tiny Code}\label{tiny-code}

Try a quick run by hand with (n = 5):

\begin{itemize}
\tightlist
\item
  start \texttt{total\ =\ 0}
\item
  add 1 → \texttt{total\ =\ 1}
\item
  add 2 → \texttt{total\ =\ 3}
\item
  add 3 → \texttt{total\ =\ 6}
\item
  add 4 → \texttt{total\ =\ 10}
\item
  add 5 → \texttt{total\ =\ 15}
\end{itemize}

Output is \texttt{15}.

You will also see this closed-form formula soon:

\[
1 + 2 + 3 + \dots + n = \frac{n(n+1)}{2}
\]

\subsubsection{Why It Matters}\label{why-it-matters}

Algorithms are the blueprints of computation. Every program, from a
calculator to an AI model, is built from algorithms. Computers are fast
at following instructions. Algorithms give those instructions structure
and purpose.

\begin{quote}
Algorithms are the language of problem solving.
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write an algorithm to find the maximum number in a list
\item
  Write an algorithm to reverse a string
\item
  Describe your morning routine as an algorithm: list the inputs, the
  steps, and the final output
\end{enumerate}

Tip: the best way to learn is to think in small, clear steps. Break a
problem into simple actions you can execute one by one.

\subsection{2. Measuring Time and
Space}\label{measuring-time-and-space-1}

Now that you know what an algorithm is, it's time to ask a deeper
question:

\begin{quote}
How do we know if one algorithm is better than another?
\end{quote}

It's not enough for an algorithm to be correct. It should also be
efficient. We measure efficiency in two key ways: time and space.

\subsubsection{Time Complexity}\label{time-complexity}

Time measures how long an algorithm takes to run, relative to its input
size. We don't measure in seconds, because hardware speed varies.
Instead, we count steps or operations.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Hi}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This loop runs \(n\) times, so it has time complexity \(O(n)\). The time
grows linearly with input size.

Another example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"*"}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

This runs \(n \times n = n^2\) times, so it has \(O(n^2)\) time
complexity.

These Big-O symbols describe how runtime grows as the input grows.

\subsubsection{Space Complexity}\label{space-complexity}

Space measures how much memory an algorithm uses.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}  \CommentTok{// O(1) space}
\end{Highlighting}
\end{Shaded}

This uses a constant amount of memory, regardless of input size.

But if we allocate an array:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}   \CommentTok{// O(n) space}
\end{Highlighting}
\end{Shaded}

This uses space proportional to \(n\).

Often, we trade time for space:

\begin{itemize}
\tightlist
\item
  Using a hash table speeds up lookups (more memory, less time)
\item
  Using a streaming algorithm saves memory (less space, more time)
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-1}

Compare two ways to compute the sum from 1 to \(n\):

Method 1: Loop

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_loop}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ total }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: \(O(n)\) Space: \(O(1)\)

Method 2: Formula

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_formula}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{*} \OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: \(O(1)\) Space: \(O(1)\)

Both are correct, but one is faster. Analyzing time and space helps you
understand why.

\subsubsection{Why It Matters}\label{why-it-matters-1}

When data grows huge (millions or billions), small inefficiencies
explode.

An algorithm that takes \(O(n^2)\) time might feel fine for 10 elements,
but impossible for 1,000,000.

Measuring time and space helps you:

\begin{itemize}
\tightlist
\item
  Predict performance
\item
  Compare different solutions
\item
  Optimize intelligently
\end{itemize}

It's your compass for navigating complexity.

\subsubsection{Try It Yourself}\label{try-it-yourself-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a simple algorithm to find the minimum in an array. Estimate its
  time and space complexity.
\item
  Compare two algorithms that solve the same problem. Which one scales
  better?
\item
  Think of a daily task that feels like \(O(n)\). Can you imagine one
  that's \(O(1)\)?
\end{enumerate}

Understanding these measurements early makes every future algorithm more
meaningful.

\subsection{3. Big-O, Big-Theta,
Big-Omega}\label{big-o-big-theta-big-omega}

Now that you can measure time and space, let's learn the language used
to describe those measurements.

When we say an algorithm is \(O(n)\), we're using asymptotic notation, a
way to describe how an algorithm's running time or memory grows as input
size \(n\) increases.

It's not about exact steps, but about how the cost scales for very large
\(n\).

\subsubsection{The Big-O (Upper Bound)}\label{the-big-o-upper-bound}

Big-O answers the question: \emph{``How bad can it get?''} It gives an
upper bound on growth, the worst-case scenario.

If an algorithm takes at most \(5n + 20\) steps, we write \(O(n)\). We
drop constants and lower-order terms because they don't matter at scale.

Common Big-O notations:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1692}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1692}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4154}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Name
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Growth
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Constant & \(O(1)\) & Flat & Accessing array element \\
Logarithmic & \(O(\log n)\) & Very slow growth & Binary search \\
Linear & \(O(n)\) & Proportional & Single loop \\
Quadratic & \(O(n^2)\) & Grows quickly & Double loop \\
Exponential & \(O(2^n)\) & Explodes & Recursive subset generation \\
\end{longtable}

If your algorithm is \(O(n)\), doubling input size roughly doubles
runtime. If it's \(O(n^2)\), doubling input size makes it about four
times slower.

\subsubsection{The Big-Theta (Tight
Bound)}\label{the-big-theta-tight-bound}

Big-Theta (\(\Theta\)) gives a tight bound, when you know the
algorithm's growth from above and below.

If runtime is roughly \(3n + 2\), then \(T(n) = \Theta(n)\). That means
it's both \(O(n)\) and \(\Omega(n)\).

\subsubsection{The Big-Omega (Lower
Bound)}\label{the-big-omega-lower-bound}

Big-Omega (\(\Omega\)) answers: \emph{``How fast can it possibly be?''}
It's the best-case growth, the lower limit.

Example:

\begin{itemize}
\tightlist
\item
  Linear search: \(\Omega(1)\) if the element is at the start
\item
  \(O(n)\) in the worst case if it's at the end
\end{itemize}

So we might say:

\[
T(n) = \Omega(1),\quad T(n) = O(n)
\]

\subsubsection{Tiny Code}\label{tiny-code-2}

Let's see Big-O in action.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_pairs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}        \CommentTok{// O(n)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}    \CommentTok{// O(n)}
\NormalTok{            total }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{;}            \CommentTok{// O(1)}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Total steps ≈ \(n \times n = n^2\). So \(T(n) = O(n^2)\).

If we added a constant-time operation before or after the loops, it
wouldn't matter. Constants vanish in asymptotic notation.

\subsubsection{Why It Matters}\label{why-it-matters-2}

Big-O, Big-Theta, and Big-Omega let you talk precisely about
performance. They are the grammar of efficiency.

When you can write:

\begin{quote}
Algorithm A runs in \(O(n \log n)\) time, \(O(n)\) space
\end{quote}

you've captured its essence clearly and compared it meaningfully.

They help you:

\begin{itemize}
\tightlist
\item
  Predict behavior at scale
\item
  Choose better data structures
\item
  Communicate efficiency in interviews and papers
\end{itemize}

It's not about exact timing, it's about growth.

\subsubsection{Try It Yourself}\label{try-it-yourself-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Analyze this code:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*=} \DecValTok{2}\OperatorTok{)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

  What's the time complexity?
\item
  Write an algorithm that's \(O(n \log n)\) (hint: merge sort).
\item
  Identify the best, worst, and average-case complexities for linear
  search and binary search.
\end{enumerate}

Learning Big-O is like learning a new language, once you're fluent, you
can see how code grows before you even run it.

\subsection{4. Algorithmic Paradigms (Greedy, Divide and Conquer,
DP)}\label{algorithmic-paradigms-greedy-divide-and-conquer-dp}

Once you can measure performance, it's time to explore how algorithms
are designed. Behind every clever solution is a guiding paradigm, a way
of thinking about problems.

Three of the most powerful are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Greedy Algorithms
\item
  Divide and Conquer
\item
  Dynamic Programming (DP)
\end{enumerate}

Each represents a different mindset for problem solving.

\subsubsection{1. Greedy Algorithms}\label{greedy-algorithms}

A greedy algorithm makes the best local choice at each step, hoping it
leads to a global optimum.

Think of it like:

\begin{quote}
``Take what looks best right now, and don't worry about the future.''
\end{quote}

They are fast and simple, but not always correct. They only work when
the greedy choice property holds.

Example: Coin Change (Greedy version) Suppose you want to make 63 cents
using US coins (25, 10, 5, 1). The greedy approach:

\begin{itemize}
\tightlist
\item
  Take 25 → 38 left
\item
  Take 25 → 13 left
\item
  Take 10 → 3 left
\item
  Take 1 × 3
\end{itemize}

This works here, but not always (try coins 1, 3, 4 for amount 6).
Simple, but not guaranteed optimal.

Common greedy algorithms:

\begin{itemize}
\tightlist
\item
  Kruskal's Minimum Spanning Tree
\item
  Prim's Minimum Spanning Tree
\item
  Dijkstra's Shortest Path (non-negative weights)
\item
  Huffman Coding
\end{itemize}

\subsubsection{2. Divide and Conquer}\label{divide-and-conquer}

This is a classic paradigm. You break the problem into smaller
subproblems, solve each recursively, and then combine the results.

It's like splitting a task among friends, then merging their answers.

Formally:

\[
T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]

Examples:

\begin{itemize}
\tightlist
\item
  Merge Sort: divide the array, sort halves, merge
\item
  Quick Sort: partition around a pivot
\item
  Binary Search: halve the range each step
\end{itemize}

Elegant and powerful, but recursion overhead can add cost if poorly
structured.

\subsubsection{3. Dynamic Programming
(DP)}\label{dynamic-programming-dp}

DP is for problems with overlapping subproblems and optimal
substructure. You solve smaller subproblems once and store the results
to avoid recomputation.

It's like divide and conquer with memory.

Example: Fibonacci Naive recursion is exponential. DP with memoization
is linear.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{static} \DataTypeTok{int}\NormalTok{ memo}\OperatorTok{[}\DecValTok{1000}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{    memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Efficient reuse, but requires insight into subproblem structure.

\subsubsection{Tiny Code}\label{tiny-code-3}

Quick comparison using Fibonacci:

Naive (Divide and Conquer)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib\_dc}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fib\_dc}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib\_dc}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{);}  \CommentTok{// exponential}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

DP (Memoization)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib\_dp}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ memo}\OperatorTok{[])} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ memo}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fib\_dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ memo}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib\_dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{,}\NormalTok{ memo}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-3}

Algorithmic paradigms give you patterns for design:

\begin{itemize}
\tightlist
\item
  Greedy: when local choices lead to a global optimum
\item
  Divide and Conquer: when the problem splits naturally
\item
  Dynamic Programming: when subproblems overlap
\end{itemize}

Once you recognize a problem's structure, you'll instantly know which
mindset fits best.

Think of paradigms as templates for reasoning, not just techniques but
philosophies.

\subsubsection{Try It Yourself}\label{try-it-yourself-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a greedy algorithm to make change using coins {[}1, 3, 4{]} for
  amount 6. Does it work?
\item
  Implement merge sort using divide and conquer.
\item
  Solve Fibonacci both ways (naive vs DP) and compare speeds.
\item
  Think of a real-life task you solve greedily.
\end{enumerate}

Learning paradigms is like learning styles of thought. Once you know
them, every problem starts to look familiar.

\subsection{5. Recurrence Relations}\label{recurrence-relations}

Every time you break a problem into smaller subproblems, you create a
recurrence, a mathematical way to describe how the total cost grows.

Recurrence relations are the backbone of analyzing recursive algorithms.
They tell us how much time or space an algorithm uses, based on the cost
of its subproblems.

\subsubsection{What Is a Recurrence?}\label{what-is-a-recurrence-1}

A recurrence relation expresses \(T(n)\), the total cost for input size
\(n\), in terms of smaller instances.

Example (Merge Sort):

\[
T(n) = 2T(n/2) + O(n)
\]

That means:

\begin{itemize}
\tightlist
\item
  It divides the problem into 2 halves (\(2T(n/2)\))
\item
  Merges results in \(O(n)\) time
\end{itemize}

You will often see recurrences like:

\begin{itemize}
\tightlist
\item
  \(T(n) = T(n - 1) + O(1)\)
\item
  \(T(n) = 2T(n/2) + O(n)\)
\item
  \(T(n) = T(n/2) + O(1)\)
\end{itemize}

Each one represents a different structure of recursion.

\subsubsection{Example 1: Simple Linear
Recurrence}\label{example-1-simple-linear-recurrence}

Consider this code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ count\_down}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{return} \DecValTok{1} \OperatorTok{+}\NormalTok{ count\_down}\OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This calls itself once for each smaller input:

\[
T(n) = T(n - 1) + O(1)
\]

Solve it:

\[
T(n) = O(n)
\]

Because it runs once per level.

\subsubsection{Example 2: Binary
Recurrence}\label{example-2-binary-recurrence}

For binary recursion:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_tree}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ sum\_tree}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{2}\OperatorTok{)} \OperatorTok{+}\NormalTok{ sum\_tree}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{2}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Here we do two subcalls on \(n/2\) and a constant amount of extra work:

\[
T(n) = 2T(n/2) + O(1)
\]

Solve it: \(T(n) = O(n)\)

Why? Each level doubles the number of calls but halves the size. There
are \(\log n\) levels, and total work adds up to \(O(n)\).

\subsubsection{Solving Recurrences}\label{solving-recurrences-1}

There are several ways to solve them:

\begin{itemize}
\item
  Substitution Method Guess the solution, then prove it by induction.
\item
  Recursion Tree Method Expand the recurrence into a tree and sum the
  cost per level.
\item
  Master Theorem Use a formula when the recurrence matches:

  \[
  T(n) = aT(n/b) + f(n)
  \]
\end{itemize}

\subsubsection{Master Theorem (Quick
Summary)}\label{master-theorem-quick-summary}

If \(T(n) = aT(n/b) + f(n)\), then:

\begin{itemize}
\tightlist
\item
  If \(f(n) = O(n^{\log_b a - \epsilon})\), then
  \(T(n) = \Theta(n^{\log_b a})\)
\item
  If \(f(n) = \Theta(n^{\log_b a})\), then
  \(T(n) = \Theta(n^{\log_b a} \log n)\)
\item
  If \(f(n) = \Omega(n^{\log_b a + \epsilon})\), and the regularity
  condition holds, then \(T(n) = \Theta(f(n))\)
\end{itemize}

Example (Merge Sort): \(a = 2\), \(b = 2\), \(f(n) = O(n)\)

\[
T(n) = 2T(n/2) + O(n) = O(n \log n)
\]

\subsubsection{Tiny Code}\label{tiny-code-4}

Let's write a quick recursive sum:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum\_array}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{==}\NormalTok{ r}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ arr}\OperatorTok{[}\NormalTok{l}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{l }\OperatorTok{+}\NormalTok{ r}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ sum\_array}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{)} \OperatorTok{+}\NormalTok{ sum\_array}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Recurrence:

\[
T(n) = 2T(n/2) + O(1)
\]

→ \(O(n)\)

If you added merging (like in merge sort), you would get \(+O(n)\):

→ \(O(n \log n)\)

\subsubsection{Why It Matters}\label{why-it-matters-4}

Recurrence relations let you predict the cost of recursive solutions.

Without them, recursion feels like magic. With them, you can quantify
efficiency.

They are key to understanding:

\begin{itemize}
\tightlist
\item
  Divide and Conquer
\item
  Dynamic Programming
\item
  Backtracking
\end{itemize}

Once you can set up a recurrence, solving it becomes a game of algebra
and logic.

\subsubsection{Try It Yourself}\label{try-it-yourself-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write a recurrence for binary search. Solve it.
\item
  Write a recurrence for merge sort. Solve it.
\item
  Analyze this function:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ fun}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\OperatorTok{;}
\NormalTok{    fun}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{2}\OperatorTok{);}
\NormalTok{    fun}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{3}\OperatorTok{);}
\NormalTok{    fun}\OperatorTok{(}\NormalTok{n}\OperatorTok{/}\DecValTok{6}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

  What's the recurrence? Approximate the complexity.
\item
  Expand \(T(n) = T(n-1) + 1\) into its explicit sum.
\end{enumerate}

Learning recurrences helps you see inside recursion. They turn code into
equations.

\subsection{6. Searching Basics}\label{searching-basics-1}

Before we sort or optimize, we need a way to find things. Searching is
one of the most fundamental actions in computing, whether it's looking
up a name, finding a key, or checking if something exists.

A search algorithm takes a collection (array, list, tree, etc.) and a
target, and returns whether the target is present (and often its
position).

Let's begin with two foundational techniques: Linear Search and Binary
Search.

\subsubsection{1. Linear Search}\label{linear-search-1}

Linear search is the simplest method:

\begin{itemize}
\tightlist
\item
  Start at the beginning
\item
  Check each element in turn
\item
  Stop if you find the target
\end{itemize}

It works on any list, sorted or not, but can be slow for large data.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ linear\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: If \texttt{arr\ =\ {[}2,\ 4,\ 6,\ 8,\ 10{]}} and
\texttt{key\ =\ 6}, it finds it at index 2.

Complexity:

\begin{itemize}
\tightlist
\item
  Time: \(O(n)\)
\item
  Space: \(O(1)\)
\end{itemize}

Linear search is simple and guaranteed to find the target if it exists,
but slow when lists are large.

\subsubsection{2. Binary Search}\label{binary-search-1}

When the list is sorted, we can do much better. Binary search repeatedly
divides the search space in half.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check the middle element
\item
  If it matches, you're done
\item
  If \texttt{target\ \textless{}\ mid}, search the left half
\item
  Else, search the right half
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: \texttt{arr\ =\ {[}2,\ 4,\ 6,\ 8,\ 10{]}}, \texttt{key\ =\ 8}

\begin{itemize}
\tightlist
\item
  mid = 6 → key \textgreater{} mid → search right half
\item
  mid = 8 → found
\end{itemize}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: \(O(\log n)\)
\item
  Space: \(O(1)\)
\end{itemize}

Binary search is a massive improvement; doubling input only adds one
extra step.

\subsubsection{3. Recursive Binary
Search}\label{recursive-binary-search}

Binary search can also be written recursively:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textgreater{}}\NormalTok{ high}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Same logic, different structure. Both iterative and recursive forms are
equally efficient.

\subsubsection{4. Choosing Between Them}\label{choosing-between-them}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Method & Works On & Time & Space & Needs Sorting \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & Any list & O(n) & O(1) & No \\
Binary Search & Sorted list & O(log n) & O(1) & Yes \\
\end{longtable}

If data is unsorted or very small, linear search is fine. If data is
sorted and large, binary search is far superior.

\subsubsection{Tiny Code}\label{tiny-code-5}

Compare the steps: For \(n = 16\):

\begin{itemize}
\tightlist
\item
  Linear search → up to 16 comparisons
\item
  Binary search → \(\log_2 16 = 4\) comparisons
\end{itemize}

That's a huge difference.

\subsubsection{Why It Matters}\label{why-it-matters-5}

Searching is the core of information retrieval. Every database,
compiler, and system relies on it.

Understanding simple searches prepares you for:

\begin{itemize}
\tightlist
\item
  Hash tables (constant-time lookups)
\item
  Tree searches (ordered structures)
\item
  Graph traversals (structured exploration)
\end{itemize}

It's not just about finding values; it's about learning how data
structure and algorithm design fit together.

\subsubsection{Try It Yourself}\label{try-it-yourself-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a linear search that returns all indices where a target appears.
\item
  Modify binary search to return the first occurrence of a target in a
  sorted array.
\item
  Compare runtime on arrays of size 10, 100, 1000.
\item
  What happens if you run binary search on an unsorted list?
\end{enumerate}

Search is the foundation. Once you master it, you'll recognize its
patterns everywhere.

\subsection{7. Sorting Basics}\label{sorting-basics}

Sorting is one of the most studied problems in computer science. Why?
Because order matters. It makes searching faster, patterns clearer, and
data easier to manage.

A sorting algorithm arranges elements in a specific order (usually
ascending or descending). Once sorted, many operations (like binary
search, merging, or deduplication) become much simpler.

Let's explore the foundational sorting methods and the principles behind
them.

\subsubsection{1. What Makes a Sort
Algorithm}\label{what-makes-a-sort-algorithm}

A sorting algorithm should define:

\begin{itemize}
\tightlist
\item
  Input: a sequence of elements
\item
  Output: the same elements, in sorted order
\item
  Stability: keeps equal elements in the same order (important for
  multi-key sorts)
\item
  In-place: uses only a constant amount of extra space
\end{itemize}

Different algorithms balance speed, memory, and simplicity.

\subsubsection{2. Bubble Sort}\label{bubble-sort}

Idea: repeatedly ``bubble up'' the largest element to the end by
swapping adjacent pairs.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bubble\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Each pass moves the largest remaining item to its final position.

\begin{itemize}
\tightlist
\item
  Time: \(O(n^2)\)
\item
  Space: \(O(1)\)
\item
  Stable: Yes
\end{itemize}

Simple but inefficient for large data.

\subsubsection{3. Selection Sort}\label{selection-sort}

Idea: repeatedly select the smallest element and put it in the correct
position.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ selection\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ min\_idx }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{])}\NormalTok{ min\_idx }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
        \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Time: \(O(n^2)\)
\item
  Space: \(O(1)\)
\item
  Stable: No
\end{itemize}

Fewer swaps, but still quadratic in time.

\subsubsection{4. Insertion Sort}\label{insertion-sort}

Idea: build the sorted list one item at a time, inserting each new item
in the right place.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ insertion\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ key }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j }\OperatorTok{\textgreater{}=} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{            j}\OperatorTok{{-}{-};}
        \OperatorTok{\}}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Time: \(O(n^2)\) (best case \(O(n)\) when nearly sorted)
\item
  Space: \(O(1)\)
\item
  Stable: Yes
\end{itemize}

Insertion sort is great for small or nearly sorted datasets. It is often
used as a base in hybrid sorts like Timsort.

\subsubsection{5. Comparing the Basics}\label{comparing-the-basics}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1525}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2034}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1695}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1017}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1356}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-place
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & O(n) & O(n²) & O(n²) & Yes & Yes \\
Selection Sort & O(n²) & O(n²) & O(n²) & No & Yes \\
Insertion Sort & O(n) & O(n²) & O(n²) & Yes & Yes \\
\end{longtable}

All three are quadratic in time, but Insertion Sort performs best on
small or partially sorted data.

\subsubsection{Tiny Code}\label{tiny-code-6}

Quick check with \texttt{arr\ =\ {[}5,\ 3,\ 4,\ 1,\ 2{]}}:

Insertion Sort (step by step)

\begin{itemize}
\tightlist
\item
  Insert 3 before 5 → {[}3, 5, 4, 1, 2{]}
\item
  Insert 4 → {[}3, 4, 5, 1, 2{]}
\item
  Insert 1 → {[}1, 3, 4, 5, 2{]}
\item
  Insert 2 → {[}1, 2, 3, 4, 5{]}
\end{itemize}

Sorted!

\subsubsection{Why It Matters}\label{why-it-matters-6}

Sorting is a gateway algorithm. It teaches you about iteration,
swapping, and optimization.

Efficient sorting is critical for:

\begin{itemize}
\tightlist
\item
  Preprocessing data for binary search
\item
  Organizing data for analysis
\item
  Building indexes and ranking systems
\end{itemize}

It's the first step toward deeper concepts like divide and conquer and
hybrid optimization.

\subsubsection{Try It Yourself}\label{try-it-yourself-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement all three: bubble, selection, insertion
\item
  Test them on arrays of size 10, 100, 1000, and note timing differences
\item
  Try sorting an array that's already sorted. Which one adapts best?
\item
  Modify insertion sort to sort in descending order
\end{enumerate}

Sorting may seem simple, but it's a cornerstone. Mastering it will shape
your intuition for almost every other algorithm.

\subsection{8. Data Structures Overview}\label{data-structures-overview}

Algorithms and data structures are two sides of the same coin. An
algorithm is how you solve a problem. A data structure is where you
store and organize data so that your algorithm can work efficiently.

You can think of data structures as containers, each one shaped for
specific access patterns, trade-offs, and performance needs. Choosing
the right one is often the key to designing a fast algorithm.

\subsubsection{1. Why Data Structures
Matter}\label{why-data-structures-matter}

Imagine you want to find a book quickly.

\begin{itemize}
\tightlist
\item
  If all books are piled randomly → you must scan every one (\(O(n)\))
\item
  If they're sorted on a shelf → you can use binary search
  (\(O(\log n)\))
\item
  If you have an index or catalog → you can find it instantly (\(O(1)\))
\end{itemize}

Different structures unlock different efficiencies.

\subsubsection{2. The Core Data
Structures}\label{the-core-data-structures}

Let's walk through the most essential ones:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1058}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2981}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4135}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1827}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Operations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Array & Fixed-size contiguous memory & Access (\(O(1)\)), Insert/Delete
(\(O(n)\)) & Fast index access \\
Linked List & Sequence of nodes with pointers & Insert/Delete
(\(O(1)\)), Access (\(O(n)\)) & Dynamic sequences \\
Stack & LIFO (last-in, first-out) & push(), pop() in \(O(1)\) & Undo,
recursion \\
Queue & FIFO (first-in, first-out) & enqueue(), dequeue() in \(O(1)\) &
Scheduling, buffers \\
Hash Table & Key-value pairs via hashing & Average \(O(1)\), Worst
\(O(n)\) & Lookup, caching \\
Heap & Partially ordered tree & Insert \(O(\log n)\), Extract-Min
\(O(\log n)\) & Priority queues \\
Tree & Hierarchical structure & Access \(O(\log n)\) (balanced) & Sorted
storage \\
Graph & Nodes + edges & Traversal \(O(V+E)\) & Networks, paths \\
Set / Map & Unique keys or key-value pairs & \(O(\log n)\) or \(O(1)\) &
Membership tests \\
\end{longtable}

Each comes with trade-offs. Arrays are fast but rigid, linked lists are
flexible but slower to access, and hash tables are lightning-fast but
unordered.

\subsubsection{3. Abstract Data Types
(ADTs)}\label{abstract-data-types-adts}

An ADT defines what operations you can do, not how they're implemented.
For example, a Stack ADT promises:

\begin{itemize}
\tightlist
\item
  \texttt{push(x)}
\item
  \texttt{pop()}
\item
  \texttt{peek()}
\end{itemize}

It can be implemented with arrays or linked lists, the behavior stays
the same.

Common ADTs:

\begin{itemize}
\tightlist
\item
  Stack
\item
  Queue
\item
  Deque
\item
  Priority Queue
\item
  Map / Dictionary
\end{itemize}

This separation of interface and implementation helps design flexible
systems.

\subsubsection{4. The Right Tool for the
Job}\label{the-right-tool-for-the-job}

Choosing the correct data structure often decides the performance of
your algorithm:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Good Choice & Reason \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undo feature & Stack & LIFO fits history \\
Scheduling tasks & Queue & FIFO order \\
Dijkstra's algorithm & Priority Queue & Extract smallest distance \\
Counting frequencies & Hash Map & Fast key lookup \\
Dynamic median & Heap + Heap & Balance two halves \\
Search by prefix & Trie & Fast prefix lookups \\
\end{longtable}

Good programmers don't just write code. They pick the right structure.

\subsubsection{Tiny Code}\label{tiny-code-7}

Example: comparing array vs linked list

Array:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[}\DecValTok{5}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{5}\OperatorTok{\};}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\DecValTok{3}\OperatorTok{]);} \CommentTok{// O(1)}
\end{Highlighting}
\end{Shaded}

Linked List:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{;} \KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;} \OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

To get the 4th element, you must traverse → \(O(n)\)

Different structures, different access costs.

\subsubsection{Why It Matters}\label{why-it-matters-7}

Every efficient algorithm depends on the right data structure.

\begin{itemize}
\tightlist
\item
  Searching, sorting, and storing all rely on structure
\item
  Memory layout affects cache performance
\item
  The wrong choice can turn \(O(1)\) into \(O(n^2)\)
\end{itemize}

Understanding these structures is like knowing the tools in a workshop.
Once you recognize their shapes, you'll instinctively know which to
grab.

\subsubsection{Try It Yourself}\label{try-it-yourself-7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a stack using an array. Then implement it using a linked
  list.
\item
  Write a queue using two stacks.
\item
  Try storing key-value pairs in a hash table (hint: mod by table size).
\item
  Compare access times for arrays vs linked lists experimentally.
\end{enumerate}

Data structures aren't just storage. They are the skeletons your
algorithms stand on.

\subsection{9. Graphs and Trees
Overview}\label{graphs-and-trees-overview}

Now that you've seen linear structures like arrays and linked lists,
it's time to explore nonlinear structures, graphs and trees. These are
the shapes behind networks, hierarchies, and relationships.

They appear everywhere: family trees, file systems, maps, social
networks, and knowledge graphs all rely on them.

\subsubsection{1. Trees}\label{trees}

A tree is a connected structure with no cycles. It's a hierarchy, and
every node (except the root) has one parent.

\begin{itemize}
\tightlist
\item
  Root: the top node
\item
  Child: a node directly connected below
\item
  Leaf: a node with no children
\item
  Height: the longest path from root to a leaf
\end{itemize}

A binary tree is one where each node has at most two children. A binary
search tree (BST) keeps elements ordered:

\begin{itemize}
\tightlist
\item
  Left child \textless{} parent \textless{} right child
\end{itemize}

Basic operations:

\begin{itemize}
\tightlist
\item
  Insert
\item
  Search
\item
  Delete
\item
  Traverse (preorder, inorder, postorder, level-order)
\end{itemize}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ val}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Insert in BST:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ insert}\OperatorTok{(}\KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{val}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{val}\OperatorTok{)}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Common Tree Types}\label{common-tree-types}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2439}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5366}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2195}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Tree & Each node has ≤ 2 children & General hierarchy \\
Binary Search Tree & Left \textless{} Root \textless{} Right & Ordered
data \\
AVL / Red-Black Tree & Self-balancing BST & Fast search/insert \\
Heap & Complete binary tree, parent ≥ or ≤ children & Priority queues \\
Trie & Tree of characters & Prefix search \\
Segment Tree & Tree over ranges & Range queries \\
Fenwick Tree & Tree with prefix sums & Efficient updates \\
\end{longtable}

Balanced trees keep height \(O(\log n)\), guaranteeing fast operations.

\subsubsection{3. Graphs}\label{graphs}

A graph generalizes the idea of trees. In graphs, nodes (vertices) can
connect freely.

A graph is a set of vertices (\(V\)) and edges (\(E\)):

\[
G = (V, E)
\]

Directed vs Undirected:

\begin{itemize}
\tightlist
\item
  Directed: edges have direction (A → B)
\item
  Undirected: edges connect both ways (A, B)
\end{itemize}

Weighted vs Unweighted:

\begin{itemize}
\tightlist
\item
  Weighted: each edge has a cost
\item
  Unweighted: all edges are equal
\end{itemize}

Representation:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Adjacency Matrix: \(n \times n\) matrix; entry \((i, j) = 1\) if edge
  exists
\item
  Adjacency List: array of lists; each vertex stores its neighbors
\end{enumerate}

Example adjacency list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ graph}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{graph}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
\NormalTok{graph}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\DecValTok{2}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Common Graph Types}\label{common-graph-types}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3235}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3676}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3088}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Graph Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & Edges without direction & Friendship network \\
Directed & Arrows indicate direction & Web links \\
Weighted & Edges have costs & Road network \\
Cyclic & Contains loops & Task dependencies \\
Acyclic & No loops & Family tree \\
DAG (Directed Acyclic) & Directed, no cycles & Scheduling, compilers \\
Complete & All pairs connected & Dense networks \\
Sparse & Few edges & Real-world graphs \\
\end{longtable}

\subsubsection{5. Basic Graph Operations}\label{basic-graph-operations}

\begin{itemize}
\tightlist
\item
  Add Vertex / Edge
\item
  Traversal: Depth-First Search (DFS), Breadth-First Search (BFS)
\item
  Path Finding: Dijkstra, Bellman-Ford
\item
  Connectivity: Union-Find, Tarjan (SCC)
\item
  Spanning Trees: Kruskal, Prim
\end{itemize}

Each graph problem has its own flavor, from finding shortest paths to
detecting cycles.

\subsubsection{Tiny Code}\label{tiny-code-8}

Breadth-first search (BFS):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ graph}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{bool}\NormalTok{ visited}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{    memset}\OperatorTok{(}\NormalTok{visited}\OperatorTok{,} \KeywordTok{false}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{visited}\OperatorTok{));}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{start}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ node }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{        printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ node}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ neighbor }\OperatorTok{:}\NormalTok{ graph}\OperatorTok{[}\NormalTok{node}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{neighbor}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                visited}\OperatorTok{[}\NormalTok{neighbor}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{neighbor}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This explores level by level, perfect for shortest paths in unweighted
graphs.

\subsubsection{Why It Matters}\label{why-it-matters-8}

Trees and graphs model relationships and connections, not just
sequences. They are essential for:

\begin{itemize}
\tightlist
\item
  Search engines (web graph)
\item
  Compilers (syntax trees, dependency DAGs)
\item
  AI (state spaces, decision trees)
\item
  Databases (indexes, joins, relationships)
\end{itemize}

Understanding them unlocks an entire world of algorithms, from DFS and
BFS to Dijkstra, Kruskal, and beyond.

\subsubsection{Try It Yourself}\label{try-it-yourself-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a simple binary search tree and implement inorder traversal.
\item
  Represent a graph with adjacency lists and print all edges.
\item
  Write a DFS and BFS for a small graph.
\item
  Draw a directed graph with a cycle and detect it manually.
\end{enumerate}

Graphs and trees move you beyond linear thinking. They let you explore
\emph{connections}, not just collections.

\subsection{10. Algorithm Design
Patterns}\label{algorithm-design-patterns}

By now, you've seen what algorithms are and how they're analyzed. You've
explored searches, sorts, structures, and recursion. The next step is
learning patterns, reusable strategies that guide how you build new
algorithms from scratch.

Just like design patterns in software architecture, algorithmic design
patterns give structure to your thinking. Once you recognize them, many
problems suddenly feel familiar.

\subsubsection{1. Brute Force}\label{brute-force}

Start simple. Try every possibility and pick the best result. Brute
force is often your baseline, clear but inefficient.

Example: Find the maximum subarray sum by checking all subarrays.

\begin{itemize}
\tightlist
\item
  Time: \(O(n^2)\)
\item
  Advantage: easy to reason about
\item
  Disadvantage: explodes for large input
\end{itemize}

Sometimes, brute force helps you see the structure needed for a better
approach.

\subsubsection{2. Divide and Conquer}\label{divide-and-conquer-1}

Split the problem into smaller parts, solve each, and combine. Ideal for
problems with self-similarity.

Classic examples:

\begin{itemize}
\tightlist
\item
  Merge Sort → split and merge
\item
  Binary Search → halve the search space
\item
  Quick Sort → partition and sort
\end{itemize}

General form:

\[
T(n) = aT(n/b) + f(n)
\]

Use recurrence relations and the Master Theorem to analyze them.

\subsubsection{3. Greedy}\label{greedy}

Make the best local decision at each step. Works only when local optimal
choices lead to a global optimum.

Examples:

\begin{itemize}
\tightlist
\item
  Activity Selection
\item
  Huffman Coding
\item
  Dijkstra (for non-negative weights)
\end{itemize}

Greedy algorithms are simple and fast when they fit.

\subsubsection{4. Dynamic Programming
(DP)}\label{dynamic-programming-dp-1}

When subproblems overlap, store results and reuse them. Think recursion
plus memory.

Two main styles:

\begin{itemize}
\tightlist
\item
  Top-Down (Memoization): recursive with caching
\item
  Bottom-Up (Tabulation): iterative filling table
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Fibonacci numbers
\item
  Knapsack
\item
  Longest Increasing Subsequence (LIS)
\item
  Matrix Chain Multiplication
\end{itemize}

DP transforms exponential recursion into polynomial time.

\subsubsection{5. Backtracking}\label{backtracking}

Explore all possibilities, but prune when constraints fail. It is brute
force with early exits.

Perfect for:

\begin{itemize}
\tightlist
\item
  N-Queens
\item
  Sudoku
\item
  Permutation generation
\item
  Subset sums
\end{itemize}

Backtracking builds solutions incrementally, abandoning paths that
cannot lead to a valid result.

\subsubsection{6. Two Pointers}\label{two-pointers}

Move two indices through a sequence to find patterns or meet conditions.

Common use:

\begin{itemize}
\tightlist
\item
  Sorted arrays (sum pairs, partitions)
\item
  String problems (palindromes, sliding windows)
\item
  Linked lists (slow and fast pointers)
\end{itemize}

Simple, but surprisingly powerful.

\subsubsection{7. Sliding Window}\label{sliding-window}

Maintain a window over data, expand or shrink it as needed.

Used for:

\begin{itemize}
\tightlist
\item
  Maximum sum subarray (Kadane's algorithm)
\item
  Substrings of length \(k\)
\item
  Longest substring without repeating characters
\end{itemize}

Helps reduce \(O(n^2)\) to \(O(n)\) in sequence problems.

\subsubsection{8. Binary Search on
Answer}\label{binary-search-on-answer}

Sometimes, the input is not sorted, but the answer space is. If you can
define a function \texttt{check(mid)} that is monotonic (true or false
changes once), you can apply binary search on possible answers.

Examples:

\begin{itemize}
\tightlist
\item
  Minimum capacity to ship packages in D days
\item
  Smallest feasible value satisfying a constraint
\end{itemize}

Powerful for optimization under monotonic conditions.

\subsubsection{9. Graph-Based}\label{graph-based}

Think in terms of nodes and edges, paths and flows.

Patterns include:

\begin{itemize}
\tightlist
\item
  BFS and DFS (exploration)
\item
  Topological Sort (ordering)
\item
  Dijkstra and Bellman-Ford (shortest paths)
\item
  Union-Find (connectivity)
\item
  Kruskal and Prim (spanning trees)
\end{itemize}

Graphs often reveal relationships hidden in data.

\subsubsection{10. Meet in the Middle}\label{meet-in-the-middle}

Split the problem into two halves, compute all possibilities for each,
and combine efficiently. Used in problems where brute force \(O(2^n)\)
is too large but \(O(2^{n/2})\) is manageable.

Examples:

\begin{itemize}
\tightlist
\item
  Subset sum (divide into two halves)
\item
  Search problems in combinatorics
\end{itemize}

A clever compromise between brute force and efficiency.

\subsubsection{Tiny Code}\label{tiny-code-9}

Example: Two Pointers to find a pair sum

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ find\_pair\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ sum }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sum }\OperatorTok{==}\NormalTok{ target}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sum }\OperatorTok{\textless{}}\NormalTok{ target}\OperatorTok{)}\NormalTok{ i}\OperatorTok{++;}
        \ControlFlowTok{else}\NormalTok{ j}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Works in \(O(n)\) for sorted arrays, elegant and fast.

\subsubsection{Why It Matters}\label{why-it-matters-9}

Patterns are mental shortcuts. They turn ``blank page'' problems into
``I've seen this shape before.''

Once you recognize the structure, you can choose a suitable pattern and
adapt it. This is how top coders solve complex problems under time
pressure, not by memorizing algorithms, but by seeing patterns.

\subsubsection{Try It Yourself}\label{try-it-yourself-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a brute-force and a divide-and-conquer solution for maximum
  subarray sum. Compare speed.
\item
  Solve the coin change problem using both greedy and DP.
\item
  Implement N-Queens with backtracking.
\item
  Use two pointers to find the smallest window with a given sum.
\item
  Pick a problem you've solved before. Can you reframe it using a
  different design pattern?
\end{enumerate}

The more patterns you practice, the faster you will map new problems to
known strategies, and the more powerful your algorithmic intuition will
become.

\section{Chapter 2. Sorting and
Searching}\label{chapter-2.-sorting-and-searching-1}

\subsection{11. Elementary Sorting (Bubble, Insertion,
Selection)}\label{elementary-sorting-bubble-insertion-selection}

Before diving into advanced sorts like mergesort or heapsort, it's
important to understand the elementary sorting algorithms , the building
blocks. They're simple, intuitive, and great for learning how sorting
works under the hood.

In this section, we'll cover three classics:

\begin{itemize}
\tightlist
\item
  Bubble Sort - swap adjacent out-of-order pairs- Selection Sort -
  select the smallest element each time- Insertion Sort - insert
  elements one by one in order These algorithms share ( O\(n^2\) ) time
  complexity but differ in behavior and stability.
\end{itemize}

\subsubsection{1. Bubble Sort}\label{bubble-sort-1}

Idea: Compare adjacent pairs and swap if they're out of order. Repeat
until the array is sorted. Each pass ``bubbles'' the largest element to
the end.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare \texttt{arr{[}j{]}} and \texttt{arr{[}j+1{]}}
\item
  Swap if \texttt{arr{[}j{]}\ \textgreater{}\ arr{[}j+1{]}}
\item
  Continue passes until no swaps are needed
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bubble\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ swapped }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{                arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{                swapped }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{swapped}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best: ( O(n) ) (already sorted)- Worst: ( O\(n^2\) )- Space: ( O(1) )-
  Stable: Yes Intuition: Imagine bubbles rising , after each pass, the
  largest ``bubble'' settles at the top.
\end{itemize}

\subsubsection{2. Selection Sort}\label{selection-sort-1}

Idea: Find the smallest element and place it at the front.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each position \texttt{i}, find the smallest element in the
  remainder of the array
\item
  Swap it with \texttt{arr{[}i{]}}
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ selection\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ min\_idx }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{])}
\NormalTok{                min\_idx }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
        \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{min\_idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best: ( O\(n^2\) )- Worst: ( O\(n^2\) )- Space: ( O(1) )- Stable: No
  Intuition: Selection sort ``selects'' the next correct element and
  fixes it. It minimizes swaps but still scans all elements.
\end{itemize}

\subsubsection{3. Insertion Sort}\label{insertion-sort-1}

Idea: Build a sorted array one element at a time by inserting each new
element into its correct position.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start from index 1
\item
  Compare with previous elements
\item
  Shift elements greater than key to the right
\item
  Insert key into the correct place
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ insertion\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ key }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j }\OperatorTok{\textgreater{}=} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
\NormalTok{            j}\OperatorTok{{-}{-};}
        \OperatorTok{\}}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{j }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best: ( O(n) ) (nearly sorted)- Worst: ( O\(n^2\) )- Space: ( O(1) )-
  Stable: Yes Intuition: It's like sorting cards in your hand , take the
  next card and slide it into the right place.
\end{itemize}

\subsubsection{4. Comparing the Three}\label{comparing-the-three}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1474}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0947}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1263}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1053}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0632}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0842}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3789}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-Place
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & O(n) & O(n²) & O(n²) & Yes & Yes & Early exit possible \\
Selection Sort & O(n²) & O(n²) & O(n²) & No & Yes & Few swaps \\
Insertion Sort & O(n) & O(n²) & O(n²) & Yes & Yes & Great on small or
nearly sorted data \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-10}

Let's see how insertion sort works on \texttt{{[}5,\ 3,\ 4,\ 1,\ 2{]}}:

\begin{itemize}
\tightlist
\item
  Start with 3 → insert before 5 → \texttt{{[}3,\ 5,\ 4,\ 1,\ 2{]}}-
  Insert 4 → \texttt{{[}3,\ 4,\ 5,\ 1,\ 2{]}}- Insert 1 →
  \texttt{{[}1,\ 3,\ 4,\ 5,\ 2{]}}- Insert 2 →
  \texttt{{[}1,\ 2,\ 3,\ 4,\ 5{]}} Sorted in five passes.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-10}

Elementary sorts teach you:

\begin{itemize}
\tightlist
\item
  How comparisons and swaps drive order- The trade-off between
  simplicity and efficiency- How to reason about stability and
  adaptability While these aren't used for large datasets in practice,
  they're used \emph{inside} hybrid algorithms like Timsort and
  IntroSort, which switch to insertion sort for small chunks.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-10}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement all three and print the array after each pass.
\item
  Test on arrays: already sorted, reversed, random, partially sorted.
\item
  Modify bubble sort to sort descending.
\item
  Try insertion sort on 10,000 elements and note its behavior.
\item
  Can you detect when the list is already sorted and stop early?
\end{enumerate}

Start simple. Master these patterns. They'll be your foundation for
everything from merge sort to radix sort.

\subsection{12. Divide-and-Conquer Sorting (Merge, Quick,
Heap)}\label{divide-and-conquer-sorting-merge-quick-heap}

Elementary sorts are great for learning, but their (O\(n^2\)) runtime
quickly becomes a bottleneck. To scale beyond small arrays, we need
algorithms that divide problems into smaller parts, sort them
independently, and combine the results.

This is the essence of divide and conquer , break it down, solve
subproblems, merge solutions. In sorting, this approach yields some of
the fastest general-purpose algorithms: Merge Sort, Quick Sort, and Heap
Sort.

\subsubsection{1. Merge Sort}\label{merge-sort-1}

Idea: Split the array in half, sort each half recursively, then merge
the two sorted halves.

Merge sort is stable, works well with linked lists, and guarantees
(O\(n \log n\)) time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide the array into halves
\item
  Recursively sort each half
\item
  Merge two sorted halves into one
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ merge}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n1 }\OperatorTok{=}\NormalTok{ m }\OperatorTok{{-}}\NormalTok{ l }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ n2 }\OperatorTok{=}\NormalTok{ r }\OperatorTok{{-}}\NormalTok{ m}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ L}\OperatorTok{[}\NormalTok{n1}\OperatorTok{],}\NormalTok{ R}\OperatorTok{[}\NormalTok{n2}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{l }\OperatorTok{+}\NormalTok{ i}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n2}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{m }\OperatorTok{+} \DecValTok{1} \OperatorTok{+}\NormalTok{ j}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ k }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n1 }\OperatorTok{\&\&}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n2}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}=}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{++];}
        \ControlFlowTok{else}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{++];}
    \OperatorTok{\}}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n1}\OperatorTok{)}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{++];}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j }\OperatorTok{\textless{}}\NormalTok{ n2}\OperatorTok{)}\NormalTok{ arr}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ R}\OperatorTok{[}\NormalTok{j}\OperatorTok{++];}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ merge\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \OperatorTok{(}\NormalTok{l }\OperatorTok{+}\NormalTok{ r}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{        merge\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ m}\OperatorTok{);}
\NormalTok{        merge\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ m }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
\NormalTok{        merge}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ m}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n \log n\)) (always)- Space: (O(n)) (temporary arrays)-
  Stable: Yes Merge sort is predictable, making it ideal for external
  sorting (like sorting data on disk).
\end{itemize}

\subsubsection{2. Quick Sort}\label{quick-sort-1}

Idea: Pick a pivot, partition the array so smaller elements go left and
larger go right, then recursively sort both sides.

Quick sort is usually the fastest in practice due to good cache locality
and low constant factors.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose a pivot (often middle or random)
\item
  Partition: move smaller elements to left, larger to right
\item
  Recursively sort the two partitions
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ low }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ pivot}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            i}\OperatorTok{++;}
            \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ quick\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ pi }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
\NormalTok{        quick\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\NormalTok{        quick\_sort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Best / Average: (O\(n \log n\))- Worst: (O\(n^2\)) (bad pivot,
  e.g.~sorted input with naive pivot)- Space: (O\(\log n\)) (recursion)-
  Stable: No (unless modified) Quick sort is often used in standard
  libraries due to its efficiency in real-world workloads.
\end{itemize}

\subsubsection{3. Heap Sort}\label{heap-sort}

Idea: Turn the array into a heap, repeatedly extract the largest
element, and place it at the end.

A heap is a binary tree where every parent is ≥ its children (max-heap).

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a max-heap
\item
  Swap the root (max) with the last element
\item
  Reduce heap size, re-heapify
\item
  Repeat until sorted
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ heapify}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ largest }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ l }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ r }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ i }\OperatorTok{+} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{l}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{])}\NormalTok{ largest }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{r}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{])}\NormalTok{ largest }\OperatorTok{=}\NormalTok{ r}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{largest }\OperatorTok{!=}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{largest}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ largest}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ heap\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{/} \DecValTok{2} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n \log n\))- Space: (O(1))- Stable: No Heap sort is reliable
  and space-efficient but less cache-friendly than quicksort.
\end{itemize}

\subsubsection{4. Comparison}\label{comparison}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1067}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0800}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2533}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Merge Sort & O(n log n) & O(n log n) & O(n log n) & O(n) & Yes &
Predictable, stable \\
Quick Sort & O(n log n) & O(n log n) & O(n²) & O(log n) & No & Fast in
practice \\
Heap Sort & O(n log n) & O(n log n) & O(n log n) & O(1) & No & In-place,
robust \\
\end{longtable}

Each one fits a niche:

\begin{itemize}
\tightlist
\item
  Merge Sort → stability and guarantees- Quick Sort → speed and cache
  performance- Heap Sort → low memory usage and simplicity
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-11}

Try sorting \texttt{{[}5,\ 1,\ 4,\ 2,\ 8{]}} with merge sort:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Split → \texttt{{[}5,1,4{]}}, \texttt{{[}2,8{]}}
\item
  Sort each → \texttt{{[}1,4,5{]}}, \texttt{{[}2,8{]}}
\item
  Merge → \texttt{{[}1,2,4,5,8{]}}
\end{enumerate}

Each recursive split halves the problem, yielding (O\(\log n\)) depth
with (O(n)) work per level.

\subsubsection{Why It Matters}\label{why-it-matters-11}

Divide-and-conquer sorting is the foundation for efficient order
processing. It introduces ideas you'll reuse in:

\begin{itemize}
\tightlist
\item
  Binary search (halving)- Matrix multiplication- Fast Fourier
  Transform- Dynamic programming These sorts teach how recursion,
  partitioning, and merging combine into scalable solutions.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-11}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement merge sort, quick sort, and heap sort.
\item
  Test all three on the same random array. Compare runtime.
\item
  Modify quick sort to use a random pivot.
\item
  Build a stable version of heap sort.
\item
  Visualize merge sort's recursion tree and merging process.
\end{enumerate}

Mastering these sorts gives you a template for solving any
divide-and-conquer problem efficiently.

\subsection{13. Counting and Distribution Sorts (Counting, Radix,
Bucket)}\label{counting-and-distribution-sorts-counting-radix-bucket}

So far, we've seen comparison-based sorts like merge sort and quicksort.
These rely on comparing elements and are bounded by the O(n log n) lower
limit for comparisons.

But what if you don't need to compare elements directly , what if
they're integers or values from a limited range?

That's where counting and distribution sorts come in. They exploit
structure, not just order, to achieve linear-time sorting in the right
conditions.

\subsubsection{1. Counting Sort}\label{counting-sort}

Idea: If your elements are integers in a known range ({[}0, k)), you can
count occurrences of each value, then reconstruct the sorted output.

Counting sort doesn't compare , it counts.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the range of input (max value (k))
\item
  Count occurrences in a frequency array
\item
  Convert counts to cumulative counts
\item
  Place elements into their sorted positions
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ counting\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ k}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ count}\OperatorTok{[}\NormalTok{k }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ output}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ k}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ count}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ count}\OperatorTok{[}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]++;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ k}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ count}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ count}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
\NormalTok{        output}\OperatorTok{[}\NormalTok{count}\OperatorTok{[}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        count}\OperatorTok{[}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ output}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}4, 2, 2, 8, 3, 3, 1{]}, k = 8 → count =
{[}0,1,2,2,1,0,0,0,1{]} → cumulative = {[}0,1,3,5,6,6,6,6,7{]} → sorted
= {[}1,2,2,3,3,4,8{]}

Complexity:

\begin{itemize}
\item
  Time: (O(n + k))- Space: (O(k))- Stable: Yes When to use:
\item
  Input is integers- Range (k) not much larger than (n)
\end{itemize}

\subsubsection{2. Radix Sort}\label{radix-sort}

Idea: Sort digits one at a time, from least significant (LSD) or most
significant (MSD), using a stable sub-sort like counting sort.

Radix sort works best when all elements have fixed-length
representations (e.g., integers, strings of equal length).

Steps (LSD method):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each digit position (from rightmost to leftmost)
\item
  Sort all elements by that digit using a stable sort (like counting
  sort)
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ get\_max}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ mx }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ mx}\OperatorTok{)}\NormalTok{ mx }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ mx}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ counting\_sort\_digit}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ exp}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ output}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ count}\OperatorTok{[}\DecValTok{10}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        count}\OperatorTok{[(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/}\NormalTok{ exp}\OperatorTok{)} \OperatorTok{\%} \DecValTok{10}\OperatorTok{]++;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{10}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        count}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ count}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ digit }\OperatorTok{=} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/}\NormalTok{ exp}\OperatorTok{)} \OperatorTok{\%} \DecValTok{10}\OperatorTok{;}
\NormalTok{        output}\OperatorTok{[}\NormalTok{count}\OperatorTok{[}\NormalTok{digit}\OperatorTok{]} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        count}\OperatorTok{[}\NormalTok{digit}\OperatorTok{]{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ output}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ radix\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=}\NormalTok{ get\_max}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ exp }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ m }\OperatorTok{/}\NormalTok{ exp }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ exp }\OperatorTok{*=} \DecValTok{10}\OperatorTok{)}
\NormalTok{        counting\_sort\_digit}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ exp}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}170, 45, 75, 90, 802, 24, 2, 66{]} → sort by 1s → 10s
→ 100s → final = {[}2, 24, 45, 66, 75, 90, 170, 802{]}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O(d \times (n + b))), where

  \begin{itemize}
  \tightlist
  \item
    (d): number of digits - (b): base (10 for decimal)- Space: (O(n +
    b))- Stable: Yes When to use:
  \end{itemize}
\item
  Fixed-length numbers- Bounded digits (e.g., base 10 or 2)
\end{itemize}

\subsubsection{3. Bucket Sort}\label{bucket-sort}

Idea: Divide elements into buckets based on value ranges, sort each
bucket individually, then concatenate.

Works best when data is uniformly distributed in a known interval.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create (k) buckets for value ranges
\item
  Distribute elements into buckets
\item
  Sort each bucket (often using insertion sort)
\item
  Merge buckets
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bucket\_sort}\OperatorTok{(}\DataTypeTok{float}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{float}\OperatorTok{\textgreater{}}\NormalTok{ buckets}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ n }\OperatorTok{*}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];} \CommentTok{// assuming 0 \textless{}= arr[i] \textless{} 1}
\NormalTok{        buckets}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        sort}\OperatorTok{(}\NormalTok{buckets}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ buckets}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{end}\OperatorTok{());}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{float}\NormalTok{ val }\OperatorTok{:}\NormalTok{ buckets}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{idx}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ val}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\item
  Average: (O(n + k))- Worst: (O\(n^2\)) (if all fall in one bucket)-
  Space: (O(n + k))- Stable: Depends on bucket sort method When to use:
\item
  Real numbers uniformly distributed in ({[}0,1))
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1688}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1558}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0779}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2338}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2597}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Counting Sort & O(n + k) & O(k) & Yes & Non-comparison & Small integer
range \\
Radix Sort & O(d(n + b)) & O(n + b) & Yes & Non-comparison &
Fixed-length numbers \\
Bucket Sort & O(n + k) avg & O(n + k) & Often & Distribution-based &
Uniform floats \\
\end{longtable}

These algorithms achieve O(n) behavior when assumptions hold , they're
specialized but incredibly fast when applicable.

\subsubsection{Tiny Code}\label{tiny-code-12}

Let's walk counting sort on
\texttt{arr\ =\ {[}4,\ 2,\ 2,\ 8,\ 3,\ 3,\ 1{]}}:

\begin{itemize}
\tightlist
\item
  Count occurrences → {[}1,2,2,1,0,0,0,1{]}- Cumulative count →
  positions- Place elements → {[}1,2,2,3,3,4,8{]} Sorted , no
  comparisons.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-12}

Distribution sorts teach a key insight:

\begin{quote}
If you know the structure of your data, you can sort faster than
comparison allows.
\end{quote}

They show how data properties , range, distribution, digit length , can
drive algorithm design.

You'll meet these ideas again in:

\begin{itemize}
\tightlist
\item
  Hashing (bucketing)- Indexing (range partitioning)- Machine learning
  (binning, histogramming)
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-12}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement counting sort for integers from 0 to 100.
\item
  Extend radix sort to sort strings by character.
\item
  Visualize bucket sort for values between 0 and 1.
\item
  What happens if you use counting sort on negative numbers? Fix it.
\item
  Compare counting vs quick sort on small integer arrays.
\end{enumerate}

These are the first glimpses of linear-time sorting , harnessing
knowledge about data to break the (O\(n \log n\)) barrier.

\subsection{14. Hybrid Sorts (IntroSort,
Timsort)}\label{hybrid-sorts-introsort-timsort}

In practice, no single sorting algorithm is perfect for all cases. Some
are fast on average but fail in worst cases (like Quick Sort). Others
are consistent but slow due to overhead (like Merge Sort). Hybrid
sorting algorithms combine multiple techniques to get the \emph{best of
all worlds} , practical speed, stability, and guaranteed performance.

Two of the most widely used hybrids in modern systems are IntroSort and
Timsort , both power the sorting functions in major programming
languages.

\subsubsection{1. The Idea Behind Hybrid
Sorting}\label{the-idea-behind-hybrid-sorting}

Real-world data is messy: sometimes nearly sorted, sometimes random,
sometimes pathological. A smart sorting algorithm should adapt to the
data.

Hybrids switch between different strategies based on:

\begin{itemize}
\tightlist
\item
  Input size- Recursion depth- Degree of order- Performance thresholds
  So, the algorithm ``introspects'' or ``adapts'' while running.
\end{itemize}

\subsubsection{2. IntroSort}\label{introsort}

IntroSort (short for \emph{introspective sort}) begins like Quick Sort,
but when recursion gets too deep , which means Quick Sort's worst case
may be coming , it switches to Heap Sort to guarantee (O\(n \log n\))
time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Quick Sort as long as recursion depth \textless{} \(2 \log n\)
\item
  If depth exceeds limit → switch to Heap Sort
\item
  For very small subarrays → switch to Insertion Sort
\end{enumerate}

This triple combo ensures:

\begin{itemize}
\tightlist
\item
  Fast average case (Quick Sort)- Guaranteed upper bound (Heap Sort)-
  Efficiency on small arrays (Insertion Sort) Code Sketch:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ intro\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ depth\_limit }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ log}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    intro\_sort\_util}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ depth\_limit}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ intro\_sort\_util}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ begin}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ end}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ depth\_limit}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ size }\OperatorTok{=}\NormalTok{ end }\OperatorTok{{-}}\NormalTok{ begin }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{size }\OperatorTok{\textless{}} \DecValTok{16}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ size}\OperatorTok{);}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{depth\_limit }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        heap\_sort\_range}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ end}\OperatorTok{);}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ end}\OperatorTok{);}
\NormalTok{    intro\_sort\_util}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ begin}\OperatorTok{,}\NormalTok{ pivot }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ depth\_limit }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\NormalTok{    intro\_sort\_util}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pivot }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ end}\OperatorTok{,}\NormalTok{ depth\_limit }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\item
  Average: (O\(n \log n\))- Worst: (O\(n \log n\))- Space:
  (O\(\log n\))- Stable: No (depends on partition scheme) Used in:
\item
  C++ STL's \texttt{std::sort}- Many systems where performance
  guarantees matter
\end{itemize}

\subsubsection{3. Timsort}\label{timsort}

Timsort is a stable hybrid combining Insertion Sort and Merge Sort. It
was designed to handle real-world data, which often has runs (already
sorted segments).

Developed by Tim Peters (Python core dev), Timsort is now used in:

\begin{itemize}
\item
  Python's \texttt{sorted()} and \texttt{.sort()}- Java's
  \texttt{Arrays.sort()} for objects Idea:
\item
  Identify runs , segments already ascending or descending- Reverse
  descending runs (to make them ascending)- Sort small runs with
  Insertion Sort- Merge runs with Merge Sort Timsort adapts beautifully
  to partially ordered data.
\end{itemize}

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Scan array, detect runs (sequences already sorted)
\item
  Push runs to a stack
\item
  Merge runs using a carefully balanced merge strategy
\end{enumerate}

Pseudocode (simplified):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ timsort(arr):}
\NormalTok{    RUN }\OperatorTok{=} \DecValTok{32}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}

    \CommentTok{\# Step 1: sort small chunks}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, n, RUN):}
\NormalTok{        insertion\_sort(arr, i, }\BuiltInTok{min}\NormalTok{((i }\OperatorTok{+}\NormalTok{ RUN }\OperatorTok{{-}} \DecValTok{1}\NormalTok{), n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{))}

    \CommentTok{\# Step 2: merge sorted runs}
\NormalTok{    size }\OperatorTok{=}\NormalTok{ RUN}
    \ControlFlowTok{while}\NormalTok{ size }\OperatorTok{\textless{}}\NormalTok{ n:}
        \ControlFlowTok{for}\NormalTok{ start }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, n, size }\OperatorTok{*} \DecValTok{2}\NormalTok{):}
\NormalTok{            mid }\OperatorTok{=}\NormalTok{ start }\OperatorTok{+}\NormalTok{ size }\OperatorTok{{-}} \DecValTok{1}
\NormalTok{            end }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(start }\OperatorTok{+}\NormalTok{ size }\OperatorTok{*} \DecValTok{2} \OperatorTok{{-}} \DecValTok{1}\NormalTok{, n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
\NormalTok{            merge(arr, start, mid, end)}
\NormalTok{        size }\OperatorTok{*=} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\item
  Best: (O(n)) (already sorted data)- Average: (O\(n \log n\))- Worst:
  (O\(n \log n\))- Space: (O(n))- Stable: Yes Key Strengths:
\item
  Excellent for real-world, partially sorted data- Stable (keeps equal
  keys in order)- Optimized merges (adaptive merging)
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1071}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1071}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1190}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Base Methods
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stability
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Real Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
IntroSort & Quick + Heap + Insertion & No & O(n log n) & O(n log n) &
O(n log n) & C++ STL \\
Timsort & Merge + Insertion & Yes & O(n) & O(n log n) & O(n log n) &
Python, Java \\
\end{longtable}

IntroSort prioritizes performance guarantees. Timsort prioritizes
adaptivity and stability.

Both show that ``one size fits all'' sorting doesn't exist , great
systems detect \emph{what's going on} and adapt.

\subsubsection{Tiny Code}\label{tiny-code-13}

Suppose we run Timsort on \texttt{{[}1,\ 2,\ 3,\ 7,\ 6,\ 5,\ 8,\ 9{]}}:

\begin{itemize}
\tightlist
\item
  Detect runs: \texttt{{[}1,2,3{]}}, \texttt{{[}7,6,5{]}},
  \texttt{{[}8,9{]}}- Reverse \texttt{{[}7,6,5{]}} →
  \texttt{{[}5,6,7{]}}- Merge runs → \texttt{{[}1,2,3,5,6,7,8,9{]}}
  Efficient because it leverages the existing order.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-13}

Hybrid sorts are the real-world heroes , they combine theory with
practice. They teach an important principle:

\begin{quote}
When one algorithm's weakness shows up, switch to another's strength.
\end{quote}

These are not academic curiosities , they're in your compiler, your
browser, your OS, your database. Understanding them means you understand
how modern languages optimize fundamental operations.

\subsubsection{Try It Yourself}\label{try-it-yourself-13}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement IntroSort and test on random, sorted, and reverse-sorted
  arrays.
\item
  Simulate Timsort's run detection on nearly sorted input.
\item
  Compare sorting speed of Insertion Sort vs Timsort for small arrays.
\item
  Add counters to Quick Sort and see when IntroSort should switch.
\item
  Explore Python's \texttt{sorted()} with different input shapes , guess
  when it uses merge vs insertion.
\end{enumerate}

Hybrid sorts remind us: good algorithms adapt , they're not rigid,
they're smart.

\subsection{15. Special Sorts (Cycle, Gnome, Comb,
Pancake)}\label{special-sorts-cycle-gnome-comb-pancake}

Not all sorting algorithms follow the mainstream divide-and-conquer or
distribution paradigms. Some were designed to solve niche problems, to
illustrate elegant ideas, or simply to experiment with different
mechanisms of ordering.

These special sorts, Cycle Sort, Gnome Sort, Comb Sort, and Pancake
Sort, are fascinating not because they're the fastest, but because they
reveal creative ways to think about permutation, local order, and
in-place operations.

\subsubsection{1. Cycle Sort}\label{cycle-sort}

Idea: Minimize the number of writes. Cycle sort rearranges elements into
cycles, placing each value directly in its correct position. It performs
exactly as many writes as there are misplaced elements, making it ideal
for flash memory or systems where writes are expensive.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each position \texttt{i}, find where \texttt{arr{[}i{]}} belongs
  (its rank).
\item
  If it's not already there, swap it into position.
\item
  Continue the cycle until the current position is correct.
\item
  Move to the next index.
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ cycle\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ cycle\_start }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ cycle\_start }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ cycle\_start}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ item }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{cycle\_start}\OperatorTok{];}
        \DataTypeTok{int}\NormalTok{ pos }\OperatorTok{=}\NormalTok{ cycle\_start}\OperatorTok{;}

        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ cycle\_start }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ item}\OperatorTok{)}\NormalTok{ pos}\OperatorTok{++;}

        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{==}\NormalTok{ cycle\_start}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}

        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{item }\OperatorTok{==}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{])}\NormalTok{ pos}\OperatorTok{++;}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{=}\NormalTok{ item}\OperatorTok{;}
\NormalTok{        item }\OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}

        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{pos }\OperatorTok{!=}\NormalTok{ cycle\_start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            pos }\OperatorTok{=}\NormalTok{ cycle\_start}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ cycle\_start }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ item}\OperatorTok{)}\NormalTok{ pos}\OperatorTok{++;}
            \ControlFlowTok{while} \OperatorTok{(}\NormalTok{item }\OperatorTok{==}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{])}\NormalTok{ pos}\OperatorTok{++;}
\NormalTok{            temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{];}
\NormalTok{            arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{=}\NormalTok{ item}\OperatorTok{;}
\NormalTok{            item }\OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n^2\))- Writes: minimal (exactly n-c, where c = \#cycles)-
  Stable: No Use Case: When minimizing writes is more important than
  runtime.
\end{itemize}

\subsubsection{2. Gnome Sort}\label{gnome-sort}

Idea: A simpler variation of insertion sort. Gnome sort moves back and
forth like a ``gnome'' tidying flower pots: if two adjacent pots are out
of order, swap and step back; otherwise, move forward.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start at index 1
\item
  If \texttt{arr{[}i{]}\ \textgreater{}=\ arr{[}i-1{]}}, move forward
\item
  Else, swap and step back (if possible)
\item
  Repeat until the end
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ gnome\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{])}\NormalTok{ i}\OperatorTok{++;}
        \ControlFlowTok{else} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{            i}\OperatorTok{{-}{-};}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n^2\))- Space: (O(1))- Stable: Yes Use Case: Educational
  simplicity. It's a readable form of insertion logic without nested
  loops.
\end{itemize}

\subsubsection{3. Comb Sort}\label{comb-sort}

Idea: An improvement over Bubble Sort by introducing a gap between
compared elements, shrinking it gradually. By jumping farther apart
early, Comb Sort helps eliminate small elements that are ``stuck'' near
the end.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with gap = n
\item
  On each pass, shrink gap = gap / 1.3
\item
  Compare and swap items \texttt{gap} apart
\item
  Stop when gap = 1 and no swaps occur
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ comb\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ gap }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ swapped }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{gap }\OperatorTok{\textgreater{}} \DecValTok{1} \OperatorTok{||}\NormalTok{ swapped}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        gap }\OperatorTok{=} \OperatorTok{(}\NormalTok{gap }\OperatorTok{*} \DecValTok{10}\OperatorTok{)} \OperatorTok{/} \DecValTok{13}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{gap }\OperatorTok{==} \DecValTok{9} \OperatorTok{||}\NormalTok{ gap }\OperatorTok{==} \DecValTok{10}\OperatorTok{)}\NormalTok{ gap }\OperatorTok{=} \DecValTok{11}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{gap }\OperatorTok{\textless{}} \DecValTok{1}\OperatorTok{)}\NormalTok{ gap }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{        swapped }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ gap }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ gap}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ gap}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ gap}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{                swapped }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Average: (O\(n \log n\))- Worst: (O\(n^2\))- Space: (O(1))- Stable: No
  Use Case: When a simple, in-place, nearly linear-time alternative to
  bubble sort is desired.
\end{itemize}

\subsubsection{4. Pancake Sort}\label{pancake-sort}

Idea: Sort an array using only one operation: flip (reversing a prefix).
It's like sorting pancakes on a plate, flip the stack so the largest
pancake goes to the bottom, then repeat for the rest.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the maximum unsorted element
\item
  Flip it to the front
\item
  Flip it again to its correct position
\item
  Reduce the unsorted portion by one
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ flip}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ start }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{start }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{start}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{        start}\OperatorTok{++;}
\NormalTok{        i}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ pancake\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ curr\_size }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ curr\_size }\OperatorTok{\textgreater{}} \DecValTok{1}\OperatorTok{;}\NormalTok{ curr\_size}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mi }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ curr\_size}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{mi}\OperatorTok{])}\NormalTok{ mi }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mi }\OperatorTok{!=}\NormalTok{ curr\_size }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            flip}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mi}\OperatorTok{);}
\NormalTok{            flip}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ curr\_size }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(n^2\))- Space: (O(1))- Stable: No Fun Fact: Pancake sort is
  the only known algorithm whose operations mimic a kitchen utensil, and
  inspired the Burnt Pancake Problem in combinatorics and genome
  rearrangement theory.
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2090}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0746}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0896}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.4478}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Distinctive Trait
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Cycle Sort & O(n²) & O(1) & No & Minimal writes \\
Gnome Sort & O(n²) & O(1) & Yes & Simple insertion-like behavior \\
Comb Sort & O(n log n) avg & O(1) & No & Shrinking gap, improved
bubble \\
Pancake Sort & O(n²) & O(1) & No & Prefix reversals only \\
\end{longtable}

Each highlights a different design goal:

\begin{itemize}
\tightlist
\item
  Cycle: minimize writes- Gnome: simplify logic- Comb: optimize
  comparisons- Pancake: restrict operations
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-14}

Example (Pancake Sort on \texttt{{[}3,\ 6,\ 1,\ 9{]}}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Max = 9 at index 3 → flip(3) → \texttt{{[}9,1,6,3{]}}
\item
  flip(3) → \texttt{{[}3,6,1,9{]}} (9 fixed)
\item
  Max = 6 → flip(1) → \texttt{{[}6,3,1,9{]}}
\item
  flip(2) → \texttt{{[}1,3,6,9{]}}
\end{enumerate}

Sorted using only flips.

\subsubsection{Why It Matters}\label{why-it-matters-14}

Special sorts show there's more than one way to think about ordering.
They're laboratories for exploring new ideas: minimizing swaps, limiting
operations, or optimizing stability. Even if they're not the go-to in
production, they deepen your intuition about sorting mechanics.

\subsubsection{Try It Yourself}\label{try-it-yourself-14}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement each algorithm and visualize their operations step-by-step.
\item
  Measure how many writes Cycle Sort performs vs.~others.
\item
  Compare Gnome and Insertion sort on nearly sorted arrays.
\item
  Modify Comb Sort's shrink factor, how does performance change?
\item
  Write Pancake Sort with printouts of every flip to see the ``stack''
  in motion.
\end{enumerate}

These quirky algorithms prove that sorting isn't just science, it's also
art and experimentation.

\subsection{16. Linear and Binary
Search}\label{linear-and-binary-search}

Searching is the process of finding a target value within a collection
of data. Depending on whether the data is sorted or unsorted, you'll use
different strategies.

In this section, we revisit two of the most fundamental searching
methods , Linear Search and Binary Search , and see how they underpin
many higher-level algorithms and data structures.

\subsubsection{1. Linear Search}\label{linear-search-2}

Idea: Check each element one by one until you find the target. This is
the simplest possible search and works on unsorted data.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start from index 0
\item
  Compare \texttt{arr{[}i{]}} with the target
\item
  If match, return index
\item
  If end reached, return -1
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ linear\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}7, 2, 4, 9, 1{]}, key = 9

\begin{itemize}
\item
  Compare 7, 2, 4, then 9 → found at index 3 Complexity:
\item
  Time: ( O(n) )- Space: ( O(1) )- Best case: ( O(1) ) (first element)-
  Worst case: ( O(n) ) Pros:
\item
  Works on any data (sorted or unsorted)- Simple to implement Cons:
\item
  Inefficient on large arrays Use it when data is small or unsorted, or
  when simplicity matters more than speed.
\end{itemize}

\subsubsection{2. Binary Search}\label{binary-search-2}

Idea: If the array is sorted, you can repeatedly halve the search space.
Compare the middle element to the target , if it's greater, search left;
if smaller, search right.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the midpoint
\item
  If \texttt{arr{[}mid{]}\ ==\ key}, done
\item
  If \texttt{arr{[}mid{]}\ \textgreater{}\ key}, search left
\item
  If \texttt{arr{[}mid{]}\ \textless{}\ key}, search right
\item
  Repeat until range is empty
\end{enumerate}

Iterative Version:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Recursive Version:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textgreater{}}\NormalTok{ high}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else}
        \ControlFlowTok{return}\NormalTok{ binary\_search\_rec}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}1, 3, 5, 7, 9, 11{]}, key = 7

\begin{itemize}
\item
  mid = 5 → key \textgreater{} mid → move right- mid = 7 → found
  Complexity:
\item
  Time: ( O\(\log n\) )- Space: ( O(1) ) (iterative) or ( O\(\log n\) )
  (recursive)- Best case: ( O(1) ) (middle element) Requirements:
\item
  Must be sorted- Must have random access (array, not linked list) Pros:
\item
  Very fast for large sorted arrays- Foundation for advanced searches
  (e.g.~interpolation, exponential) Cons:
\item
  Needs sorted data- Doesn't adapt to frequent insertions/deletions
\end{itemize}

\subsubsection{3. Binary Search
Variants}\label{binary-search-variants-1}

Binary search is a \emph{pattern} as much as a single algorithm. You can
tweak it to find:

\begin{itemize}
\tightlist
\item
  First occurrence: move left if \texttt{arr{[}mid{]}\ ==\ key}- Last
  occurrence: move right if \texttt{arr{[}mid{]}\ ==\ key}- Lower bound:
  first index ≥ key- Upper bound: first index \textgreater{} key Example
  (Lower Bound):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lower\_bound}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ low}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Usage: These variants power functions like \texttt{std::lower\_bound()}
in C++ and binary search trees' lookup logic.

\subsubsection{4. Comparison}\label{comparison-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1688}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1039}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0649}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2338}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3247}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Works On
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sorted Data Needed
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & Any & O(n) & O(1) & No & Best for small/unsorted \\
Binary Search & Sorted & O(log n) & O(1) & Yes & Fastest on ordered
arrays \\
\end{longtable}

Binary search trades simplicity for power , once your data is sorted,
you unlock sublinear search.

\subsubsection{Tiny Code}\label{tiny-code-15}

Compare on array \texttt{{[}2,\ 4,\ 6,\ 8,\ 10{]}}, key = 8:

\begin{itemize}
\tightlist
\item
  Linear: 4 steps- Binary: 2 steps This gap grows huge with size , for
  \(n = 10^6\), linear takes up to a million steps, binary about 20.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-15}

These two searches form the foundation of retrieval. Linear search shows
brute-force iteration; binary search shows how structure (sorted order)
leads to exponential improvement.

From databases to compiler symbol tables to tree lookups, this principle
, \emph{divide to search faster} , is everywhere.

\subsubsection{Try It Yourself}\label{try-it-yourself-15}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement linear and binary search.
\item
  Count comparisons for ( n = 10, 100, 1000 ).
\item
  Modify binary search to return the first occurrence of a duplicate.
\item
  Try binary search on unsorted data , what happens?
\item
  Combine with sorting: sort array, then search.
\end{enumerate}

Mastering these searches builds intuition for all lookup operations ,
they are the gateway to efficient data retrieval.

\subsection{17. Interpolation and Exponential
Search}\label{interpolation-and-exponential-search}

Linear and binary search work well across many scenarios, but they don't
take into account how data is distributed. When values are uniformly
distributed, we can \emph{estimate} where the target lies, instead of
always splitting the range in half. This leads to Interpolation Search,
which ``jumps'' close to where the value should be.

For unbounded or infinite lists, we can't even know the size of the
array up front , that's where Exponential Search shines, by quickly
expanding its search window before switching to binary search.

Let's dive into both.

\subsubsection{1. Interpolation Search}\label{interpolation-search}

Idea: If data is sorted and uniformly distributed, you can
\emph{predict} where a key might be using linear interpolation. Instead
of splitting at the middle, estimate the position based on the value's
proportion in the range.

Formula: \[
\text{pos} = \text{low} + \frac{(key - arr[low]) \times (high - low)}{arr[high] - arr[low]}
\]

This ``guesses'' where the key lies. If (key = arr{[}pos{]}), we're
done. Otherwise, adjust \texttt{low} or \texttt{high} and repeat.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute estimated position \texttt{pos}
\item
  Compare \texttt{arr{[}pos{]}} with \texttt{key}
\item
  Narrow range accordingly
\item
  Repeat while \texttt{low\ \textless{}=\ high} and \texttt{key} within
  range
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ interpolation\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ high }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high }\OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textgreater{}=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textless{}=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{==}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ low}\OperatorTok{;}
            \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ pos }\OperatorTok{=}\NormalTok{ low }\OperatorTok{+} \OperatorTok{((}\DataTypeTok{double}\OperatorTok{)(}\NormalTok{key }\OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{])} \OperatorTok{*} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low}\OperatorTok{))} \OperatorTok{/} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{]);}

        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)}
            \ControlFlowTok{return}\NormalTok{ pos}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{            low }\OperatorTok{=}\NormalTok{ pos }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}
\NormalTok{            high }\OperatorTok{=}\NormalTok{ pos }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}10, 20, 30, 40, 50{]}, key = 40 pos = 0 + ((40 - 10) *
(4 - 0)) / (50 - 10) = 3 → found at index 3

Complexity:

\begin{itemize}
\item
  Best: (O(1))- Average: (O\(\log \log n\)) (uniform data)- Worst:
  (O(n)) (non-uniform or skewed data)- Space: (O(1)) When to Use:
\item
  Data is sorted and nearly uniform- Numeric data where values grow
  steadily Note: Interpolation search is adaptive , faster when data is
  predictable, slower when data is irregular.
\end{itemize}

\subsubsection{2. Exponential Search}\label{exponential-search-1}

Idea: When you don't know the array size (e.g., infinite streams, linked
data, files), you can't just binary search from 0 to n-1. Exponential
search finds a search range dynamically by doubling its step size until
it overshoots the target, then does binary search within that range.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If \texttt{arr{[}0{]}\ ==\ key}, return 0
\item
  Find a range \texttt{{[}bound/2,\ bound{]}} such that
  \texttt{arr{[}bound{]}\ \textgreater{}=\ key}
\item
  Perform binary search in that range
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ exponential\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ bound }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{bound }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{bound}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{        bound }\OperatorTok{*=} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ low }\OperatorTok{=}\NormalTok{ bound }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ high }\OperatorTok{=} \OperatorTok{(}\NormalTok{bound }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{?}\NormalTok{ bound }\OperatorTok{:}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \CommentTok{// Binary search in [low, high]}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ mid}\OperatorTok{;}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}\NormalTok{ low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}2, 4, 6, 8, 10, 12, 14, 16{]}, key = 10

\begin{itemize}
\item
  Step: bound = 1 (4), 2 (6), 4 (10 ≥ key)- Binary search {[}2,4{]} →
  found Complexity:
\item
  Time: (O\(\log i\)), where (i) is index of the target- Space: (O(1))-
  Best: (O(1)) When to Use:
\item
  Unbounded or streamed data- Unknown array size but sorted order
\end{itemize}

\subsubsection{3. Comparison}\label{comparison-5}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2376}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0891}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1188}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0990}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1584}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2970}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Requirement
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & O(1) & O(n) & O(n) & Unsorted & Works everywhere \\
Binary Search & O(1) & O(log n) & O(log n) & Sorted & Predictable
halving \\
Interpolation Search & O(1) & O(log log n) & O(n) & Sorted + Uniform &
Adaptive, fast on uniform data \\
Exponential Search & O(1) & O(log n) & O(log n) & Sorted & Great for
unknown size \\
\end{longtable}

Interpolation improves on binary \emph{if} data is smooth. Exponential
shines when size is unknown.

\subsubsection{Tiny Code}\label{tiny-code-16}

Interpolation intuition: If your data is evenly spaced (10, 20, 30, 40,
50), the value 40 should be roughly 75\% along. Instead of halving every
time, we jump \emph{right near it}. It's data-aware searching.

Exponential intuition: When size is unknown, ``expand until you find the
wall,'' then search within.

\subsubsection{Why It Matters}\label{why-it-matters-16}

These two searches show how context shapes algorithm design:

\begin{itemize}
\tightlist
\item
  \emph{Distribution} (Interpolation Search)- \emph{Boundaries}
  (Exponential Search) They teach that performance depends not only on
  structure (sortedness) but also metadata , how much you know about
  data spacing or limits.
\end{itemize}

These principles resurface in skip lists, search trees, and
probabilistic indexing.

\subsubsection{Try It Yourself}\label{try-it-yourself-16}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Test interpolation search on {[}10, 20, 30, 40, 50{]} , note how few
  steps it takes.
\item
  Try the same on {[}1, 2, 4, 8, 16, 32, 64{]} , note slowdown.
\item
  Implement exponential search and simulate an ``infinite'' array by
  stopping at \texttt{n}.
\item
  Compare binary vs interpolation search on random vs uniform data.
\item
  Extend exponential search to linked lists , how does complexity
  change?
\end{enumerate}

Understanding these searches helps you tailor lookups to the shape of
your data , a key skill in algorithmic thinking.

\subsection{18. Selection Algorithms (Quickselect, Median of
Medians)}\label{selection-algorithms-quickselect-median-of-medians}

Sometimes you don't need to sort an entire array , you just want the
k-th smallest (or largest) element. Sorting everything is overkill when
you only need one specific rank. Selection algorithms solve this problem
efficiently, often in linear time.

They're the backbone of algorithms for median finding, percentiles, and
order statistics, and they underpin operations like \emph{pivot
selection} in Quick Sort.

\subsubsection{1. The Selection Problem}\label{the-selection-problem}

Given an unsorted array of ( n ) elements and a number ( k ), find the
element that would be at position ( k ) if the array were sorted.

For example: arr = {[}7, 2, 9, 4, 6{]}, (k = 3) → Sorted = {[}2, 4, 6,
7, 9{]} → 3rd smallest = 6

We can solve this without sorting everything.

\subsubsection{2. Quickselect}\label{quickselect}

Idea: Quickselect is a selection variant of Quick Sort. It partitions
the array around a pivot, but recurses only on the side that contains
the k-th element.

It has average-case O(n) time because each partition roughly halves the
search space.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose a pivot (random or last element)
\item
  Partition array into elements \textless{} pivot and \textgreater{}
  pivot
\item
  Let \texttt{pos} be the pivot's index after partition
\item
  If \texttt{pos\ ==\ k-1} → done
\item
  If \texttt{pos\ \textgreater{}\ k-1} → recurse left
\item
  If \texttt{pos\ \textless{}\ k-1} → recurse right
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ pivot}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
\NormalTok{            i}\OperatorTok{++;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ temp }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{];}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]} \OperatorTok{=}\NormalTok{ temp}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ quickselect}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ k}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{==}\NormalTok{ high}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ pos }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ rank }\OperatorTok{=}\NormalTok{ pos }\OperatorTok{{-}}\NormalTok{ low }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank }\OperatorTok{==}\NormalTok{ k}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ arr}\OperatorTok{[}\NormalTok{pos}\OperatorTok{];}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank }\OperatorTok{\textgreater{}}\NormalTok{ k}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ quickselect}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ pos }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ k}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ quickselect}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pos }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ k }\OperatorTok{{-}}\NormalTok{ rank}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}7, 2, 9, 4, 6{]}, ( k = 3 )

\begin{itemize}
\item
  Pivot = 6- Partition → {[}2, 4, 6, 9, 7{]}, pos = 2- rank = 3 → found
  (6) Complexity:
\item
  Average: (O(n))- Worst: (O\(n^2\)) (bad pivots)- Space: (O(1))-
  In-place When to Use:
\item
  Fast average case- You don't need full sorting Quickselect is used in
  C++'s \texttt{nth\_element()} and many median-finding implementations.
\end{itemize}

\subsubsection{3. Median of Medians}\label{median-of-medians}

Idea: Guarantee worst-case ( O(n) ) time by choosing a good pivot
deterministically.

This method ensures the pivot divides the array into reasonably balanced
parts every time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide array into groups of 5
\item
  Find the median of each group (using insertion sort)
\item
  Recursively find the median of these medians → pivot
\item
  Partition array around this pivot
\item
  Recurse into the side containing the k-th element
\end{enumerate}

This guarantees at least 30\% of elements are eliminated each step →
linear time in worst case.

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ select\_pivot}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ high }\OperatorTok{{-}}\NormalTok{ low }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{5}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ low}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
        \ControlFlowTok{return}\NormalTok{ low }\OperatorTok{+}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \OperatorTok{\}}

    \DataTypeTok{int}\NormalTok{ medians}\OperatorTok{[(}\NormalTok{n }\OperatorTok{+} \DecValTok{4}\OperatorTok{)} \OperatorTok{/} \DecValTok{5}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ i}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{/} \DecValTok{5}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5}\OperatorTok{,} \DecValTok{5}\OperatorTok{);}
\NormalTok{        medians}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5} \OperatorTok{+} \DecValTok{2}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{*} \DecValTok{5} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        insertion\_sort}\OperatorTok{(}\NormalTok{arr }\OperatorTok{+}\NormalTok{ low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5}\OperatorTok{,}\NormalTok{ n }\OperatorTok{\%} \DecValTok{5}\OperatorTok{);}
\NormalTok{        medians}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{low }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*} \DecValTok{5} \OperatorTok{+} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%} \DecValTok{5}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{];}
\NormalTok{        i}\OperatorTok{++;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ select\_pivot}\OperatorTok{(}\NormalTok{medians}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

You'd then partition around \texttt{pivot} and recurse just like
Quickselect.

Complexity:

\begin{itemize}
\tightlist
\item
  Worst: (O(n))- Space: (O(1)) (in-place version)- Stable: No (doesn't
  preserve order) Why It Matters: Median of Medians is slower in
  practice than Quickselect but provides theoretical guarantees , vital
  in real-time or critical systems.
\end{itemize}

\subsubsection{4. Special Cases}\label{special-cases}

\begin{itemize}
\tightlist
\item
  Min / Max: trivial , just scan once ((O(n)))- Median:
  \(k = \lceil n/2 \rceil\) , can use Quickselect or Median of Medians-
  Top-k Elements: use partial selection or heaps (k smallest/largest)
  Example: To get top 5 scores from a million entries, use Quickselect
  to find 5th largest, then filter ≥ threshold.
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-6}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1910}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0787}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0899}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.3034}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
In-Place
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Quickselect & O(n) & O(n) & O(n²) & No & Yes & Fast in practice \\
Median of Medians & O(n) & O(n) & O(n) & No & Yes & Deterministic \\
Sorting & O(n log n) & O(n log n) & O(n log n) & Depends & Depends &
Overkill for single element \\
\end{longtable}

Quickselect is fast and simple; Median of Medians is safe and
predictable.

\subsubsection{Tiny Code}\label{tiny-code-17}

Find 4th smallest in {[}9, 7, 2, 5, 4, 3{]}:

\begin{itemize}
\tightlist
\item
  Pivot = 4 → partition {[}2,3,4,9,7,5{]}- 4 at position 2 → rank = 3
  \textless{} 4 → recurse right- New range {[}9,7,5{]}, ( k = 1 ) →
  smallest = 5 Result: 5
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-17}

Selection algorithms reveal a key insight:

\begin{quote}
Sometimes you don't need everything , just what matters.
\end{quote}

They form the basis for:

\begin{itemize}
\tightlist
\item
  Median filters in signal processing- Partitioning steps in sorting-
  k-th order statistics- Robust statistics and quantile computation They
  embody a ``partial work, full answer'' philosophy , do exactly enough.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-17}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Quickselect and find k-th smallest for various k.
\item
  Compare runtime vs full sorting.
\item
  Modify Quickselect to find k-th largest.
\item
  Implement Median of Medians pivot selection.
\item
  Use Quickselect to find median of 1,000 random elements.
\end{enumerate}

Mastering selection algorithms helps you reason about efficiency ,
you'll learn when to stop sorting and start selecting.

\subsection{19. Range Searching and Nearest
Neighbor}\label{range-searching-and-nearest-neighbor}

Searching isn't always about finding a single key. Often, you need to
find all elements within a given range , or the closest match to a query
point.

These problems are central to databases, computational geometry, and
machine learning (like k-NN classification). This section introduces
algorithms for range queries (e.g.~find all values between \texttt{L}
and \texttt{R}) and nearest neighbor searches (e.g.~find the point
closest to query \texttt{q}).

\subsubsection{1. Range Searching}\label{range-searching}

Idea: Given a set of data points (1D or multidimensional), quickly
report all points within a specified range.

In 1D (simple arrays), range queries can be handled by binary search and
prefix sums. In higher dimensions, we need trees designed for efficient
spatial querying.

\subsubsection{A. 1D Range Query (Sorted
Array)}\label{a.-1d-range-query-sorted-array}

Goal: Find all elements in \texttt{{[}L,\ R{]}}.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use lower bound to find first element ≥ L
\item
  Use upper bound to find first element \textgreater{} R
\item
  Output all elements in between
\end{enumerate}

Code (C++-style pseudo):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ l }\OperatorTok{=}\NormalTok{ lower\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,}\NormalTok{ L}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=}\NormalTok{ upper\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,}\NormalTok{ R}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Time Complexity:

\begin{itemize}
\tightlist
\item
  Binary search bounds: (O\(\log n\))- Reporting results: (O(k)) where
  (k) = number of elements in range → Total: (O\(\log n + k\))
\end{itemize}

\subsubsection{B. Prefix Sum Range Query (For
sums)}\label{b.-prefix-sum-range-query-for-sums}

If you just need the sum (not the actual elements), use prefix sums:

\[
\text{prefix}[i] = a_0 + a_1 + \ldots + a_i
\]

Then range sum: \[
\text{sum}(L, R) = \text{prefix}[R] - \text{prefix}[L - 1]
\]

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{prefix}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    prefix}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ range\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{R}\OperatorTok{]} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{L }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{?}\NormalTok{ prefix}\OperatorTok{[}\NormalTok{L }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{:} \DecValTok{0}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: (O(1)) per query after (O(n)) preprocessing.

Used in:

\begin{itemize}
\tightlist
\item
  Databases for fast range aggregation- Fenwick trees, segment trees
\end{itemize}

\subsubsection{C. 2D Range Queries (Rectangular
Regions)}\label{c.-2d-range-queries-rectangular-regions}

For points ((x, y)), queries like:

\begin{quote}
``Find all points where \(L_x ≤ x ≤ R_x\) and \(L_y ≤ y ≤ R_y\)''
\end{quote}

Use specialized structures:

\begin{itemize}
\tightlist
\item
  Range Trees (balanced BSTs per dimension)- Fenwick Trees / Segment
  Trees (for 2D arrays)- KD-Trees (spatial decomposition) Time:
  (O\(\log^2 n + k\)) typical for 2D Space: (O\(n \log n\))
\end{itemize}

\subsubsection{2. Nearest Neighbor
Search}\label{nearest-neighbor-search}

Idea: Given a set of points, find the one closest to query (q). Distance
is often Euclidean, but can be any metric.

Brute Force: Check all points → (O(n)) per query. Too slow for large
datasets.

We need structures that let us prune far regions fast.

\subsubsection{A. KD-Tree}\label{a.-kd-tree}

KD-tree = K-dimensional binary tree. Each level splits points by one
coordinate, alternating axes. Used for efficient nearest neighbor search
in low dimensions (2D-10D).

Construction:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose axis = depth \% k
\item
  Sort points by axis
\item
  Pick median → root
\item
  Recursively build left and right
\end{enumerate}

Query (Nearest Neighbor):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Traverse down tree based on query position
\item
  Backtrack , check whether hypersphere crosses splitting plane
\item
  Keep track of best (closest) distance
\end{enumerate}

Complexity:

\begin{itemize}
\item
  Build: (O\(n \log n\))- Query: (O\(\log n\)) avg, (O(n)) worst Use
  Cases:
\item
  Nearest city lookup- Image / feature vector matching- Game AI spatial
  queries Code Sketch (2D Example):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Point }\OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\};}

\DataTypeTok{double}\NormalTok{ dist}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ sqrt}\OperatorTok{((}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)*(}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{+} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{)*(}\NormalTok{a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

(Full KD-tree implementation omitted for brevity , idea is recursive
partitioning.)

\subsubsection{B. Ball Tree / VP-Tree}\label{b.-ball-tree-vp-tree}

For high-dimensional data, KD-trees degrade. Alternatives like Ball
Trees (split by hyperspheres) or VP-Trees (Vantage Point Trees) perform
better.

They split based on distance metrics, not coordinate axes.

\subsubsection{C. Approximate Nearest Neighbor
(ANN)}\label{c.-approximate-nearest-neighbor-ann}

For large-scale, high-dimensional data (e.g.~embeddings, vectors):

\begin{itemize}
\item
  Locality Sensitive Hashing (LSH)- HNSW (Hierarchical Navigable Small
  World Graphs) These trade exactness for speed, common in:
\item
  Vector databases- Recommendation systems- AI model retrieval
\end{itemize}

\subsubsection{3. Summary}\label{summary-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1358}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2099}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Brute Force
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimized
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time (Query)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1D Range Query & Scan O(n) & Binary Search & O(log n + k) & Sorted
data \\
Range Sum & O(n) & Prefix Sum & O(1) & Static data \\
2D Range Query & O(n) & Range Tree & O(log² n + k) & Spatial
filtering \\
Nearest Neighbor & O(n) & KD-Tree & O(log n) avg & Exact, low-dim \\
Nearest Neighbor (high-dim) & O(n) & HNSW / LSH & \textasciitilde O(1) &
Approximate \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-18}

Simple 1D range query:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{5}\OperatorTok{,} \DecValTok{7}\OperatorTok{,} \DecValTok{9}\OperatorTok{,} \DecValTok{11}\OperatorTok{\};}
\DataTypeTok{int}\NormalTok{ L }\OperatorTok{=} \DecValTok{4}\OperatorTok{,}\NormalTok{ R }\OperatorTok{=} \DecValTok{10}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ l }\OperatorTok{=}\NormalTok{ lower\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+} \DecValTok{6}\OperatorTok{,}\NormalTok{ L}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=}\NormalTok{ upper\_bound}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ arr }\OperatorTok{+} \DecValTok{6}\OperatorTok{,}\NormalTok{ R}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ arr}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);} \CommentTok{// 5 7 9}
\end{Highlighting}
\end{Shaded}

Output: \texttt{5\ 7\ 9}

\subsubsection{Why It Matters}\label{why-it-matters-18}

Range and nearest-neighbor queries power:

\begin{itemize}
\tightlist
\item
  Databases (SQL range filters, BETWEEN)- Search engines (spatial
  indexing)- ML (k-NN classifiers, vector similarity)- Graphics / Games
  (collision detection, spatial queries) These are not just searches ,
  they're geometric lookups, linking algorithms to spatial reasoning.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-18}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function to return all numbers in \texttt{{[}L,\ R{]}} using
  binary search.
\item
  Build a prefix sum array and answer 5 range-sum queries in O(1).
\item
  Implement a KD-tree for 2D points and query nearest neighbor.
\item
  Compare brute-force vs KD-tree search on 1,000 random points.
\item
  Explore Python's \texttt{scipy.spatial.KDTree} or
  \texttt{sklearn.neighbors}.
\end{enumerate}

These algorithms bridge searching with geometry and analytics, forming
the backbone of spatial computation.

\subsection{20. Search Optimizations and
Variants}\label{search-optimizations-and-variants}

We've explored the main search families , linear, binary, interpolation,
exponential , each fitting a different data shape or constraint. Now
let's move one step further: optimizing search for performance and
adapting it to specialized scenarios.

This section introduces practical variants and enhancements used in real
systems, databases, and competitive programming, including jump search,
fibonacci search, ternary search, and exponential + binary combinations.

\subsubsection{1. Jump Search}\label{jump-search}

Idea: If data is sorted, we can ``jump'' ahead by fixed steps instead of
scanning linearly. It's like hopping through the array in blocks , when
you overshoot the target, you step back and linearly search that block.

It strikes a balance between linear and binary search , fewer
comparisons without the recursion or halving of binary search.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose jump size = \(\sqrt{n}\)
\item
  Jump by blocks until \texttt{arr{[}step{]}\ \textgreater{}\ key}
\item
  Linear search in previous block
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ jump\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ step }\OperatorTok{=}\NormalTok{ sqrt}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ prev }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{min}\OperatorTok{(}\NormalTok{step}\OperatorTok{,}\NormalTok{ n}\OperatorTok{)} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        prev }\OperatorTok{=}\NormalTok{ step}\OperatorTok{;}
\NormalTok{        step }\OperatorTok{+=}\NormalTok{ sqrt}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{prev }\OperatorTok{\textgreater{}=}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ prev}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ min}\OperatorTok{(}\NormalTok{step}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: arr = {[}1, 3, 5, 7, 9, 11, 13, 15{]}, key = 11

\begin{itemize}
\item
  step = 2- Jump 5, 7, 9, 11 → found Complexity:
\item
  Time: (O\(\sqrt{n}\))- Space: (O(1))- Works on sorted data When to
  Use: For moderately sized sorted lists when you want fewer comparisons
  but minimal overhead.
\end{itemize}

\subsubsection{2. Fibonacci Search}\label{fibonacci-search}

Idea: Similar to binary search, but it splits the array based on
Fibonacci numbers instead of midpoints. This allows using only addition
and subtraction (no division), useful on hardware where division is
costly.

Also, like binary search, it halves (roughly) the search space each
iteration.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find the smallest Fibonacci number ≥ n
\item
  Use it to compute probe index
\item
  Compare and move interval accordingly
\end{enumerate}

Code (Sketch):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fibonacci\_search}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ fibMMm2 }\OperatorTok{=} \DecValTok{0}\OperatorTok{;} \CommentTok{// (m{-}2)\textquotesingle{}th Fibonacci}
    \DataTypeTok{int}\NormalTok{ fibMMm1 }\OperatorTok{=} \DecValTok{1}\OperatorTok{;} \CommentTok{// (m{-}1)\textquotesingle{}th Fibonacci}
    \DataTypeTok{int}\NormalTok{ fibM }\OperatorTok{=}\NormalTok{ fibMMm2 }\OperatorTok{+}\NormalTok{ fibMMm1}\OperatorTok{;} \CommentTok{// m\textquotesingle{}th Fibonacci}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{fibM }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        fibMMm2 }\OperatorTok{=}\NormalTok{ fibMMm1}\OperatorTok{;}
\NormalTok{        fibMMm1 }\OperatorTok{=}\NormalTok{ fibM}\OperatorTok{;}
\NormalTok{        fibM }\OperatorTok{=}\NormalTok{ fibMMm2 }\OperatorTok{+}\NormalTok{ fibMMm1}\OperatorTok{;}
    \OperatorTok{\}}

    \DataTypeTok{int}\NormalTok{ offset }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{fibM }\OperatorTok{\textgreater{}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{offset }\OperatorTok{+}\NormalTok{ fibMMm2}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            fibM }\OperatorTok{=}\NormalTok{ fibMMm1}\OperatorTok{;}
\NormalTok{            fibMMm1 }\OperatorTok{=}\NormalTok{ fibMMm2}\OperatorTok{;}
\NormalTok{            fibMMm2 }\OperatorTok{=}\NormalTok{ fibM }\OperatorTok{{-}}\NormalTok{ fibMMm1}\OperatorTok{;}
\NormalTok{            offset }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \OperatorTok{\}} \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            fibM }\OperatorTok{=}\NormalTok{ fibMMm2}\OperatorTok{;}
\NormalTok{            fibMMm1 }\OperatorTok{=}\NormalTok{ fibMMm1 }\OperatorTok{{-}}\NormalTok{ fibMMm2}\OperatorTok{;}
\NormalTok{            fibMMm2 }\OperatorTok{=}\NormalTok{ fibM }\OperatorTok{{-}}\NormalTok{ fibMMm1}\OperatorTok{;}
        \OperatorTok{\}} \ControlFlowTok{else} \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fibMMm1 }\OperatorTok{\&\&}\NormalTok{ arr}\OperatorTok{[}\NormalTok{offset }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ offset }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Time: (O\(\log n\))- Space: (O(1))- Sorted input required Fun Fact:
  Fibonacci search was originally designed for tape drives , where
  random access is expensive, and predictable jumps matter.
\end{itemize}

\subsubsection{3. Ternary Search}\label{ternary-search}

Idea: When the function or sequence is unimodal (strictly increasing
then decreasing), you can locate a maximum or minimum by splitting the
range into three parts instead of two.

Used not for discrete lookup but for optimization on sorted functions.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide range into thirds
\item
  Evaluate at two midpoints \texttt{m1}, \texttt{m2}
\item
  Eliminate one-third based on comparison
\item
  Repeat until range is small
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ ternary\_search}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ high}\OperatorTok{,} \DataTypeTok{double} \OperatorTok{(*}\NormalTok{f}\OperatorTok{)(}\DataTypeTok{double}\OperatorTok{))} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ m1 }\OperatorTok{=}\NormalTok{ low }\OperatorTok{+} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low}\OperatorTok{)} \OperatorTok{/} \DecValTok{3}\OperatorTok{;}
        \DataTypeTok{double}\NormalTok{ m2 }\OperatorTok{=}\NormalTok{ high }\OperatorTok{{-}} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low}\OperatorTok{)} \OperatorTok{/} \DecValTok{3}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{f}\OperatorTok{(}\NormalTok{m1}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ f}\OperatorTok{(}\NormalTok{m2}\OperatorTok{))}
\NormalTok{            low }\OperatorTok{=}\NormalTok{ m1}\OperatorTok{;}
        \ControlFlowTok{else}
\NormalTok{            high }\OperatorTok{=}\NormalTok{ m2}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{low }\OperatorTok{+}\NormalTok{ high}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: Find minimum of ( f(x) = (x-3)\^{}2 ) between {[}0,10{]}. After
iterations, converges to (x ≈ 3).

Complexity:

\begin{itemize}
\tightlist
\item
  Time: \(O(\log\text{range})\)
\item
  Space: \(O(1)\)
\item
  Works for unimodal functions
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Mathematical optimization
\item
  Search-based tuning
\item
  Game AI decision models
\end{itemize}

\subsubsection{4. Binary Search Variants
(Review)}\label{binary-search-variants-review}

Binary search can be tailored to answer richer queries:

\begin{itemize}
\tightlist
\item
  Lower Bound: first index ≥ key- Upper Bound: first index
  \textgreater{} key- Equal Range: range of all equal elements- Rotated
  Arrays: find element in rotated sorted array- Infinite Arrays: use
  exponential expansion Rotated Example: arr = {[}6,7,9,1,3,4{]}, key =
  3 → Find pivot, then binary search correct side.
\end{itemize}

\subsubsection{5. Combined Searches}\label{combined-searches}

Real systems often chain algorithms:

\begin{itemize}
\tightlist
\item
  Exponential + Binary Search → when bounds unknown- Interpolation +
  Linear Search → when near target- Jump + Linear Search → hybrid
  iteration These hybrids use context switching , pick a fast search,
  then fall back to simple scan in a narrowed window.
\end{itemize}

\subsubsection{6. Summary}\label{summary-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2537}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0746}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2388}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2537}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Data Requirement
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Special Strength
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Jump Search & O(√n) & O(1) & Sorted & Fewer comparisons \\
Fibonacci Search & O(log n) & O(1) & Sorted & Division-free \\
Ternary Search & O(log range) & O(1) & Unimodal & Optimization \\
Binary Variants & O(log n) & O(1) & Sorted & Bound finding \\
Combined Searches & Adaptive & O(1) & Mixed & Practical hybrids \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-19}

Jump Search intuition:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Blocks of size sqrt(n)}
\OperatorTok{[}\DecValTok{1}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{5}\OperatorTok{,} \DecValTok{7}\OperatorTok{,} \DecValTok{9}\OperatorTok{,} \DecValTok{11}\OperatorTok{,} \DecValTok{13}\OperatorTok{,} \DecValTok{15}\OperatorTok{]}
\NormalTok{Step}\OperatorTok{:} \DecValTok{3}\NormalTok{ → }\DecValTok{7} \OperatorTok{\textgreater{}} \DecValTok{6}\NormalTok{ → search previous block}
\end{Highlighting}
\end{Shaded}

Jumps reduce comparisons dramatically vs linear scan.

\subsubsection{Why It Matters}\label{why-it-matters-19}

Search optimization is about adapting structure to context. You don't
always need a fancy data structure , sometimes a tweak like fixed-step
jumping or Fibonacci spacing yields massive gains.

These ideas influence:

\begin{itemize}
\tightlist
\item
  Indexing in databases- Compilers' symbol resolution- Embedded systems
  with low-level constraints They embody the principle: search smarter,
  not harder.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-19}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Jump Search and test vs Binary Search on 1M elements.
\item
  Write a Fibonacci Search , compare steps taken.
\item
  Use Ternary Search to find min of a convex function.
\item
  Modify binary search to find element in rotated array.
\item
  Combine Jump + Linear , how does it behave for small n?
\end{enumerate}

Understanding these variants arms you with flexibility , the heart of
algorithmic mastery.

\section{Chapter 3. Data Structures in
Actions}\label{chapter-3.-data-structures-in-actions}

\subsection{21. Arrays, Linked Lists, Stacks,
Queues}\label{arrays-linked-lists-stacks-queues}

Every data structure is built on top of a few core foundations , the
ones that teach you how data is stored, accessed, and moved. In this
section, we'll revisit the essentials: arrays, linked lists, stacks, and
queues.

They're simple, but they show you the most important design trade-offs
in algorithms:

\begin{itemize}
\tightlist
\item
  Contiguity vs.~flexibility- Speed vs.~dynamic growth-
  Last-in-first-out vs.~first-in-first-out access
\end{itemize}

\subsubsection{1. Arrays}\label{arrays}

Idea: A contiguous block of memory storing elements of the same type.
Access by index in O(1) time , that's their superpower.

Operations:

\begin{itemize}
\tightlist
\item
  Access \texttt{arr{[}i{]}}: (O(1))- Update \texttt{arr{[}i{]}}:
  (O(1))- Insert at end: (O(1)) (amortized for dynamic arrays)- Insert
  in middle: (O(n))- Delete: (O(n)) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[}\DecValTok{5}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{10}\OperatorTok{,} \DecValTok{20}\OperatorTok{,} \DecValTok{30}\OperatorTok{,} \DecValTok{40}\OperatorTok{,} \DecValTok{50}\OperatorTok{\};}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ arr}\OperatorTok{[}\DecValTok{2}\OperatorTok{]);} \CommentTok{// 30}
\end{Highlighting}
\end{Shaded}

Strengths:

\begin{itemize}
\item
  Fast random access- Cache-friendly (contiguous memory)- Simple,
  predictable Weaknesses:
\item
  Fixed size (unless using dynamic array)- Costly inserts/deletes
  Dynamic Arrays: Languages provide resizable arrays (like
  \texttt{vector} in C++ or \texttt{ArrayList} in Java) using doubling
  strategy , when full, allocate new array twice as big and copy. This
  gives amortized (O(1)) insertion at end.
\end{itemize}

\subsubsection{2. Linked Lists}\label{linked-lists}

Idea: A chain of nodes, where each node stores a value and a pointer to
the next. No contiguous memory required.

Operations:

\begin{itemize}
\tightlist
\item
  Access: (O(n))- Insert/Delete at head: (O(1))- Search: (O(n)) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ data}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ head }\OperatorTok{=}\NormalTok{ NULL}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Types:

\begin{itemize}
\item
  Singly Linked List: one pointer (next)- Doubly Linked List: two
  pointers (next, prev)- Circular Linked List: last node points back to
  first Strengths:
\item
  Dynamic size- Fast insert/delete (no shifting) Weaknesses:
\item
  Slow access- Extra memory for pointers- Poor cache locality Linked
  lists shine when memory is fragmented or frequent insertions/deletions
  are needed.
\end{itemize}

\subsubsection{3. Stack}\label{stack}

Idea: A Last-In-First-Out (LIFO) structure , the most recently added
element is the first to be removed.

Used in:

\begin{itemize}
\item
  Function call stacks- Expression evaluation- Undo operations
  Operations:
\item
  \texttt{push(x)}: add element on top- \texttt{pop()}: remove top
  element- \texttt{peek()}: view top element Example (Array-based
  Stack):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define MAX }\DecValTok{100}
\DataTypeTok{int}\NormalTok{ stack}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ top }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ push}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ stack}\OperatorTok{[++}\NormalTok{top}\OperatorTok{]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ pop}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ stack}\OperatorTok{[}\NormalTok{top}\OperatorTok{{-}{-}];} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ peek}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ stack}\OperatorTok{[}\NormalTok{top}\OperatorTok{];} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: All (O(1)): push, pop, peek

Variants:

\begin{itemize}
\tightlist
\item
  Linked-list-based stack (no fixed size)- Min-stack (tracks minimums)
  Stacks also appear implicitly , in recursion and backtracking
  algorithms.
\end{itemize}

\subsubsection{4. Queue}\label{queue}

Idea: A First-In-First-Out (FIFO) structure , the first added element
leaves first.

Used in:

\begin{itemize}
\item
  Task scheduling- BFS traversal- Producer-consumer pipelines
  Operations:
\item
  \texttt{enqueue(x)}: add to rear- \texttt{dequeue()}: remove from
  front- \texttt{front()}: view front Example (Array-based Queue):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define MAX }\DecValTok{100}
\DataTypeTok{int}\NormalTok{ queue}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ front }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ rear }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ enqueue}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ queue}\OperatorTok{[}\NormalTok{rear}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ dequeue}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ queue}\OperatorTok{[}\NormalTok{front}\OperatorTok{++];} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This simple implementation can waste space. A circular queue fixes that
by wrapping indices modulo \texttt{MAX}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rear }\OperatorTok{=} \OperatorTok{(}\NormalTok{rear }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ MAX}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Complexity: All (O(1)): enqueue, dequeue

Variants:

\begin{itemize}
\tightlist
\item
  Deque (double-ended queue): push/pop from both ends- Priority Queue:
  dequeue highest priority (not strictly FIFO)
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-7}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2794}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Order
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Memory
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Array & O(1) & O(n) & O(n) & Indexed & Contiguous & Fast access \\
Linked List & O(n) & O(1)* & O(1)* & Sequential & Pointers & Flexible
size \\
Stack & O(1) & O(1) & O(1) & LIFO & Minimal & Call stack, parsing \\
Queue & O(1) & O(1) & O(1) & FIFO & Minimal & Scheduling, BFS \\
\end{longtable}

(* at head or tail with pointer)

\subsubsection{Tiny Code}\label{tiny-code-20}

Simple stack example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{push}\OperatorTok{(}\DecValTok{10}\OperatorTok{);}
\NormalTok{push}\OperatorTok{(}\DecValTok{20}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ pop}\OperatorTok{());} \CommentTok{// 20}
\end{Highlighting}
\end{Shaded}

Simple queue example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{enqueue}\OperatorTok{(}\DecValTok{5}\OperatorTok{);}
\NormalTok{enqueue}\OperatorTok{(}\DecValTok{8}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ dequeue}\OperatorTok{());} \CommentTok{// 5}
\end{Highlighting}
\end{Shaded}

These short routines appear in almost every algorithm , from recursion
stacks to graph traversals.

\subsubsection{Why It Matters}\label{why-it-matters-20}

These four structures form the spine of data structures:

\begin{itemize}
\tightlist
\item
  Arrays teach indexing and memory- Linked lists teach pointers and
  dynamic allocation- Stacks teach recursion and reversal- Queues teach
  scheduling and order maintenance Every complex structure (trees,
  heaps, graphs) builds on these.
\end{itemize}

Master them, and every algorithm will feel more natural.

\subsubsection{Try It Yourself}\label{try-it-yourself-20}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a linked list with \texttt{insert\_front} and
  \texttt{delete\_value}.
\item
  Build a stack and use it to reverse an array.
\item
  Implement a queue for a round-robin scheduler.
\item
  Convert infix expression to postfix using a stack.
\item
  Compare time taken to insert 1000 elements in array vs linked list.
\end{enumerate}

Understanding these foundations gives you the vocabulary of structure ,
the way algorithms organize their thoughts in memory.

\subsection{22. Hash Tables and Variants (Cuckoo, Robin Hood,
Consistent)}\label{hash-tables-and-variants-cuckoo-robin-hood-consistent}

When you need lightning-fast lookups, insertions, and deletions, few
data structures match the raw efficiency of a hash table. They're
everywhere , from symbol tables and caches to compilers and databases ,
powering average-case O(1) access.

In this section, we'll unpack how hash tables work, their collision
strategies, and explore modern variants like Cuckoo Hashing, Robin Hood
Hashing, and Consistent Hashing, each designed to handle different
real-world needs.

\subsubsection{1. The Core Idea}\label{the-core-idea}

A hash table maps keys to values using a hash function that transforms
the key into an index in an array.

\[
\text{index} = h(\text{key}) \bmod \text{table\_size}
\]

If no two keys hash to the same index, all operations are (O(1)). But in
practice, collisions happen , two keys may map to the same slot , and we
must handle them smartly.

\subsubsection{2. Collision Resolution
Strategies}\label{collision-resolution-strategies}

A. Separate Chaining Each table slot holds a linked list (or dynamic
array) of entries with the same hash.

Pros: Simple, handles load factor \textgreater{} 1 Cons: Extra pointers,
memory overhead

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ value}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ table}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ value}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ node }\OperatorTok{=}\NormalTok{ malloc}\OperatorTok{(}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{=}\NormalTok{ key}\OperatorTok{;}\NormalTok{ node}\OperatorTok{{-}\textgreater{}}\NormalTok{value }\OperatorTok{=}\NormalTok{ value}\OperatorTok{;}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{next }\OperatorTok{=}\NormalTok{ table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{];}
\NormalTok{    table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ node}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

B. Open Addressing All keys live directly in the table. On collision,
find another slot.

Three main strategies:

\begin{itemize}
\tightlist
\item
  Linear probing: try next slot (+1)- Quadratic probing: step size
  increases quadratically- Double hashing: second hash decides step size
  Example (Linear Probing):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ value}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{used}\OperatorTok{)}
\NormalTok{        idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
\NormalTok{    table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{Entry}\OperatorTok{)\{}\NormalTok{key}\OperatorTok{,}\NormalTok{ value}\OperatorTok{,} \DecValTok{1}\OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Load Factor \(\alpha = \frac{n}{m}\) affects performance , when too
high, rehash to larger size.

\subsubsection{3. Modern Variants}\label{modern-variants}

Classic hash tables can degrade under heavy collisions. Modern variants
reduce probe chains and balance load more evenly.

\subsubsection{A. Cuckoo Hashing}\label{a.-cuckoo-hashing}

Idea: Each key has two possible locations , if both full, evict one
(``kick out the cuckoo'') and reinsert. Ensures constant lookup , at
most two probes.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute two hashes (h\_1(key)), (h\_2(key))
\item
  If slot 1 empty → place
\item
  Else evict occupant, reinsert it using alternate hash
\item
  Repeat until placed or cycle detected (rehash if needed)
\end{enumerate}

Code Sketch (Conceptual):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ h1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ h2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{key }\OperatorTok{/}\NormalTok{ SIZE}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pos1 }\OperatorTok{=}\NormalTok{ h1}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{])} \OperatorTok{\{}\NormalTok{ table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;} \ControlFlowTok{return}\OperatorTok{;} \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ displaced }\OperatorTok{=}\NormalTok{ table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{];}\NormalTok{ table1}\OperatorTok{[}\NormalTok{pos1}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}

    \DataTypeTok{int}\NormalTok{ pos2 }\OperatorTok{=}\NormalTok{ h2}\OperatorTok{(}\NormalTok{displaced}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{table2}\OperatorTok{[}\NormalTok{pos2}\OperatorTok{])} \OperatorTok{\{}\NormalTok{ table2}\OperatorTok{[}\NormalTok{pos2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ displaced}\OperatorTok{;} \ControlFlowTok{return}\OperatorTok{;} \OperatorTok{\}}
    \CommentTok{// continue evicting if needed}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pros:

\begin{itemize}
\item
  Worst-case O(1) lookup (constant probes)- Predictable latency Cons:
\item
  Rehash needed on insertion failure- More complex logic Used in
  high-performance caches and real-time systems.
\end{itemize}

\subsubsection{B. Robin Hood Hashing}\label{b.-robin-hood-hashing}

Idea: Steal slots from richer (closer) keys to ensure fairness. When
inserting, if you find someone with smaller probe distance, swap ,
``steal from the rich, give to the poor.''

This balances probe lengths and improves variance and average lookup
time.

Key Principle: \[
\text{If new\_probe\_distance} > \text{existing\_probe\_distance} \Rightarrow \text{swap}
\]

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dist }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{used}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{].}\NormalTok{dist }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{)} \OperatorTok{\{}
            \CommentTok{// swap entries}
\NormalTok{            Entry tmp }\OperatorTok{=}\NormalTok{ table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{];}
\NormalTok{            table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{Entry}\OperatorTok{)\{}\NormalTok{key}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{,} \DecValTok{1}\OperatorTok{\};}
\NormalTok{            key }\OperatorTok{=}\NormalTok{ tmp}\OperatorTok{.}\NormalTok{key}\OperatorTok{;}
\NormalTok{            dist }\OperatorTok{=}\NormalTok{ tmp}\OperatorTok{.}\NormalTok{dist}\OperatorTok{;}
        \OperatorTok{\}}
\NormalTok{        idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
\NormalTok{        dist}\OperatorTok{++;}
    \OperatorTok{\}}
\NormalTok{    table}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{Entry}\OperatorTok{)\{}\NormalTok{key}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{,} \DecValTok{1}\OperatorTok{\};}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pros:

\begin{itemize}
\item
  Reduced variance- Better performance under high load Cons:
\item
  Slightly slower insertion Used in modern languages like Rust
  (\texttt{hashbrown}) and Swift.
\end{itemize}

\subsubsection{C. Consistent Hashing}\label{c.-consistent-hashing}

Idea: When distributing keys across multiple nodes, you want minimal
movement when adding/removing a node. Consistent hashing maps both keys
and nodes onto a circular hash ring.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Hash nodes into a ring
\item
  Hash keys into same ring
\item
  Each key belongs to the next node clockwise
\end{enumerate}

When a node is added or removed, only nearby keys move.

Used in:

\begin{itemize}
\tightlist
\item
  Distributed caches (Memcached, DynamoDB)- Load balancing- Sharding in
  databases Code (Conceptual):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ring: 0 {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} 2\^{}32}
\NormalTok{Nodes: N1 at hash("A"), N2 at hash("B")}
\NormalTok{Key: hash("User42") → assign to next node clockwise}
\end{Highlighting}
\end{Shaded}

Pros:

\begin{itemize}
\item
  Minimal rebalancing- Scalable Cons:
\item
  More complex setup- Requires virtual nodes for even distribution
\end{itemize}

\subsubsection{4. Complexity Overview}\label{complexity-overview}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2059}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1029}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3382}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Search
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Memory
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Chaining & O(1) avg & O(1) avg & O(1) avg & High & Simple, dynamic \\
Linear Probing & O(1) avg & O(1) avg & O(1) avg & Low & Clustering
risk \\
Cuckoo & O(1) & O(1) & O(1) & Medium & Two tables, predictable \\
Robin Hood & O(1) & O(1) & O(1) & Low & Balanced probes \\
Consistent & O(log n) & O(log n) & O(log n) & Depends & Distributed
keys \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-21}

Simple hash table with linear probing:

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define SIZE }\DecValTok{10}
\DataTypeTok{int}\NormalTok{ keys}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{],}\NormalTok{ values}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{],}\NormalTok{ used}\OperatorTok{[}\NormalTok{SIZE}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ value}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{idx}\OperatorTok{])}\NormalTok{ idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
\NormalTok{    keys}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ key}\OperatorTok{;}\NormalTok{ values}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=}\NormalTok{ value}\OperatorTok{;}\NormalTok{ used}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Lookup:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ get}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ idx }\OperatorTok{=}\NormalTok{ hash}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{idx}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{keys}\OperatorTok{[}\NormalTok{idx}\OperatorTok{]} \OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ values}\OperatorTok{[}\NormalTok{idx}\OperatorTok{];}
\NormalTok{        idx }\OperatorTok{=} \OperatorTok{(}\NormalTok{idx }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ SIZE}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-21}

Hash tables show how structure and randomness combine for speed. They
embody the idea that a good hash function + smart collision handling =
near-constant performance.

Variants like Cuckoo and Robin Hood are examples of modern engineering
trade-offs , balancing performance, memory, and predictability.
Consistent hashing extends these ideas to distributed systems.

\subsubsection{Try It Yourself}\label{try-it-yourself-21}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a hash table with chaining and test collision handling.
\item
  Modify it to use linear probing , measure probe lengths.
\item
  Simulate Cuckoo hashing with random inserts.
\item
  Implement Robin Hood swapping logic , observe fairness.
\item
  Draw a consistent hash ring with 3 nodes and 10 keys , track movement
  when adding one node.
\end{enumerate}

Once you master these, you'll see hashing everywhere , from dictionaries
to distributed databases.

\subsection{23. Heaps (Binary, Fibonacci,
Pairing)}\label{heaps-binary-fibonacci-pairing}

Heaps are priority-driven data structures , they always give you fast
access to the most important element, typically the minimum or maximum.
They're essential for priority queues, scheduling, graph algorithms
(like Dijkstra), and streaming analytics.

In this section, we'll start from the basic binary heap and then explore
more advanced ones like Fibonacci and pairing heaps, which trade off
simplicity, speed, and amortized guarantees.

\subsubsection{1. The Heap Property}\label{the-heap-property}

A heap is a tree-based structure (often represented as an array) that
satisfies:

\begin{itemize}
\tightlist
\item
  Min-Heap: Every node ≤ its children- Max-Heap: Every node ≥ its
  children This ensures the root always holds the smallest (or largest)
  element.
\end{itemize}

Complete Binary Tree: All levels filled except possibly the last, which
is filled left to right.

Example (Min-Heap):

\begin{verbatim}
        2
      /   \
     4     5
    / \   /
   9  10 15
\end{verbatim}

Here, the smallest element (2) is at the root.

\subsubsection{2. Binary Heap}\label{binary-heap}

Storage: Stored compactly in an array. For index \texttt{i} (0-based):

\begin{itemize}
\tightlist
\item
  Parent = \texttt{(i\ -\ 1)\ /\ 2}- Left child = \texttt{2i\ +\ 1}-
  Right child = \texttt{2i\ +\ 2} Operations:
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Description & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{push(x)} & Insert element & (O\(\log n\)) \\
\texttt{pop()} & Remove root & (O\(\log n\)) \\
\texttt{peek()} & Get root & (O(1)) \\
\texttt{heapify()} & Build heap & (O(n)) \\
\end{longtable}

\subsubsection{A. Insertion (Push)}\label{a.-insertion-push}

Insert at the end, then bubble up until heap property is restored.

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ push}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[],} \DataTypeTok{int} \OperatorTok{*}\NormalTok{n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \OperatorTok{(*}\NormalTok{n}\OperatorTok{)++;}
\NormalTok{    heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ heap}\OperatorTok{[(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)/}\DecValTok{2}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heap}\OperatorTok{[(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)/}\DecValTok{2}\OperatorTok{];}
\NormalTok{        heap}\OperatorTok{[(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)/}\DecValTok{2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        i }\OperatorTok{=} \OperatorTok{(}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Removal (Pop)}\label{b.-removal-pop}

Replace root with last element, then bubble down (heapify).

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ heapify}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ smallest }\OperatorTok{=}\NormalTok{ i}\OperatorTok{,}\NormalTok{ l }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ r }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{i }\OperatorTok{+} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ heap}\OperatorTok{[}\NormalTok{l}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{])}\NormalTok{ smallest }\OperatorTok{=}\NormalTok{ l}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ heap}\OperatorTok{[}\NormalTok{r}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{])}\NormalTok{ smallest }\OperatorTok{=}\NormalTok{ r}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{smallest }\OperatorTok{!=}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ tmp }\OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ heap}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{];}\NormalTok{ heap}\OperatorTok{[}\NormalTok{smallest}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tmp}\OperatorTok{;}
\NormalTok{        heapify}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ smallest}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pop:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ pop}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[],} \DataTypeTok{int} \OperatorTok{*}\NormalTok{n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ root }\OperatorTok{=}\NormalTok{ heap}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
\NormalTok{    heap}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heap}\OperatorTok{[{-}{-}(*}\NormalTok{n}\OperatorTok{)];}
\NormalTok{    heapify}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{*}\NormalTok{n}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Building a Heap}\label{c.-building-a-heap}

Heapify bottom-up from last non-leaf: (O(n))

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n}\OperatorTok{/}\DecValTok{2} \OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})}
\NormalTok{    heapify}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Applications}\label{d.-applications}

\begin{itemize}
\tightlist
\item
  Heapsort: Repeatedly pop min (O(n log n))- Priority Queue: Fast access
  to smallest/largest- Graph Algorithms: Dijkstra, Prim- Streaming:
  Median finding using two heaps
\end{itemize}

\subsubsection{3. Fibonacci Heap}\label{fibonacci-heap}

Idea: A heap optimized for algorithms that do many decrease-key
operations (like Dijkstra's). It stores a collection of trees with lazy
merging, giving amortized bounds:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation & Amortized Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & (O(1)) \\
Find-Min & (O(1)) \\
Extract-Min & (O\(\log n\)) \\
Decrease-Key & (O(1)) \\
Merge & (O(1)) \\
\end{longtable}

It achieves this by delaying structural fixes until absolutely necessary
(using potential method in amortized analysis).

Structure:

\begin{itemize}
\tightlist
\item
  A circular linked list of roots- Each node can have multiple children-
  Consolidation on extract-min ensures minimal degree duplication Used
  in theoretical optimizations where asymptotic complexity matters
  (e.g.~Dijkstra in (O\(E + V \log V\)) vs (O\(E \log V\))).
\end{itemize}

\subsubsection{4. Pairing Heap}\label{pairing-heap}

Idea: A simpler, practical alternative to Fibonacci heaps.
Self-adjusting structure using a tree with multiple children.

Operations:

\begin{itemize}
\item
  Insert: (O(1))- Extract-Min: (O\(\log n\)) amortized- Decrease-Key:
  (O\(\log n\)) amortized Steps:
\item
  \texttt{merge} two heaps: attach one as child of the other-
  \texttt{extract-min}: remove root, merge children in pairs, then merge
  all results Why It's Popular:
\item
  Easier to implement- Great real-world performance- Used in functional
  programming and priority schedulers
\end{itemize}

\subsubsection{5. Comparison}\label{comparison-8}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1707}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0976}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1341}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1463}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0610}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1220}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2683}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Heap Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Extract-Min
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Decrease-Key
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Merge
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Simplicity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Heap & O(log n) & O(log n) & O(log n) & O(n) & Easy &
General-purpose \\
Fibonacci Heap & O(1) & O(log n) & O(1) & O(1) & Complex & Theoretical
optimality \\
Pairing Heap & O(1) & O(log n) & O(log n) & O(1) & Moderate & Practical
alternative \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-22}

Binary Heap Demo:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ heap}\OperatorTok{[}\DecValTok{100}\OperatorTok{],}\NormalTok{ n }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{push}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{,} \DecValTok{10}\OperatorTok{);}
\NormalTok{push}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{,} \DecValTok{4}\OperatorTok{);}
\NormalTok{push}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{,} \DecValTok{7}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ pop}\OperatorTok{(}\NormalTok{heap}\OperatorTok{,} \OperatorTok{\&}\NormalTok{n}\OperatorTok{));} \CommentTok{// 4}
\end{Highlighting}
\end{Shaded}

Output: \texttt{4}

\subsubsection{Why It Matters}\label{why-it-matters-22}

Heaps show how to prioritize elements dynamically. From sorting to
scheduling, they're the backbone of many ``choose the best next''
algorithms. Variants like Fibonacci and Pairing Heaps demonstrate how
amortized analysis can unlock deeper efficiency , crucial in graph
theory and large-scale optimization.

\subsubsection{Try It Yourself}\label{try-it-yourself-22}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a binary min-heap with \texttt{push}, \texttt{pop}, and
  \texttt{peek}.
\item
  Use a heap to sort a list (Heapsort).
\item
  Build a priority queue for task scheduling.
\item
  Study how Dijkstra changes when replacing arrays with heaps.
\item
  Explore Fibonacci heap pseudo-code , trace \texttt{decrease-key}.
\end{enumerate}

Mastering heaps gives you a deep sense of priority-driven design , how
to keep ``the best'' element always within reach.

\subsection{24. Balanced Trees (AVL, Red-Black, Splay,
Treap)}\label{balanced-trees-avl-red-black-splay-treap}

Unbalanced trees can degrade into linear lists, turning your beautiful
(O\(\log n\)) search into a sad (O(n)) crawl. Balanced trees solve this
, they keep the height logarithmic, guaranteeing fast lookups,
insertions, and deletions.

In this section, you'll learn how different balancing philosophies work
, AVL (strict balance), Red-Black (relaxed balance), Splay
(self-adjusting), and Treap (randomized balance).

\subsubsection{1. The Idea of Balance}\label{the-idea-of-balance}

For a binary search tree (BST):

\[
\text{height} = O(\log n)
\]

only if it's balanced , meaning the number of nodes in left and right
subtrees differ by a small factor.

Unbalanced BST (bad):

\begin{verbatim}
1
 \
  2
   \
    3
\end{verbatim}

Balanced BST (good):

\begin{verbatim}
  2
 / \
1   3
\end{verbatim}

Balance ensures efficient:

\begin{itemize}
\tightlist
\item
  \texttt{search(x)} → (O\(\log n\))- \texttt{insert(x)} →
  (O\(\log n\))- \texttt{delete(x)} → (O\(\log n\))
\end{itemize}

\subsubsection{2. AVL Tree (Adelson-Velsky \&
Landis)}\label{avl-tree-adelson-velsky-landis}

Invented in 1962, AVL is the first self-balancing BST. It enforces
strict balance: \[
| \text{height(left)} - \text{height(right)} | \le 1
\]

Whenever this condition breaks, rotations fix it.

Rotations:

\begin{itemize}
\tightlist
\item
  LL (Right Rotation): imbalance on left-left- RR (Left Rotation):
  imbalance on right-right- LR / RL: double rotation cases Code
  (Rotation Example):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ y}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ x }\OperatorTok{=}\NormalTok{ y}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{;}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ T }\OperatorTok{=}\NormalTok{ x}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{;}
\NormalTok{    x}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ y}\OperatorTok{;}
\NormalTok{    y}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ T}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Height \& Balance Factor:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ height}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{?}\NormalTok{ n}\OperatorTok{{-}\textgreater{}}\NormalTok{h }\OperatorTok{:} \DecValTok{0}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ balance}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ height}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ height}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{);} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Properties:

\begin{itemize}
\tightlist
\item
  Strict height bound: (O\(\log n\))- More rotations (slower
  insertions)- Excellent lookup speed Used when lookups \textgreater{}
  updates (databases, indexing).
\end{itemize}

\subsubsection{3. Red-Black Tree}\label{red-black-tree}

Idea: A slightly looser balance for faster insertions. Each node has a
color (Red/Black) with these rules:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Root is black
\item
  Red node's children are black
\item
  Every path has same number of black nodes
\item
  Null nodes are black
\end{enumerate}

Balance through color flips + rotations

Compared to AVL:

\begin{itemize}
\item
  Fewer rotations (faster insert/delete)- Slightly taller (slower
  lookup)- Simpler amortized balance Used in:
\item
  C++ \texttt{std::map}, \texttt{std::set}- Java \texttt{TreeMap}, Linux
  scheduler Complexity: All major operations (O\(\log n\))
\end{itemize}

\subsubsection{4. Splay Tree}\label{splay-tree}

Idea: Bring recently accessed node to root via splaying (rotations). It
adapts to access patterns , the more you access a key, the faster it
becomes.

Splaying Steps:

\begin{itemize}
\tightlist
\item
  Zig: one rotation (root child)- Zig-Zig: two rotations (same side)-
  Zig-Zag: two rotations (different sides) Code (Conceptual):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ splay}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root }\OperatorTok{||}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
        \CommentTok{// splay in left subtree}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}
\NormalTok{            root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ splay}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{),}
\NormalTok{            root }\OperatorTok{=}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}
\NormalTok{            root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ splay}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{),}
\NormalTok{            root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ rotateLeft}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{);}
        \ControlFlowTok{return}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
        \CommentTok{// symmetric}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Why It's Cool: No strict balance, but amortized (O\(\log n\)).
Frequently accessed elements stay near top.

Used in self-adjusting caches, rope data structures, memory allocators.

\subsubsection{5. Treap (Tree + Heap)}\label{treap-tree-heap}

Idea: Each node has two keys:

\begin{itemize}
\tightlist
\item
  BST key → order property- Priority → heap property Insertion = normal
  BST insert + heap fix via rotation.
\end{itemize}

Balance comes from randomization , random priorities ensure expected
(O\(\log n\)) height.

Code Sketch:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ priority}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ insert}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{key}\OperatorTok{,}\NormalTok{ rand}\OperatorTok{());}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}

    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{\&\&}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{priority }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{priority}\OperatorTok{)}
\NormalTok{        root }\OperatorTok{=}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{\&\&}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{{-}\textgreater{}}\NormalTok{priority }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{priority}\OperatorTok{)}
\NormalTok{        root }\OperatorTok{=}\NormalTok{ rotateLeft}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Advantages:

\begin{itemize}
\tightlist
\item
  Simple logic- Random balancing- Expected (O\(\log n\)) Used in
  randomized algorithms and functional programming.
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-9}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0947}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1263}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.0947}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.2211}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1368}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1684}}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1579}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tree
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Balance Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rotations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Height
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Insert/Delete
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Lookup
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
AVL & Strict & More & (O\(\log n\)) & Medium & Fast & Lookup-heavy \\
Red-Black & Relaxed & Fewer & (O\(\log n\)) & Fast & Medium & Library
std \\
Splay & Adaptive & Variable & Amortized (O\(\log n\)) & Fast & Fast
(amortized) & Access patterns \\
Treap & Randomized & Avg few & (O\(\log n\)) expected & Simple & Simple
& Probabilistic \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-23}

AVL Insert (Skeleton):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ insert}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
\NormalTok{    root}\OperatorTok{{-}\textgreater{}}\NormalTok{h }\OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ max}\OperatorTok{(}\NormalTok{height}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{),}\NormalTok{ height}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{));}
    \DataTypeTok{int}\NormalTok{ b }\OperatorTok{=}\NormalTok{ balance}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}} \DecValTok{1} \OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ rotateRight}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textless{}} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{\&\&}\NormalTok{ key }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ rotateLeft}\OperatorTok{(}\NormalTok{root}\OperatorTok{);}
    \CommentTok{// other cases...}
    \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-23}

Balanced trees guarantee predictable performance under dynamic updates.
Each variant represents a philosophy:

\begin{itemize}
\tightlist
\item
  AVL: precision- Red-Black: practicality- Splay: adaptability- Treap:
  randomness Together, they teach one core idea , keep height in check,
  no matter the operations.
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-23}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement an AVL tree and visualize rotations.
\item
  Insert keys {[}10, 20, 30, 40, 50{]} and trace Red-Black color
  changes.
\item
  Splay after each access , see which keys stay near top.
\item
  Build a Treap with random priorities , measure average height.
\item
  Compare performance of BST vs AVL on sorted input.
\end{enumerate}

Balanced trees are the architects of order , always keeping chaos one
rotation away.

\subsection{25. Segment Trees and Fenwick
Trees}\label{segment-trees-and-fenwick-trees}

When you need to answer range queries quickly (like sum, min, max) and
support updates to individual elements, simple prefix sums won't cut it
anymore.

You need something smarter , data structures that can divide and conquer
over ranges, updating and combining results efficiently.

That's exactly what Segment Trees and Fenwick Trees (Binary Indexed
Trees) do:

\begin{itemize}
\tightlist
\item
  Query over a range in (O\(\log n\))- Update elements in (O\(\log n\))
  They're the backbone of competitive programming, signal processing,
  and database analytics.
\end{itemize}

\subsubsection{1. The Problem}\label{the-problem}

Given an array \texttt{A{[}0..n-1{]}}, support:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{update(i,\ x)} → change \texttt{A{[}i{]}} to \texttt{x}
\item
  \texttt{query(L,\ R)} → compute sum (or min, max) of
  \texttt{A{[}L..R{]}}
\end{enumerate}

Naive approach:

\begin{itemize}
\tightlist
\item
  Update: (O(1))- Query: (O(n)) Prefix sums fix one but not both.
  Segment and Fenwick trees fix both.
\end{itemize}

\subsubsection{2. Segment Tree}\label{segment-tree}

Idea: Divide the array into segments (intervals) recursively. Each node
stores an aggregate (sum, min, max) of its range. You can combine child
nodes to get any range result.

Structure (Sum Example):

\begin{verbatim}
           [0,7] sum=36
         /           \
   [0,3]=10         [4,7]=26
   /     \           /      \
[0,1]=3 [2,3]=7  [4,5]=11  [6,7]=15
\end{verbatim}

Each node represents a range {[}L,R{]}. Leaf nodes = single elements.

\subsubsection{A. Build}\label{a.-build}

Recursive Construction: Time: (O(n))

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ build}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ node}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)}\NormalTok{ tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{L}\OperatorTok{];}
    \ControlFlowTok{else} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L }\OperatorTok{+}\NormalTok{ R}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{        build}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{);}
\NormalTok{        build}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{);}
\NormalTok{        tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{]} \OperatorTok{+}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Query (Range Sum)}\label{b.-query-range-sum}

Query {[}l, r{]} recursively:

\begin{itemize}
\tightlist
\item
  If current range {[}L, R{]} fully inside {[}l, r{]}, return node
  value- If disjoint, return 0- Else combine children
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ node}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ L }\OperatorTok{||}\NormalTok{ R }\OperatorTok{\textless{}}\NormalTok{ l}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}=}\NormalTok{ L }\OperatorTok{\&\&}\NormalTok{ R }\OperatorTok{\textless{}=}\NormalTok{ r}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L }\OperatorTok{+}\NormalTok{ R}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ query}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ r}\OperatorTok{)}
         \OperatorTok{+}\NormalTok{ query}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,}\NormalTok{ l}\OperatorTok{,}\NormalTok{ r}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Update}\label{c.-update}

Change \texttt{arr{[}i{]}\ =\ x} and update tree nodes covering
\texttt{i}.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ update}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ node}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)}\NormalTok{ tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
    \ControlFlowTok{else} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L }\OperatorTok{+}\NormalTok{ R}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}=}\NormalTok{ mid}\OperatorTok{)}\NormalTok{ update}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
        \ControlFlowTok{else}\NormalTok{ update}\OperatorTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\NormalTok{        tree}\OperatorTok{[}\NormalTok{node}\OperatorTok{]} \OperatorTok{=}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{]} \OperatorTok{+}\NormalTok{ tree}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{node}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexities:

\begin{itemize}
\tightlist
\item
  Build: (O(n))- Query: (O\(\log n\))- Update: (O\(\log n\))- Space:
  (O(4n))
\end{itemize}

\subsubsection{D. Variants}\label{d.-variants}

Segment trees are flexible:

\begin{itemize}
\tightlist
\item
  Range minimum/maximum- Range GCD- Lazy propagation → range updates- 2D
  segment tree for grids
\end{itemize}

\subsubsection{3. Fenwick Tree (Binary Indexed
Tree)}\label{fenwick-tree-binary-indexed-tree}

Idea: Stores cumulative frequencies using bit manipulation. Each node
covers a range size = LSB(index).

Simpler, smaller, but supports only associative ops (sum, xor, etc.)

Indexing:

\begin{itemize}
\tightlist
\item
  Parent: \texttt{i\ +\ (i\ \&\ -i)}- Child: \texttt{i\ -\ (i\ \&\ -i)}
  Build: Initialize with zero, then add elements one by one.
\end{itemize}

Add / Update:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Prefix Sum:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{{-}=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        res }\OperatorTok{+=}\NormalTok{ bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Range Sum {[}L, R{]}: \[
\text{sum}(R) - \text{sum}(L-1)
\]

Complexities:

\begin{itemize}
\tightlist
\item
  Build: (O\(n \log n\))- Query: (O\(\log n\))- Update: (O\(\log n\))-
  Space: (O(n))
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-10}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Segment Tree & Fenwick Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Space & O(4n) & O(n) \\
Build & O(n) & O(n log n) \\
Query & O(log n) & O(log n) \\
Update & O(log n) & O(log n) \\
Range Update & With Lazy & Tricky \\
Range Query & Flexible & Sum/XOR only \\
Implementation & Moderate & Simple \\
\end{longtable}

\subsubsection{5. Applications}\label{applications}

\begin{itemize}
\item
  Sum / Min / Max / XOR queries- Frequency counts- Inversions counting-
  Order statistics- Online problems where array updates over time Used
  in:
\item
  Competitive programming- Databases (analytics on changing data)- Time
  series queries- Games (damage/range updates)
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-24}

Fenwick Tree Example:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ bit}\OperatorTok{[}\DecValTok{1001}\OperatorTok{],}\NormalTok{ n}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ update}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ val}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{{-}=}\NormalTok{ i }\OperatorTok{\&} \OperatorTok{{-}}\NormalTok{i}\OperatorTok{)}
\NormalTok{        res }\OperatorTok{+=}\NormalTok{ bit}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}

\CommentTok{// range sum}
\DataTypeTok{int}\NormalTok{ range\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ query}\OperatorTok{(}\NormalTok{R}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ query}\OperatorTok{(}\NormalTok{L }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-24}

Segment and Fenwick trees embody divide-and-conquer over data ,
balancing dynamic updates with range queries. They're how modern systems
aggregate live data efficiently.

They teach a powerful mindset:

\begin{quote}
``If you can split a problem, you can solve it fast.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-24}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a segment tree for sum queries.
\item
  Add range minimum queries (RMQ).
\item
  Implement a Fenwick tree , test with prefix sums.
\item
  Solve: number of inversions in array using Fenwick tree.
\item
  Add lazy propagation to segment tree for range updates.
\end{enumerate}

Once you master these, range queries will never scare you again , you'll
slice through them in logarithmic time.

\subsection{26. Disjoint Set Union
(Union-Find)}\label{disjoint-set-union-union-find}

Many problems involve grouping elements into sets and efficiently
checking whether two elements belong to the same group , like connected
components in a graph, network connectivity, Kruskal's MST, or even
social network clustering.

For these, the go-to structure is the Disjoint Set Union (DSU), also
called Union-Find. It efficiently supports two operations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{find(x)} → which set does \texttt{x} belong to?
\item
  \texttt{union(x,\ y)} → merge the sets containing \texttt{x} and
  \texttt{y}.
\end{enumerate}

With path compression and union by rank, both operations run in
near-constant time, specifically (O(\alpha(n))), where \(\alpha\) is the
inverse Ackermann function (practically ≤ 4).

\subsubsection{1. The Problem}\label{the-problem-1}

Suppose you have (n) elements initially in separate sets. Over time, you
want to:

\begin{itemize}
\tightlist
\item
  Merge two sets- Check if two elements share the same set Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Sets: \{1\}, \{2\}, \{3\}, \{4\}, \{5\}}
\NormalTok{Union(1,2) → \{1,2\}, \{3\}, \{4\}, \{5\}}
\NormalTok{Union(3,4) → \{1,2\}, \{3,4\}, \{5\}}
\NormalTok{Find(2) == Find(1)? Yes}
\NormalTok{Find(5) == Find(3)? No}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Basic Implementation}\label{basic-implementation}

Each element has a parent pointer. Initially, every node is its own
parent.

Parent array representation:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ make\_set}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ v}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This works, but deep trees can form , making \texttt{find} slow. We fix
that with path compression.

\subsubsection{3. Path Compression}\label{path-compression}

Every time we call \texttt{find(v)}, we make all nodes along the path
point directly to the root. This flattens the tree dramatically.

Optimized Find:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ v}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

So next time, lookups will be (O(1)) for those nodes.

\subsubsection{4. Union by Rank / Size}\label{union-by-rank-size}

When merging, always attach the smaller tree to the larger to keep depth
small.

Union by Rank:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{N}\OperatorTok{],}\NormalTok{ rank}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ make\_set}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{    rank}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}
\NormalTok{            swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{==}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}
\NormalTok{            rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]++;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Union by Size (Alternative): Track size of each set and attach smaller
to larger.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ size}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}
\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{size}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ size}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
\NormalTok{        size}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ size}\OperatorTok{[}\NormalTok{b}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Complexity}\label{complexity}

With both path compression and union by rank, all operations are
effectively constant time: \[
O(\alpha(n)) \approx O(1)
\]

For all practical (n), (\alpha(n) \le 4).

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Make set & O(1) \\
Find & O(α(n)) \\
Union & O(α(n)) \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-1}

\begin{itemize}
\tightlist
\item
  Graph Connectivity: determine connected components- Kruskal's MST: add
  edges, avoid cycles- Dynamic connectivity- Image segmentation- Network
  clustering- Cycle detection in undirected graphs Example: Kruskal's
  Algorithm
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sort}\OperatorTok{(}\NormalTok{edges}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ edges}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{edge e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{)} \OperatorTok{!=}\NormalTok{ find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        union\_sets}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{v}\OperatorTok{);}
\NormalTok{        mst\_weight }\OperatorTok{+=}\NormalTok{ e}\OperatorTok{.}\NormalTok{w}\OperatorTok{;}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Example}\label{example}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\DecValTok{6}\OperatorTok{],}\NormalTok{ rank}\OperatorTok{[}\DecValTok{6}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ init}\OperatorTok{()} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=} \DecValTok{5}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{        rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    init}\OperatorTok{();}
\NormalTok{    union\_sets}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{    union\_sets}\OperatorTok{(}\DecValTok{3}\OperatorTok{,} \DecValTok{4}\OperatorTok{);}
\NormalTok{    union\_sets}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ find}\OperatorTok{(}\DecValTok{4}\OperatorTok{));} \CommentTok{// prints representative of \{1,2,3,4\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Result: \texttt{\{1,2,3,4\}}, \texttt{\{5\}}

\subsubsection{8. Visualization}\label{visualization}

\begin{verbatim}
Before compression:
1
 \
  2
   \
    3

After compression:
1
├─2
└─3
\end{verbatim}

Every \texttt{find} call makes future queries faster.

\subsubsection{9. Comparison}\label{comparison-11}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Variant & Find & Union & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Basic & O(n) & O(n) & Deep trees \\
Path Compression & O(α(n)) & O(α(n)) & Very fast \\
+ Rank / Size & O(α(n)) & O(α(n)) & Balanced \\
Persistent DSU & O(log n) & O(log n) & Undo/rollback support \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-25}

Full DSU with path compression + rank:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\DecValTok{1000}\OperatorTok{],}\NormalTok{ rank}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ make\_set}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{    rank}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ union\_sets}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{==}\NormalTok{ rank}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}
\NormalTok{            rank}\OperatorTok{[}\NormalTok{a}\OperatorTok{]++;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-25}

Union-Find embodies structural sharing and lazy optimization , you don't
balance eagerly, but just enough. It's one of the most elegant
demonstrations of how constant-time algorithms are possible through
clever organization.

It teaches a key algorithmic lesson:

\begin{quote}
``Work only when necessary, and fix structure as you go.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-25}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement DSU and test \texttt{find}/\texttt{union}.
\item
  Build a program that counts connected components.
\item
  Solve Kruskal's MST using DSU.
\item
  Add \texttt{get\_size(v)} to return component size.
\item
  Try rollback DSU (keep stack of changes).
\end{enumerate}

Union-Find is the quiet powerhouse behind many graph and connectivity
algorithms , simple, fast, and deeply elegant.

\subsection{27. Probabilistic Data Structures (Bloom, Count-Min,
HyperLogLog)}\label{probabilistic-data-structures-bloom-count-min-hyperloglog}

When you work with massive data streams , billions of elements, too big
for memory , you can't store everything. But what if you don't need
\emph{perfect} answers, just \emph{fast and tiny approximate ones}?

That's where probabilistic data structures shine. They trade a bit of
accuracy for huge space savings and constant-time operations.

In this section, we'll explore three of the most famous:

\begin{itemize}
\tightlist
\item
  Bloom Filters → membership queries- Count-Min Sketch → frequency
  estimation- HyperLogLog → cardinality estimation Each of them answers
  ``How likely is X?'' or ``How many?'' efficiently , perfect for modern
  analytics, caching, and streaming systems.
\end{itemize}

\subsubsection{1. Bloom Filter , ``Is this element probably in the
set?''}\label{bloom-filter-is-this-element-probably-in-the-set}

A Bloom filter answers:

\begin{quote}
``Is \texttt{x} in the set?'' with either maybe yes or definitely no.
\end{quote}

No false negatives, but \emph{some} false positives.

\subsubsection{A. Idea}\label{a.-idea}

Use an array of bits (size \texttt{m}), all initialized to 0. Use k
different hash functions.

To insert an element:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute k hashes: ( h\_1(x), h\_2(x), \ldots, h\_k(x) )
\item
  Set each bit position \(b_i = 1\)
\end{enumerate}

To query an element:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute same k hashes
\item
  If all bits are 1 → maybe yes
\item
  If any bit is 0 → definitely no
\end{enumerate}

\subsubsection{B. Example}\label{b.-example}

Insert \texttt{dog}:

\begin{itemize}
\tightlist
\item
  (h\_1(dog)=2, h\_2(dog)=5, h\_3(dog)=9) Set bits 2, 5, 9 → 1
\end{itemize}

Check \texttt{cat}:

\begin{itemize}
\tightlist
\item
  If any hash bit = 0 → not present
\end{itemize}

\subsubsection{C. Complexity}\label{c.-complexity}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Accuracy \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(k) & O(m) & Tunable \\
Query & O(k) & O(m) & False positives \\
\end{longtable}

False positive rate ≈ ( \(1 - e^{-kn/m}\)\^{}k )

Choose \texttt{m} and \texttt{k} based on expected \texttt{n} and
acceptable error.

\subsubsection{D. Code}\label{d.-code}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define M }\DecValTok{1000}
\DataTypeTok{int}\NormalTok{ bitset}\OperatorTok{[}\NormalTok{M}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{*} \DecValTok{17}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{int}\NormalTok{ hash2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{*} \DecValTok{31} \OperatorTok{+} \DecValTok{7}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    bitset}\OperatorTok{[}\NormalTok{hash1}\OperatorTok{(}\NormalTok{x}\OperatorTok{)]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{    bitset}\OperatorTok{[}\NormalTok{hash2}\OperatorTok{(}\NormalTok{x}\OperatorTok{)]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ contains}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ bitset}\OperatorTok{[}\NormalTok{hash1}\OperatorTok{(}\NormalTok{x}\OperatorTok{)]} \OperatorTok{\&\&}\NormalTok{ bitset}\OperatorTok{[}\NormalTok{hash2}\OperatorTok{(}\NormalTok{x}\OperatorTok{)];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Used in:

\begin{itemize}
\tightlist
\item
  Caches (check before disk lookup)- Spam filters- Databases (join
  filtering)- Blockchain and peer-to-peer networks
\end{itemize}

\subsubsection{2. Count-Min Sketch , ``How often has this
appeared?''}\label{count-min-sketch-how-often-has-this-appeared}

Tracks frequency counts in a stream, using sub-linear memory.

Instead of a full table, it uses a 2D array of counters, each row hashed
with a different hash function.

\subsubsection{A. Insert}\label{a.-insert}

For each row \texttt{i}:

\begin{itemize}
\tightlist
\item
  Compute hash (h\_i(x))- Increment \texttt{count{[}i{]}{[}h\_i(x){]}++}
  \#\#\#\# B. Query
\end{itemize}

For element \texttt{x}:

\begin{itemize}
\tightlist
\item
  Compute all (h\_i(x))- Take \texttt{min(count{[}i{]}{[}h\_i(x){]})}
  across rows → gives an upper-bounded estimate of true frequency
\end{itemize}

\subsubsection{C. Code}\label{c.-code}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define W }\DecValTok{1000}
\PreprocessorTok{\#define D }\DecValTok{5}
\DataTypeTok{int}\NormalTok{ count}\OperatorTok{[}\NormalTok{D}\OperatorTok{][}\NormalTok{W}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{*} \OperatorTok{(}\DecValTok{17}\OperatorTok{*}\NormalTok{i }\OperatorTok{+} \DecValTok{3}\OperatorTok{))} \OperatorTok{\%}\NormalTok{ W}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ D}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        count}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{hash}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{)]++;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ res }\OperatorTok{=}\NormalTok{ INT\_MAX}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ D}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        res }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{res}\OperatorTok{,}\NormalTok{ count}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{hash}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{ x}\OperatorTok{)]);}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Complexity}\label{d.-complexity}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(D) & O(W×D) \\
Query & O(D) & O(W×D) \\
\end{longtable}

Error controlled by: \[
\varepsilon = \frac{1}{W}, \quad \delta = 1 - e^{-D}
\]

Used in:

\begin{itemize}
\tightlist
\item
  Frequency counting in streams- Hot-key detection- Network flow
  analysis- Trending topics
\end{itemize}

\subsubsection{3. HyperLogLog , ``How many unique
items?''}\label{hyperloglog-how-many-unique-items}

Estimates cardinality (number of distinct elements) with very small
memory (\textasciitilde1.5 KB for millions).

\subsubsection{A. Idea}\label{a.-idea-1}

Hash each element uniformly → 32-bit value. Split hash into:

\begin{itemize}
\tightlist
\item
  Prefix bits → bucket index- Suffix bits → count leading zeros Each
  bucket stores the max leading zero count seen. At the end, use
  harmonic mean of counts to estimate distinct values.
\end{itemize}

\subsubsection{B. Formula}\label{b.-formula}

\[
E = \alpha_m \cdot m^2 \cdot \Big(\sum_{i=1}^m 2^{-M[i]}\Big)^{-1}
\]

where \texttt{M{[}i{]}} is the zero count in bucket \texttt{i}, and
\(\alpha_m\) is a correction constant.

Accuracy: \textasciitilde1.04 / √m

\subsubsection{C. Complexity}\label{c.-complexity-1}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Error \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Add & O(1) & O(m) & \textasciitilde1.04/√m \\
Merge & O(m) & O(m) & , \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Web analytics (unique visitors)- Databases (\texttt{COUNT\ DISTINCT})-
  Distributed systems (mergeable estimates)
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-12}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0735}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2206}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2353}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Query
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Memory
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Error
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bloom & Membership & O(k) & Tiny & False positives & No deletions \\
Count-Min & Frequency & O(D) & Small & Overestimate & Streaming
counts \\
HyperLogLog & Cardinality & O(1) & Very small & \textasciitilde1\% &
Mergeable \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-26}

Bloom Filter Demo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add}\OperatorTok{(}\DecValTok{42}\OperatorTok{);}
\NormalTok{add}\OperatorTok{(}\DecValTok{17}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ contains}\OperatorTok{(}\DecValTok{42}\OperatorTok{));} \CommentTok{// 1 (maybe yes)}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ contains}\OperatorTok{(}\DecValTok{99}\OperatorTok{));} \CommentTok{// 0 (definitely no)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-26}

Probabilistic data structures show how approximation beats impossibility
when resources are tight. They make it feasible to process massive
streams in real time, when storing everything is impossible.

They teach a deeper algorithmic truth:

\begin{quote}
``A bit of uncertainty can buy you a world of scalability.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-26}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a Bloom filter with 3 hash functions.
\item
  Measure false positive rate for 10K elements.
\item
  Build a Count-Min Sketch and test frequency estimation.
\item
  Approximate unique elements using HyperLogLog logic.
\item
  Explore real-world systems: Redis (Bloom/CM Sketch), PostgreSQL
  (HyperLogLog).
\end{enumerate}

These tiny probabilistic tools are how big data becomes tractable.

\subsection{28. Skip Lists and B-Trees}\label{skip-lists-and-b-trees}

When you want fast search, insert, and delete but need a structure
that's easier to code than trees or optimized for disk and memory
blocks, two clever ideas step in:

\begin{itemize}
\tightlist
\item
  Skip Lists → randomized, layered linked lists that behave like
  balanced BSTs- B-Trees → multi-way trees that minimize disk I/O and
  organize large data blocks Both guarantee (O\(\log n\)) operations,
  but they shine in very different environments , Skip Lists in-memory,
  B-Trees on disk.
\end{itemize}

\subsubsection{1. Skip Lists}\label{skip-lists}

Invented by: William Pugh (1990) Goal: Simulate binary search using
linked lists with probabilistic shortcuts.

\subsubsection{A. Idea}\label{a.-idea-2}

A skip list is a stack of linked lists, each level skipping over more
elements.

Example:

\begin{verbatim}
Level 3:        ┌───────> 50 ───────┐
Level 2:   ┌──> 10 ─────> 30 ─────> 50 ───┐
Level 1:  5 ──> 10 ──> 20 ──> 30 ──> 40 ──> 50
\end{verbatim}

Higher levels are sparser and let you ``skip'' large chunks of the list.

You search top-down:

\begin{itemize}
\tightlist
\item
  Move right while next ≤ target- Drop down when you can't go further
  This mimics binary search , logarithmic layers, logarithmic hops.
\end{itemize}

\subsubsection{B. Construction}\label{b.-construction}

Each inserted element is given a random height, with geometric
distribution:

\begin{itemize}
\tightlist
\item
  Level 1 (base) always exists- Level 2 with probability ½- Level 3 with
  ¼, etc. Expected total nodes = 2n, Expected height = (O\(\log n\))
\end{itemize}

\subsubsection{C. Operations}\label{c.-operations}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Search & (O\(\log n\)) & O(n) & Randomized balance \\
Insert & (O\(\log n\)) & O(n) & Rebuild towers \\
Delete & (O\(\log n\)) & O(n) & Rewire pointers \\
\end{longtable}

Search Algorithm:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ search}\OperatorTok{(}\NormalTok{SkipList}\OperatorTok{*}\NormalTok{ sl}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ sl}\OperatorTok{{-}\textgreater{}}\NormalTok{head}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ lvl }\OperatorTok{=}\NormalTok{ sl}\OperatorTok{{-}\textgreater{}}\NormalTok{level}\OperatorTok{;}\NormalTok{ lvl }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ lvl}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]{-}\textgreater{}}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{            cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{forward}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ cur}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ NULL}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Skip Lists are simple, fast, and probabilistically balanced , no
rotations, no rebalancing.

\subsubsection{D. Why Use Skip Lists?}\label{d.-why-use-skip-lists}

\begin{itemize}
\item
  Easier to implement than balanced trees- Support concurrent access
  well- Randomized, not deterministic , but highly reliable Used in:
\item
  Redis (sorted sets)- LevelDB / RocksDB internals- Concurrent maps
\end{itemize}

\subsubsection{2. B-Trees}\label{b-trees}

Invented by: Rudolf Bayer \& Ed McCreight (1972) Goal: Reduce disk
access by grouping data in blocks.

A B-Tree is a generalization of a BST:

\begin{itemize}
\tightlist
\item
  Each node holds multiple keys and children- Keys are kept sorted-
  Child subtrees span ranges between keys
\end{itemize}

\subsubsection{A. Structure}\label{a.-structure}

A B-Tree of order \texttt{m}:

\begin{itemize}
\tightlist
\item
  Each node has ≤ \texttt{m} children- Each internal node has
  \texttt{k-1} keys if it has \texttt{k} children- All leaves at the
  same depth Example (order 3):
\end{itemize}

\begin{verbatim}
        [17 | 35]
       /    |     \
 [5 10] [20 25 30] [40 45 50]
\end{verbatim}

\subsubsection{B. Operations}\label{b.-operations}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Search

  \begin{itemize}
  \tightlist
  \item
    Traverse from root - Binary search in each node's key array - Follow
    appropriate child → (O\(\log_m n\))
  \end{itemize}
\item
  Insert

  \begin{itemize}
  \tightlist
  \item
    Insert in leaf - If overflow → split node - Promote median key to
    parent
  \end{itemize}
\item
  Delete

  \begin{itemize}
  \tightlist
  \item
    Borrow or merge if node underflows Each split or merge keeps height
    minimal.
  \end{itemize}
\end{enumerate}

\subsubsection{C. Complexity}\label{c.-complexity-2}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Disk Accesses & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Search & (O\(\log_m n\)) & (O\(\log_m n\)) & m = branching factor \\
Insert & (O\(\log_m n\)) & (O(1)) splits & Balanced \\
Delete & (O\(\log_m n\)) & (O(1)) merges & Balanced \\
\end{longtable}

Height ≈ \(\log_m n\) → very shallow when (m) large (e.g.~100).

\subsubsection{D. B+ Tree Variant}\label{d.-b-tree-variant}

In B+ Trees:

\begin{itemize}
\item
  All data in leaves (internal nodes = indexes)- Leaves linked →
  efficient range queries Used in:
\item
  Databases (MySQL, PostgreSQL)- File systems (NTFS, HFS+)- Key-value
  stores
\end{itemize}

\subsubsection{E. Example Flow}\label{e.-example-flow}

Insert 25:

\begin{verbatim}
[10 | 20 | 30] → overflow
Split → [10] [30]
Promote 20
Root: [20]
\end{verbatim}

\subsubsection{3. Comparison}\label{comparison-13}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Skip List & B-Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Balancing & Randomized & Deterministic \\
Fanout & 2 (linked) & m-way \\
Environment & In-memory & Disk-based \\
Search & O(log n) & O\(log_m n\) \\
Insert/Delete & O(log n) & O\(log_m n\) \\
Concurrency & Easy & Complex \\
Range Queries & Sequential scan & Linked leaves (B+) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-27}

Skip List Search (Conceptual):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ search}\OperatorTok{(}\NormalTok{SkipList}\OperatorTok{*}\NormalTok{ list}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ list}\OperatorTok{{-}\textgreater{}}\NormalTok{head}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ lvl }\OperatorTok{=}\NormalTok{ list}\OperatorTok{{-}\textgreater{}}\NormalTok{level}\OperatorTok{;}\NormalTok{ lvl }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ lvl}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{]{-}\textgreater{}}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ key}\OperatorTok{)}
\NormalTok{            cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{lvl}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    cur }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\DecValTok{0}\OperatorTok{];}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\&\&}\NormalTok{ cur}\OperatorTok{{-}\textgreater{}}\NormalTok{key }\OperatorTok{==}\NormalTok{ key}\OperatorTok{)} \OperatorTok{?}\NormalTok{ cur }\OperatorTok{:}\NormalTok{ NULL}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

B-Tree Node (Skeleton):

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define M }\DecValTok{4}
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ keys}\OperatorTok{[}\NormalTok{M}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ child}\OperatorTok{[}\NormalTok{M}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ n}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-27}

Skip Lists and B-Trees show two paths to balance:

\begin{itemize}
\tightlist
\item
  Randomized simplicity (Skip List)- Block-based order (B-Tree) Both
  offer logarithmic guarantees, but one optimizes pointer chasing, the
  other I/O.
\end{itemize}

They're fundamental to:

\begin{itemize}
\tightlist
\item
  In-memory caches (Skip List)- On-disk indexes (B-Tree, B+ Tree)-
  Sorted data structures across systems
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-27}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a basic skip list and insert random keys.
\item
  Trace a search path across levels.
\item
  Implement B-Tree insert and split logic.
\item
  Compare height of BST vs B-Tree for 1,000 keys.
\item
  Explore how Redis and MySQL use these internally.
\end{enumerate}

Together, they form the bridge between linked lists and balanced trees,
uniting speed, structure, and scalability.

\subsection{29. Persistent and Functional Data
Structures}\label{persistent-and-functional-data-structures}

Most data structures are ephemeral , when you update them, the old
version disappears. But sometimes, you want to keep all past versions,
so you can go back in time, undo operations, or run concurrent reads
safely.

That's the magic of persistent data structures: every update creates a
new version while sharing most of the old structure.

This section introduces the idea of persistence, explores how to make
classic structures like arrays and trees persistent, and explains why
functional programming loves them.

\subsubsection{1. What Is Persistence?}\label{what-is-persistence}

A persistent data structure preserves previous versions after updates.
You can access any version , past or present , without side effects.

Three levels:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1184}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6842}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1974}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Partial & Can access past versions, but only modify the latest & Undo
stack \\
Full & Can access and modify any version & Immutable map \\
Confluent & Can combine different versions & Git-like merges \\
\end{longtable}

This is essential in functional programming, undo systems, version
control, persistent segment trees, and immutable databases.

\subsubsection{2. Ephemeral vs
Persistent}\label{ephemeral-vs-persistent}

Ephemeral:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arr}\OperatorTok{[}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \DecValTok{7}\OperatorTok{;} \CommentTok{// old value lost forever}
\end{Highlighting}
\end{Shaded}

Persistent:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_arr }\OperatorTok{=}\NormalTok{ update}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{7}\OperatorTok{);} \CommentTok{// old\_arr still exists}
\end{Highlighting}
\end{Shaded}

Persistent structures use structural sharing , unchanged parts are
reused, not copied.

\subsubsection{3. Persistent Linked List}\label{persistent-linked-list}

Easiest example: each update creates a new head, reusing the tail.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{;}\NormalTok{ Node}\OperatorTok{*}\NormalTok{ next}\OperatorTok{;} \OperatorTok{\};}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ push}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ head}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ newHead }\OperatorTok{=}\NormalTok{ malloc}\OperatorTok{(}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
\NormalTok{    newHead}\OperatorTok{{-}\textgreater{}}\NormalTok{val }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
\NormalTok{    newHead}\OperatorTok{{-}\textgreater{}}\NormalTok{next }\OperatorTok{=}\NormalTok{ head}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ newHead}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Now both \texttt{old\_head} and \texttt{new\_head} coexist. Each version
is immutable , you never change existing nodes.

Access: old and new lists share most of their structure:

\begin{verbatim}
v0: 1 → 2 → 3
v1: 0 → 1 → 2 → 3
\end{verbatim}

Only one new node was created.

\subsubsection{4. Persistent Binary Tree}\label{persistent-binary-tree}

For trees, updates create new paths from the root to the modified node,
reusing the rest.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ update}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pos}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{val}\OperatorTok{);}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ node }\OperatorTok{=}\NormalTok{ malloc}\OperatorTok{(}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
    \OperatorTok{*}\NormalTok{node }\OperatorTok{=} \OperatorTok{*}\NormalTok{root}\OperatorTok{;} \CommentTok{// copy}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)}\NormalTok{ node}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{=}\NormalTok{ update}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{else}\NormalTok{ node}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ update}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ node}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Each \texttt{update} creates a new version , only (O\(\log n\)) new
nodes per change.

This is the core of persistent segment trees used in competitive
programming.

\subsubsection{5. Persistent Array (Functional
Trick)}\label{persistent-array-functional-trick}

Arrays are trickier because of random access. Solutions:

\begin{itemize}
\item
  Use balanced binary trees as array replacements- Each update replaces
  one node- Persistent vector = tree of small arrays (used in Clojure,
  Scala) This gives:
\item
  Access: (O\(\log n\))- Update: (O\(\log n\))- Space: (O\(\log n\)) per
  update
\end{itemize}

\subsubsection{6. Persistent Segment
Tree}\label{persistent-segment-tree}

Used for versioned range queries:

\begin{itemize}
\tightlist
\item
  Each update = new root- Each version = snapshot of history Example:
  Track how array changes over time, query ``sum in range {[}L,R{]} at
  version t''.
\end{itemize}

Build:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ build}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{L}\OperatorTok{]);}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L}\OperatorTok{+}\NormalTok{R}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}
\NormalTok{        build}\OperatorTok{(}\NormalTok{L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{),}
\NormalTok{        build}\OperatorTok{(}\NormalTok{mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{),}
\NormalTok{        sum}
    \OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Update: only (O\(\log n\)) new nodes

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ update}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ prev}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ L}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ R}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pos}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ val}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{L }\OperatorTok{==}\NormalTok{ R}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{val}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{L}\OperatorTok{+}\NormalTok{R}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{\textless{}=}\NormalTok{ mid}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{update}\OperatorTok{(}\NormalTok{prev}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ L}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{),}\NormalTok{ prev}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{);}
    \ControlFlowTok{else}
        \ControlFlowTok{return}\NormalTok{ newNode}\OperatorTok{(}\NormalTok{prev}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ update}\OperatorTok{(}\NormalTok{prev}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{,}\NormalTok{ val}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Each version = new root; old ones still valid.

\subsubsection{7. Functional Perspective}\label{functional-perspective}

In functional programming, data is immutable by default. Instead of
mutating, you create a new version.

This allows:

\begin{itemize}
\tightlist
\item
  Thread-safety (no races)- Time-travel debugging- Undo/redo systems-
  Concurrency without locks Languages like Haskell, Clojure, and Elm
  build everything this way.
\end{itemize}

For example, Clojure's \texttt{persistent\ vector} uses path copying and
branching factor 32 for (O\(\log_{32} n\)) access.

\subsubsection{8. Applications}\label{applications-2}

\begin{itemize}
\tightlist
\item
  Undo / Redo stacks (text editors, IDEs)- Version control (Git trees)-
  Immutable databases (Datomic)- Segment trees over time (competitive
  programming)- Snapshots in memory allocators or games
\end{itemize}

\subsubsection{9. Complexity}\label{complexity-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2361}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Access
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space per Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Persistent Linked List & O(1) & O(1) & O(1) & Simple sharing \\
Persistent Tree & O(log n) & O(log n) & O(log n) & Path copying \\
Persistent Array & O(log n) & O(log n) & O(log n) & Tree-backed \\
Persistent Segment Tree & O(log n) & O(log n) & O(log n) & Versioned
queries \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-28}

Persistent Linked List Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ v0 }\OperatorTok{=}\NormalTok{ NULL}\OperatorTok{;}
\NormalTok{v0 }\OperatorTok{=}\NormalTok{ push}\OperatorTok{(}\NormalTok{v0}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{v0 }\OperatorTok{=}\NormalTok{ push}\OperatorTok{(}\NormalTok{v0}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{Node}\OperatorTok{*}\NormalTok{ v1 }\OperatorTok{=}\NormalTok{ push}\OperatorTok{(}\NormalTok{v0}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\CommentTok{// v0 = [2,3], v1 = [1,2,3]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-28}

Persistence is about time as a first-class citizen. It lets you:

\begin{itemize}
\tightlist
\item
  Roll back- Compare versions- Work immutably and safely It's the
  algorithmic foundation behind functional programming, time-travel
  debugging, and immutable data systems.
\end{itemize}

It teaches this powerful idea:

\begin{quote}
``Never destroy , always build upon what was.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-28}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a persistent stack using linked lists.
\item
  Write a persistent segment tree for range sums.
\item
  Track array versions after each update and query old states.
\item
  Compare space/time with an ephemeral one.
\item
  Explore persistent structures in Clojure (\texttt{conj},
  \texttt{assoc}) or Rust (\texttt{im} crate).
\end{enumerate}

Persistence transforms data from fleeting state into a history you can
navigate , a timeline of structure and meaning.

\subsection{30. Advanced Trees and Range
Queries}\label{advanced-trees-and-range-queries}

So far, you've seen balanced trees (AVL, Red-Black, Treap) and
segment-based structures (Segment Trees, Fenwick Trees). Now it's time
to combine those ideas and step into advanced trees , data structures
that handle dynamic sets, order statistics, intervals, ranges, and
geometry-like queries in logarithmic time.

This chapter is about trees that go beyond search , they store order,
track ranges, and answer complex queries efficiently.

We'll explore:

\begin{itemize}
\tightlist
\item
  Order Statistic Trees (k-th element, rank queries)- Interval Trees
  (range overlaps)- Range Trees (multi-dimensional search)- KD-Trees
  (spatial partitioning)- Merge Sort Trees (offline range queries)
\end{itemize}

\subsubsection{1. Order Statistic Tree}\label{order-statistic-tree}

Goal: find the k-th smallest element, or the rank of an element, in
(O\(\log n\)).

Built on top of a balanced BST (e.g.~Red-Black) by storing subtree
sizes.

\subsubsection{A. Augmented Tree Nodes}\label{a.-augmented-tree-nodes}

Each node keeps:

\begin{itemize}
\tightlist
\item
  \texttt{key}: element value- \texttt{left}, \texttt{right}: children-
  \texttt{size}: number of nodes in subtree
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ size}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Whenever you rotate or insert, update \texttt{size}:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{?}\NormalTok{ n}\OperatorTok{{-}\textgreater{}}\NormalTok{size }\OperatorTok{:} \DecValTok{0}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{void}\NormalTok{ update\_size}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n}\OperatorTok{)}\NormalTok{ n}\OperatorTok{{-}\textgreater{}}\NormalTok{size }\OperatorTok{=}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{+}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Find k-th Element}\label{b.-find-k-th-element}

Recursively use subtree sizes:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ kth}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ k}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ left }\OperatorTok{=}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k }\OperatorTok{==}\NormalTok{ left }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textless{}=}\NormalTok{ left}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ kth}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ k}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{return}\NormalTok{ kth}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ k }\OperatorTok{{-}}\NormalTok{ left }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: (O\(\log n\))

\subsubsection{C. Find Rank}\label{c.-find-rank}

Find position of a key (number of smaller elements):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ rank}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textless{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ rank}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{key }\OperatorTok{\textgreater{}}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{key}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{+} \DecValTok{1} \OperatorTok{+}\NormalTok{ rank}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ key}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ get\_size}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Used in:

\begin{itemize}
\tightlist
\item
  Databases (ORDER BY, pagination)- Quantile queries- Online median
  maintenance
\end{itemize}

\subsubsection{2. Interval Tree}\label{interval-tree}

Goal: find all intervals overlapping with a given point or range.

Used in computational geometry, scheduling, and genomic data.

\subsubsection{A. Structure}\label{a.-structure-1}

BST ordered by interval low endpoint. Each node stores:

\begin{itemize}
\tightlist
\item
  \texttt{low}, \texttt{high}: interval bounds- \texttt{max}: maximum
  \texttt{high} in its subtree
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{,}\NormalTok{ max}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Query Overlap}\label{b.-query-overlap}

Check if \texttt{x} overlaps \texttt{node-\textgreater{}interval}: If
not, go left or right based on \texttt{max} values.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ overlap}\OperatorTok{(}\NormalTok{Interval a}\OperatorTok{,}\NormalTok{ Interval b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{.}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ b}\OperatorTok{.}\NormalTok{high }\OperatorTok{\&\&}\NormalTok{ b}\OperatorTok{.}\NormalTok{low }\OperatorTok{\textless{}=}\NormalTok{ a}\OperatorTok{.}\NormalTok{high}\OperatorTok{;}
\OperatorTok{\}}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{Node}\OperatorTok{*}\NormalTok{ root}\OperatorTok{,}\NormalTok{ Interval q}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ NULL}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{overlap}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{interval}\OperatorTok{,}\NormalTok{ q}\OperatorTok{))} \ControlFlowTok{return}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left }\OperatorTok{\&\&}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{{-}\textgreater{}}\NormalTok{max }\OperatorTok{\textgreater{}=}\NormalTok{ q}\OperatorTok{.}\NormalTok{low}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{left}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{right}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time: (O\(\log n\)) average

\subsubsection{C. Use Cases}\label{c.-use-cases}

\begin{itemize}
\tightlist
\item
  Calendar/schedule conflict detection- Collision detection- Genome
  region lookup- Segment intersection
\end{itemize}

\subsubsection{3. Range Tree}\label{range-tree}

Goal: multi-dimensional queries like

\begin{quote}
``How many points fall inside rectangle {[}x1, x2{]} × {[}y1, y2{]}?''
\end{quote}

Structure:

\begin{itemize}
\tightlist
\item
  Primary BST on x- Each node stores secondary BST on y Query time:
  (O\(\log^2 n\)) Space: (O\(n \log n\))
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  2D search- Computational geometry- Databases (spatial joins)
\end{itemize}

\subsubsection{4. KD-Tree}\label{kd-tree}

Goal: efficiently search points in k-dimensional space.

Alternate splitting dimensions at each level:

\begin{itemize}
\item
  Level 0 → split by x- Level 1 → split by y- Level 2 → split by z Each
  node stores:
\item
  Point (vector)- Split axis Used for:
\item
  Nearest neighbor search- Range queries- ML (k-NN classifiers) Time:
\item
  Build: (O\(n \log n\))- Query: (O\(\sqrt{n}\)) average in 2D
\end{itemize}

\subsubsection{5. Merge Sort Tree}\label{merge-sort-tree}

Goal: query ``number of elements ≤ k in range {[}L, R{]}''

Built like a segment tree, but each node stores a sorted list of its
range.

Build: merge children lists Query: binary search in node lists

Time:

\begin{itemize}
\tightlist
\item
  Build: (O\(n \log n\))- Query: (O\(\log^2 n\)) Used in offline queries
  and order-statistics over ranges.
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-14}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1600}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1733}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3467}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tree Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Query
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Update
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Order Statistic & k-th, rank & O(log n) & O(log n) & Augmented BST \\
Interval & Overlaps & O(log n + k) & O(log n) & Store intervals \\
Range Tree & 2D range & O(log² n + k) & O(log² n) & Multi-dim \\
KD-Tree & Spatial & O(√n) avg & O(log n) & Nearest neighbor \\
Merge Sort Tree & Offline rank & O(log² n) & Static & Built from sorted
segments \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-29}

Order Statistic Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Node}\OperatorTok{*}\NormalTok{ root }\OperatorTok{=}\NormalTok{ NULL}\OperatorTok{;}
\NormalTok{root }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{10}\OperatorTok{);}
\NormalTok{root }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{20}\OperatorTok{);}
\NormalTok{root }\OperatorTok{=}\NormalTok{ insert}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{30}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ kth}\OperatorTok{(}\NormalTok{root}\OperatorTok{,} \DecValTok{2}\OperatorTok{){-}\textgreater{}}\NormalTok{key}\OperatorTok{);} \CommentTok{// 20}
\end{Highlighting}
\end{Shaded}

Interval Query:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Interval q }\OperatorTok{=} \OperatorTok{\{}\DecValTok{15}\OperatorTok{,} \DecValTok{17}\OperatorTok{\};}
\NormalTok{Node}\OperatorTok{*}\NormalTok{ res }\OperatorTok{=}\NormalTok{ overlap\_search}\OperatorTok{(}\NormalTok{root}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{res}\OperatorTok{)}\NormalTok{ printf}\OperatorTok{(}\StringTok{"Overlap: [}\SpecialCharTok{\%d}\StringTok{, }\SpecialCharTok{\%d}\StringTok{]}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ res}\OperatorTok{{-}\textgreater{}}\NormalTok{low}\OperatorTok{,}\NormalTok{ res}\OperatorTok{{-}\textgreater{}}\NormalTok{high}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-29}

These trees extend balance into dimensions and ranges. They let you
query ordered data efficiently: ``How many?'', ``Which overlaps?'',
``Where is k-th smallest?''.

They teach a deeper design principle:

\begin{quote}
``Augment structure with knowledge , balance plus metadata equals
power.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-29}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement an order statistic tree , test rank/k-th queries.
\item
  Insert intervals and test overlap detection.
\item
  Build a simple KD-tree for 2D points.
\item
  Solve rectangle counting with a range tree.
\item
  Precompute a merge sort tree for offline queries.
\end{enumerate}

These advanced trees form the final evolution of structured queries ,
blending geometry, order, and logarithmic precision.

\section{Chapter 4. Graph
Algorithms}\label{chapter-4.-graph-algorithms-1}

\subsection{31. Traversals (DFS, BFS, Iterative
Deepening)}\label{traversals-dfs-bfs-iterative-deepening}

Graphs are everywhere , maps, networks, dependencies, state spaces.
Before you can analyze them, you need a way to visit their vertices ,
systematically, without getting lost or looping forever.

That's where graph traversals come in. They're the foundation for
everything that follows: connected components, shortest paths, spanning
trees, topological sorts, and more.

This section walks through the three pillars:

\begin{itemize}
\tightlist
\item
  DFS (Depth-First Search) , explore deeply before backtracking- BFS
  (Breadth-First Search) , explore level by level- Iterative Deepening ,
  a memory-friendly hybrid
\end{itemize}

\subsubsection{1. Representing Graphs}\label{representing-graphs}

Before traversal, you need a good structure.

Adjacency List (most common):

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define MAX }\DecValTok{1000}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

Add edges:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ add\_edge}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{    adj}\OperatorTok{[}\NormalTok{v}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);} \CommentTok{// omit if directed}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Track visited vertices:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ visited}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Depth-First Search
(DFS)}\label{depth-first-search-dfs-1}

DFS dives deep, following one branch fully before exploring others. It's
recursive, like exploring a maze by always turning left until you hit a
wall.

\subsubsection{A. Recursive Form}\label{a.-recursive-form}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Start it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfs}\OperatorTok{(}\NormalTok{start\_node}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Iterative Form (with
Stack)}\label{b.-iterative-form-with-stack}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs\_iter}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    stack}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ s}\OperatorTok{;}
\NormalTok{    s}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{start}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{s}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ s}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ s}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ s}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Complexity}\label{c.-complexity-3}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Graph Type & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adjacency List & O(V + E) & O(V) \\
\end{longtable}

DFS is used in:

\begin{itemize}
\tightlist
\item
  Connected components- Cycle detection- Topological sort- Backtracking
  \& search- Articulation points / bridges
\end{itemize}

\subsubsection{3. Breadth-First Search
(BFS)}\label{breadth-first-search-bfs-1}

BFS explores neighbors first , it's like expanding in waves. This
guarantees shortest path in unweighted graphs.

\subsubsection{A. BFS with Queue}\label{a.-bfs-with-queue}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{start}\OperatorTok{);}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Track Distance}\label{b.-track-distance}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{void}\NormalTok{ bfs\_dist}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ MAX}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Now \texttt{dist{[}v{]}} gives shortest distance from \texttt{s}.

\subsubsection{C. Complexity}\label{c.-complexity-4}

Same as DFS:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
O(V + E) & O(V) \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Shortest paths (unweighted)- Level-order traversal- Bipartite check-
  Connected components
\end{itemize}

\subsubsection{4. Iterative Deepening Search
(IDS)}\label{iterative-deepening-search-ids}

DFS is memory-light but might go too deep. BFS is optimal but can use a
lot of memory. Iterative Deepening Search (IDS) combines both.

It performs DFS with increasing depth limits:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ dls}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ depth}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ target}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{depth }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dls}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ target}\OperatorTok{,}\NormalTok{ depth }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{))} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ ids}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ max\_depth}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ max\_depth}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dls}\OperatorTok{(}\NormalTok{start}\OperatorTok{,}\NormalTok{ target}\OperatorTok{,}\NormalTok{ d}\OperatorTok{))} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Used in:

\begin{itemize}
\tightlist
\item
  AI search problems (state spaces)- Game trees (chess, puzzles)
\end{itemize}

\subsubsection{5. Traversal Order
Examples}\label{traversal-order-examples}

For a graph:

\begin{verbatim}
1 - 2 - 3
|   |
4 - 5
\end{verbatim}

DFS (starting at 1): 1 → 2 → 3 → 5 → 4 BFS (starting at 1): 1 → 2 → 4 →
3 → 5

\subsubsection{6. Directed vs Undirected}\label{directed-vs-undirected}

\begin{itemize}
\item
  Undirected: mark both directions- Directed: follow edge direction only
  DFS on directed graphs is core to:
\item
  SCC (Strongly Connected Components)- Topological Sorting- Reachability
  analysis
\end{itemize}

\subsubsection{7. Traversal Trees}\label{traversal-trees}

Each traversal implicitly builds a spanning tree:

\begin{itemize}
\item
  DFS Tree: based on recursion- BFS Tree: based on levels Use them to:
\item
  Detect cross edges, back edges- Classify edges (important for
  algorithms like Tarjan's)
\end{itemize}

\subsubsection{8. Comparison}\label{comparison-15}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3714}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Aspect
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
DFS
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
BFS
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strategy & Deep first & Level-wise \\
Space & O(V) (stack) & O(V) (queue) \\
Path Optimality & Not guaranteed & Yes (unweighted) \\
Applications & Cycle detection, backtracking & Shortest path, level
order \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-30}

DFS + BFS Combo:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ traverse}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ visited}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
\NormalTok{    dfs}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ visited}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
\NormalTok{    bfs}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-30}

DFS and BFS are the roots of graph theory in practice. Every algorithm
you'll meet later , shortest paths, flows, SCCs , builds upon them.

They teach you how to navigate structure, how to systematically explore
unknowns, and how search lies at the heart of computation.

\subsubsection{Try It Yourself}\label{try-it-yourself-30}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build an adjacency list and run DFS/BFS from vertex 1.
\item
  Track discovery and finish times in DFS.
\item
  Use BFS to compute shortest paths in an unweighted graph.
\item
  Modify DFS to count connected components.
\item
  Implement IDS for a puzzle like the 8-puzzle.
\end{enumerate}

Graph traversal is the art of exploration , once you master it, the rest
of graph theory falls into place.

\subsection{32. Strongly Connected Components (Tarjan,
Kosaraju)}\label{strongly-connected-components-tarjan-kosaraju}

In directed graphs, edges have direction, so connectivity gets tricky.
It's not enough for vertices to be reachable , you need mutual
reachability.

That's the essence of a strongly connected component (SCC):

\begin{quote}
A set of vertices where every vertex can reach every other vertex.
\end{quote}

Think of SCCs as islands of mutual connectivity , inside, you can go
anywhere; outside, you can't. They're the building blocks for
simplifying directed graphs into condensation DAGs (no cycles).

We'll explore two classic algorithms:

\begin{itemize}
\tightlist
\item
  Kosaraju's Algorithm , clean, intuitive, two-pass- Tarjan's Algorithm
  , one-pass, stack-based elegance
\end{itemize}

\subsubsection{1. Definition}\label{definition}

A Strongly Connected Component (SCC) in a directed graph ( G = (V, E) )
is a maximal subset of vertices \(C \subseteq V\) such that for every
pair ( (u, v) \in C ): \(u \to v\) and \(v \to u\).

In other words, every node in (C) is reachable from every other node in
(C).

Example:

\begin{verbatim}
1 → 2 → 3 → 1   forms an SCC  
4 → 5           separate SCCs
\end{verbatim}

\subsubsection{2. Applications}\label{applications-3}

\begin{itemize}
\tightlist
\item
  Condensation DAG: compress SCCs into single nodes , no cycles remain.-
  Component-based reasoning: topological sorting on DAG of SCCs.-
  Program analysis: detecting cycles, dependencies.- Web graphs: find
  clusters of mutually linked pages.- Control-flow: loops and strongly
  connected subroutines.
\end{itemize}

\subsubsection{3. Kosaraju's Algorithm}\label{kosarajus-algorithm}

A simple two-pass algorithm using DFS and graph reversal.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run DFS and push nodes onto a stack in finish-time order.
\item
  Reverse the graph (edges flipped).
\item
  Pop nodes from stack; DFS on reversed graph; each DFS = one SCC.
\end{enumerate}

\subsubsection{A. Implementation}\label{a.-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ rev}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ visited}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{stack}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ st}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ sccs}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ dfs1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            dfs1}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{    st}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ dfs2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ comp}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{    comp}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ rev}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            dfs2}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ comp}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ kosaraju}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \CommentTok{// Pass 1: order by finish time}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ dfs1}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}

    \CommentTok{// Reverse graph}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{            rev}\OperatorTok{[}\NormalTok{v}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}

    \CommentTok{// Pass 2: collect SCCs}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{visited}\OperatorTok{,}\NormalTok{ visited }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{st}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ st}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ st}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ comp}\OperatorTok{;}
\NormalTok{            dfs2}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ comp}\OperatorTok{);}
\NormalTok{            sccs}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{comp}\OperatorTok{);}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: (O(V + E)) , two DFS passes.

Space Complexity: (O(V + E))

\subsubsection{B. Example}\label{b.-example-1}

Graph:

\begin{verbatim}
1 → 2 → 3  
↑   ↓   ↓  
5 ← 4 ← 6
\end{verbatim}

SCCs:

\begin{itemize}
\tightlist
\item
  \{1,2,4,5\}- \{3,6\}
\end{itemize}

\subsubsection{4. Tarjan's Algorithm}\label{tarjans-algorithm}

More elegant: one DFS pass, no reversal, stack-based. It uses discovery
times and low-link values to detect SCC roots.

\subsubsection{A. Idea}\label{a.-idea-3}

\begin{itemize}
\tightlist
\item
  \texttt{disc{[}u{]}}: discovery time of node \texttt{u}-
  \texttt{low{[}u{]}}: smallest discovery time reachable from
  \texttt{u}- A node is root of an SCC if
  \texttt{disc{[}u{]}\ ==\ low{[}u{]}} Maintain a stack of active nodes
  (in current DFS path).
\end{itemize}

\subsubsection{B. Implementation}\label{b.-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ disc}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ low}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ timer}\OperatorTok{;}
\DataTypeTok{bool}\NormalTok{ inStack}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{stack}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ st}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ sccs}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ dfs\_tarjan}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    disc}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \OperatorTok{++}\NormalTok{timer}\OperatorTok{;}
\NormalTok{    st}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
\NormalTok{    inStack}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{disc}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dfs\_tarjan}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{            low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
        \OperatorTok{\}} \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{inStack}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ disc}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{disc}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{==}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ comp}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ st}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ st}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{            inStack}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
\NormalTok{            comp}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ u}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
        \OperatorTok{\}}
\NormalTok{        sccs}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{comp}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ tarjan}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{disc}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{            dfs\_tarjan}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: (O(V + E))

Space Complexity: (O(V))

\subsubsection{C. Walkthrough}\label{c.-walkthrough}

Graph:

\begin{verbatim}
1 → 2 → 3  
↑   ↓   ↓  
5 ← 4 ← 6
\end{verbatim}

DFS visits nodes in order; when it finds a node whose
\texttt{disc\ ==\ low}, it pops from the stack to form an SCC.

Result:

\begin{verbatim}
SCC1: 1 2 4 5
SCC2: 3 6
\end{verbatim}

\subsubsection{5. Comparison}\label{comparison-16}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Kosaraju & Tarjan \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS Passes & 2 & 1 \\
Reversal Needed & Yes & No \\
Stack & Yes (finish order) & Yes (active path) \\
Implementation & Simple conceptually & Compact, efficient \\
Time & O(V + E) & O(V + E) \\
\end{longtable}

\subsubsection{6. Condensation Graph}\label{condensation-graph}

Once SCCs are found, you can build a DAG: Each SCC becomes a node, edges
represent cross-SCC connections. Topological sorting now applies.

Used in:

\begin{itemize}
\tightlist
\item
  Dependency analysis- Strong component compression- DAG dynamic
  programming
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-31}

Print SCCs (Tarjan):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tarjan}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{\&}\NormalTok{comp }\OperatorTok{:}\NormalTok{ sccs}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ x }\OperatorTok{:}\NormalTok{ comp}\OperatorTok{)}\NormalTok{ printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-31}

SCC algorithms turn chaotic directed graphs into structured DAGs.
They're the key to reasoning about cycles, dependencies, and modularity.

Understanding them reveals a powerful truth:

\begin{quote}
``Every complex graph can be reduced to a simple hierarchy , once you
find its strongly connected core.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-31}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement both Kosaraju and Tarjan , verify they match.
\item
  Build SCC DAG and run topological sort on it.
\item
  Detect cycles via SCC size \textgreater{} 1.
\item
  Use SCCs to solve 2-SAT (boolean satisfiability).
\item
  Visualize condensation of a graph with 6 nodes.
\end{enumerate}

Once you can find SCCs, you can tame directionality , transforming messy
networks into ordered systems.

\subsection{33. Shortest Paths (Dijkstra, Bellman-Ford, A*,
Johnson)}\label{shortest-paths-dijkstra-bellman-ford-a-johnson}

Once you can traverse a graph, the next natural question is:

\begin{quote}
``What is the shortest path between two vertices?''
\end{quote}

Shortest path algorithms are the heart of routing, navigation, planning,
and optimization. They compute minimal cost paths , whether distance,
time, or weight , and adapt to different edge conditions (non-negative,
negative, heuristic).

This section covers the most essential algorithms:

\begin{itemize}
\tightlist
\item
  Dijkstra's Algorithm , efficient for non-negative weights-
  Bellman-Ford Algorithm , handles negative edges- A* , best-first with
  heuristics- Johnson's Algorithm , all-pairs shortest paths in sparse
  graphs
\end{itemize}

\subsubsection{1. The Shortest Path
Problem}\label{the-shortest-path-problem}

Given a weighted graph ( G = (V, E) ) and a source ( s ), find
\(\text{dist}[v]\), the minimum total weight to reach every vertex ( v
).

Variants:

\begin{itemize}
\tightlist
\item
  Single-source shortest path (SSSP) , one source to all- Single-pair ,
  one source to one target- All-pairs shortest path (APSP) , every pair-
  Dynamic shortest path , with updates
\end{itemize}

\subsubsection{2. Dijkstra's Algorithm}\label{dijkstras-algorithm}

Best for non-negative weights. Idea: explore vertices in increasing
distance order, like water spreading.

\subsubsection{A. Steps}\label{a.-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize all distances to infinity.
\item
  Set source distance = 0.
\item
  Use a priority queue to always pick the node with smallest tentative
  distance.
\item
  Relax all outgoing edges.
\end{enumerate}

\subsubsection{B. Implementation (Adjacency
List)}\label{b.-implementation-adjacency-list}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}bits/stdc++.h\textgreater{}}
\NormalTok{using namespace std}\OperatorTok{;}

\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];} \CommentTok{// (neighbor, weight)}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ dijkstra}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{},}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\DecValTok{0}\OperatorTok{,}\NormalTok{ s}\OperatorTok{\});}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{d}\OperatorTok{,}\NormalTok{ u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{d }\OperatorTok{!=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
\NormalTok{                pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ v}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Using priority queue (binary heap): \(O((V + E)\log V)\)
\item
  Space: \(O(V + E)\)
\end{itemize}

\subsubsection{C. Example}\label{c.-example}

Graph:

\begin{verbatim}
1 →(2) 2 →(3) 3
↓(4)       ↑(1)
4 →(2)─────┘
\end{verbatim}

\texttt{dijkstra(1)} gives shortest distances:

\begin{verbatim}
dist[1] = 0  
dist[2] = 2  
dist[3] = 5  
dist[4] = 4
\end{verbatim}

\subsubsection{D. Properties}\label{d.-properties}

\begin{itemize}
\tightlist
\item
  Works only if all edges \(w \ge 0\)- Can reconstruct path via
  \texttt{parent{[}v{]}}- Used in:

  \begin{itemize}
  \tightlist
  \item
    GPS and routing systems - Network optimization - Scheduling with
    positive costs
  \end{itemize}
\end{itemize}

\subsubsection{3. Bellman-Ford Algorithm}\label{bellman-ford-algorithm}

Handles negative edge weights, and detects negative cycles.

\subsubsection{A. Idea}\label{a.-idea-4}

Relax all edges (V-1) times. If on (V)-th iteration you can still relax
→ negative cycle exists.

\subsubsection{B. Implementation}\label{b.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Edge }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ edges}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{bool}\NormalTok{ bellman\_ford}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto}\NormalTok{ e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ e}\OperatorTok{.}\NormalTok{w }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{])}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ e}\OperatorTok{.}\NormalTok{w}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \CommentTok{// Check for negative cycle}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto}\NormalTok{ e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ e}\OperatorTok{.}\NormalTok{w }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{])}
            \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;} \CommentTok{// negative cycle}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O(VE)) Works even when (w \textless{} 0).

\subsubsection{C. Example}\label{c.-example-1}

Graph:

\begin{verbatim}
1 →(2) 2 →(-5) 3 →(2) 4
\end{verbatim}

Bellman-Ford finds path 1→2→3→4 with total cost (-1).

If a cycle reduces total weight indefinitely, algorithm detects it.

\subsubsection{D. Use Cases}\label{d.-use-cases}

\begin{itemize}
\tightlist
\item
  Currency exchange arbitrage- Game graphs with penalties- Detecting
  impossible constraints
\end{itemize}

\subsubsection{4. A* Search Algorithm}\label{a-search-algorithm}

Heuristic-guided shortest path, perfect for pathfinding (AI, maps,
games).

It combines actual cost and estimated cost: \[
f(v) = g(v) + h(v)
\] where

\begin{itemize}
\tightlist
\item
  (g(v)): known cost so far- (h(v)): heuristic estimate (must be
  admissible)
\end{itemize}

\subsubsection{A. Pseudocode}\label{a.-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{},}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{h}\OperatorTok{[}\NormalTok{start}\OperatorTok{],}\NormalTok{ start}\OperatorTok{\});}

\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
    \KeywordTok{auto} \OperatorTok{[}\NormalTok{f}\OperatorTok{,}\NormalTok{ u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ goal}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ new\_g }\OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{new\_g }\OperatorTok{\textless{}}\NormalTok{ g}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            g}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ new\_g}\OperatorTok{;}
\NormalTok{            pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{g}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+}\NormalTok{ h}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ v}\OperatorTok{\});}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Heuristic Example:

\begin{itemize}
\tightlist
\item
  Euclidean distance (for grids)- Manhattan distance (for 4-direction
  movement)
\end{itemize}

\subsubsection{B. Use Cases}\label{b.-use-cases}

\begin{itemize}
\tightlist
\item
  Game AI (pathfinding)- Robot motion planning- Map navigation
  Complexity: (O(E)) in best case, depends on heuristic quality.
\end{itemize}

\subsubsection{5. Johnson's Algorithm}\label{johnsons-algorithm}

Goal: All-Pairs Shortest Path in sparse graphs with negative edges (no
negative cycles).

Idea:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add new vertex \texttt{q} connected to all others with edge weight 0
\item
  Run Bellman-Ford from \texttt{q} to get potential \texttt{h(v)}
\item
  Reweight edges: (w'(u, v) = w(u, v) + h(u) - h(v)) (now all weights ≥
  0)
\item
  Run Dijkstra from each vertex
\end{enumerate}

Complexity: (O\(VE + V^2 \log V\))

\subsubsection{6. Summary}\label{summary-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2353}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2157}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0882}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1961}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handles Negative Weights
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Detects Negative Cycle
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Heuristic
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Dijkstra & No & No & No & O((V+E) log V) & Non-negative weights \\
Bellman-Ford & Yes & Yes & No & O(VE) & Negative edges \\
A* & No (unless careful) & No & Yes & Depends & Pathfinding \\
Johnson & Yes (no neg. cycles) & Yes & No & O(VE + V log V) & All-pairs,
sparse \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-32}

Dijkstra Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dijkstra}\OperatorTok{(}\NormalTok{n}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"dist[}\SpecialCharTok{\%d}\StringTok{] = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-32}

Shortest paths are the essence of optimization , not just in graphs, but
in reasoning: finding minimal cost, minimal distance, minimal risk.

These algorithms teach:

\begin{quote}
``The path to a goal isn't random , it's guided by structure, weight,
and knowledge.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-32}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a weighted graph and compare Dijkstra vs Bellman-Ford.
\item
  Introduce a negative edge and observe Bellman-Ford detecting it.
\item
  Implement A* on a grid with obstacles.
\item
  Use Dijkstra to plan routes in a city map dataset.
\item
  Try Johnson's algorithm for all-pairs shortest paths.
\end{enumerate}

Master these, and you master direction + cost = intelligence in motion.

\subsection{34. Shortest Path Variants (0-1 BFS, Bidirectional,
Heuristic
A*)}\label{shortest-path-variants-0-1-bfs-bidirectional-heuristic-a}

Sometimes the classic shortest path algorithms aren't enough. You might
have special edge weights (only 0 or 1), a need for faster searches, or
extra structure you can exploit.

That's where shortest path variants come in , they're optimized
adaptations of the big three (BFS, Dijkstra, A*) for specific scenarios.

In this section, we'll explore:

\begin{itemize}
\tightlist
\item
  0-1 BFS → when edge weights are only 0 or 1- Bidirectional Search →
  meet-in-the-middle for speed- Heuristic A* → smarter exploration
  guided by estimates Each shows how structure in your problem can yield
  speed-ups.
\end{itemize}

\subsubsection{1. 0-1 BFS}\label{bfs}

If all edge weights are either 0 or 1, you don't need a priority queue.
A deque (double-ended queue) is enough for (O(V + E)) time.

Why? Because edges with weight 0 should be processed immediately, while
edges with weight 1 can wait one step longer.

\subsubsection{A. Algorithm}\label{a.-algorithm}

Use a deque.

\begin{itemize}
\tightlist
\item
  When relaxing an edge with weight 0, push to front.- When relaxing an
  edge with weight 1, push to back.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];} \CommentTok{// (v, w)}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\DecValTok{1000}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ zero\_one\_bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{dist}\OperatorTok{,}\NormalTok{ dist }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{    deque}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ dq}\OperatorTok{;}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    dq}\OperatorTok{.}\NormalTok{push\_front}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{dq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ dq}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ dq}\OperatorTok{.}\NormalTok{pop\_front}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{w }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dq}\OperatorTok{.}\NormalTok{push\_front}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
                \ControlFlowTok{else}\NormalTok{ dq}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Example}\label{b.-example-2}

Graph:

\begin{verbatim}
1 -0-> 2 -1-> 3  
|              ^  
1              |  
+--------------+
\end{verbatim}

Shortest path from 1 to 3 = 1 (via edge 1-2-3). Deque ensures weight-0
edges don't get delayed.

\subsubsection{C. Complexity}\label{c.-complexity-5}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
O(V + E) & O(V) & Optimal for binary weights \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Layered BFS- Grid problems with binary costs- BFS with teleportation
  (weight 0 edges)
\end{itemize}

\subsubsection{2. Bidirectional Search}\label{bidirectional-search}

Sometimes you just need one path , from source to target , in an
unweighted graph. Instead of expanding from one side, expand from both
ends and stop when they meet.

This reduces search depth from (O\(b^d\)) to (O\(b^{d/2}\)) (huge gain
for large graphs).

\subsubsection{A. Idea}\label{a.-idea-5}

Run BFS from both source and target simultaneously. When their frontiers
intersect, you've found the shortest path.

\subsubsection{B. Implementation}\label{b.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ visited\_from\_s}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ visited\_from\_t}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ qs}\OperatorTok{,}\NormalTok{ qt}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ bidirectional\_bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    qs}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}\NormalTok{ visited\_from\_s}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{    qt}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{t}\OperatorTok{);}\NormalTok{ visited\_from\_t}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{qs}\OperatorTok{.}\NormalTok{empty}\OperatorTok{()} \OperatorTok{\&\&} \OperatorTok{!}\NormalTok{qt}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{step}\OperatorTok{(}\NormalTok{qs}\OperatorTok{,}\NormalTok{ visited\_from\_s}\OperatorTok{,}\NormalTok{ visited\_from\_t}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{step}\OperatorTok{(}\NormalTok{qt}\OperatorTok{,}\NormalTok{ visited\_from\_t}\OperatorTok{,}\NormalTok{ visited\_from\_s}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ step}\OperatorTok{(}\NormalTok{queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ q}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ vis}\OperatorTok{[],} \DataTypeTok{bool}\NormalTok{ other}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ size }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{size}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{other}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{vis}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                vis}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Complexity}\label{c.-complexity-6}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
O\(b^{d/2}\) & O\(b^{d/2}\) & Doubly fast in practice \\
\end{longtable}

Used in:

\begin{itemize}
\tightlist
\item
  Maze solvers- Shortest paths in large sparse graphs- Social network
  ``degrees of separation''
\end{itemize}

\subsubsection{3. Heuristic A* (Revisited)}\label{heuristic-a-revisited}

A* generalizes Dijkstra with goal-directed search using heuristics. We
revisit it here to show how heuristics change exploration order.

\subsubsection{A. Cost Function}\label{a.-cost-function}

\[
f(v) = g(v) + h(v)
\]

\begin{itemize}
\tightlist
\item
  (g(v)): cost so far- (h(v)): estimated cost to goal- (h(v)) must be
  admissible ((h(v) \le \text{true cost}))
\end{itemize}

\subsubsection{B. Implementation}\label{b.-implementation-3}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ v}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ f}\OperatorTok{,}\NormalTok{ g}\OperatorTok{;}
    \DataTypeTok{bool}\NormalTok{ operator}\OperatorTok{\textgreater{}(}\DataTypeTok{const}\NormalTok{ Node}\OperatorTok{\&}\NormalTok{ o}\OperatorTok{)} \DataTypeTok{const} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ f }\OperatorTok{\textgreater{}}\NormalTok{ o}\OperatorTok{.}\NormalTok{f}\OperatorTok{;} \OperatorTok{\}}
\OperatorTok{\};}

\NormalTok{priority\_queue}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ astar}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ start}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ goal}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    h}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{start}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{start}\OperatorTok{,}\NormalTok{ g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{+}\NormalTok{ h}\OperatorTok{[}\NormalTok{start}\OperatorTok{],}\NormalTok{ g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]\});}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{u}\OperatorTok{,}\NormalTok{ f\_u}\OperatorTok{,}\NormalTok{ g\_u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ goal}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ new\_g }\OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{new\_g }\OperatorTok{\textless{}}\NormalTok{ g}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                g}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ new\_g}\OperatorTok{;}
                \DataTypeTok{int}\NormalTok{ f\_v }\OperatorTok{=}\NormalTok{ new\_g }\OperatorTok{+}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\NormalTok{                pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{v}\OperatorTok{,}\NormalTok{ f\_v}\OperatorTok{,}\NormalTok{ new\_g}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example Heuristics}\label{c.-example-heuristics}

\begin{itemize}
\tightlist
\item
  Grid map: Manhattan distance (h(x, y) = \textbar x - x\_g\textbar{} +
  \textbar y - y\_g\textbar)
\item
  Navigation: straight-line (Euclidean)- Game tree: evaluation function
\end{itemize}

\subsubsection{D. Performance}\label{d.-performance}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Heuristic & Effect \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Perfect (h = true cost) & Optimal, visits minimal nodes \\
Admissible but weak & Still correct, more nodes \\
Overestimate & May fail (non-admissible) \\
\end{longtable}

\subsubsection{4. Comparison}\label{comparison-17}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1875}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weight Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0-1 BFS & 0 or 1 & Deque-based & O(V+E) & O(V) & No heap \\
Bidirectional BFS & Unweighted & Two-way search & O\(b^{d/2}\) &
O\(b^{d/2}\) & Meets in middle \\
A* & Non-negative & Heuristic search & Depends & O(V) & Guided \\
\end{longtable}

\subsubsection{5. Example Scenario}\label{example-scenario}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4091}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Grid with teleport (cost 0) & 0-1 BFS \\
Huge social graph (find shortest chain) & Bidirectional BFS \\
Game AI pathfinding & A* with Manhattan heuristic \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-33}

0-1 BFS Quick Demo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\NormalTok{zero\_one\_bfs}\OperatorTok{(}\DecValTok{3}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{[}\DecValTok{3}\OperatorTok{]);} \CommentTok{// shortest = 1}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-33}

Special cases deserve special tools. These variants show that
understanding structure (like edge weights or symmetry) can yield huge
gains.

They embody a principle:

\begin{quote}
``Don't just run faster , run smarter, guided by what you know.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-33}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement 0-1 BFS for a grid with cost 0 teleports.
\item
  Compare BFS vs Bidirectional BFS on a large maze.
\item
  Write A* for an 8x8 chessboard knight's move puzzle.
\item
  Tune heuristics , see how overestimating breaks A*.
\item
  Combine A* and 0-1 BFS for hybrid search.
\end{enumerate}

With these in hand, you can bend shortest path search to the shape of
your problem , efficient, elegant, and exact.

\subsection{35. Minimum Spanning Trees (Kruskal, Prim,
Borůvka)}\label{minimum-spanning-trees-kruskal-prim-borux16fvka}

When a graph connects multiple points with weighted edges, sometimes you
don't want the \emph{shortest path}, but the \emph{cheapest network}
that connects everything.

That's the Minimum Spanning Tree (MST) problem:

\begin{quote}
Given a connected, weighted, undirected graph, find a subset of edges
that connects all vertices with minimum total weight and no cycles.
\end{quote}

MSTs are everywhere , from building networks and designing circuits to
clustering and approximation algorithms.

Three cornerstone algorithms solve it beautifully:

\begin{itemize}
\tightlist
\item
  Kruskal's , edge-based, union-find- Prim's , vertex-based, greedy
  expansion- Borůvka's , component merging in parallel
\end{itemize}

\subsubsection{1. What Is a Spanning
Tree?}\label{what-is-a-spanning-tree}

A spanning tree connects all vertices with exactly (V-1) edges. Among
all spanning trees, the one with minimum total weight is the MST.

Properties:

\begin{itemize}
\tightlist
\item
  Contains no cycles- Connects all vertices- Edge count = (V - 1)-
  Unique if all weights distinct
\end{itemize}

\subsubsection{2. MST Applications}\label{mst-applications}

\begin{itemize}
\tightlist
\item
  Network design (roads, cables, pipelines)- Clustering (e.g.,
  hierarchical clustering)- Image segmentation- Approximation (e.g., TSP
  \textasciitilde{} 2 × MST)- Graph simplification
\end{itemize}

\subsubsection{3. Kruskal's Algorithm}\label{kruskals-algorithm}

Build the MST edge-by-edge, in order of increasing weight. Use
Union-Find (Disjoint Set Union) to avoid cycles.

\subsubsection{A. Steps}\label{a.-steps-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Sort all edges by weight.
\item
  Initialize each vertex as its own component.
\item
  For each edge (u, v):

  \begin{itemize}
  \tightlist
  \item
    If \texttt{u} and \texttt{v} are in different components → include
    edge - Union their sets Stop when (V-1) edges chosen.
  \end{itemize}
\end{enumerate}

\subsubsection{B. Implementation}\label{b.-implementation-4}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Edge }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ edges}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{==}\NormalTok{ x }\OperatorTok{?}\NormalTok{ x }\OperatorTok{:}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]);}
\OperatorTok{\}}
\DataTypeTok{bool}\NormalTok{ unite}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);}\NormalTok{ b }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{==}\NormalTok{ b}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank\_}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank\_}\OperatorTok{[}\NormalTok{a}\OperatorTok{]} \OperatorTok{==}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{b}\OperatorTok{])}\NormalTok{ rank\_}\OperatorTok{[}\NormalTok{a}\OperatorTok{]++;}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ kruskal}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    iota}\OperatorTok{(}\NormalTok{parent}\OperatorTok{,}\NormalTok{ parent }\OperatorTok{+}\NormalTok{ n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\NormalTok{    sort}\OperatorTok{(}\NormalTok{edges}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ edges}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \OperatorTok{[](}\NormalTok{Edge a}\OperatorTok{,}\NormalTok{ Edge b}\OperatorTok{)\{} \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{.}\NormalTok{w }\OperatorTok{\textless{}}\NormalTok{ b}\OperatorTok{.}\NormalTok{w}\OperatorTok{;} \OperatorTok{\});}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{\&}\NormalTok{e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{unite}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))}
\NormalTok{            total }\OperatorTok{+=}\NormalTok{ e}\OperatorTok{.}\NormalTok{w}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Sorting edges: (O\(E \log E\))- Union-Find operations: (O(\alpha(V)))
  (almost constant)- Total: (O\(E \log E\))
\end{itemize}

\subsubsection{C. Example}\label{c.-example-2}

Graph:

\begin{verbatim}
1 -4- 2  
|     |  
2     3  
 \-1-/
\end{verbatim}

Edges sorted: (1-3,1), (1-2,4), (2-3,3)

Pick 1-3, 2-3 → MST weight = 1 + 3 = 4

\subsubsection{4. Prim's Algorithm}\label{prims-algorithm}

Grow MST from a starting vertex, adding the smallest outgoing edge each
step.

Similar to Dijkstra , but pick edges, not distances.

\subsubsection{A. Steps}\label{a.-steps-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with one vertex, mark as visited.
\item
  Use priority queue for candidate edges.
\item
  Pick smallest edge that connects to an unvisited vertex.
\item
  Add vertex to MST, repeat until all visited.
\end{enumerate}

\subsubsection{B. Implementation}\label{b.-implementation-5}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];} \CommentTok{// (v, w)}
\DataTypeTok{bool}\NormalTok{ used}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ prim}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ start}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{},}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{},}\NormalTok{ greater}\OperatorTok{\textless{}\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\DecValTok{0}\OperatorTok{,}\NormalTok{ start}\OperatorTok{\});}
    \DataTypeTok{int}\NormalTok{ total }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{w}\OperatorTok{,}\NormalTok{ u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{();}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        used}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ w}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w2}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{used}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}\NormalTok{ pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{w2}\OperatorTok{,}\NormalTok{ v}\OperatorTok{\});}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  \(O((V+E) \log V)\) with binary heap
\end{itemize}

Used when:

\begin{itemize}
\tightlist
\item
  Graph is dense
\item
  Easier to grow tree than sort all edges
\end{itemize}

\subsubsection{C. Example}\label{c.-example-3}

Graph:

\begin{verbatim}
1 -2- 2  
|     |  
4     1  
 \-3-/
\end{verbatim}

Start at 1 → choose (1-2), (1-3) → MST weight = 2 + 3 = 5

\subsubsection{5. Borůvka's Algorithm}\label{borux16fvkas-algorithm}

Less famous, but elegant , merges cheapest outgoing edge per component
in parallel.

Each component picks one cheapest outgoing edge, adds it, merges
components. Repeat until one component left.

Complexity: (O\(E \log V\))

Used in parallel/distributed MST computations.

\subsubsection{6. Comparison}\label{comparison-18}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1406}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.4062}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1562}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0938}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2031}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Kruskal & Edge-based, sort all edges & O(E log E) & O(E) & Sparse
graphs \\
Prim & Vertex-based, grow tree & O(E log V) & O(V+E) & Dense graphs \\
Borůvka & Component merging & O(E log V) & O(E) & Parallel MST \\
\end{longtable}

\subsubsection{7. MST Properties}\label{mst-properties}

\begin{itemize}
\tightlist
\item
  Cut Property: For any cut, smallest crossing edge ∈ MST.- Cycle
  Property: For any cycle, largest edge not ∈ MST.- MST may not be
  unique if equal weights.
\end{itemize}

\subsubsection{8. Building the Tree}\label{building-the-tree}

Store MST edges:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ mst\_edges}\OperatorTok{;}
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{unite}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))}\NormalTok{ mst\_edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{e}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Then use MST for:

\begin{itemize}
\tightlist
\item
  Path queries- Clustering (remove largest edge)- Approximation TSP
  (preorder traversal)
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-34}

Kruskal Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(\{}\DecValTok{1}\OperatorTok{,}\DecValTok{2}\OperatorTok{,}\DecValTok{4}\OperatorTok{\});}
\NormalTok{edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(\{}\DecValTok{1}\OperatorTok{,}\DecValTok{3}\OperatorTok{,}\DecValTok{1}\OperatorTok{\});}
\NormalTok{edges}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(\{}\DecValTok{2}\OperatorTok{,}\DecValTok{3}\OperatorTok{,}\DecValTok{3}\OperatorTok{\});}
\NormalTok{printf}\OperatorTok{(}\StringTok{"MST = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ kruskal}\OperatorTok{(}\DecValTok{3}\OperatorTok{));} \CommentTok{// 4}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-34}

MSTs model connection without redundancy. They're about efficiency ,
connecting everything at minimal cost, a principle that appears in
infrastructure, data, and even ideas.

They teach:

\begin{quote}
``You can connect the whole with less , if you choose wisely.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-34}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Kruskal's algorithm using union-find.
\item
  Run Prim's algorithm and compare output.
\item
  Build MST on random weighted graph , visualize tree.
\item
  Remove heaviest edge from MST to form two clusters.
\item
  Explore Borůvka for parallel execution.
\end{enumerate}

MSTs are how you span complexity with minimal effort , a tree of
balance, economy, and order.

\subsection{36. Flows (Ford-Fulkerson, Edmonds-Karp,
Dinic)}\label{flows-ford-fulkerson-edmonds-karp-dinic}

Some graphs don't just connect , they \emph{carry} something. Imagine
water flowing through pipes, traffic through roads, data through a
network. Each edge has a capacity, and you want to know:

\begin{quote}
``How much can I send from source to sink before the system clogs?''
\end{quote}

That's the Maximum Flow problem , a cornerstone of combinatorial
optimization, powering algorithms for matching, cuts, scheduling, and
more.

This section covers the big three:

\begin{itemize}
\tightlist
\item
  Ford-Fulkerson , the primal idea- Edmonds-Karp , BFS-based
  implementation- Dinic's Algorithm , layered speed
\end{itemize}

\subsubsection{1. Problem Definition}\label{problem-definition}

Given a directed graph ( G = (V, E) ), each edge ( (u, v) ) has a
capacity ( c(u, v) \ge 0 ).

We have:

\begin{itemize}
\tightlist
\item
  Source ( s )- Sink ( t ) We want the maximum flow from ( s ) to ( t ):
  a function ( f(u, v) ) that satisfies:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Capacity constraint: ( 0 \le f(u, v) \le c(u, v) )
\item
  Flow conservation: For every vertex \(v \neq s, t\): (\sum f(u, v) =
  \sum f(v, w))
\end{enumerate}

Total flow = (\sum f(s, v))

\subsubsection{2. The Big Picture}\label{the-big-picture}

Max Flow - Min Cut Theorem:

\begin{quote}
The value of the maximum flow equals the capacity of the minimum cut.
\end{quote}

So finding a max flow is equivalent to finding the bottleneck.

\subsubsection{3. Ford-Fulkerson Method}\label{ford-fulkerson-method}

The idea:

\begin{itemize}
\tightlist
\item
  While there exists a path from (s) to (t) with available capacity,
  push flow along it.
\end{itemize}

Each step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find augmenting path
\item
  Send flow = min residual capacity along it
\item
  Update residual capacities
\end{enumerate}

Repeat until no augmenting path.

\subsubsection{A. Residual Graph}\label{a.-residual-graph}

Residual capacity: \[
r(u, v) = c(u, v) - f(u, v)
\] If ( f(u, v) \textgreater{} 0 ), then add reverse edge ( (v, u) )
with capacity ( f(u, v) ).

This allows undoing flow if needed.

\subsubsection{B. Implementation
(DFS-style)}\label{b.-implementation-dfs-style}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ cap}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{][}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ flow}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ vis}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ t}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\NormalTok{    vis}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ \_}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{vis}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ pushed }\OperatorTok{=}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ min}\OperatorTok{(}\NormalTok{flow}\OperatorTok{,}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]),}\NormalTok{ vis}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pushed }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ pushed}\OperatorTok{;}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ pushed}\OperatorTok{;}
                \ControlFlowTok{return}\NormalTok{ pushed}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ ford\_fulkerson}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ flow }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ vis}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
        \DataTypeTok{int}\NormalTok{ pushed }\OperatorTok{=}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{,}\NormalTok{ vis}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pushed }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{        flow }\OperatorTok{+=}\NormalTok{ pushed}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(E \cdot \text{max flow}\)) , depends on flow magnitude.

\subsubsection{4. Edmonds-Karp Algorithm}\label{edmonds-karp-algorithm}

A refinement:

\begin{quote}
Always choose shortest augmenting path (by edges) using BFS.
\end{quote}

Guarantees polynomial time.

\subsubsection{A. Implementation (BFS + parent
tracking)}\label{a.-implementation-bfs-parent-tracking}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ bfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ parent}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{parent}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ parent}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\NormalTok{    queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{s}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{\});}
\NormalTok{    parent}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \OperatorTok{{-}}\DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \KeywordTok{auto} \OperatorTok{[}\NormalTok{u}\OperatorTok{,}\NormalTok{ flow}\OperatorTok{]} \OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ \_}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ new\_flow }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{flow}\OperatorTok{,}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]);}
\NormalTok{                parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ t}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ new\_flow}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{v}\OperatorTok{,}\NormalTok{ new\_flow}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ edmonds\_karp}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ flow }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ parent}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ new\_flow}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{((}\NormalTok{new\_flow }\OperatorTok{=}\NormalTok{ bfs}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ parent}\OperatorTok{,}\NormalTok{ n}\OperatorTok{)))} \OperatorTok{\{}
\NormalTok{        flow }\OperatorTok{+=}\NormalTok{ new\_flow}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ t}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ s}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
\NormalTok{            cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ new\_flow}\OperatorTok{;}
\NormalTok{            cap}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ new\_flow}\OperatorTok{;}
\NormalTok{            v }\OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(VE^2\)) Always terminates (no dependence on flow
values).

\subsubsection{5. Dinic's Algorithm}\label{dinics-algorithm}

A modern classic , uses BFS to build level graph, and DFS to send
blocking flow.

It works layer-by-layer, avoiding useless exploration.

\subsubsection{A. Steps}\label{a.-steps-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build level graph via BFS (assign levels to reachable nodes).
\item
  DFS sends flow along level-respecting paths.
\item
  Repeat until no path remains.
\end{enumerate}

\subsubsection{B. Implementation}\label{b.-implementation-6}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ level}\OperatorTok{,}\NormalTok{ ptr}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ bfs\_level}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    fill}\OperatorTok{(}\NormalTok{level}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ level}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
\NormalTok{    level}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ \_}\OperatorTok{]} \OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{level}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                level}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ level}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{                q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
            \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ level}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ dfs\_flow}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pushed}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ t }\OperatorTok{||}\NormalTok{ pushed }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ pushed}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int} \OperatorTok{\&}\NormalTok{cid }\OperatorTok{=}\NormalTok{ ptr}\OperatorTok{[}\NormalTok{u}\OperatorTok{];}\NormalTok{ cid }\OperatorTok{\textless{}} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)}\NormalTok{adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{].}\NormalTok{size}\OperatorTok{();}\NormalTok{ cid}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{cid}\OperatorTok{].}\NormalTok{first}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{level}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==}\NormalTok{ level}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\&\&}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ tr }\OperatorTok{=}\NormalTok{ dfs\_flow}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ min}\OperatorTok{(}\NormalTok{pushed}\OperatorTok{,}\NormalTok{ cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]));}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{tr }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ tr}\OperatorTok{;}
\NormalTok{                cap}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ tr}\OperatorTok{;}
                \ControlFlowTok{return}\NormalTok{ tr}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ dinic}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ flow }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    level}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    ptr}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{bfs\_level}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ n}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        fill}\OperatorTok{(}\NormalTok{ptr}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ ptr}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \DecValTok{0}\OperatorTok{);}
        \ControlFlowTok{while} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ pushed }\OperatorTok{=}\NormalTok{ dfs\_flow}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ t}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{))}
\NormalTok{            flow }\OperatorTok{+=}\NormalTok{ pushed}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ flow}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(EV^2\)) worst case, (O\(E \sqrt{V}\)) in practice.

\subsubsection{6. Comparison}\label{comparison-19}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1505}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2151}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2043}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2688}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Strategy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handles
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ford-Fulkerson & DFS augmenting paths & Integral capacities &
O\(E × max_flow\) & Simple, may loop on reals \\
Edmonds-Karp & BFS augmenting paths & All capacities & O(VE²) & Always
terminates \\
Dinic & Level graph + DFS & All capacities & O(V²E) & Fast in
practice \\
\end{longtable}

\subsubsection{7. Applications}\label{applications-4}

\begin{itemize}
\tightlist
\item
  Network routing- Bipartite matching- Task assignment (flows = people →
  jobs)- Image segmentation (min-cut)- Circulation with demands- Data
  pipelines, max throughput systems
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-35}

Ford-Fulkerson Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{,} \DecValTok{5}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{2}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{2}\OperatorTok{);}
\NormalTok{add\_edge}\OperatorTok{(}\DecValTok{3}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{3}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"Max flow = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ ford\_fulkerson}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \DecValTok{4}\OperatorTok{,} \DecValTok{4}\OperatorTok{));} \CommentTok{// 5}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-35}

Flow algorithms transform capacity constraints into solvable systems.
They reveal the deep unity between optimization and structure: every
maximum flow defines a minimum bottleneck cut.

They embody a timeless truth:

\begin{quote}
``To understand limits, follow the flow.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-35}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Ford-Fulkerson using DFS.
\item
  Switch to Edmonds-Karp and observe performance gain.
\item
  Build Dinic's level graph and visualize layers.
\item
  Model job assignment as bipartite flow.
\item
  Verify Max Flow = Min Cut on small examples.
\end{enumerate}

Once you master flows, you'll see them hidden in everything that moves ,
from data to decisions.

\subsection{37. Cuts (Stoer-Wagner, Karger,
Gomory-Hu)}\label{cuts-stoer-wagner-karger-gomory-hu}

Where flow problems ask \emph{``How much can we send?''}, cut problems
ask \emph{``Where does it break?''}

A cut splits a graph into two disjoint sets. The minimum cut is the
smallest set of edges whose removal disconnects the graph , the tightest
``bottleneck'' holding it together.

This chapter explores three major algorithms:

\begin{itemize}
\tightlist
\item
  Stoer-Wagner , deterministic min-cut for undirected graphs- Karger's
  Randomized Algorithm , fast, probabilistic- Gomory-Hu Tree , compress
  all-pairs min-cuts into one tree Cuts reveal hidden structure ,
  clusters, vulnerabilities, boundaries , and form the dual to flows via
  the Max-Flow Min-Cut Theorem.
\end{itemize}

\subsubsection{1. The Min-Cut Problem}\label{the-min-cut-problem}

Given a weighted undirected graph ( G = (V, E) ): Find the minimum total
weight of edges whose removal disconnects the graph.

Equivalent to:

\begin{quote}
The smallest sum of edge weights crossing any partition (
\(S, V \setminus S\) ).
\end{quote}

For directed graphs, you use max-flow methods; For undirected graphs,
specialized algorithms exist.

\subsubsection{2. Applications}\label{applications-5}

\begin{itemize}
\tightlist
\item
  Network reliability , weakest link detection- Clustering , partition
  graph by minimal interconnection- Circuit design , splitting
  components- Image segmentation , separating regions- Community
  detection , sparse connections between groups
\end{itemize}

\subsubsection{3. Stoer-Wagner Algorithm
(Deterministic)}\label{stoer-wagner-algorithm-deterministic}

A clean, deterministic method for global minimum cut in undirected
graphs.

\subsubsection{A. Idea}\label{a.-idea-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start with the full vertex set ( V ).
\item
  Repeatedly run Maximum Adjacency Search:

  \begin{itemize}
  \tightlist
  \item
    Start from a vertex - Grow a set by adding the most tightly
    connected vertex - The last added vertex defines a cut3. Contract
    the last two added vertices into one.
  \end{itemize}
\item
  Keep track of smallest cut seen.
\end{enumerate}

Repeat until one vertex remains.

\subsubsection{B. Implementation (Adjacency
Matrix)}\label{b.-implementation-adjacency-matrix}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ g}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{][}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ w}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ added}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ exist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ stoer\_wagner}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ best }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ v}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    iota}\OperatorTok{(}\NormalTok{v}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ v}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),} \DecValTok{0}\OperatorTok{);}

    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textgreater{}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        fill}\OperatorTok{(}\NormalTok{w}\OperatorTok{,}\NormalTok{ w }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\NormalTok{        fill}\OperatorTok{(}\NormalTok{added}\OperatorTok{,}\NormalTok{ added }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
        \DataTypeTok{int}\NormalTok{ prev }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ sel }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
                \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{added}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\&\&} \OperatorTok{(}\NormalTok{sel }\OperatorTok{==} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{||}\NormalTok{ w}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ w}\OperatorTok{[}\NormalTok{sel}\OperatorTok{]))}\NormalTok{ sel }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                best }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{best}\OperatorTok{,}\NormalTok{ w}\OperatorTok{[}\NormalTok{sel}\OperatorTok{]);}
                \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{                    g}\OperatorTok{[}\NormalTok{prev}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{prev}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ g}\OperatorTok{[}\NormalTok{sel}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
\NormalTok{                v}\OperatorTok{.}\NormalTok{erase}\OperatorTok{(}\NormalTok{v}\OperatorTok{.}\NormalTok{begin}\OperatorTok{()} \OperatorTok{+}\NormalTok{ sel}\OperatorTok{);}
\NormalTok{                n}\OperatorTok{{-}{-};}
                \ControlFlowTok{break}\OperatorTok{;}
            \OperatorTok{\}}
\NormalTok{            added}\OperatorTok{[}\NormalTok{sel}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ w}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ g}\OperatorTok{[}\NormalTok{sel}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
\NormalTok{            prev }\OperatorTok{=}\NormalTok{ sel}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ best}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(V^3\)), or (O\(VE + V^2 \log V\)) with heaps Input:
weighted undirected graph Output: global min cut value

\subsubsection{C. Example}\label{c.-example-4}

Graph:

\begin{verbatim}
1 -3- 2  
|     |  
4     2  
 \-5-/
\end{verbatim}

Cuts:

\begin{itemize}
\tightlist
\item
  \{1,2\}\textbar\{3\} → 7- \{1,3\}\textbar\{2\} → 5 Min cut = 5
\end{itemize}

\subsubsection{4. Karger's Algorithm
(Randomized)}\label{kargers-algorithm-randomized}

A simple, elegant probabilistic method. Repeatedly contract random edges
until two vertices remain; the remaining crossing edges form a cut.

Run multiple times → high probability of finding min cut.

\subsubsection{A. Algorithm}\label{a.-algorithm-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  While ( \textbar V\textbar{} \textgreater{} 2 ):

  \begin{itemize}
  \tightlist
  \item
    Choose random edge ((u, v)) - Contract (u, v) into one node - Remove
    self-loops2. Return number of edges between remaining nodes
  \end{itemize}
\end{enumerate}

Repeat (O\(n^2 \log n\)) times for high confidence.

\subsubsection{B. Implementation Sketch}\label{b.-implementation-sketch}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Edge }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Edge}\OperatorTok{\textgreater{}}\NormalTok{ edges}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ find}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{==}\NormalTok{ x }\OperatorTok{?}\NormalTok{ x }\OperatorTok{:}\NormalTok{ parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{x}\OperatorTok{]);} \OperatorTok{\}}
\DataTypeTok{void}\NormalTok{ unite}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ parent}\OperatorTok{[}\NormalTok{find}\OperatorTok{(}\NormalTok{b}\OperatorTok{)]} \OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{a}\OperatorTok{);} \OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ karger}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=}\NormalTok{ edges}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\NormalTok{    iota}\OperatorTok{(}\NormalTok{parent}\OperatorTok{,}\NormalTok{ parent }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ vertices }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{vertices }\OperatorTok{\textgreater{}} \DecValTok{2}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{edges}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{u}\OperatorTok{),}\NormalTok{ v }\OperatorTok{=}\NormalTok{ find}\OperatorTok{(}\NormalTok{edges}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{v}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ v}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        unite}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
\NormalTok{        vertices}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ cuts }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto}\NormalTok{ e }\OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{u}\OperatorTok{)} \OperatorTok{!=}\NormalTok{ find}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{v}\OperatorTok{))}\NormalTok{ cuts}\OperatorTok{++;}
    \ControlFlowTok{return}\NormalTok{ cuts}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Expected Time: (O\(n^2\)) per run Probability of success: (2 / (n(n-1)))
per run Run multiple trials and take minimum.

\subsubsection{C. Use Case}\label{c.-use-case}

Great for large sparse graphs, or when approximate solutions are
acceptable. Intuitive: the min cut survives random contractions if
chosen carefully enough.

\subsubsection{5. Gomory-Hu Tree}\label{gomory-hu-tree}

A compact way to store all-pairs min-cuts. It compresses (O\(V^2\)) flow
computations into V-1 cuts.

\subsubsection{A. Idea}\label{a.-idea-7}

\begin{itemize}
\tightlist
\item
  Build a tree where the min cut between any two vertices = the minimum
  edge weight on their path in the tree.
\end{itemize}

\subsubsection{B. Algorithm}\label{b.-algorithm}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Pick vertex (s).
\item
  For each vertex \(t \neq s\),

  \begin{itemize}
  \tightlist
  \item
    Run max flow to find min cut between (s, t). - Partition vertices
    accordingly.3. Connect partitions to form a tree.
  \end{itemize}
\end{enumerate}

Result: Gomory-Hu tree (V-1 edges).

Now any pair's min cut = smallest edge on path between them.

Complexity: (O(V)) max flow runs.

\subsubsection{C. Uses}\label{c.-uses}

\begin{itemize}
\tightlist
\item
  Quickly answer all-pairs cut queries- Network reliability-
  Hierarchical clustering
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-20}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1348}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1461}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1124}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2584}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2360}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Randomized
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Graph
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Stoer-Wagner & Deterministic & No & Undirected & O(V³) & Global min
cut \\
Karger & Randomized & Yes & Undirected & O(n² log n) (multi-run) &
Probabilistic min cut \\
Gomory-Hu & Deterministic & No & Undirected & O(V × MaxFlow) & All-pairs
min cuts \\
\end{longtable}

\subsubsection{7. Relationship to Flows}\label{relationship-to-flows}

By Max-Flow Min-Cut, min-cut capacity = max-flow value.

So you can find:

\begin{itemize}
\tightlist
\item
  s-t min cut = via max flow- global min cut = min over all (s, t) pairs
  Specialized algorithms just make it faster.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-36}

Stoer-Wagner Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{printf}\OperatorTok{(}\StringTok{"Global Min Cut = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ stoer\_wagner}\OperatorTok{(}\NormalTok{n}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Karger Multi-Run:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ ans }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    ans }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{ans}\OperatorTok{,}\NormalTok{ karger}\OperatorTok{(}\NormalTok{n}\OperatorTok{));}
\NormalTok{printf}\OperatorTok{(}\StringTok{"Approx Min Cut = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ ans}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-36}

Cuts show you fragility , the weak seams of connection. While flows tell
you \emph{how much can pass}, cuts reveal \emph{where it breaks first}.

They teach:

\begin{quote}
``To understand strength, study what happens when you pull things
apart.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-36}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Stoer-Wagner and test on small graphs.
\item
  Run Karger 100 times and track success rate.
\item
  Build a Gomory-Hu tree and answer random pair queries.
\item
  Verify Max-Flow = Min-Cut equivalence on examples.
\item
  Use cuts for community detection in social graphs.
\end{enumerate}

Mastering cuts gives you both grip and insight , where systems hold, and
where they give way.

\subsection{38. Matchings (Hopcroft-Karp, Hungarian,
Blossom)}\label{matchings-hopcroft-karp-hungarian-blossom}

In many problems, we need to pair up elements efficiently: students to
schools, jobs to workers, tasks to machines.

These are matching problems , find sets of edges with no shared
endpoints that maximize cardinality or weight.

Depending on graph type, different algorithms apply:

\begin{itemize}
\tightlist
\item
  Hopcroft-Karp , fast matching in bipartite graphs- Hungarian Algorithm
  , optimal weighted assignment- Edmonds' Blossom Algorithm , general
  graphs (non-bipartite) Matching is a fundamental combinatorial
  structure, appearing in scheduling, flow networks, and resource
  allocation.
\end{itemize}

\subsubsection{1. Terminology}\label{terminology}

\begin{itemize}
\item
  Matching: set of edges with no shared vertices- Maximum Matching:
  matching with largest number of edges- Perfect Matching: covers all
  vertices (each vertex matched once)- Maximum Weight Matching: matching
  with largest total edge weight Graph Types:
\item
  Bipartite: vertices split into two sets (L, R); edges only between
  sets- General: arbitrary connections (may contain odd cycles)
\end{itemize}

\subsubsection{2. Applications}\label{applications-6}

\begin{itemize}
\tightlist
\item
  Job assignment- Network flows- Resource allocation- Student-project
  pairing- Stable marriages (with preferences)- Computer vision (feature
  correspondence)
\end{itemize}

\subsubsection{3. Hopcroft-Karp Algorithm (Bipartite
Matching)}\label{hopcroft-karp-algorithm-bipartite-matching}

A highly efficient algorithm for maximum cardinality matching in
bipartite graphs.

It uses layered BFS + DFS to find multiple augmenting paths
simultaneously.

\subsubsection{A. Idea}\label{a.-idea-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize matching empty.
\item
  While augmenting paths exist:

  \begin{itemize}
  \tightlist
  \item
    BFS builds layer graph (shortest augmenting paths). - DFS finds all
    augmenting paths along those layers. Each phase increases matching
    size significantly.
  \end{itemize}
\end{enumerate}

\subsubsection{B. Complexity}\label{b.-complexity}

\[
O(E \sqrt{V})
\]

Much faster than augmenting one path at a time (like Ford-Fulkerson).

\subsubsection{C. Implementation}\label{c.-implementation}

Let \texttt{pairU{[}u{]}} = matched vertex in R, or 0 if unmatched
\texttt{pairV{[}v{]}} = matched vertex in L, or 0 if unmatched

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adjL}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ pairU}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ pairV}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ dist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ nL}\OperatorTok{,}\NormalTok{ nR}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ bfs}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ nL}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairU}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
        \ControlFlowTok{else}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ found }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ found}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adjL}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
                \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}\NormalTok{ found }\OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
                \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]]} \OperatorTok{==}\NormalTok{ INF}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                    dist}\OperatorTok{[}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{                    q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
                \OperatorTok{\}}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ found }\OperatorTok{!=}\NormalTok{ INF}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{bool}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adjL}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{||} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]]} \OperatorTok{==}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\&\&}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{])))} \OperatorTok{\{}
\NormalTok{            pairU}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{            pairV}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
            \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ hopcroft\_karp}\OperatorTok{()} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ matching }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{bfs}\OperatorTok{())} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ nL}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{pairU}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{u}\OperatorTok{))}\NormalTok{ matching}\OperatorTok{++;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ matching}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Example}\label{d.-example}

Graph:

\begin{verbatim}
U = {1,2,3}, V = {a,b}
Edges: 1–a, 2–a, 3–b
\end{verbatim}

Matching: \{1-a, 3-b\} (size 2)

\subsubsection{4. Hungarian Algorithm (Weighted Bipartite
Matching)}\label{hungarian-algorithm-weighted-bipartite-matching}

Solves assignment problem , given cost matrix \(c_{ij}\), assign each
(i) to one (j) minimizing total cost (or maximizing profit).

\subsubsection{A. Idea}\label{a.-idea-9}

Subtract minimums row- and column-wise → expose zeros → find minimal
zero-cover → adjust matrix → repeat.

Equivalent to solving min-cost perfect matching on a bipartite graph.

\subsubsection{B. Complexity}\label{b.-complexity-1}

\[
O(V^3)
\]

Works for dense graphs, moderate sizes.

\subsubsection{C. Implementation Sketch (Matrix
Form)}\label{c.-implementation-sketch-matrix-form}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ hungarian}\OperatorTok{(}\DataTypeTok{const}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ cost}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ cost}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ u}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ v}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ p}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ way}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        p}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ j0 }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ minv}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{        vector}\OperatorTok{\textless{}}\DataTypeTok{char}\OperatorTok{\textgreater{}}\NormalTok{ used}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
        \ControlFlowTok{do} \OperatorTok{\{}
\NormalTok{            used}\OperatorTok{[}\NormalTok{j0}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
            \DataTypeTok{int}\NormalTok{ i0 }\OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{j0}\OperatorTok{],}\NormalTok{ delta }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{,}\NormalTok{ j1}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{used}\OperatorTok{[}\NormalTok{j}\OperatorTok{])} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i0}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ u}\OperatorTok{[}\NormalTok{i0}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ v}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\textless{}}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ cur}\OperatorTok{,}\NormalTok{ way}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j0}\OperatorTok{;}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ delta}\OperatorTok{)}\NormalTok{ delta }\OperatorTok{=}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{],}\NormalTok{ j1 }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
            \OperatorTok{\}}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{used}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ u}\OperatorTok{[}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{]]} \OperatorTok{+=}\NormalTok{ delta}\OperatorTok{,}\NormalTok{ v}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ delta}\OperatorTok{;}
                \ControlFlowTok{else}\NormalTok{ minv}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ delta}\OperatorTok{;}
\NormalTok{            j0 }\OperatorTok{=}\NormalTok{ j1}\OperatorTok{;}
        \OperatorTok{\}} \ControlFlowTok{while} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{j0}\OperatorTok{]);}
        \ControlFlowTok{do} \OperatorTok{\{} \DataTypeTok{int}\NormalTok{ j1 }\OperatorTok{=}\NormalTok{ way}\OperatorTok{[}\NormalTok{j0}\OperatorTok{];}\NormalTok{ p}\OperatorTok{[}\NormalTok{j0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{j1}\OperatorTok{];}\NormalTok{ j0 }\OperatorTok{=}\NormalTok{ j1}\OperatorTok{;} \OperatorTok{\}} \ControlFlowTok{while} \OperatorTok{(}\NormalTok{j0}\OperatorTok{);}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\NormalTok{v}\OperatorTok{[}\DecValTok{0}\OperatorTok{];} \CommentTok{// minimal cost}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{D. Example}\label{d.-example-1}

Cost matrix:

\begin{verbatim}
  a  b  c
1 3  2  1
2 2  3  2
3 3  2  3
\end{verbatim}

Optimal assignment = 1-c, 2-a, 3-b Cost = 1 + 2 + 2 = 5

\subsubsection{5. Edmonds' Blossom Algorithm (General
Graphs)}\label{edmonds-blossom-algorithm-general-graphs}

For non-bipartite graphs, simple augmenting path logic breaks down (odd
cycles). Blossom algorithm handles this via contraction of blossoms (odd
cycles).

\subsubsection{A. Idea}\label{a.-idea-10}

\begin{itemize}
\tightlist
\item
  Find augmenting paths- When odd cycle encountered (blossom), shrink it
  into one vertex- Continue search- Expand blossoms at end
\end{itemize}

\subsubsection{B. Complexity}\label{b.-complexity-2}

\[
O(V^3)
\]

Though complex to implement, it's the general-purpose solution for
matchings.

\subsubsection{C. Use Cases}\label{c.-use-cases-1}

\begin{itemize}
\tightlist
\item
  Non-bipartite job/task assignments- General pairing problems- Network
  design
\end{itemize}

\subsubsection{6. Comparison}\label{comparison-21}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1970}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1515}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1212}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1515}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3788}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Graph Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Weighted
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hopcroft-Karp & Bipartite & No & O(E√V) & Max cardinality \\
Hungarian & Bipartite & Yes & O(V³) & Min/Max cost matching \\
Blossom & General & Yes & O(V³) & Max cardinality or weight \\
\end{longtable}

\subsubsection{7. Relation to Flows}\label{relation-to-flows}

Bipartite matching = max flow on network:

\begin{itemize}
\tightlist
\item
  Left → Source edges (capacity 1)- Right → Sink edges (capacity 1)-
  Between sets → edges (capacity 1) Matching size = flow value
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-37}

Hopcroft-Karp Demo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nL }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}\NormalTok{ nR }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}
\NormalTok{adjL}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{\};}
\NormalTok{adjL}\OperatorTok{[}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{\};}
\NormalTok{adjL}\OperatorTok{[}\DecValTok{3}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{2}\OperatorTok{\};}
\NormalTok{printf}\OperatorTok{(}\StringTok{"Max Matching = }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ hopcroft\_karp}\OperatorTok{());} \CommentTok{// 2}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-37}

Matchings are the language of pairing and assignment. They express
cooperation without overlap , a structure of balance.

They reveal a deep duality:

\begin{quote}
``Every match is a flow, every assignment an optimization.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-37}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a bipartite graph and run Hopcroft-Karp.
\item
  Solve an assignment problem with Hungarian algorithm.
\item
  Explore Blossom's contraction idea conceptually.
\item
  Compare max-flow vs matching approach.
\item
  Use matching to model scheduling (people ↔ tasks).
\end{enumerate}

Matching teaches how to pair without conflict, a lesson both
mathematical and universal.

\subsection{39. Tree Algorithms (LCA, HLD, Centroid
Decomposition)}\label{tree-algorithms-lca-hld-centroid-decomposition}

Trees are the backbone of many algorithms , they are connected, acyclic,
and wonderfully structured.

Because of their simplicity, they allow elegant divide-and-conquer,
dynamic programming, and query techniques. This section covers three
fundamental patterns:

\begin{itemize}
\tightlist
\item
  Lowest Common Ancestor (LCA) , answer ancestor queries fast-
  Heavy-Light Decomposition (HLD) , break trees into chains for segment
  trees / path queries- Centroid Decomposition , recursively split tree
  by balance for divide-and-conquer Each reveals a different way to
  reason about trees , by depth, by chains, or by balance.
\end{itemize}

\subsubsection{1. Lowest Common Ancestor
(LCA)}\label{lowest-common-ancestor-lca}

Given a tree, two nodes (u, v). The LCA is the lowest node (farthest
from root) that is an ancestor of both.

Applications:

\begin{itemize}
\tightlist
\item
  Distance queries- Path decomposition- RMQ / binary lifting- Tree DP
  and rerooting
\end{itemize}

\subsubsection{A. Naive Approach}\label{a.-naive-approach}

Climb ancestors until they meet. But this is (O(n)) per query , too slow
for many queries.

\subsubsection{B. Binary Lifting}\label{b.-binary-lifting}

Precompute ancestors at powers of 2. Then jump up by powers to align
depths.

Preprocessing:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DFS to record depth
\item
  \texttt{up{[}v{]}{[}k{]}} = 2\^{}k-th ancestor of v
\end{enumerate}

Answering query:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Lift deeper node up to same depth
\item
  Lift both together while
  \texttt{up{[}u{]}{[}k{]}\ !=\ up{[}v{]}{[}k{]}}
\item
  Return parent
\end{enumerate}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ LOG }\OperatorTok{=} \DecValTok{20}\OperatorTok{;}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ up}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{][}\NormalTok{LOG}\OperatorTok{],}\NormalTok{ depth}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ p}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ LOG}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{        up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]][}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ lca}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ v}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}\NormalTok{ swap}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ diff }\OperatorTok{=}\NormalTok{ depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ LOG}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{diff }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ k}\OperatorTok{))}\NormalTok{ u }\OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{u }\OperatorTok{==}\NormalTok{ v}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ u}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ LOG}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ k}\OperatorTok{{-}{-})}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ up}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{k}\OperatorTok{])}
\NormalTok{            u }\OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{k}\OperatorTok{],}\NormalTok{ v }\OperatorTok{=}\NormalTok{ up}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ up}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Preprocess: (O\(n \log n\))- Query: (O\(\log n\))
\end{itemize}

\subsubsection{C. Example}\label{c.-example-5}

Tree:

\begin{verbatim}
    1
   / \
  2   3
 / \
4   5
\end{verbatim}

\begin{itemize}
\tightlist
\item
  LCA(4,5) = 2- LCA(4,3) = 1
\end{itemize}

\subsubsection{2. Heavy-Light Decomposition
(HLD)}\label{heavy-light-decomposition-hld}

When you need to query paths (sum, max, min, etc.) on trees efficiently,
you can use Heavy-Light Decomposition.

\subsubsection{A. Idea}\label{a.-idea-11}

Decompose the tree into chains:

\begin{itemize}
\tightlist
\item
  Heavy edge = edge to child with largest subtree- Light edges = others
  Result: Every path from root to leaf crosses at most (O\(\log n\))
  light edges.
\end{itemize}

So, a path query can be broken into (O\(\log^2 n\)) segment tree
queries.

\subsubsection{B. Steps}\label{b.-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DFS to compute subtree sizes and identify heavy child
\item
  Decompose into chains
\item
  Assign IDs for segment tree
\item
  Use Segment Tree / BIT on linearized array
\end{enumerate}

Key functions:

\begin{itemize}
\tightlist
\item
  \texttt{dfs\_sz(u)} → compute subtree sizes-
  \texttt{decompose(u,\ head)} → assign chain heads Code (core):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ parent}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ depth}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ heavy}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ head}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ pos}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ cur\_pos }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ dfs\_sz}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ size }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ max\_sz }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
\NormalTok{        depth}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ depth}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ sz }\OperatorTok{=}\NormalTok{ dfs\_sz}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sz }\OperatorTok{\textgreater{}}\NormalTok{ max\_sz}\OperatorTok{)}\NormalTok{ max\_sz }\OperatorTok{=}\NormalTok{ sz}\OperatorTok{,}\NormalTok{ heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
\NormalTok{        size }\OperatorTok{+=}\NormalTok{ sz}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ size}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ decompose}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ h}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    head}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ h}\OperatorTok{;}
\NormalTok{    pos}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ cur\_pos}\OperatorTok{++;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)}\NormalTok{ decompose}\OperatorTok{(}\NormalTok{heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ h}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ v }\OperatorTok{!=}\NormalTok{ heavy}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{            decompose}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Query path(u, v):

\begin{itemize}
\item
  While heads differ, move up chain by chain- Query segment tree in
  \texttt{{[}pos{[}head{[}u{]}{]},\ pos{[}u{]}{]}}- When in same chain,
  query segment \texttt{{[}pos{[}v{]},\ pos{[}u{]}{]}} Complexity:
\item
  Build: (O(n))- Query/Update: (O\(\log^2 n\))
\end{itemize}

\subsubsection{C. Use Cases}\label{c.-use-cases-2}

\begin{itemize}
\tightlist
\item
  Path sums- Path maximums- Edge updates- Subtree queries
\end{itemize}

\subsubsection{3. Centroid Decomposition}\label{centroid-decomposition}

Centroid = node that splits tree into subtrees ≤ n/2 each. By removing
centroids recursively, we form a centroid tree.

Used for divide-and-conquer on trees.

\subsubsection{A. Steps}\label{a.-steps-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find centroid

  \begin{itemize}
  \item
    DFS to compute subtree sizes - Choose node where largest subtree ≤
    n/22. Decompose:
  \item
    Remove centroid - Recurse on subtrees Code (core):
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ subtree}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ removed}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{int}\NormalTok{ dfs\_size}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    subtree}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p }\OperatorTok{\&\&} \OperatorTok{!}\NormalTok{removed}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            subtree}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dfs\_size}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ subtree}\OperatorTok{[}\NormalTok{u}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ find\_centroid}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p }\OperatorTok{\&\&} \OperatorTok{!}\NormalTok{removed}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{subtree}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{)}
                \ControlFlowTok{return}\NormalTok{ find\_centroid}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ u}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ decompose}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ dfs\_size}\OperatorTok{(}\NormalTok{u}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ c }\OperatorTok{=}\NormalTok{ find\_centroid}\OperatorTok{(}\NormalTok{u}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\NormalTok{    removed}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \CommentTok{// process centroid here}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{c}\OperatorTok{])}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{removed}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{            decompose}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ c}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n \log n\))

\subsubsection{B. Applications}\label{b.-applications}

\begin{itemize}
\tightlist
\item
  Distance queries (decompose + store distance to centroid)- Tree
  problems solvable by divide-and-conquer- Dynamic queries (add/remove
  nodes)
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-22}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1591}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1477}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1477}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2386}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0568}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Query
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Preprocess
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LCA & Ancestor query & (O\(\log n\)) & (O\(n \log n\)) & Fast ancestor
lookup & \\
HLD & Path queries & (O\(\log^2 n\)) & (O(n)) & Segment tree-friendly
& \\
Centroid Decomposition & Divide tree & - & (O\(n \log n\)) & Balanced
splits & \\
\end{longtable}

\subsubsection{5. Interconnections}\label{interconnections}

\begin{itemize}
\tightlist
\item
  HLD often uses LCA internally.- Centroid decomposition may use
  distance to ancestor (via LCA).- All exploit tree structure to achieve
  sublinear queries.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-38}

LCA(4,5):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfs}\OperatorTok{(}\DecValTok{1}\OperatorTok{,}\DecValTok{1}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ lca}\OperatorTok{(}\DecValTok{4}\OperatorTok{,}\DecValTok{5}\OperatorTok{));} \CommentTok{// 2}
\end{Highlighting}
\end{Shaded}

HLD Path Sum: Build segment tree on \texttt{pos{[}u{]}} order, query
along chains.

Centroid: \texttt{decompose(1,\ -1);}

\subsubsection{Why It Matters}\label{why-it-matters-38}

Tree algorithms show how structure unlocks efficiency. They transform
naive traversals into fast, layered, or recursive solutions.

To master data structures, you must learn to ``climb'' and ``cut'' trees
intelligently.

\begin{quote}
``Every rooted path hides a logarithm.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-38}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement binary lifting LCA and test queries.
\item
  Add segment tree over HLD and run path sums.
\item
  Decompose tree by centroid and count nodes at distance k.
\item
  Combine LCA + HLD for path min/max.
\item
  Draw centroid tree of a simple graph.
\end{enumerate}

Master these, and trees will stop being ``just graphs'' , they'll become
\emph{tools}.

\subsection{40. Advanced Graph Algorithms and
Tricks}\label{advanced-graph-algorithms-and-tricks}

By now you've seen the big families , traversals, shortest paths, flows,
matchings, cuts, and trees. But real-world graphs often bring extra
constraints: dynamic updates, multiple sources, layered structures, or
special properties (planar, DAG, sparse).

This section gathers powerful advanced graph techniques , tricks and
patterns that appear across problems once you've mastered the basics.

We'll explore:

\begin{itemize}
\tightlist
\item
  Topological Sorting \& DAG DP- Strongly Connected Components
  (Condensation Graphs)- Articulation Points \& Bridges (2-Edge/Vertex
  Connectivity)- Eulerian \& Hamiltonian Paths- Graph Coloring \&
  Bipartiteness Tests- Cycle Detection \& Directed Acyclic Reasoning-
  Small-to-Large Merging, DSU on Tree, Mo's Algorithm on Trees- Bitmask
  DP on Graphs- Dynamic Graphs (Incremental/Decremental BFS/DFS)-
  Special Graphs (Planar, Sparse, Dense) These aren't just algorithms ,
  they're patterns that let you attack harder graph problems with
  insight.
\end{itemize}

\subsubsection{1. Topological Sorting \& DAG
DP}\label{topological-sorting-dag-dp}

In a DAG (Directed Acyclic Graph), edges always point forward. This
makes it possible to order vertices linearly so all edges go from left
to right , a topological order.

Use cases:

\begin{itemize}
\tightlist
\item
  Task scheduling- Dependency resolution- DP on DAG (longest/shortest
  path, counting paths) Algorithm (Kahn's):
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ topo\_sort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ indeg}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{),}\NormalTok{ res}\OperatorTok{;}
\NormalTok{    queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ indeg}\OperatorTok{[}\NormalTok{v}\OperatorTok{]++;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ u }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ u}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{indeg}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{        res}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
            \ControlFlowTok{if} \OperatorTok{({-}{-}}\NormalTok{indeg}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

DAG DP:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \DecValTok{0}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{:}\NormalTok{ topo\_order}\OperatorTok{)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ weight}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{v}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Complexity: O(V + E)

\subsubsection{2. Strongly Connected Components
(Condensation)}\label{strongly-connected-components-condensation}

In directed graphs, vertices may form SCCs (mutually reachable
components). Condensing SCCs yields a DAG, often easier to reason about.

Use:

\begin{itemize}
\tightlist
\item
  Component compression- Meta-graph reasoning- Cycle condensation
  Tarjan's Algorithm: DFS with low-link values, single pass.
\end{itemize}

Kosaraju's Algorithm: Two passes , DFS on graph and reversed graph.

Complexity: O(V + E)

Once SCCs are built, you can run DP or topological sort on the condensed
DAG.

\subsubsection{3. Articulation Points \&
Bridges}\label{articulation-points-bridges}

Find critical vertices/edges whose removal disconnects the graph.

\begin{itemize}
\tightlist
\item
  Articulation point: vertex whose removal increases component count-
  Bridge: edge whose removal increases component count Algorithm:
  Tarjan's DFS Track discovery time \texttt{tin{[}u{]}} and lowest
  reachable ancestor \texttt{low{[}u{]}}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    tin}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \OperatorTok{++}\NormalTok{timer}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{tin}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{            low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ tin}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}\NormalTok{ bridge}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}=}\NormalTok{ tin}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ p }\OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)}\NormalTok{ cut\_vertex}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
        \OperatorTok{\}} \ControlFlowTok{else}\NormalTok{ low}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{low}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ tin}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Applications:

\begin{itemize}
\tightlist
\item
  Network reliability- Biconnected components- 2-edge/vertex
  connectivity tests
\end{itemize}

\subsubsection{4. Eulerian \& Hamiltonian
Paths}\label{eulerian-hamiltonian-paths}

\begin{itemize}
\tightlist
\item
  Eulerian Path: visits every edge exactly once

  \begin{itemize}
  \tightlist
  \item
    Exists if graph is connected and 0 or 2 vertices have odd degree-
    Hamiltonian Path: visits every vertex exactly once (NP-hard) Euler
    Tour Construction: Hierholzer's algorithm (O(E))
  \end{itemize}
\end{itemize}

Applications:

\begin{itemize}
\tightlist
\item
  Route reconstruction (e.g., word chains)- Postman problems
\end{itemize}

\subsubsection{5. Graph Coloring \&
Bipartiteness}\label{graph-coloring-bipartiteness}

Bipartite Check: DFS/ BFS alternating colors Fails if odd cycle found.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ bipartite}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ color}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{color}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        queue}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ q}\OperatorTok{;}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}\NormalTok{ color}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{q}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{.}\NormalTok{front}\OperatorTok{();}\NormalTok{ q}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{color}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)}
\NormalTok{                    color}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ color}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{\^{}} \DecValTok{1}\OperatorTok{,}\NormalTok{ q}\OperatorTok{.}\NormalTok{push}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
                \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{color}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{==}\NormalTok{ color}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
                    \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Applications:

\begin{itemize}
\tightlist
\item
  2-SAT reduction- Planar graph coloring- Conflict-free assignment
\end{itemize}

\subsubsection{6. Cycle Detection}\label{cycle-detection-1}

\begin{itemize}
\tightlist
\item
  DFS + recursion stack for directed graphs- Union-Find for undirected
  graphs Used to test acyclicity, detect back edges, or find cycles for
  rollback or consistency checks.
\end{itemize}

\subsubsection{7. DSU on Tree (Small-to-Large
Merging)}\label{dsu-on-tree-small-to-large-merging}

For queries like ``count distinct colors in subtree,'' merge results
from smaller to larger subtrees to maintain O(n log n).

Pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  DFS through children
\item
  Keep large child's data structure
\item
  Merge small child's data in
\end{enumerate}

Applications:

\begin{itemize}
\tightlist
\item
  Offline subtree queries- Heavy subproblem caching
\end{itemize}

\subsubsection{8. Mo's Algorithm on Trees}\label{mos-algorithm-on-trees}

Offline algorithm to answer path queries efficiently:

\begin{itemize}
\tightlist
\item
  Convert path queries to ranges via Euler Tour- Use Mo's ordering to
  process in O((N + Q)√N) Useful when online updates aren't required.
\end{itemize}

\subsubsection{9. Bitmask DP on Graphs}\label{bitmask-dp-on-graphs}

For small graphs (n ≤ 20): State = subset of vertices e.g., Traveling
Salesman Problem (TSP)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min cost to visit mask}\OperatorTok{,}\NormalTok{ end at u}
\end{Highlighting}
\end{Shaded}

Transition:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{v}\OperatorTok{)][}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\NormalTok{v}\OperatorTok{])}
\end{Highlighting}
\end{Shaded}

Complexity: O(n² 2ⁿ)

\subsubsection{10. Dynamic Graphs}\label{dynamic-graphs}

Graphs that change:

\begin{itemize}
\tightlist
\item
  Incremental BFS: maintain distances as edges added- Decremental
  connectivity: union-find rollback or dynamic trees Used in online
  queries, evolving networks, or real-time systems.
\end{itemize}

\subsubsection{11. Special Graph Classes}\label{special-graph-classes}

\begin{itemize}
\tightlist
\item
  Planar graphs: ≤ 3V-6E; use face counting- Sparse graphs: adjacency
  lists best- Dense graphs: adjacency matrix / bitset Optimizations
  often hinge on density.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-39}

Topological Order:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{auto}\NormalTok{ order }\OperatorTok{=}\NormalTok{ topo\_sort}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ u }\OperatorTok{:}\NormalTok{ order}\OperatorTok{)}\NormalTok{ printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{ "}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Bridge Check: \texttt{if\ (low{[}v{]}\ \textgreater{}\ tin{[}u{]})} edge
is a bridge.

Euler Path Check: Count odd-degree nodes == 0 or 2.

\subsubsection{Why It Matters}\label{why-it-matters-39}

These advanced techniques complete your toolkit. They're not isolated ,
they combine to solve real-world puzzles: dependency graphs, robust
networks, optimized paths, compressed states.

They teach a mindset:

\begin{quote}
``Graphs are not obstacles , they're shapes of possibility.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-39}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement topological sort and DAG DP.
\item
  Find SCCs and build condensation graph.
\item
  Detect articulation points and bridges.
\item
  Check Euler path conditions on random graphs.
\item
  Try DSU on tree for subtree statistics.
\item
  Solve TSP via bitmask DP for n ≤ 15.
\end{enumerate}

Once you can mix and match these tools, you're no longer just navigating
graphs , you're shaping them.

\section{Chapter 5. Dynamic
Programming}\label{chapter-5.-dynamic-programming-1}

\subsection{41. DP Basics and State
Transitions}\label{dp-basics-and-state-transitions}

Dynamic Programming (DP) is one of the most powerful ideas in algorithm
design. It's about breaking a big problem into smaller overlapping
subproblems, solving each once, and reusing their answers.

When brute force explodes exponentially, DP brings it back under
control. This section introduces the mindset, the mechanics, and the
math behind DP.

\subsubsection{1. The Core Idea}\label{the-core-idea-1}

Many problems have two key properties:

\begin{itemize}
\item
  Overlapping subproblems: The same smaller computations repeat many
  times.
\item
  Optimal substructure: The optimal solution to a problem can be built
  from optimal solutions to its subproblems.
\end{itemize}

DP solves each subproblem once, stores the result, and reuses it. This
saves exponential time , often reducing ( O\(2^n\) ) to ( O\(n^2\) ) or
( O(n) ).

\subsubsection{2. The Recipe}\label{the-recipe}

When approaching a DP problem, follow this pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define the state. Decide what subproblems you'll solve. Example:
  \texttt{dp{[}i{]}\ =\ best\ answer\ for\ first\ i\ elements}.
\item
  Write the recurrence. Express each state in terms of smaller ones.
  Example: \texttt{dp{[}i{]}\ =\ dp{[}i-1{]}\ +\ cost(i)}
\item
  Set the base cases. Where does the recursion start? Example:
  \texttt{dp{[}0{]}\ =\ 0}
\item
  Decide the order. Bottom-up (iterative) or top-down (recursive with
  memoization).
\item
  Return the final answer. Often \texttt{dp{[}n{]}} or
  \texttt{max(dp{[}i{]})}.
\end{enumerate}

\subsubsection{3. Example: Fibonacci
Numbers}\label{example-fibonacci-numbers}

Let's begin with a classic , the nth Fibonacci number ( F(n) = F(n-1) +
F(n-2) ).

Recursive (slow):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This recomputes the same values over and over , exponential time.

Top-Down DP (Memoization):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fib}\OperatorTok{(}\NormalTok{n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Bottom-Up DP (Tabulation):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{    dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Space Optimized:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ fib}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ a }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ b }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ c}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        c }\OperatorTok{=}\NormalTok{ a }\OperatorTok{+}\NormalTok{ b}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=}\NormalTok{ b}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{=}\NormalTok{ c}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. States, Transitions, and
Dependencies}\label{states-transitions-and-dependencies}

A DP table is a map from states to answers. Each state depends on others
via a transition function.

Think of it like a graph , each edge represents a recurrence relation.

Example:

\begin{itemize}
\tightlist
\item
  State: \texttt{dp{[}i{]}\ =\ number\ of\ ways\ to\ reach\ step\ i}-
  Transition: \texttt{dp{[}i{]}\ =\ dp{[}i-1{]}\ +\ dp{[}i-2{]}} (like
  stairs)- Base: \texttt{dp{[}0{]}\ =\ 1}
\end{itemize}

\subsubsection{5. Common DP Patterns}\label{common-dp-patterns}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  1D Linear DP

  \begin{itemize}
  \tightlist
  \item
    Problems like Fibonacci, climbing stairs, LIS.
  \end{itemize}
\item
  2D DP

  \begin{itemize}
  \tightlist
  \item
    Grids, sequences, or combinations (LCS, knapsack).
  \end{itemize}
\item
  Bitmask DP

  \begin{itemize}
  \tightlist
  \item
    Subsets, TSP, combinatorial optimization.
  \end{itemize}
\item
  DP on Trees

  \begin{itemize}
  \tightlist
  \item
    Subtree computations (sum, diameter).
  \end{itemize}
\item
  Digit DP

  \begin{itemize}
  \tightlist
  \item
    Counting numbers with properties in a range.
  \end{itemize}
\item
  Segment DP

  \begin{itemize}
  \tightlist
  \item
    Matrix chain multiplication, interval merges.
  \end{itemize}
\end{enumerate}

\subsubsection{6. Top-Down vs Bottom-Up}\label{top-down-vs-bottom-up}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1098}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2805}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2927}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3171}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Approach
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Pros
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cons
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Top-Down & Recursion + Memoization & Easy to write, intuitive & Stack
overhead, needs memo \\
Bottom-Up & Iteration & Fast, space-optimizable & Harder to derive
order \\
\end{longtable}

When dependencies are simple and acyclic, bottom-up shines. When they're
complex, top-down is easier.

\subsubsection{7. Example 2: Climbing
Stairs}\label{example-2-climbing-stairs}

You can climb 1 or 2 steps at a time. How many distinct ways to reach
step ( n )?

State: \texttt{dp{[}i{]}\ =\ ways\ to\ reach\ step\ i} Transition:
\texttt{dp{[}i{]}\ =\ dp{[}i-1{]}\ +\ dp{[}i-2{]}} Base:
\texttt{dp{[}0{]}\ =\ 1,\ dp{[}1{]}\ =\ 1}

Code:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ climb}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{    dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{];}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Debugging DP}\label{debugging-dp}

To debug DP:

\begin{itemize}
\tightlist
\item
  Print intermediate states.- Visualize table (especially 2D).- Check
  base cases.- Trace one small example by hand.
\end{itemize}

\subsubsection{9. Complexity}\label{complexity-2}

Most DP algorithms are linear or quadratic in number of states:

\begin{itemize}
\tightlist
\item
  Time = (\#states) × (work per transition)- Space = (\#states) Example:
  Fibonacci: ( O(n) ) time, ( O(1) ) space Knapsack: ( O\(n \times W\) )
  LCS: ( O\(n \times m\) )
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-40}

Fibonacci (tabulated):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\DecValTok{100}\OperatorTok{];}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{];}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d}\StringTok{"}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-40}

DP is the art of remembering. It transforms recursion into iteration,
chaos into order.

From optimization to counting, from paths to sequences , once you see
substructure, DP becomes your hammer.

\begin{quote}
``Every repetition hides a recurrence.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-40}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write top-down and bottom-up Fibonacci.
\item
  Count ways to climb stairs with steps \{1,2,3\}.
\item
  Compute number of paths in an n×m grid.
\item
  Try to spot state, recurrence, base in each problem.
\item
  Draw dependency graphs to visualize transitions.
\end{enumerate}

DP isn't a formula , it's a mindset: break problems into parts, remember
the past, and build from it.

\subsection{42. Classic Problems (Knapsack, Subset Sum, Coin
Change)}\label{classic-problems-knapsack-subset-sum-coin-change}

Now that you know what dynamic programming \emph{is}, let's dive into
the classic trio , problems that every programmer meets early on:

\begin{itemize}
\tightlist
\item
  Knapsack (maximize value under weight constraint)- Subset Sum (can we
  form a given sum?)- Coin Change (how many ways or fewest coins to
  reach a total) These are the training grounds of DP: each shows how to
  define states, transitions, and base cases clearly.
\end{itemize}

\subsubsection{1. 0/1 Knapsack Problem}\label{knapsack-problem}

Problem: You have \texttt{n} items, each with weight \texttt{w{[}i{]}}
and value \texttt{v{[}i{]}}. A knapsack with capacity \texttt{W}. Pick
items (each at most once) to maximize total value, without exceeding
weight.

\subsubsection{A. State}\label{a.-state}

\texttt{dp{[}i{]}{[}w{]}} = max value using first \texttt{i} items with
capacity \texttt{w}

\subsubsection{B. Recurrence}\label{b.-recurrence}

For item \texttt{i}:

\begin{itemize}
\tightlist
\item
  If we don't take it: \texttt{dp{[}i-1{]}{[}w{]}}- If we take it (if
  \texttt{w{[}i{]}\ ≤\ w}):
  \texttt{dp{[}i-1{]}{[}w\ -\ w{[}i{]}{]}\ +\ v{[}i{]}} So, \[
  dp[i][w] = \max(dp[i-1][w], dp[i-1][w - w[i]] + v[i])
  \]
\end{itemize}

\subsubsection{C. Base Case}\label{c.-base-case}

\texttt{dp{[}0{]}{[}w{]}\ =\ 0} for all w (no items = no value)

\subsubsection{D. Implementation}\label{d.-implementation}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ knapsack}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ W}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ w}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ v}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{W}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ W}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ j }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{w}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{\textless{}=}\NormalTok{ j}\OperatorTok{)}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j }\OperatorTok{{-}}\NormalTok{ w}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]]} \OperatorTok{+}\NormalTok{ v}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{W}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: Time: (O(nW)) Space: (O(nW)) (can be optimized to 1D (O(W)))

\subsubsection{E. Space Optimization (1D
DP)}\label{e.-space-optimization-1d-dp}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{W}\OperatorTok{+}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ w }\OperatorTok{=}\NormalTok{ W}\OperatorTok{;}\NormalTok{ w }\OperatorTok{\textgreater{}=}\NormalTok{ weight}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ w}\OperatorTok{{-}{-})}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{w}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{w}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{w }\OperatorTok{{-}}\NormalTok{ weight}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{+}\NormalTok{ value}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{F. Example}\label{f.-example}

Items:

\begin{verbatim}
w = [2, 3, 4, 5]
v = [3, 4, 5, 6]
W = 5
\end{verbatim}

Best: take items 1 + 2 → value 7

\subsubsection{2. Subset Sum}\label{subset-sum}

Problem: Given a set \texttt{S} of integers, can we pick some to sum to
\texttt{target}?

\subsubsection{A. State}\label{a.-state-1}

\texttt{dp{[}i{]}{[}sum{]}\ =\ true} if we can form sum \texttt{sum}
using first \texttt{i} elements.

\subsubsection{B. Recurrence}\label{b.-recurrence-1}

\begin{itemize}
\tightlist
\item
  Don't take: \texttt{dp{[}i-1{]}{[}sum{]}}- Take (if
  \texttt{a{[}i{]}\ ≤\ sum}): \texttt{dp{[}i-1{]}{[}sum\ -\ a{[}i{]}{]}}
  So, \[
  dp[i][sum] = dp[i-1][sum] ; || ; dp[i-1][sum - a[i]]
  \]
\end{itemize}

\subsubsection{C. Base Case}\label{c.-base-case-1}

\texttt{dp{[}0{]}{[}0{]}\ =\ true} (sum 0 possible with no elements)
\texttt{dp{[}0{]}{[}sum{]}\ =\ false} for sum \textgreater{} 0

\subsubsection{D. Implementation}\label{d.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ subset\_sum}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ target}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{bool}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{target}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ target}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ target}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ j}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{||}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]];}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{target}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: Time: (O\(n \cdot target\))

\subsubsection{E. Example}\label{e.-example}

S = {[}3, 34, 4, 12, 5, 2{]}, target = 9 Yes → 4 + 5

\subsubsection{3. Coin Change}\label{coin-change}

Two variants:

\subsubsection{(a) Count Ways (Unbounded
Coins)}\label{a-count-ways-unbounded-coins}

``How many ways to make total \texttt{T} with coins \texttt{c{[}{]}}?''

Order doesn't matter.

State:
\texttt{dp{[}i{]}{[}t{]}\ =\ ways\ using\ first\ i\ coins\ for\ total\ t}

Recurrence:

\begin{itemize}
\tightlist
\item
  Skip coin: \texttt{dp{[}i-1{]}{[}t{]}}- Take coin (unlimited):
  \texttt{dp{[}i{]}{[}t\ -\ c{[}i{]}{]}} \[
  dp[i][t] = dp[i-1][t] + dp[i][t - c[i]]
  \]
\end{itemize}

Base: \texttt{dp{[}0{]}{[}0{]}\ =\ 1}

1D Simplified:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}\DecValTok{0}\OperatorTok{\};}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ coin }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=}\NormalTok{ coin}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t }\OperatorTok{{-}}\NormalTok{ coin}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

\subsubsection{(b) Min Coins (Fewest Coins to Reach
Total)}\label{b-min-coins-fewest-coins-to-reach-total}

State: \texttt{dp{[}t{]}\ =\ min\ coins\ to\ reach\ t}

Recurrence: \[
dp[t] = \min_{c_i \le t}(dp[t - c_i] + 1)
\]

Base: \texttt{dp{[}0{]}\ =\ 0}, rest = INF

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{fill}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{+}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{t }\OperatorTok{\textgreater{}=}\NormalTok{ c}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t }\OperatorTok{{-}}\NormalTok{ c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Example}\label{example-1}

Coins = {[}1,2,5{]}, Total = 5

\begin{itemize}
\tightlist
\item
  Ways: 4 (5; 2+2+1; 2+1+1+1; 1+1+1+1+1)- Min Coins: 1 (5)
\end{itemize}

\subsubsection{4. Summary}\label{summary-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2535}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1408}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2958}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1408}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0/1 Knapsack & Max value & dp{[}i{]}{[}w{]} & max(take, skip) & O(nW) \\
Subset Sum & Feasibility & dp{[}i{]}{[}sum{]} & OR of include/exclude &
O(n * sum) \\
Coin Change (ways) & Counting & dp{[}t{]} & dp{[}t{]} + dp{[}t - coin{]}
& O(nT) \\
Coin Change (min) & Optimization & dp{[}t{]} & min(dp{[}t - coin{]} + 1)
& O(nT) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-41}

Min Coin Change (1D):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
\NormalTok{fill}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{+}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{);}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=}\NormalTok{ c}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{t}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{t }\OperatorTok{{-}}\NormalTok{ c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{T}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-41}

These three are archetypes:

\begin{itemize}
\tightlist
\item
  Knapsack: optimize under constraint- Subset Sum: choose feasibility-
  Coin Change: count or minimize Once you master them, you can spot
  their patterns in harder problems , from resource allocation to
  pathfinding.
\end{itemize}

\begin{quote}
``Every constraint hides a choice; every choice hides a state.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-41}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement 0/1 Knapsack (2D and 1D).
\item
  Solve Subset Sum for target 30 with random list.
\item
  Count coin combinations for amount 10.
\item
  Compare ``min coins'' vs ``ways to form.''
\item
  Write down state-transition diagram for each.
\end{enumerate}

These three form your DP foundation , the grammar for building more
complex algorithms.

\subsection{43. Sequence Problems (LIS, LCS, Edit
Distance)}\label{sequence-problems-lis-lcs-edit-distance}

Sequence problems form the \emph{heart} of dynamic programming. They
appear in strings, arrays, genomes, text comparison, and version
control. Their power comes from comparing prefixes , building large
answers from aligned smaller ones.

This section explores three cornerstones:

\begin{itemize}
\tightlist
\item
  LIS (Longest Increasing Subsequence)- LCS (Longest Common
  Subsequence)- Edit Distance (Levenshtein Distance) Each teaches a new
  way to think about subproblems, transitions, and structure.
\end{itemize}

\subsubsection{1. Longest Increasing Subsequence
(LIS)}\label{longest-increasing-subsequence-lis}

Problem: Given an array, find the length of the longest subsequence that
is \emph{strictly increasing}.

A subsequence isn't necessarily contiguous , you can skip elements.

Example: \texttt{{[}10,\ 9,\ 2,\ 5,\ 3,\ 7,\ 101,\ 18{]}} → LIS is
\texttt{{[}2,\ 3,\ 7,\ 18{]}} → length 4

\subsubsection{A. State}\label{a.-state-2}

\texttt{dp{[}i{]}} = length of LIS ending at index \texttt{i}

\subsubsection{B. Recurrence}\label{b.-recurrence-2}

\[
dp[i] = 1 + \max_{j < i \land a[j] < a[i]} dp[j]
\]

If no smaller \texttt{a{[}j{]}}, then \texttt{dp{[}i{]}\ =\ 1}.

\subsubsection{C. Base}\label{c.-base}

\texttt{dp{[}i{]}\ =\ 1} for all i (each element alone is an LIS)

\subsubsection{D. Implementation}\label{d.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lis}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{],}\NormalTok{ best }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{        best }\OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{best}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ best}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^2\))

\subsubsection{E. Binary Search
Optimization}\label{e.-binary-search-optimization}

Use a tail array:

\begin{itemize}
\item
  \texttt{tail{[}len{]}\ =\ min\ possible\ ending\ value\ of\ LIS\ of\ length\ len}
  For each \texttt{x}:
\item
  Replace \texttt{tail{[}idx{]}} via lower\_bound
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lis\_fast}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}\&}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ tail}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ x }\OperatorTok{:}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\{}
        \KeywordTok{auto}\NormalTok{ it }\OperatorTok{=}\NormalTok{ lower\_bound}\OperatorTok{(}\NormalTok{tail}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ tail}\OperatorTok{.}\NormalTok{end}\OperatorTok{(),}\NormalTok{ x}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{it }\OperatorTok{==}\NormalTok{ tail}\OperatorTok{.}\NormalTok{end}\OperatorTok{())}\NormalTok{ tail}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{x}\OperatorTok{);}
        \ControlFlowTok{else} \OperatorTok{*}\NormalTok{it }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ tail}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n \log n\))

\subsubsection{2. Longest Common Subsequence
(LCS)}\label{longest-common-subsequence-lcs}

Problem: Given two strings, find the longest subsequence present in
both.

Example: \texttt{s1\ =\ "ABCBDAB"}, \texttt{s2\ =\ "BDCABA"} LCS =
``BCBA'' → length 4

\subsubsection{A. State}\label{a.-state-3}

\texttt{dp{[}i{]}{[}j{]}} = LCS length between \texttt{s1{[}0..i-1{]}}
and \texttt{s2{[}0..j-1{]}}

\subsubsection{B. Recurrence}\label{b.-recurrence-3}

\[
dp[i][j] =
\begin{cases}
dp[i-1][j-1] + 1, & \text{if } s_1[i-1] = s_2[j-1], \\
\max(dp[i-1][j],\, dp[i][j-1]), & \text{otherwise.}
\end{cases}
\]

\subsubsection{C. Base}\label{c.-base-1}

\texttt{dp{[}0{]}{[}*{]}\ =\ dp{[}*{]}{[}0{]}\ =\ 0} (empty string)

\subsubsection{D. Implementation}\label{d.-implementation-3}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ lcs}\OperatorTok{(}\NormalTok{string a}\OperatorTok{,}\NormalTok{ string b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{(),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ b}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0} \OperatorTok{||}\NormalTok{ j }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O(nm))

\subsubsection{E. Reconstruct LCS}\label{e.-reconstruct-lcs}

Trace back from \texttt{dp{[}n{]}{[}m{]}}:

\begin{itemize}
\tightlist
\item
  If chars equal → take it and move diagonally- Else move toward larger
  neighbor
\end{itemize}

\subsubsection{F. Example}\label{f.-example-1}

a = ``AGGTAB'', b = ``GXTXAYB'' LCS = ``GTAB'' → 4

\subsubsection{3. Edit Distance (Levenshtein
Distance)}\label{edit-distance-levenshtein-distance}

Problem: Minimum operations (insert, delete, replace) to convert string
\texttt{a} → \texttt{b}.

Example: \texttt{kitten\ →\ sitting} = 3 (replace k→s, insert i, insert
g)

\subsubsection{A. State}\label{a.-state-4}

\texttt{dp{[}i{]}{[}j{]}} = min edits to convert \texttt{a{[}0..i-1{]}}
→ \texttt{b{[}0..j-1{]}}

\subsubsection{B. Recurrence}\label{b.-recurrence-4}

If \texttt{a{[}i-1{]}\ ==\ b{[}j-1{]}}: \[
dp[i][j] = dp[i-1][j-1]
\]

Else: \[
dp[i][j] = 1 + \min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
\] (Delete, Insert, Replace)

\subsubsection{C. Base}\label{c.-base-2}

\begin{itemize}
\tightlist
\item
  \texttt{dp{[}0{]}{[}j{]}\ =\ j} (insert all)-
  \texttt{dp{[}i{]}{[}0{]}\ =\ i} (delete all)
\end{itemize}

\subsubsection{D. Implementation}\label{d.-implementation-4}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ edit\_distance}\OperatorTok{(}\NormalTok{string a}\OperatorTok{,}\NormalTok{ string b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{(),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ b}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{j }\OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
            \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ min}\OperatorTok{(\{}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]\});}
        \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O(nm))

\subsubsection{E. Example}\label{e.-example-1}

a = ``horse'', b = ``ros''

\begin{itemize}
\tightlist
\item
  replace h→r, delete r, delete e → 3
\end{itemize}

\subsubsection{4. Summary}\label{summary-5}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1806}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1111}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3194}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LIS & Single seq & dp{[}i{]} & 1 + max(dp{[}j{]}) & O(n²) / O(n log
n) \\
LCS & Two seqs & dp{[}i{]}{[}j{]} & if match +1 else max & O(nm) \\
Edit Distance & Two seqs & dp{[}i{]}{[}j{]} & if match 0 else 1 + min &
O(nm) \\
\end{longtable}

\subsubsection{5. Common Insights}\label{common-insights}

\begin{itemize}
\tightlist
\item
  LIS builds upward , from smaller sequences.- LCS aligns two sequences
  , compare prefixes.- Edit Distance quantifies \emph{difference} ,
  minimal edits. They're templates for bioinformatics, text diffing,
  version control, and more.
\end{itemize}

\subsubsection{Tiny Code}\label{tiny-code-42}

LCS:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\ControlFlowTok{else}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-42}

Sequence DPs teach you how to compare progressions , how structure and
similarity evolve over time.

They transform vague ``compare these'' tasks into crisp recurrence
relations.

\begin{quote}
``To align is to understand.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-42}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement LIS (O(n²) and O(n log n))
\item
  Find LCS of two given strings
\item
  Compute edit distance between ``intention'' and ``execution''
\item
  Modify LCS to print one valid subsequence
\item
  Try to unify LCS and Edit Distance in a single table
\end{enumerate}

Master these, and you can handle any DP on sequences , the DNA of
algorithmic thinking.

\subsection{44. Matrix and Chain
Problems}\label{matrix-and-chain-problems}

Dynamic programming shines when a problem involves choices over
intervals , which order, which split, which parenthesis. This chapter
explores a class of problems built on chains and matrices, where order
matters and substructure is defined by intervals.

We'll study:

\begin{itemize}
\tightlist
\item
  Matrix Chain Multiplication (MCM) - optimal parenthesization- Polygon
  Triangulation - divide shape into minimal-cost triangles- Optimal BST
  / Merge Patterns - weighted merging decisions These problems teach
  interval DP, where each state represents a segment ({[}i, j{]}).
\end{itemize}

\subsubsection{1. Matrix Chain Multiplication
(MCM)}\label{matrix-chain-multiplication-mcm}

Problem: Given matrices \(A_1, A_2, ..., A_n\), find the
parenthesization that minimizes total scalar multiplications.

Matrix \(A_i\) has dimensions \(p[i-1] \times p[i]\). We can multiply
\(A_i \cdot A_{i+1}\) only if inner dimensions match.

Goal: Minimize operations: \[
\text{cost}(i, j) = \min_k \big(\text{cost}(i, k) + \text{cost}(k+1, j) + p[i-1] \cdot p[k] \cdot p[j]\big)
\]

\subsubsection{A. State}\label{a.-state-5}

\texttt{dp{[}i{]}{[}j{]}} = min multiplications to compute \(A_i...A_j\)

\subsubsection{B. Base}\label{b.-base}

\texttt{dp{[}i{]}{[}i{]}\ =\ 0} (single matrix needs no multiplication)

\subsubsection{C. Recurrence}\label{c.-recurrence}

\[
dp[i][j] = \min_{i \le k < j} { dp[i][k] + dp[k+1][j] + p[i-1] \times p[k] \times p[j] }
\]

\subsubsection{D. Implementation}\label{d.-implementation-5}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ matrix\_chain}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ p}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INT\_MAX}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}
\NormalTok{                    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{][}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^3\)) time, (O\(n^2\)) space

\subsubsection{E. Example}\label{e.-example-2}

p = {[}10, 20, 30, 40, 30{]} Optimal order: ((A1A2)A3)A4 → cost 30000

\subsubsection{2. Polygon Triangulation}\label{polygon-triangulation}

Given a convex polygon with \texttt{n} vertices, connect
non-intersecting diagonals to minimize total cost. Cost of a triangle =
perimeter or product of side weights.

This is the same structure as MCM , divide polygon by diagonals.

\subsubsection{A. State}\label{a.-state-6}

\texttt{dp{[}i{]}{[}j{]}} = min triangulation cost for polygon vertices
from i to j.

\subsubsection{B. Recurrence}\label{b.-recurrence-5}

\[
dp[i][j] = \min_{i < k < j} (dp[i][k] + dp[k][j] + cost(i, j, k))
\]

Base: dp{[}i{]}{[}i+1{]} = 0 (fewer than 3 points)

\subsubsection{C. Implementation}\label{c.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ polygon\_triangulation}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{Point}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ p}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \DataTypeTok{double}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \FloatTok{1e18}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}
\NormalTok{                    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dist}\OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{])+}\NormalTok{dist}\OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{],}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{])+}\NormalTok{dist}\OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{],}\NormalTok{p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]));}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^3\))

\subsubsection{3. Optimal Binary Search Tree
(OBST)}\label{optimal-binary-search-tree-obst}

Given sorted keys \(k_1 < k_2 < \dots < k_n\) with search frequencies (
f{[}i{]} ), construct a BST with minimal expected search cost.

The more frequently accessed nodes should be nearer the root.

\subsubsection{A. State}\label{a.-state-7}

\texttt{dp{[}i{]}{[}j{]}} = min cost to build BST from keys
\texttt{i..j} \texttt{sum{[}i{]}{[}j{]}} = sum of frequencies from i to
j (precomputed)

\subsubsection{B. Recurrence}\label{b.-recurrence-6}

\[
dp[i][j] = \min_{k=i}^{j} (dp[i][k-1] + dp[k+1][j] + sum[i][j])
\]

Each root adds one to depth of its subtrees → extra cost =
\texttt{sum{[}i{]}{[}j{]}}

\subsubsection{C. Implementation}\label{c.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ optimal\_bst}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ freq}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{],}\NormalTok{ sum}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ freq}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ freq}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{            sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ freq}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+}\NormalTok{len}\OperatorTok{{-}}\DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INT\_MAX}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ r }\OperatorTok{\textless{}=}\NormalTok{ j}\OperatorTok{;}\NormalTok{ r}\OperatorTok{++)} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ left }\OperatorTok{=} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textgreater{}}\NormalTok{ i}\OperatorTok{)} \OperatorTok{?}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{r}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{:} \DecValTok{0}\OperatorTok{;}
                \DataTypeTok{int}\NormalTok{ right }\OperatorTok{=} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)} \OperatorTok{?}\NormalTok{ dp}\OperatorTok{[}\NormalTok{r}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{:} \DecValTok{0}\OperatorTok{;}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ left }\OperatorTok{+}\NormalTok{ right }\OperatorTok{+}\NormalTok{ sum}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: (O\(n^3\))

\subsubsection{4. Merge Pattern Problems}\label{merge-pattern-problems}

Many problems , merging files, joining ropes, Huffman coding , involve
repeatedly combining elements with minimal total cost.

All follow this template: \[
dp[i][j] = \min_{k} (dp[i][k] + dp[k+1][j] + \text{merge cost})
\]

Same structure as MCM.

\subsubsection{5. Key Pattern: Interval
DP}\label{key-pattern-interval-dp}

State:
\texttt{dp{[}i{]}{[}j{]}\ =\ best\ answer\ for\ subarray\ {[}i..j{]}}
Transition: Try all splits \texttt{k} between \texttt{i} and \texttt{j}

Template:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)}
 \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{       dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{j}\OperatorTok{,}\NormalTok{k}\OperatorTok{));}
 \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{6. Summary}\label{summary-6}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1250}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Recurrence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MCM & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k{]}+dp{[}k+1{]}{[}j{]}+p{[}i-1{]}\emph{p{[}k{]}}p{[}j{]})
& O(n³) \\
Polygon Triangulation & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k{]}+dp{[}k{]}{[}j{]}+cost) & O(n³) \\
OBST & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k-1{]}+dp{[}k+1{]}{[}j{]}+sum{[}i{]}{[}j{]}) & O(n³) \\
Merge Problems & dp{[}i{]}{[}j{]} &
min(dp{[}i{]}{[}k{]}+dp{[}k+1{]}{[}j{]}+merge cost) & O(n³) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-43}

Matrix Chain (Compact):

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]*}\NormalTok{p}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
  \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-43}

These problems are DP in 2D , reasoning over intervals and splits. They
train your ability to ``cut the problem'' at every possible point.

\begin{quote}
``Between every start and end lies a choice of where to divide.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-43}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement MCM and print parenthesization.
\item
  Solve polygon triangulation with edge weights.
\item
  Build OBST for frequencies {[}34, 8, 50{]}.
\item
  Visualize DP table diagonally.
\item
  Generalize to merging \texttt{k} segments at a time.
\end{enumerate}

Master these, and you'll see interval DP patterns hiding in parsing,
merging, and even AI planning.

\subsection{45. Bitmask DP and Traveling
Salesman}\label{bitmask-dp-and-traveling-salesman}

Some dynamic programming problems require you to track which items have
been used, or which subset of elements is active at a given point. This
is where Bitmask DP shines. It encodes subsets as binary masks, allowing
you to represent state space efficiently.

This technique is a must-know for:

\begin{itemize}
\tightlist
\item
  Traveling Salesman Problem (TSP)- Subset covering / visiting problems-
  Permutations and combinations of sets- Game states and toggles
\end{itemize}

\subsubsection{1. The Idea of Bitmask DP}\label{the-idea-of-bitmask-dp}

A bitmask is an integer whose binary representation encodes a subset.

For ( n ) elements:

\begin{itemize}
\tightlist
\item
  There are \(2^n\) subsets.- A subset is represented by a mask from
  \texttt{0} to \texttt{(1\ \textless{}\textless{}\ n)\ -\ 1}. Example
  for \texttt{n\ =\ 4}:
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Subset & Mask (binary) & Mask (decimal) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
∅ & 0000 & 0 \\
\{0\} & 0001 & 1 \\
\{1\} & 0010 & 2 \\
\{0,1,3\} & 1011 & 11 \\
\end{longtable}

We can check membership:

\begin{itemize}
\tightlist
\item
  \texttt{mask\ \&\ (1\ \textless{}\textless{}\ i)} → whether element
  \texttt{i} is in subset We can add elements:
\item
  \texttt{mask\ \textbar{}\ (1\ \textless{}\textless{}\ i)} → add
  element \texttt{i} We can remove elements:
\item
  \texttt{mask\ \&\ \textasciitilde{}(1\ \textless{}\textless{}\ i)} →
  remove element \texttt{i}
\end{itemize}

\subsubsection{2. Example: Traveling Salesman Problem
(TSP)}\label{example-traveling-salesman-problem-tsp}

Problem: Given \texttt{n} cities and cost matrix
\texttt{cost{[}i{]}{[}j{]}}, find the minimum cost Hamiltonian cycle
visiting all cities exactly once and returning to start.

\subsubsection{A. State}\label{a.-state-8}

\texttt{dp{[}mask{]}{[}i{]}} = minimum cost to reach city \texttt{i}
having visited subset \texttt{mask}

\begin{itemize}
\tightlist
\item
  \texttt{mask} → set of visited cities- \texttt{i} → current city
\end{itemize}

\subsubsection{B. Base Case}\label{b.-base-case}

\texttt{dp{[}1\textless{}\textless{}0{]}{[}0{]}\ =\ 0} (start at city 0,
only 0 visited)

\subsubsection{C. Transition}\label{c.-transition}

For each subset \texttt{mask} and city \texttt{i} in \texttt{mask}, try
moving from \texttt{i} to \texttt{j} not in \texttt{mask}:

\[
dp[mask \cup (1 << j)][j] = \min \big(dp[mask \cup (1 << j)][j], dp[mask][i] + cost[i][j]\big)
\]

\subsubsection{D. Implementation}\label{d.-implementation-6}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ tsp}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ cost}\OperatorTok{[}\DecValTok{20}\OperatorTok{][}\DecValTok{20}\OperatorTok{])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{const} \DataTypeTok{int}\NormalTok{ INF }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{N}\OperatorTok{][}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ m }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ m}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{m}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}

\NormalTok{    dp}\OperatorTok{[}\DecValTok{1}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;} \CommentTok{// start at city 0}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ mask}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(!(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{)))} \ControlFlowTok{continue}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
                \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ j}\OperatorTok{))} \ControlFlowTok{continue}\OperatorTok{;}
                \DataTypeTok{int}\NormalTok{ next }\OperatorTok{=}\NormalTok{ mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ j}\OperatorTok{);}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{next}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{next}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \DataTypeTok{int}\NormalTok{ ans }\OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        ans }\OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{ans}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{N}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ ans}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  States: ( O\(n \cdot 2^n\) )- Transitions: ( O(n) )- Total: (
  O\(n^2 \cdot 2^n\) )
\end{itemize}

\subsubsection{E. Example}\label{e.-example-3}

\begin{verbatim}
n = 4
cost = {
 {0, 10, 15, 20},
 {10, 0, 35, 25},
 {15, 35, 0, 30},
 {20, 25, 30, 0}
}
\end{verbatim}

Optimal path: 0 → 1 → 3 → 2 → 0 Cost = 80

\subsubsection{3. Other Common Bitmask DP
Patterns}\label{other-common-bitmask-dp-patterns}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Subset Sum / Partition
  \texttt{dp{[}mask{]}\ =\ true\ if\ subset\ represented\ by\ mask\ satisfies\ property}
\item
  Counting Set Bits \texttt{\_\_builtin\_popcount(mask)} gives number of
  elements in subset.
\item
  Iterating Over Submasks
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ sub }\OperatorTok{=}\NormalTok{ mask}\OperatorTok{;}\NormalTok{ sub}\OperatorTok{;}\NormalTok{ sub }\OperatorTok{=} \OperatorTok{(}\NormalTok{sub}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\&}\NormalTok{ mask}\OperatorTok{)}
    \CommentTok{// handle subset sub}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Assigning Tasks (Assignment Problem)
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Each mask represents set of workers assigned.- State:
  \texttt{dp{[}mask{]}\ =\ min\ cost\ for\ assigned\ tasks}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask}\OperatorTok{)} \ControlFlowTok{for} \OperatorTok{(}\NormalTok{task}\OperatorTok{)}
 \ControlFlowTok{if} \OperatorTok{(!(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ task}\OperatorTok{)))}
\NormalTok{   dp}\OperatorTok{[}\NormalTok{mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ task}\OperatorTok{)]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask }\OperatorTok{|} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ task}\OperatorTok{)],}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{\_\_builtin\_popcount}\OperatorTok{(}\NormalTok{mask}\OperatorTok{)][}\NormalTok{task}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Memory Tricks}\label{memory-tricks}

\begin{itemize}
\tightlist
\item
  If only previous masks needed, use rolling arrays:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{next}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \OperatorTok{...}
\NormalTok{swap}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,}\NormalTok{ next\_dp}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Compress dimensions: (O\(2^n\)) memory for small \texttt{n}
\end{itemize}

\subsubsection{5. Summary}\label{summary-7}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
TSP & dp{[}mask{]}{[}i{]} & min(dp{[}mask{]}{[}i{]} +
cost{[}i{]}{[}j{]}) & O(n²·2ⁿ) \\
Assignment & dp{[}mask{]} & add one new element & O(n²·2ⁿ) \\
Subset Sum & dp{[}mask{]} & union of valid subsets & O(2ⁿ·n) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-44}

Core Transition:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask}\OperatorTok{)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{i}\OperatorTok{))}
      \ControlFlowTok{for} \OperatorTok{(}\NormalTok{j}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(!(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{j}\OperatorTok{)))}
\NormalTok{          dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{|(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{j}\OperatorTok{)][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{|(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{j}\OperatorTok{)][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-44}

Bitmask DP is how you enumerate subsets efficiently. It bridges
combinatorics and optimization, solving exponential problems with
manageable constants.

\begin{quote}
``Every subset is a story, and bits are its alphabet.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-44}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve TSP with 4 cities (hand-trace the table).
\item
  Implement Assignment Problem using bitmask DP.
\item
  Count subsets with even sum.
\item
  Use bitmask DP to find maximum compatible set of tasks.
\item
  Explore how to optimize memory with bit tricks.
\end{enumerate}

Bitmask DP unlocks the world of subset-based reasoning , the foundation
of combinatorial optimization.

\subsection{46. Digit DP and SOS DP}\label{digit-dp-and-sos-dp}

In some problems, you don't iterate over indices or subsets , you
iterate over digits or masks to count or optimize over structured
states. Two major flavors stand out:

\begin{itemize}
\tightlist
\item
  Digit DP - counting numbers with certain properties (e.g.~digit sum,
  constraints)- SOS DP (Sum Over Subsets) - efficiently computing
  functions over all subsets These are essential techniques when brute
  force would require enumerating every number or subset, which quickly
  becomes impossible.
\end{itemize}

\subsubsection{1. Digit DP (Counting with
Constraints)}\label{digit-dp-counting-with-constraints}

Digit DP is used to count or sum over all numbers ≤ N that satisfy a
condition, such as:

\begin{itemize}
\tightlist
\item
  The sum of digits equals a target.- The number doesn't contain a
  forbidden digit.- The number has certain parity or divisibility.
  Instead of iterating over all numbers (up to 10¹⁸!), we iterate
  digit-by-digit.
\end{itemize}

\subsubsection{A. State Design}\label{a.-state-design}

Typical DP state:

\texttt{dp{[}pos{]}{[}sum{]}{[}tight{]}{[}leading\_zero{]}}

\begin{itemize}
\tightlist
\item
  \texttt{pos}: current digit index (from most significant to least)-
  \texttt{sum}: property tracker (e.g.~sum of digits, remainder)-
  \texttt{tight}: whether we're still restricted by N's prefix-
  \texttt{leading\_zero}: whether we've started placing nonzero digits
\end{itemize}

\subsubsection{B. Transition}\label{b.-transition}

At each digit position, we choose a digit \texttt{d}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{limit }\OperatorTok{=}\NormalTok{ tight }\OperatorTok{?} \OperatorTok{(}\NormalTok{digit at pos in N}\OperatorTok{)} \OperatorTok{:} \DecValTok{9}
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ limit}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    new\_tight }\OperatorTok{=}\NormalTok{ tight }\OperatorTok{\&\&} \OperatorTok{(}\NormalTok{d }\OperatorTok{==}\NormalTok{ limit}\OperatorTok{)}
\NormalTok{    new\_sum }\OperatorTok{=}\NormalTok{ sum }\OperatorTok{+}\NormalTok{ d}
    \CommentTok{// or new\_mod = (mod * 10 + d) \% M}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Transition accumulates results across valid choices.

\subsubsection{C. Base Case}\label{c.-base-case-2}

When \texttt{pos\ ==\ len(N)} (end of digits):

\begin{itemize}
\tightlist
\item
  Return 1 if condition holds (e.g.~\texttt{sum\ ==\ target}), else 0
\end{itemize}

\subsubsection{D. Example: Count numbers ≤ N with digit sum =
S}\label{d.-example-count-numbers-n-with-digit-sum-s}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ dp}\OperatorTok{[}\DecValTok{20}\OperatorTok{][}\DecValTok{200}\OperatorTok{][}\DecValTok{2}\OperatorTok{];}

\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ solve}\OperatorTok{(}\NormalTok{string s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pos}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sum}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ tight}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pos }\OperatorTok{==}\NormalTok{ s}\OperatorTok{.}\NormalTok{size}\OperatorTok{())} \ControlFlowTok{return}\NormalTok{ sum }\OperatorTok{==} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{sum }\OperatorTok{\textless{}} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{]} \OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{];}

    \DataTypeTok{int}\NormalTok{ limit }\OperatorTok{=}\NormalTok{ tight }\OperatorTok{?} \OperatorTok{(}\NormalTok{s}\OperatorTok{[}\NormalTok{pos}\OperatorTok{]} \OperatorTok{{-}} \CharTok{\textquotesingle{}0\textquotesingle{}}\OperatorTok{)} \OperatorTok{:} \DecValTok{9}\OperatorTok{;}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ limit}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)}
\NormalTok{        res }\OperatorTok{+=}\NormalTok{ solve}\OperatorTok{(}\NormalTok{s}\OperatorTok{,}\NormalTok{ pos}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ sum}\OperatorTok{{-}}\NormalTok{d}\OperatorTok{,}\NormalTok{ tight }\OperatorTok{\&\&} \OperatorTok{(}\NormalTok{d}\OperatorTok{==}\NormalTok{limit}\OperatorTok{));}

    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{]} \OperatorTok{=}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Usage:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{string N }\OperatorTok{=} \StringTok{"12345"}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ S }\OperatorTok{=} \DecValTok{9}\OperatorTok{;}
\NormalTok{memset}\OperatorTok{(}\NormalTok{dp}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{,} \KeywordTok{sizeof}\NormalTok{ dp}\OperatorTok{);}
\NormalTok{cout }\OperatorTok{\textless{}\textless{}}\NormalTok{ solve}\OperatorTok{(}\NormalTok{N}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ S}\OperatorTok{,} \DecValTok{1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Complexity: O(number of digits × sum × 2) → typically O(20 × 200 × 2)

\subsubsection{E. Example Variants}\label{e.-example-variants}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Count numbers divisible by 3 → track remainder:
  \texttt{new\_rem\ =\ (rem*10\ +\ d)\ \%\ 3}
\item
  Count numbers without consecutive equal digits → add
  \texttt{last\_digit} to state.
\item
  Count beautiful numbers (like palindromes, no repeated digits) → track
  bitmask of used digits.
\end{enumerate}

\subsubsection{F. Summary}\label{f.-summary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
State
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Transition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sum of digits = S & dp{[}pos{]}{[}sum{]}{[}tight{]} & sum-d &
O(len·S) \\
Divisible by k & dp{[}pos{]}{[}rem{]}{[}tight{]} & (rem*10+d)\%k &
O(len·k) \\
No repeated digits & dp{[}pos{]}{[}mask{]}{[}tight{]} & mask &
O(len·2¹⁰) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-45}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ d }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ d }\OperatorTok{\textless{}=}\NormalTok{ limit}\OperatorTok{;}\NormalTok{ d}\OperatorTok{++)}
\NormalTok{    res }\OperatorTok{+=}\NormalTok{ solve}\OperatorTok{(}\NormalTok{pos}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ sum}\OperatorTok{{-}}\NormalTok{d}\OperatorTok{,}\NormalTok{ tight }\OperatorTok{\&\&} \OperatorTok{(}\NormalTok{d}\OperatorTok{==}\NormalTok{limit}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. SOS DP (Sum Over
Subsets)}\label{sos-dp-sum-over-subsets}

When dealing with functions on subsets, we sometimes need to compute:

\[
f(S) = \sum_{T \subseteq S} g(T)
\]

Naively O(3ⁿ). SOS DP reduces it to O(n·2ⁿ).

\subsubsection{A. Setup}\label{a.-setup}

Let \texttt{f{[}mask{]}\ =\ g{[}mask{]}} initially. For each bit
\texttt{i}:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{n}\OperatorTok{);}\NormalTok{ mask}\OperatorTok{++)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{i}\OperatorTok{))}
\NormalTok{        f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{\^{}(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{i}\OperatorTok{)];}
\end{Highlighting}
\end{Shaded}

After this, \texttt{f{[}mask{]}} = sum of \texttt{g{[}sub{]}} for all
\texttt{sub\ ⊆\ mask}.

\subsubsection{B. Example}\label{b.-example-3}

Given array \texttt{a{[}mask{]}}, compute
\texttt{sum{[}mask{]}\ =\ sum\_\{sub\ ⊆\ mask\}\ a{[}sub{]}}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ n }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ n}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ f}\OperatorTok{[}\NormalTok{N}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{N}\OperatorTok{];}
\CommentTok{// initialize a[]}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ mask}\OperatorTok{++)}\NormalTok{ f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{mask}\OperatorTok{];}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ mask}\OperatorTok{++)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{))}
\NormalTok{        f}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ f}\OperatorTok{[}\NormalTok{mask }\OperatorTok{\^{}} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{)];}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Why It Works}\label{c.-why-it-works}

Each iteration adds contributions from subsets differing by one bit. By
processing all bits, every subset's contribution propagates upward.

\subsubsection{D. Variants}\label{d.-variants-1}

\begin{itemize}
\tightlist
\item
  Sum over supersets: reverse direction.- Max instead of sum: replace
  \texttt{+=} with \texttt{max=}.- XOR convolution: combine values under
  XOR subset relation.
\end{itemize}

\subsubsection{E. Applications}\label{e.-applications}

\begin{itemize}
\tightlist
\item
  Inclusion-exclusion acceleration- Precomputing subset statistics- DP
  over masks with subset transitions
\end{itemize}

\subsubsection{F. Complexity}\label{f.-complexity}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Naive & SOS DP \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Subset sum & O(3ⁿ) & O(n·2ⁿ) \\
Superset sum & O(3ⁿ) & O(n·2ⁿ) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-45}

Digit DP teaches counting under constraints , thinking digit by digit.
SOS DP teaches subset propagation , spreading information efficiently.

Together, they show how to tame exponential state spaces with structure.

\begin{quote}
``When the search space explodes, symmetry and structure are your
compass.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-45}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count numbers ≤ 10⁹ whose digit sum = 10.
\item
  Count numbers ≤ 10⁶ without repeated digits.
\item
  Compute f{[}mask{]} = sum\_\{sub⊆mask\} a{[}sub{]} for n=4.
\item
  Use SOS DP to find how many subsets of bits have even sum.
\item
  Modify Digit DP to handle leading zeros explicitly.
\end{enumerate}

Master these, and you can handle structured exponential problems with
elegance and speed.

\subsection{47. DP Optimizations (Divide \& Conquer, Convex Hull Trick,
Knuth)}\label{dp-optimizations-divide-conquer-convex-hull-trick-knuth}

Dynamic Programming often starts with a simple recurrence, but naïve
implementations can be too slow (e.g., ( O\(n^2\) ) or worse). When the
recurrence has special structure , such as monotonicity or convexity ,
we can exploit it to reduce time complexity drastically.

This chapter introduces three powerful optimization families:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide and Conquer DP
\item
  Convex Hull Trick (CHT)
\item
  Knuth Optimization
\end{enumerate}

Each one is based on discovering order or geometry hidden inside
transitions.

\subsubsection{1. Divide and Conquer
Optimization}\label{divide-and-conquer-optimization}

If you have a recurrence like: \[
dp[i] = \min_{k < i} { dp[k] + C(k, i) }
\]

and the optimal k for dp{[}i{]} ≤ optimal k for dp{[}i+1{]}, you can use
divide \& conquer to compute dp in ( O\(n \log n\) ) or (
O\(n \log^2 n\) ).

This property is called monotonicity of argmin.

\subsubsection{A. Conditions}\label{a.-conditions}

Let ( C(k, i) ) be the cost to transition from ( k ) to ( i ). Divide
and conquer optimization applies if:

\[
opt(i) \le opt(i+1)
\]

and ( C ) satisfies quadrangle inequality (or similar convex structure).

\subsubsection{B. Template}\label{b.-template}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ compute}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optL}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optR}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textgreater{}}\NormalTok{ r}\OperatorTok{)} \ControlFlowTok{return}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{l }\OperatorTok{+}\NormalTok{ r}\OperatorTok{)} \OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{    pair}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ best }\OperatorTok{=} \OperatorTok{\{}\NormalTok{INF}\OperatorTok{,} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ optL}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}=}\NormalTok{ min}\OperatorTok{(}\NormalTok{mid}\OperatorTok{,}\NormalTok{ optR}\OperatorTok{);}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ val }\OperatorTok{=}\NormalTok{ dp\_prev}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{k}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textless{}}\NormalTok{ best}\OperatorTok{.}\NormalTok{first}\OperatorTok{)}\NormalTok{ best }\OperatorTok{=} \OperatorTok{\{}\NormalTok{val}\OperatorTok{,}\NormalTok{ k}\OperatorTok{\};}
    \OperatorTok{\}}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]} \OperatorTok{=}\NormalTok{ best}\OperatorTok{.}\NormalTok{first}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ opt }\OperatorTok{=}\NormalTok{ best}\OperatorTok{.}\NormalTok{second}\OperatorTok{;}
\NormalTok{    compute}\OperatorTok{(}\NormalTok{l}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ optL}\OperatorTok{,}\NormalTok{ opt}\OperatorTok{);}
\NormalTok{    compute}\OperatorTok{(}\NormalTok{mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{,}\NormalTok{ r}\OperatorTok{,}\NormalTok{ opt}\OperatorTok{,}\NormalTok{ optR}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

You call it as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{compute}\OperatorTok{(}\DecValTok{1}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \DecValTok{0}\OperatorTok{,}\NormalTok{ n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example: Divide Array into K
Segments}\label{c.-example-divide-array-into-k-segments}

Given array \texttt{a{[}1..n{]}}, divide into \texttt{k} parts to
minimize \[
dp[i][k] = \min_{j < i} dp[j][k-1] + cost(j+1, i)
\] If cost satisfies quadrangle inequality, you can optimize each layer
in ( O\(n \log n\) ).

\subsubsection{D. Complexity}\label{d.-complexity-1}

Naive: ( O\(n^2\) ) → Optimized: ( O\(n \log n\) )

\subsubsection{2. Convex Hull Trick (CHT)}\label{convex-hull-trick-cht}

Applies when DP recurrence is linear in i and k: \[
dp[i] = \min_{k < i} (m_k \cdot x_i + b_k)
\]

where:

\begin{itemize}
\tightlist
\item
  \(m_k\) is slope (depends on k)- ( b\_k = dp{[}k{]} + c(k) )- \(x_i\)
  is known (monotonic) You can maintain lines \(y = m_k x + b_k\) in a
  convex hull, and query min efficiently.
\end{itemize}

\subsubsection{A. Conditions}\label{a.-conditions-1}

\begin{itemize}
\tightlist
\item
  Slopes \(m_k\) are monotonic (either increasing or decreasing)- Query
  points \(x_i\) are sorted If both monotonic, we can use pointer walk
  in O(1) amortized per query. Otherwise, use Li Chao Tree (O(log n)).
\end{itemize}

\subsubsection{B. Implementation (Monotonic
Slopes)}\label{b.-implementation-monotonic-slopes}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Line }\OperatorTok{\{} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{,}\NormalTok{ b}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{deque}\OperatorTok{\textless{}}\NormalTok{Line}\OperatorTok{\textgreater{}}\NormalTok{ hull}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ bad}\OperatorTok{(}\NormalTok{Line l1}\OperatorTok{,}\NormalTok{ Line l2}\OperatorTok{,}\NormalTok{ Line l3}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{l3}\OperatorTok{.}\NormalTok{b }\OperatorTok{{-}}\NormalTok{ l1}\OperatorTok{.}\NormalTok{b}\OperatorTok{)*(}\NormalTok{l1}\OperatorTok{.}\NormalTok{m }\OperatorTok{{-}}\NormalTok{ l2}\OperatorTok{.}\NormalTok{m}\OperatorTok{)} \OperatorTok{\textless{}=} \OperatorTok{(}\NormalTok{l2}\OperatorTok{.}\NormalTok{b }\OperatorTok{{-}}\NormalTok{ l1}\OperatorTok{.}\NormalTok{b}\OperatorTok{)*(}\NormalTok{l1}\OperatorTok{.}\NormalTok{m }\OperatorTok{{-}}\NormalTok{ l3}\OperatorTok{.}\NormalTok{m}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ add}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Line l }\OperatorTok{=} \OperatorTok{\{}\NormalTok{m}\OperatorTok{,}\NormalTok{ b}\OperatorTok{\};}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{hull}\OperatorTok{.}\NormalTok{size}\OperatorTok{()} \OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&}\NormalTok{ bad}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{hull}\OperatorTok{.}\NormalTok{size}\OperatorTok{(){-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{.}\NormalTok{back}\OperatorTok{(),}\NormalTok{ l}\OperatorTok{))}
\NormalTok{        hull}\OperatorTok{.}\NormalTok{pop\_back}\OperatorTok{();}
\NormalTok{    hull}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{l}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ query}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{hull}\OperatorTok{.}\NormalTok{size}\OperatorTok{()} \OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&} 
\NormalTok{          hull}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{m}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ hull}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{b }\OperatorTok{\textgreater{}=}\NormalTok{ hull}\OperatorTok{[}\DecValTok{1}\OperatorTok{].}\NormalTok{m}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ hull}\OperatorTok{[}\DecValTok{1}\OperatorTok{].}\NormalTok{b}\OperatorTok{)}
\NormalTok{        hull}\OperatorTok{.}\NormalTok{pop\_front}\OperatorTok{();}
    \ControlFlowTok{return}\NormalTok{ hull}\OperatorTok{.}\NormalTok{front}\OperatorTok{().}\NormalTok{m}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ hull}\OperatorTok{.}\NormalTok{front}\OperatorTok{().}\NormalTok{b}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example: DP for Line-Based
Recurrence}\label{c.-example-dp-for-line-based-recurrence}

\[
dp[i] = a_i^2 + \min_{j < i} (dp[j] + b_j \cdot a_i)
\] Here \(m_j = b_j\), \(x_i = a_i\), \(b_j = dp[j]\)

\subsubsection{D. Complexity}\label{d.-complexity-2}

\begin{itemize}
\tightlist
\item
  Naive: ( O\(n^2\) )- CHT: ( O(n) ) or ( O\(n \log n\) )
\end{itemize}

\subsubsection{3. Knuth Optimization}\label{knuth-optimization}

Used in interval DP problems (like Matrix Chain, Merging Stones).

If:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(dp[i][j] = \min_{k=i}^{j-1} (dp[i][k] + dp[k+1][j] + w(i,j))\)
\item
  The cost \(w(i,j)\) satisfies the quadrangle inequality: \[
  w(a,c) + w(b,d) \le w(a,d) + w(b,c)
  \]
\item
  And the monotonicity condition: \[
  opt[i][j-1] \le opt[i][j] \le opt[i+1][j]
  \]
\end{enumerate}

Then you can reduce the search space from ( O(n) ) to ( O(1) ) per cell,
making total complexity ( O\(n^2\) ) instead of ( O\(n^3\) ).

\subsubsection{A. Implementation}\label{a.-implementation-1}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ opt}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}\NormalTok{ k }\OperatorTok{\textless{}=}\NormalTok{ opt}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ val }\OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{j}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textless{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ val}\OperatorTok{;}
\NormalTok{                opt}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ k}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Example}\label{b.-example-4}

Optimal Binary Search Tree or Merging Stones (with additive cost).
Typical improvement: ( O\(n^3\) \to O\(n^2\) )

\subsubsection{4. Summary}\label{summary-8}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2405}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2278}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3165}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2152}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Applies To
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Divide \& Conquer DP & 1D transitions & Monotonic argmin & O(n log n) \\
Convex Hull Trick & Linear transitions & Monotonic slopes & O(n) / O(n
log n) \\
Knuth Optimization & Interval DP & Quadrangle + Monotonicity & O(n²) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-46}

Divide \& Conquer Template

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ compute}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optL}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ optR}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

CHT Query

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{size}\OperatorTok{\textgreater{}=}\DecValTok{2} \OperatorTok{\&\&}\NormalTok{ f}\OperatorTok{[}\DecValTok{1}\OperatorTok{](}\NormalTok{x}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ f}\OperatorTok{[}\DecValTok{0}\OperatorTok{](}\NormalTok{x}\OperatorTok{))}\NormalTok{ pop\_front}\OperatorTok{();}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-46}

These optimizations show that DP isn't just brute force with memory ,
it's mathematical reasoning on structure.

Once you spot monotonicity or linearity, you can shrink a quadratic
solution into near-linear time.

\begin{quote}
``Optimization is the art of seeing simplicity hiding in structure.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-46}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Optimize Matrix Chain DP using Knuth.
\item
  Apply Divide \& Conquer on
  \texttt{dp{[}i{]}\ =\ min\_\{k\textless{}i\}(dp{[}k{]}+(i-k)\^{}2)}.
\item
  Solve Slope DP with CHT for convex cost functions.
\item
  Compare runtime vs naive DP on random data.
\item
  Derive conditions for opt monotonicity in your custom recurrence.
\end{enumerate}

Master these techniques, and you'll turn your DPs from slow prototypes
into lightning-fast solutions.

\subsection{48. Tree DP and Rerooting}\label{tree-dp-and-rerooting}

Dynamic Programming on trees is one of the most elegant and powerful
patterns in algorithm design. Unlike linear arrays or grids, trees form
hierarchical structures, where each node depends on its children or
parent. Tree DP teaches you how to aggregate results up and down the
tree, handling problems where subtrees interact.

In this section, we'll cover:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Basic Tree DP (rooted trees)
\item
  DP over children (bottom-up aggregation)
\item
  Rerooting technique (top-down propagation)
\item
  Common applications and examples
\end{enumerate}

\subsubsection{1. Basic Tree DP: The Idea}\label{basic-tree-dp-the-idea}

We define \texttt{dp{[}u{]}} to represent some property of the subtree
rooted at \texttt{u}. Then we combine children's results to compute
\texttt{dp{[}u{]}}.

This bottom-up approach is like postorder traversal.

Example structure:

\begin{verbatim}
function dfs(u, parent):
    dp[u] = base_value
    for v in adj[u]:
        if v == parent: continue
        dfs(v, u)
        dp[u] = combine(dp[u], dp[v])
\end{verbatim}

\subsubsection{Example 1: Size of
Subtree}\label{example-1-size-of-subtree}

Let \texttt{dp{[}u{]}\ =\ number\ of\ nodes\ in\ subtree\ rooted\ at\ u}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Key idea: Combine children's sizes to get parent size. Complexity: (
O(n) )

\subsubsection{Example 2: Height of
Tree}\label{example-2-height-of-tree}

Let \texttt{dp{[}u{]}\ =\ height\ of\ subtree\ rooted\ at\ u}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{],} \DecValTok{1} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This gives you the height when rooted at any node.

\subsubsection{2. DP Over Children (Bottom-Up
Aggregation)}\label{dp-over-children-bottom-up-aggregation}

Tree DP is all about merging children.

For example, if you want the number of ways to color or number of
independent sets, you compute children's dp and merge results at parent.

\subsubsection{Example 3: Counting Independent
Sets}\label{example-3-counting-independent-sets}

In a tree, an independent set is a set of nodes with no two adjacent.

State:

\begin{itemize}
\tightlist
\item
  \texttt{dp{[}u{]}{[}0{]}} = ways if \texttt{u} is not selected-
  \texttt{dp{[}u{]}{[}1{]}} = ways if \texttt{u} is selected Recurrence:
  \[
  dp[u][0] = \prod_{v \in children(u)} (dp[v][0] + dp[v][1])
  \]
\end{itemize}

\[
dp[u][1] = \prod_{v \in children(u)} dp[v][0]
\]

Implementation:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{*=} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\DecValTok{1}\OperatorTok{]);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{][}\DecValTok{1}\OperatorTok{]} \OperatorTok{*=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{][}\DecValTok{0}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Final answer = \texttt{dp{[}root{]}{[}0{]}\ +\ dp{[}root{]}{[}1{]}}

\subsubsection{Example 4: Maximum Path Sum in
Tree}\label{example-4-maximum-path-sum-in-tree}

Let \texttt{dp{[}u{]}} = max path sum starting at \texttt{u} and going
down To find best path anywhere, store a global max over child pairs.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ ans }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ best1 }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ best2 }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ val }\OperatorTok{=}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{)} \OperatorTok{+}\NormalTok{ weight}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textgreater{}}\NormalTok{ best1}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{best1}\OperatorTok{,}\NormalTok{ val}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{val }\OperatorTok{\textgreater{}}\NormalTok{ best2}\OperatorTok{)}\NormalTok{ best2 }\OperatorTok{=}\NormalTok{ val}\OperatorTok{;}
    \OperatorTok{\}}
\NormalTok{    ans }\OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{ans}\OperatorTok{,}\NormalTok{ best1 }\OperatorTok{+}\NormalTok{ best2}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ best1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This gives tree diameter or max path sum.

\subsubsection{3. Rerooting Technique}\label{rerooting-technique}

Rerooting DP allows you to compute answers for every node as root,
without recomputing from scratch ( O\(n^2\) ). It's also known as DP on
trees with re-rooting.

\subsubsection{Idea}\label{idea}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First, compute \texttt{dp\_down{[}u{]}} = answer for subtree when
  rooted at \texttt{u}.
\item
  Then, propagate info from parent to child (\texttt{dp\_up{[}u{]}}), so
  each node gets info from outside its subtree.
\item
  Combine \texttt{dp\_down} and \texttt{dp\_up} to get
  \texttt{dp\_all{[}u{]}}.
\end{enumerate}

\subsubsection{Example 5: Sum of Distances from Each
Node}\label{example-5-sum-of-distances-from-each-node}

Let's find \texttt{ans{[}u{]}} = sum of distances from \texttt{u} to all
nodes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Root the tree at 0.
\item
  Compute subtree sizes and total distance from root.
\item
  Reroot to adjust distances using parent's info.
\end{enumerate}

Step 1: Bottom-up:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs1}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    sz}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dfs1}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
\NormalTok{        sz}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Step 2: Top-down:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs2}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{==}\NormalTok{ p}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\NormalTok{        dfs2}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

After \texttt{dfs2}, \texttt{dp{[}u{]}} = sum of distances from node
\texttt{u}.

Complexity: ( O(n) )

\subsubsection{4. General Rerooting
Template}\label{general-rerooting-template}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1. Postorder: compute dp\_down[u] from children}
\DataTypeTok{void}\NormalTok{ dfs\_down}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ p}\OperatorTok{):}
\NormalTok{    dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ base}
    \ControlFlowTok{for}\NormalTok{ v in adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{]:}
        \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{:}
\NormalTok{            dfs\_down}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{)}
\NormalTok{            dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ dp\_down}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}

\CommentTok{// 2. Preorder: use parent\textquotesingle{}s dp\_up to compute dp\_all[u]}
\DataTypeTok{void}\NormalTok{ dfs\_up}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ p}\OperatorTok{,}\NormalTok{ dp\_up\_parent}\OperatorTok{):}
\NormalTok{    ans}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{dp\_down}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ dp\_up\_parent}\OperatorTok{)}
\NormalTok{    prefix}\OperatorTok{,}\NormalTok{ suffix }\OperatorTok{=}\NormalTok{ prefix products of children}
    \ControlFlowTok{for}\NormalTok{ each child v}\OperatorTok{:}
\NormalTok{        dp\_up\_v }\OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{prefix}\OperatorTok{[}\NormalTok{v}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ suffix}\OperatorTok{[}\NormalTok{v}\OperatorTok{+}\DecValTok{1}\OperatorTok{],}\NormalTok{ dp\_up\_parent}\OperatorTok{)}
\NormalTok{        dfs\_up}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{,}\NormalTok{ dp\_up\_v}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

This template generalizes rerooting to many problems:

\begin{itemize}
\tightlist
\item
  Maximum distance from each node- Number of ways to select subtrees-
  Sum of subtree sizes seen from each root
\end{itemize}

\subsubsection{5. Summary}\label{summary-9}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Pattern & Description & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Basic Tree DP & Combine child subresults & O(n) \\
DP Over Children & Each node depends on children & O(n) \\
Rerooting DP & Compute result for every root & O(n) \\
Multiple States & Track choices (e.g.~include/exclude) & O(n·state) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-47}

Subtree Size

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ u}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v}\OperatorTok{:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{u}\OperatorTok{);}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{];}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Reroot Sum Distances

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{+} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ sz}\OperatorTok{[}\NormalTok{v}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-47}

Tree DP is how we think recursively over structure , each node's truth
emerges from its children. Rerooting expands this idea globally, giving
every node its own perspective.

\begin{quote}
``In the forest of states, each root sees a different world , yet all
follow the same law.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-47}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count number of nodes in each subtree.
\item
  Compute sum of depths from each node.
\item
  Find tree diameter using DP.
\item
  Count number of independent sets modulo 1e9+7.
\item
  Implement rerooting to find max distance from each node.
\end{enumerate}

Tree DP turns recursive patterns into universal strategies for
hierarchical data.

\subsection{49. DP Reconstruction and
Traceback}\label{dp-reconstruction-and-traceback}

So far, we've focused on computing optimal values (min cost, max score,
count of ways). But in most real problems, we don't just want the number
, we want to know how we got it.

That's where reconstruction comes in: once you've filled your DP table,
you can trace back the decisions that led to the optimal answer.

This chapter shows you how to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Record transitions during DP computation
\item
  Reconstruct paths, subsets, or sequences
\item
  Handle multiple reconstructions (paths, sets, parent links)
\item
  Understand traceback in 1D, 2D, and graph-based DPs
\end{enumerate}

\subsubsection{1. The Core Idea}\label{the-core-idea-2}

Each DP state comes from a choice. If you store \emph{which choice was
best}, you can walk backward from the final state to rebuild the
solution.

Think of it as:

\begin{verbatim}
dp[i] = best over options
choice[i] = argmin or argmax option
\end{verbatim}

Then:

\begin{verbatim}
reconstruction_path = []
i = n
while i > 0:
    reconstruction_path.push(choice[i])
    i = choice[i].prev
\end{verbatim}

You're not just solving , you're remembering the path.

\subsubsection{2. Reconstruction in 1D
DP}\label{reconstruction-in-1d-dp}

\subsubsection{Example: Coin Change (Minimum
Coins)}\label{example-coin-change-minimum-coins}

Problem: Find minimum number of coins to make value \texttt{n}.

Recurrence: \[
dp[x] = 1 + \min_{c \in coins, c \le x} dp[x-c]
\]

To reconstruct which coins were used:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{],}\NormalTok{ prev\_coin}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{];}
\NormalTok{dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ x }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ x }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ x}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c }\OperatorTok{:}\NormalTok{ coins}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x }\OperatorTok{\textgreater{}=}\NormalTok{ c }\OperatorTok{\&\&}\NormalTok{ dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{{-}}\NormalTok{c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{x}\OperatorTok{{-}}\NormalTok{c}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{            prev\_coin}\OperatorTok{[}\NormalTok{x}\OperatorTok{]} \OperatorTok{=}\NormalTok{ c}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Reconstruction:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ used}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ cur }\OperatorTok{=}\NormalTok{ n}\OperatorTok{;}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{cur }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    used}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{prev\_coin}\OperatorTok{[}\NormalTok{cur}\OperatorTok{]);}
\NormalTok{    cur }\OperatorTok{{-}=}\NormalTok{ prev\_coin}\OperatorTok{[}\NormalTok{cur}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Output: coins used in one optimal solution.

\subsubsection{Example: LIS
Reconstruction}\label{example-lis-reconstruction}

You know how to find LIS length. Now reconstruct the sequence.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{],}\NormalTok{ prev}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ best\_end }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ prev}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1} \OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
\NormalTok{            prev}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
        \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{best\_end}\OperatorTok{])}\NormalTok{ best\_end }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Rebuild LIS:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ lis}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ best\_end}\OperatorTok{;}\NormalTok{ i }\OperatorTok{!=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{=}\NormalTok{ prev}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
\NormalTok{    lis}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\NormalTok{reverse}\OperatorTok{(}\NormalTok{lis}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ lis}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Reconstruction in 2D
DP}\label{reconstruction-in-2d-dp}

\subsubsection{Example: LCS (Longest Common
Subsequence)}\label{example-lcs-longest-common-subsequence}

We have \texttt{dp{[}i{]}{[}j{]}} filled using:

\[
dp[i][j] =
\begin{cases}
dp[i-1][j-1] + 1, & \text{if } a[i-1] = b[j-1], \\
\max(dp[i-1][j], dp[i][j-1]), & \text{otherwise.}
\end{cases}
\]

To reconstruct LCS:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=}\NormalTok{ m}\OperatorTok{;}
\NormalTok{string lcs }\OperatorTok{=} \StringTok{""}\OperatorTok{;}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ j }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        lcs}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
\NormalTok{        i}\OperatorTok{{-}{-};}\NormalTok{ j}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ i}\OperatorTok{{-}{-};}
    \ControlFlowTok{else}\NormalTok{ j}\OperatorTok{{-}{-};}
\OperatorTok{\}}
\NormalTok{reverse}\OperatorTok{(}\NormalTok{lcs}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ lcs}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\end{Highlighting}
\end{Shaded}

Output: one valid LCS string.

\subsubsection{Example: Edit Distance}\label{example-edit-distance}

Operations: insert, delete, replace.

You can store the operation:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"match"}\OperatorTok{;}
\ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{)}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"replace"}\OperatorTok{;}
\ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+} \DecValTok{1}\OperatorTok{)}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"delete"}\OperatorTok{;}
\ControlFlowTok{else}\NormalTok{ op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \StringTok{"insert"}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Then backtrack to list operations:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ j }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==} \StringTok{"match"}\OperatorTok{)}\NormalTok{ i}\OperatorTok{{-}{-},}\NormalTok{ j}\OperatorTok{{-}{-};}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==} \StringTok{"replace"}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\StringTok{"Replace"}\OperatorTok{);}\NormalTok{ i}\OperatorTok{{-}{-};}\NormalTok{ j}\OperatorTok{{-}{-};} \OperatorTok{\}}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{op}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{==} \StringTok{"delete"}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\StringTok{"Delete"}\OperatorTok{);}\NormalTok{ i}\OperatorTok{{-}{-};} \OperatorTok{\}}
    \ControlFlowTok{else} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\StringTok{"Insert"}\OperatorTok{);}\NormalTok{ j}\OperatorTok{{-}{-};} \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Reconstruction in Path
Problems}\label{reconstruction-in-path-problems}

When DP tracks shortest paths, you can keep parent pointers.

\subsubsection{Example: Bellman-Ford Path
Reconstruction}\label{example-bellman-ford-path-reconstruction}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\NormalTok{n}\OperatorTok{],}\NormalTok{ parent}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{dist}\OperatorTok{[}\NormalTok{src}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{u}\OperatorTok{,}\NormalTok{v}\OperatorTok{,}\NormalTok{w}\OperatorTok{]} \OperatorTok{:}\NormalTok{ edges}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w }\OperatorTok{\textless{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{        dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u}\OperatorTok{;}
    \OperatorTok{\}}

\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ path}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ v }\OperatorTok{=}\NormalTok{ dest}\OperatorTok{;}\NormalTok{ v }\OperatorTok{!=}\NormalTok{ src}\OperatorTok{;}\NormalTok{ v }\OperatorTok{=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\NormalTok{    path}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{path}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{src}\OperatorTok{);}
\NormalTok{reverse}\OperatorTok{(}\NormalTok{path}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ path}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
\end{Highlighting}
\end{Shaded}

You now have the actual shortest path.

\subsubsection{5. Handling Multiple
Solutions}\label{handling-multiple-solutions}

Sometimes multiple optimal paths exist. You can:

\begin{itemize}
\tightlist
\item
  Store all predecessors instead of one- Backtrack recursively to
  enumerate all solutions- Tie-break deterministically (e.g.,
  lexicographically smallest) Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{new\_val }\OperatorTok{==}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ parents}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{j}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Then recursively generate all possible paths.

\subsubsection{6. Visualization}\label{visualization-1}

DP reconstruction often looks like following arrows in a grid or graph:

\begin{itemize}
\tightlist
\item
  LCS: diagonal (↖), up (↑), left (←)- Shortest path: parent edges- LIS:
  predecessor chain You're walking through decisions, not just numbers.
\end{itemize}

\subsubsection{7. Summary}\label{summary-10}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Type & State & Reconstruction \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1D DP & \texttt{prev{[}i{]}} & Trace chain \\
2D DP & \texttt{op{[}i{]}{[}j{]}} & Follow choices \\
Graph DP & \texttt{parent{[}v{]}} & Follow edges \\
Counting DP & optional & Recover counts / paths \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-48}

General pattern:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{state}\OperatorTok{)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{choice}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{better}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ value}\OperatorTok{;}
\NormalTok{        parent}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ choice}\OperatorTok{;}
    \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Then:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{state }\OperatorTok{!=}\NormalTok{ base}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    path}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{parent}\OperatorTok{[}\NormalTok{state}\OperatorTok{]);}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ parent}\OperatorTok{[}\NormalTok{state}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-48}

Solving DP gets you the score , reconstructing shows you the story. It's
the difference between knowing the answer and understanding the
reasoning.

\begin{quote}
``Numbers tell you the outcome; pointers tell you the path.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-48}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reconstruct one LIS path.
\item
  Print all LCSs for small strings.
\item
  Show edit operations to transform ``cat'' → ``cut''.
\item
  Track subset used in Knapsack to reach exact weight.
\item
  Recover optimal merge order in Matrix Chain DP.
\end{enumerate}

Reconstruction turns DP from a static table into a narrative of
decisions , a map back through the maze of optimal choices.

\subsection{50. Meta-DP and Optimization
Templates}\label{meta-dp-and-optimization-templates}

We've now explored many flavors of dynamic programming , on sequences,
grids, trees, graphs, subsets, and digits. This final chapter in the DP
arc zooms out to the \emph{meta-level}: how to see DP patterns,
generalize them, and turn them into reusable templates.

If classical DP is about solving one problem, meta-DP is about
recognizing \emph{families} of problems that share structure. You'll
learn how to build your own DP frameworks, use common templates, and
reason from first principles.

\subsubsection{1. What Is Meta-DP?}\label{what-is-meta-dp}

A \emph{Meta-DP} is a high-level abstraction of a dynamic programming
pattern. It encodes:

\begin{itemize}
\tightlist
\item
  State definition pattern- Transition pattern- Optimization structure-
  Dimensional dependencies By learning these patterns, you can design
  DPs faster, reuse logic across problems, and spot optimizations early.
\end{itemize}

Think of Meta-DP as:

\begin{quote}
``Instead of memorizing 100 DPs, master 10 DP blueprints.''
\end{quote}

\subsubsection{2. The Four Building
Blocks}\label{the-four-building-blocks}

Every DP has the same core ingredients:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  State: what subproblem you're solving

  \begin{itemize}
  \item
    Often \texttt{dp{[}i{]}}, \texttt{dp{[}i{]}{[}j{]}}, or
    \texttt{dp{[}mask{]}} - Represents smallest unit of progress2.
    Transition: how to build larger subproblems from smaller ones
  \item
    E.g. \texttt{dp{[}i{]}\ =\ min(dp{[}j{]}\ +\ cost(j,\ i))}3. Base
    Case: known trivial answers
  \item
    E.g. \texttt{dp{[}0{]}\ =\ 0}4. Order: how to fill the states
  \item
    E.g. increasing \texttt{i}, decreasing \texttt{i}, or topological
    order Once you can describe a problem in these four, it \emph{is} a
    DP.
  \end{itemize}
\end{enumerate}

\subsubsection{3. Meta-Templates for Common
Structures}\label{meta-templates-for-common-structures}

Below are generalized templates to use and adapt.

\subsubsection{A. Line DP (1D
Sequential)}\label{a.-line-dp-1d-sequential}

Shape: linear progression Examples:

\begin{itemize}
\tightlist
\item
  Fibonacci- Knapsack (1D capacity)- LIS (sequential dependency)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ base}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{:}\NormalTok{ transitions}\OperatorTok{(}\NormalTok{i}\OperatorTok{))}
\NormalTok{        dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{j}\OperatorTok{,}\NormalTok{ i}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Visualization: → → → Each state depends on previous positions.

\subsubsection{B. Grid DP (2D Spatial)}\label{b.-grid-dp-2d-spatial}

Shape: grid or matrix Examples:

\begin{itemize}
\tightlist
\item
  Paths in a grid- Edit Distance- Counting paths with obstacles
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Visualization: ⬇️ ⬇️ ➡️ Moves from top-left to bottom-right.

\subsubsection{C. Interval DP}\label{c.-interval-dp}

Shape: segments or subarrays Examples:

\begin{itemize}
\tightlist
\item
  Matrix Chain Multiplication- Optimal BST- Merging Stones
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{      j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ len }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
      \ControlFlowTok{for} \OperatorTok{(}\NormalTok{k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}
\NormalTok{          dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{j}\OperatorTok{));}
  \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Key Insight: overlapping intervals, split points.

\subsubsection{D. Subset DP}\label{d.-subset-dp}

Shape: subsets of a set Examples:

\begin{itemize}
\tightlist
\item
  Traveling Salesman (TSP)- Assignment problem- SOS DP
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}} \OperatorTok{(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\NormalTok{n}\OperatorTok{);}\NormalTok{ mask}\OperatorTok{++)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{sub }\OperatorTok{=}\NormalTok{ mask}\OperatorTok{;}\NormalTok{ sub}\OperatorTok{;}\NormalTok{ sub }\OperatorTok{=} \OperatorTok{(}\NormalTok{sub}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)\&}\NormalTok{mask}\OperatorTok{)}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{mask}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{sub}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Key Insight: use bitmasks to represent subsets.

\subsubsection{E. Tree DP}\label{e.-tree-dp}

Shape: hierarchical dependencies Examples:

\begin{itemize}
\tightlist
\item
  Subtree sizes- Independent sets- Rerooting
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ dfs}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ p}\OperatorTok{):}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ base}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{v in children}\OperatorTok{)}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v }\OperatorTok{!=}\NormalTok{ p}\OperatorTok{)}
\NormalTok{      dfs}\OperatorTok{(}\NormalTok{v}\OperatorTok{,}\NormalTok{ u}\OperatorTok{)}
\NormalTok{      dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{])}
\end{Highlighting}
\end{Shaded}

\subsubsection{F. Graph DP (Topological
Order)}\label{f.-graph-dp-topological-order}

Shape: DAG structure Examples:

\begin{itemize}
\tightlist
\item
  Longest path in DAG- Counting paths- DAG shortest path
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{u in topo\_order}\OperatorTok{)}
  \ControlFlowTok{for} \OperatorTok{(}\NormalTok{v in adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])}
\NormalTok{    dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ weight}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{v}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Key: process nodes in topological order.

\subsubsection{G. Digit DP}\label{g.-digit-dp}

Shape: positional digits, constrained transitions Examples:

\begin{itemize}
\tightlist
\item
  Count numbers satisfying digit conditions- Divisibility / digit sum
  problems
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{pos}\OperatorTok{][}\NormalTok{sum}\OperatorTok{][}\NormalTok{tight}\OperatorTok{]} \OperatorTok{=}\NormalTok{ ∑ dp}\OperatorTok{[}\NormalTok{next\_pos}\OperatorTok{][}\NormalTok{new\_sum}\OperatorTok{][}\NormalTok{new\_tight}\OperatorTok{];}
\end{Highlighting}
\end{Shaded}

\subsubsection{H. Knuth / Divide \& Conquer / Convex Hull
Trick}\label{h.-knuth-divide-conquer-convex-hull-trick}

Shape: optimization over monotone or convex transitions Examples:

\begin{itemize}
\tightlist
\item
  Cost-based splits- Line-based transitions
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min\_k }\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{k}\OperatorTok{,}\NormalTok{ i}\OperatorTok{))}
\end{Highlighting}
\end{Shaded}

Key: structure in \texttt{opt{[}i{]}} or \texttt{slope}.

\subsubsection{4. Recognizing DP Type}\label{recognizing-dp-type}

Ask these diagnostic questions:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7121}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2879}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Question
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Clue
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``Does each step depend on smaller subproblems?'' & DP \\
``Do I split a segment?'' & Interval DP \\
``Do I choose subsets?'' & Subset / Bitmask DP \\
``Do I move along positions?'' & Line DP \\
``Do I merge children?'' & Tree DP \\
``Do I process in a DAG?'' & Graph DP \\
``Do I track digits or constraints?'' & Digit DP \\
\end{longtable}

\subsubsection{5. Optimization Layer}\label{optimization-layer}

Once you have a working DP, ask:

\begin{itemize}
\tightlist
\item
  Can transitions be reduced (monotonicity)?- Can overlapping cost be
  cached (prefix sums)?- Can dimensions be compressed (rolling arrays)?-
  Can you reuse solutions for each segment (Divide \& Conquer / Knuth)?
  This transforms your DP from conceptual to efficient.
\end{itemize}

\subsubsection{6. Meta-DP:
Transformations}\label{meta-dp-transformations}

\begin{itemize}
\tightlist
\item
  Compress dimensions: if only \texttt{dp{[}i-1{]}} needed, use 1D
  array.- Invert loops: bottom-up ↔ top-down.- Change base: prefix-sums
  for range queries.- State lifting: add dimension for new property
  (like remainder, parity, bitmask). \textgreater{} ``When stuck, add a
  dimension. When slow, remove one.''
\end{itemize}

\subsubsection{7. Common Template
Snippets}\label{common-template-snippets}

Rolling 1D Knapsack:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{c }\OperatorTok{=}\NormalTok{ C}\OperatorTok{;}\NormalTok{ c }\OperatorTok{\textgreater{}=}\NormalTok{ w}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ c}\OperatorTok{{-}{-})}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{c}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{c}\OperatorTok{{-}}\NormalTok{w}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{+}\NormalTok{ val}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\end{Highlighting}
\end{Shaded}

Top-Down Memoization:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ solve}\OperatorTok{(}\NormalTok{state}\OperatorTok{):}
  \ControlFlowTok{if} \OperatorTok{(}\NormalTok{visited}\OperatorTok{[}\NormalTok{state}\OperatorTok{])} \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{];}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{solve}\OperatorTok{(}\NormalTok{next\_states}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

Iterative DP:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{state in order}\OperatorTok{)}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ merge}\OperatorTok{(}\NormalTok{prev\_states}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Building Your Own DP
Framework}\label{building-your-own-dp-framework}

You can design a generic \texttt{DP(state,\ transition)} class:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ DP }\OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}}\NormalTok{ dp}\OperatorTok{;}
\NormalTok{    function}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{(}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{)\textgreater{}}\NormalTok{ cost}\OperatorTok{;}
\NormalTok{    DP}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \KeywordTok{auto}\NormalTok{ cost}\OperatorTok{):}\NormalTok{ dp}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ INF}\OperatorTok{),}\NormalTok{ cost}\OperatorTok{(}\NormalTok{cost}\OperatorTok{)} \OperatorTok{\{\}}
    \DataTypeTok{void}\NormalTok{ solve}\OperatorTok{()} \OperatorTok{\{} \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ j}\OperatorTok{\textless{}}\NormalTok{i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} 
\NormalTok{         dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ min}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ cost}\OperatorTok{(}\NormalTok{j}\OperatorTok{,}\NormalTok{ i}\OperatorTok{));} \OperatorTok{\}}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Reusable, readable, flexible.

\subsubsection{9. Summary}\label{summary-11}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
DP Type & Core State & Shape & Typical Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Line DP & dp{[}i{]} & Linear & O(n²) → O(n) \\
Grid DP & dp{[}i{]}{[}j{]} & Matrix & O(n·m) \\
Interval DP & dp{[}i{]}{[}j{]} & Triangular & O(n³) \\
Subset DP & dp{[}mask{]} & Exponential & O(n·2ⁿ) \\
Tree DP & dp{[}u{]} & Tree & O(n) \\
Digit DP & dp{[}pos{]}{[}sum{]} & Recursive & O(len·sum) \\
Graph DP & dp{[}v{]} & DAG & O(V+E) \\
\end{longtable}

\subsubsection{Tiny Code}\label{tiny-code-49}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{state in order}\OperatorTok{)}
\NormalTok{  dp}\OperatorTok{[}\NormalTok{state}\OperatorTok{]} \OperatorTok{=}\NormalTok{ combine}\OperatorTok{(}\NormalTok{all\_prev}\OperatorTok{(}\NormalTok{state}\OperatorTok{));}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-49}

Meta-DP turns your thinking from case-by-case to pattern-by-pattern. You
stop memorizing formulas and start \emph{seeing shapes}: lines, grids,
intervals, trees, masks.

Once you can name the shape, you can write the DP.

\begin{quote}
``DP is not about filling tables. It's about recognizing structure.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-49}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Classify each classic DP problem into a type.
\item
  Write one template per pattern (Line, Grid, Tree, etc.).
\item
  Create a \texttt{dp\_solve(state,\ transitions)} function to
  generalize logic.
\item
  For each pattern, practice a small example.
\item
  Build your own ``Little Book of DP Patterns'' with code snippets.
\end{enumerate}

This is your bridge from concrete solutions to algorithmic fluency , the
foundation for mastering the next 950 algorithms ahead.

\section{Chapter 6. Strings and Text
Algorithms}\label{chapter-6.-strings-and-text-algorithms}

\subsection{51. Number Theory (GCD, Modular Arithmetic,
CRT)}\label{number-theory-gcd-modular-arithmetic-crt}

Number theory forms the mathematical backbone of many algorithms , from
hashing and cryptography to modular combinatorics and primality testing.
In algorithmic problem-solving, it's all about working with integers,
divisibility, and modular systems efficiently.

This section covers the essential toolkit:

\begin{itemize}
\tightlist
\item
  GCD and Extended Euclidean Algorithm- Modular Arithmetic (addition,
  subtraction, multiplication, inverse)- Modular Exponentiation- Chinese
  Remainder Theorem (CRT)
\end{itemize}

\subsubsection{1. The Greatest Common Divisor
(GCD)}\label{the-greatest-common-divisor-gcd}

The GCD of two integers \(a\) and \(b\), denoted \(\gcd(a, b)\), is the
largest integer that divides both. It's the cornerstone for fraction
simplification, Diophantine equations, and modular inverses.

\subsubsection{A. Euclidean Algorithm}\label{a.-euclidean-algorithm}

Based on: \[
\gcd(a, b) = \gcd(b, a \bmod b)
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ gcd}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ b }\OperatorTok{==} \DecValTok{0} \OperatorTok{?}\NormalTok{ a }\OperatorTok{:}\NormalTok{ gcd}\OperatorTok{(}\NormalTok{b}\OperatorTok{,}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ b}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time complexity: \(O(\log \min(a,b))\)

\subsubsection{B. Extended Euclidean
Algorithm}\label{b.-extended-euclidean-algorithm}

Finds integers ( x, y ) such that: \[
ax + by = \gcd(a, b)
\]

This is critical for finding modular inverses.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ ext\_gcd}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{int} \OperatorTok{\&}\NormalTok{x}\OperatorTok{,} \DataTypeTok{int} \OperatorTok{\&}\NormalTok{y}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        x }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ y }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{return}\NormalTok{ a}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ x1}\OperatorTok{,}\NormalTok{ y1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ g }\OperatorTok{=}\NormalTok{ ext\_gcd}\OperatorTok{(}\NormalTok{b}\OperatorTok{,}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ b}\OperatorTok{,}\NormalTok{ x1}\OperatorTok{,}\NormalTok{ y1}\OperatorTok{);}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ y1}\OperatorTok{;}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ x1 }\OperatorTok{{-}} \OperatorTok{(}\NormalTok{a }\OperatorTok{/}\NormalTok{ b}\OperatorTok{)} \OperatorTok{*}\NormalTok{ y1}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ g}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Bezout's Identity}\label{c.-bezouts-identity}

If \(g = \gcd(a,b)\), then \(ax + by = g\) has integer solutions. If
\(g = 1\), \(x\) is the modular inverse of \(a modulo b\).

\subsubsection{2. Modular Arithmetic}\label{modular-arithmetic}

A modular system ``wraps around'' after a certain value ( m ).

We write: \[
a \equiv b \pmod{m} \quad \text{if } m \mid (a - b)
\]

It behaves like ordinary arithmetic, with the rule:

\begin{itemize}
\tightlist
\item
  \((a + b) \bmod m = ((a \bmod m) + (b \bmod m)) \bmod m\)
\item
  \((a \cdot b) \bmod m = ((a \bmod m) \cdot (b \bmod m)) \bmod m\)
\item
  \((a - b) \bmod m = ((a \bmod m) - (b \bmod m) + m) \bmod m\)
\end{itemize}

\subsubsection{A. Modular
Exponentiation}\label{a.-modular-exponentiation}

Compute \(a^b \bmod m\) efficiently using binary exponentiation.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ modpow}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{    a }\OperatorTok{\%=}\NormalTok{ m}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ res }\OperatorTok{=} \OperatorTok{(}\NormalTok{res }\OperatorTok{*}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=} \OperatorTok{(}\NormalTok{a }\OperatorTok{*}\NormalTok{ a}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: ( O\(\log b\) )

\subsubsection{B. Modular Inverse}\label{b.-modular-inverse}

Given ( a ), find \(a^{-1}\) such that: \[
a \cdot a^{-1} \equiv 1 \pmod{m}
\]

Case 1: If ( m ) is prime, use Fermat's Little Theorem: \[
a^{-1} \equiv a^{m-2} \pmod{m}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ modinv}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ m}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{,}\NormalTok{ m}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Case 2: If ( a ) and ( m ) are coprime, use Extended GCD:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ inv}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ g }\OperatorTok{=}\NormalTok{ ext\_gcd}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ m}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{g }\OperatorTok{!=} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;} \CommentTok{// no inverse}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{\%}\NormalTok{ m }\OperatorTok{+}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Modular Division}\label{c.-modular-division}

To divide \(a / b \bmod m\): \[
a / b \equiv a \cdot b^{-1} \pmod{m}
\]

So compute the inverse and multiply.

\subsubsection{3. Chinese Remainder Theorem
(CRT)}\label{chinese-remainder-theorem-crt}

The CRT solves systems of congruences: \[
x \equiv a_1 \pmod{m_1}
\]

\[
x \equiv a_2 \pmod{m_2}
\] If moduli \(m_1, m_2, \dots, m_k\) are pairwise coprime, there exists
a unique solution modulo \(M = m_1 m_2 \dots m_k\).

\subsubsection{A. 2-Equation Example}\label{a.-2-equation-example}

Solve: \[
x \equiv a_1 \pmod{m_1}, \quad x \equiv a_2 \pmod{m_2}
\]

Let:

\begin{itemize}
\tightlist
\item
  \(M = m_1 m_2\)- \(M_1 = M / m_1\)- \(M_2 = M / m_2\) Find inverses
  \(inv_1 = M_1^{-1} \bmod m_1\), \(inv_2 = M_2^{-1} \bmod m_2\)
\end{itemize}

Then: \[
x = (a_1 \cdot M_1 \cdot inv_1 + a_2 \cdot M_2 \cdot inv_2) \bmod M
\]

\subsubsection{B. Implementation}\label{b.-implementation-7}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ crt}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ a}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ M }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mod }\OperatorTok{:}\NormalTok{ m}\OperatorTok{)}\NormalTok{ M }\OperatorTok{*=}\NormalTok{ mod}\OperatorTok{;}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ Mi }\OperatorTok{=}\NormalTok{ M }\OperatorTok{/}\NormalTok{ m}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ inv }\OperatorTok{=}\NormalTok{ modinv}\OperatorTok{(}\NormalTok{Mi }\OperatorTok{\%}\NormalTok{ m}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ m}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\NormalTok{        res }\OperatorTok{=} \OperatorTok{(}\NormalTok{res }\OperatorTok{+} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*}\NormalTok{ Mi }\OperatorTok{\%}\NormalTok{ M }\OperatorTok{*}\NormalTok{ inv }\OperatorTok{\%}\NormalTok{ M}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{res }\OperatorTok{\%}\NormalTok{ M }\OperatorTok{+}\NormalTok{ M}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Example}\label{c.-example-6}

Solve:

\begin{verbatim}
x ≡ 2 (mod 3)
x ≡ 3 (mod 5)
x ≡ 2 (mod 7)
\end{verbatim}

Solution: ( x = 23 ) (mod 105)

Check:

\begin{itemize}
\tightlist
\item
  ( 23 \% 3 = 2 )- ( 23 \% 5 = 3 )- ( 23 \% 7 = 2 )
\end{itemize}

\subsubsection{4. Tiny Code}\label{tiny-code-50}

GCD

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ gcd}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ b }\OperatorTok{?}\NormalTok{ gcd}\OperatorTok{(}\NormalTok{b}\OperatorTok{,}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ b}\OperatorTok{)} \OperatorTok{:}\NormalTok{ a}\OperatorTok{;} \OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Modular Power

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modpow}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ m}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

Modular Inverse

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modinv}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ m}\OperatorTok{)}
\end{Highlighting}
\end{Shaded}

CRT

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{crt}\OperatorTok{(}\NormalTok{a}\OperatorTok{[],}\NormalTok{ m}\OperatorTok{[])}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Summary}\label{summary-12}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4722}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3194}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GCD & \(\gcd(a,b) = \gcd(b, a \bmod b)\) & Simplify ratios \\
Extended GCD & \(ax + by = \gcd(a,b)\) & Find modular inverse \\
Modular Inverse & \(a^{-1} \equiv a^{m-2} \pmod{m}\) & Solve modular
equations \\
Modular Exp & \(a^b \bmod m\) & Fast exponentiation \\
CRT & Combine congruences & Multi-mod system \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-50}

Number theory lets algorithms speak the language of integers , turning
huge computations into modular games. From hashing to RSA, from
combinatorics to cryptography, it's everywhere.

\begin{quote}
``When numbers wrap around, math becomes modular , and algorithms become
magical.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-50}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute gcd(48, 180).
\item
  Find inverse of 7 mod 13.
\item
  Solve \(x ≡ 1 \pmod{2}, x ≡ 2 \pmod{3}, x ≡ 3 \pmod{5}\).
\item
  Implement modular division \(a / b \bmod m\).
\item
  Use modpow to compute \(3^{200} \bmod 13\).
\end{enumerate}

These basics unlock higher algorithms in cryptography, combinatorics,
and beyond.

\subsection{52. Primality and Factorization (Miller-Rabin, Pollard
Rho)}\label{primality-and-factorization-miller-rabin-pollard-rho}

Primality and factorization are core to number theory, cryptography, and
competitive programming. Many modern systems (RSA, ECC) rely on the
hardness of factoring large numbers. Here, we learn how to test if a
number is prime and break it into factors efficiently.

We'll cover:

\begin{itemize}
\tightlist
\item
  Trial Division
\item
  Sieve of Eratosthenes (for precomputation)
\item
  Probabilistic Primality Test (Miller-Rabin)
\item
  Integer Factorization (Pollard Rho)
\end{itemize}

\subsubsection{1. Trial Division}\label{trial-division}

The simplest way to test primality is by dividing by all integers up to
√n.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ is\_prime}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}} \DecValTok{2}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{==} \DecValTok{2}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ i }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=} \DecValTok{2}\OperatorTok{)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%}\NormalTok{ i }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(\sqrt{n}\) ) Good for \(n \le 10^6\), impractical
for large ( n ).

\subsubsection{2. Sieve of Eratosthenes}\label{sieve-of-eratosthenes}

For checking many numbers at once, use a sieve.

Idea: Mark all multiples of each prime starting from 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{bool}\OperatorTok{\textgreater{}}\NormalTok{ sieve}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{bool}\OperatorTok{\textgreater{}}\NormalTok{ is\_prime}\OperatorTok{(}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);}
\NormalTok{    is\_prime}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ is\_prime}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_prime}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{)}
\NormalTok{                is\_prime}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ is\_prime}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log \log n\) )

Useful for generating primes up to \(10^7\).

\subsubsection{3. Modular Multiplication}\label{modular-multiplication}

Before we do probabilistic tests or factorization, we need safe modular
multiplication for large numbers.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ modmul}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    \_\_int128 res }\OperatorTok{=} \OperatorTok{(}\NormalTok{\_\_int128}\OperatorTok{)}\NormalTok{a }\OperatorTok{*}\NormalTok{ b }\OperatorTok{\%}\NormalTok{ m}\OperatorTok{;}
    \ControlFlowTok{return} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{)}\NormalTok{res}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Avoid overflow for \(n \approx 10^{18}\).

\subsubsection{4. Miller-Rabin Primality
Test}\label{miller-rabin-primality-test}

A probabilistic test that can check if ( n ) is prime or composite in (
O\(k \log^3 n\) ).

Idea: For a prime ( n ): \[
a^{n-1} \equiv 1 \pmod{n}
\] But for composites, most ( a ) fail this.

We write \(n - 1 = 2^s \cdot d\), ( d ) odd.

For each base ( a ):

\begin{itemize}
\tightlist
\item
  Compute \(x = a^d \bmod n\)- If ( x = 1 ) or ( x = n - 1 ), pass-
  Else, square ( s-1 ) times- If none equal ( n - 1 ), composite
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ miller\_rabin}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}} \DecValTok{2}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ p }\OperatorTok{:} \OperatorTok{\{}\DecValTok{2}\OperatorTok{,}\DecValTok{3}\OperatorTok{,}\DecValTok{5}\OperatorTok{,}\DecValTok{7}\OperatorTok{,}\DecValTok{11}\OperatorTok{,}\DecValTok{13}\OperatorTok{,}\DecValTok{17}\OperatorTok{,}\DecValTok{19}\OperatorTok{,}\DecValTok{23}\OperatorTok{,}\DecValTok{29}\OperatorTok{,}\DecValTok{31}\OperatorTok{,}\DecValTok{37}\OperatorTok{\})}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%}\NormalTok{ p }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{==}\NormalTok{ p}\OperatorTok{;}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ d }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ s }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{((}\NormalTok{d }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)} \OperatorTok{==} \DecValTok{0}\OperatorTok{)}\NormalTok{ d }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{,}\NormalTok{ s}\OperatorTok{++;}
    \KeywordTok{auto}\NormalTok{ modpow }\OperatorTok{=} \OperatorTok{[\&](}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ r }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ r }\OperatorTok{=}\NormalTok{ modmul}\OperatorTok{(}\NormalTok{r}\OperatorTok{,}\NormalTok{ a}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\NormalTok{            a }\OperatorTok{=}\NormalTok{ modmul}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ a}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\NormalTok{            b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{return}\NormalTok{ r}\OperatorTok{;}
    \OperatorTok{\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a }\OperatorTok{:} \OperatorTok{\{}\DecValTok{2}\OperatorTok{,} \DecValTok{325}\OperatorTok{,} \DecValTok{9375}\OperatorTok{,} \DecValTok{28178}\OperatorTok{,} \DecValTok{450775}\OperatorTok{,} \DecValTok{9780504}\OperatorTok{,} \DecValTok{1795265022}\OperatorTok{\})} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a }\OperatorTok{\%}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ d}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x }\OperatorTok{==} \DecValTok{1} \OperatorTok{||}\NormalTok{ x }\OperatorTok{==}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \DataTypeTok{bool}\NormalTok{ composite }\OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ r }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ r }\OperatorTok{\textless{}}\NormalTok{ s}\OperatorTok{;}\NormalTok{ r}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{            x }\OperatorTok{=}\NormalTok{ modmul}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x }\OperatorTok{==}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                composite }\OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
                \ControlFlowTok{break}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{composite}\OperatorTok{)} \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Deterministic for:

\begin{itemize}
\tightlist
\item
  \(n < 2^{64}\) with bases above. Complexity: ( O\(k \log^3 n\) )
\end{itemize}

\subsubsection{5. Pollard Rho
Factorization}\label{pollard-rho-factorization}

Efficient for finding nontrivial factors of large composites. Based on
Floyd's cycle detection (Tortoise and Hare).

Idea: Define a pseudo-random function: \[
f(x) = (x^2 + c) \bmod n
\] Then find \(\gcd(|x - y|, n)\) where \(x, y\) move at different
speeds.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ pollard\_rho}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{2}\OperatorTok{;}
    \KeywordTok{auto}\NormalTok{ f }\OperatorTok{=} \OperatorTok{[\&](}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ c}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{return} \OperatorTok{(}\NormalTok{modmul}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ n}\OperatorTok{)} \OperatorTok{+}\NormalTok{ c}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ n}\OperatorTok{;}
    \OperatorTok{\};}
    \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{)} \OperatorTok{+} \DecValTok{2}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ y }\OperatorTok{=}\NormalTok{ x}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ c }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{+} \DecValTok{1}\OperatorTok{;}
        \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ d }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{d }\OperatorTok{==} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            x }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ c}\OperatorTok{);}
\NormalTok{            y }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{f}\OperatorTok{(}\NormalTok{y}\OperatorTok{,}\NormalTok{ c}\OperatorTok{),}\NormalTok{ c}\OperatorTok{);}
\NormalTok{            d }\OperatorTok{=}\NormalTok{ gcd}\OperatorTok{(}\NormalTok{abs}\OperatorTok{(}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ y}\OperatorTok{),}\NormalTok{ n}\OperatorTok{);}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{d }\OperatorTok{!=}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ d}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check if ( n ) is prime (Miller-Rabin)
\item
  If not, find a factor using Pollard Rho
\item
  Recurse on factors
\end{enumerate}

Complexity: \textasciitilde{} ( O\(n^{1/4}\) ) average

\subsubsection{6. Example}\label{example-2}

Factorize ( n = 8051 ):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Miller-Rabin → composite
\item
  Pollard Rho → factor 83
\item
  ( 8051 / 83 = 97 )
\item
  Both primes ⇒ ( 8051 = 83 × 97 )
\end{enumerate}

\subsubsection{7. Tiny Code}\label{tiny-code-51}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ factor}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ n}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{f}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{1}\OperatorTok{)} \ControlFlowTok{return}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{miller\_rabin}\OperatorTok{(}\NormalTok{n}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        f}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
        \ControlFlowTok{return}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ d }\OperatorTok{=}\NormalTok{ pollard\_rho}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    factor}\OperatorTok{(}\NormalTok{d}\OperatorTok{,}\NormalTok{ f}\OperatorTok{);}
\NormalTok{    factor}\OperatorTok{(}\NormalTok{n }\OperatorTok{/}\NormalTok{ d}\OperatorTok{,}\NormalTok{ f}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Call \texttt{factor(n,\ f)} to get prime factors.

\subsubsection{8. Summary}\label{summary-13}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2188}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2656}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3125}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2031}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trial Division & Small primes & ( O\(\sqrt{n}\) ) & Deterministic \\
Sieve & Precompute primes & ( O\(n \log \log n\) ) & Deterministic \\
Miller-Rabin & Primality test & ( O\(k \log^3 n\) ) & Probabilistic \\
Pollard Rho & Factorization & ( O\(n^{1/4}\) ) & Probabilistic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-51}

Modern security, number theory problems, and many algorithmic puzzles
depend on knowing when a number is prime and factoring it quickly when
it isn't. These tools are the entry point to RSA, modular combinatorics,
and advanced cryptography.

\subsubsection{Try It Yourself}\label{try-it-yourself-51}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check if 97 is prime using trial division and Miller-Rabin.
\item
  Factorize 5959 (should yield 59 × 101).
\item
  Generate all primes ≤ 100 using a sieve.
\item
  Write a recursive factorizer using Pollard Rho + Miller-Rabin.
\item
  Measure performance difference between \(\sqrt{n}\) trial and Pollard
  Rho for \(n \approx 10^{12}\).
\end{enumerate}

These techniques make huge numbers approachable , one factor at a time.

\subsection{53. Combinatorics (Permutations, Combinations,
Subsets)}\label{combinatorics-permutations-combinations-subsets}

Combinatorics is the art of counting structures , how many ways can we
arrange, select, or group things? In algorithms, it's everywhere: DP
transitions, counting paths, bitmask enumeration, and probabilistic
reasoning. Here we'll build a toolkit for computing factorials, nCr,
nPr, and subset counts, both exactly and under a modulus.

\subsubsection{1. Factorials and
Precomputation}\label{factorials-and-precomputation}

Most combinatorial formulas rely on factorials: \[
n! = 1 \times 2 \times 3 \times \dots \times n
\]

We can precompute them modulo ( m ) (often \(10^9+7\)) for efficiency.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ MOD }\OperatorTok{=} \FloatTok{1e9} \OperatorTok{+} \DecValTok{7}\OperatorTok{;}
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ MAXN }\OperatorTok{=} \FloatTok{1e6}\OperatorTok{;}
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ fact}\OperatorTok{[}\NormalTok{MAXN }\OperatorTok{+} \DecValTok{1}\OperatorTok{],}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{MAXN }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}

\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ modpow}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ res }\OperatorTok{=}\NormalTok{ res }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=}\NormalTok{ a }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ init\_factorials}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    fact}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ MAXN}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        fact}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ fact}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{]} \OperatorTok{*}\NormalTok{ i }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{    invfact}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{]} \OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{fact}\OperatorTok{[}\NormalTok{MAXN}\OperatorTok{],}\NormalTok{ MOD }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ MAXN }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})}
\NormalTok{        invfact}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{]} \OperatorTok{*} \OperatorTok{(}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Now you can compute ( nCr ) and ( nPr ) in ( O(1) ) time.

\subsubsection{2. Combinations ( nCr )}\label{combinations-ncr}

The number of ways to choose r items from ( n ) items: \[
C(n, r) = \frac{n!}{r!(n-r)!}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ nCr}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ r }\OperatorTok{\textgreater{}}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fact}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{*}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{r}\OperatorTok{]} \OperatorTok{\%}\NormalTok{ MOD }\OperatorTok{*}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ r}\OperatorTok{]} \OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Properties:

\begin{itemize}
\tightlist
\item
  \((C(n, 0) = 1),\ (C(n, n) = 1)\)
\item
  \(C(n, r) = C(n, n - r)\)
\item
  Pascal's Rule: \(C(n, r) = C(n - 1, r - 1) + C(n - 1, r)\)
\end{itemize}

\subsubsection{Example}\label{example-3}

( C(5, 2) = 10 ) There are 10 ways to pick 2 elements from a 5-element
set.

\subsubsection{3. Permutations ( nPr )}\label{permutations-npr}

Number of ways to arrange r elements chosen from ( n ): \[
P(n, r) = \frac{n!}{(n-r)!}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ nPr}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{r }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ r }\OperatorTok{\textgreater{}}\NormalTok{ n}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ fact}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{*}\NormalTok{ invfact}\OperatorTok{[}\NormalTok{n }\OperatorTok{{-}}\NormalTok{ r}\OperatorTok{]} \OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Example}\label{example-4}

( P(5, 2) = 20 ) Choosing 2 out of 5 elements and arranging them yields
20 orders.

\subsubsection{4. Subsets and Power Set}\label{subsets-and-power-set}

Each element has 2 choices: include or exclude. Hence, number of
subsets: \[
2^n
\]

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ subsets\_count}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ modpow}\OperatorTok{(}\DecValTok{2}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Enumerating subsets using bitmasks:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ mask }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ mask }\OperatorTok{\textless{}} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ n}\OperatorTok{);}\NormalTok{ mask}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{mask }\OperatorTok{\&} \OperatorTok{(}\DecValTok{1} \OperatorTok{\textless{}\textless{}}\NormalTok{ i}\OperatorTok{))}
            \OperatorTok{;} \CommentTok{// include element i}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Total: \(2^n\) subsets, ( O\(n2^n\) ) time to enumerate.

\subsubsection{5. Multisets and
Repetition}\label{multisets-and-repetition}

Number of ways to choose ( r ) items from ( n ) with repetition: \[
C(n + r - 1, r)
\]

For example, number of ways to give 5 candies to 3 kids (each can get
0): ( C(3+5-1, 5) = C(7,5) = 21 )

\subsubsection{6. Modular Combinatorics}\label{modular-combinatorics}

When working modulo ( p ): - Use modular inverse for division. -
\(C(n, r) \bmod p = fact[n] \cdot invfact[r] \cdot invfact[n - r] \bmod p\)

When \(n \ge p\), use Lucas' Theorem: \[
C(n, r) \bmod p = C(n/p, r/p) \cdot C(n%p, r%p) \bmod p
\]

\subsubsection{7. Stirling and Bell Numbers
(Advanced)}\label{stirling-and-bell-numbers-advanced}

\begin{itemize}
\tightlist
\item
  Stirling Numbers of 2nd Kind: ways to partition ( n ) items into ( k )
  non-empty subsets \[
  S(n,k) = k \cdot S(n-1,k) + S(n-1,k-1)
  \]
\item
  Bell Numbers: total number of partitions \[
  B(n) = \sum_{k=0}^{n} S(n,k)
  \]
\end{itemize}

Used in set partition and grouping problems.

\subsubsection{8. Tiny Code}\label{tiny-code-52}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init\_factorials}\OperatorTok{();}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%lld\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ nCr}\OperatorTok{(}\DecValTok{10}\OperatorTok{,} \DecValTok{3}\OperatorTok{));}  \CommentTok{// 120}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%lld\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ nPr}\OperatorTok{(}\DecValTok{10}\OperatorTok{,} \DecValTok{3}\OperatorTok{));}  \CommentTok{// 720}
\NormalTok{printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%lld\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ subsets\_count}\OperatorTok{(}\DecValTok{5}\OperatorTok{));} \CommentTok{// 32}
\end{Highlighting}
\end{Shaded}

\subsubsection{9. Summary}\label{summary-14}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1446}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4458}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2289}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1807}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Factorial & \(n!\) & All arrangements & \(5! = 120\) \\
Combination & \(C(n, r) = \frac{n!}{r!(n - r)!}\) & Choose &
\(C(5, 2) = 10\) \\
Permutation & \(P(n, r) = \frac{n!}{(n - r)!}\) & Arrange &
\(P(5, 2) = 20\) \\
Subsets & \(2^n\) & All combinations & \(2^3 = 8\) \\
Multisets & \(C(n + r - 1, r)\) & Repetition allowed &
\(C(4, 2) = 6\) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-52}

Combinatorics underlies probability, DP counting, and modular problems.
You can't master competitive programming or algorithm design without
counting possibilities correctly. It teaches how structure emerges from
choice , and how to count it efficiently.

\subsubsection{Try It Yourself}\label{try-it-yourself-52}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \(C(1000, 500) \bmod (10^9 + 7)\).
\item
  Count the number of 5-bit subsets with exactly 3 bits on,
  i.e.~\(C(5, 3)\).
\item
  Write a loop to print all subsets of \texttt{\{a,\ b,\ c,\ d\}}.
\item
  Use Lucas' theorem for \(C(10^6, 1000) \bmod 13\).
\item
  Implement Stirling recursion and print \(S(5, 2)\).
\end{enumerate}

Every algorithmic counting trick , from Pascal's triangle to binomial
theorem , starts right here.

\subsection{54. Probability and Randomized
Algorithms}\label{probability-and-randomized-algorithms}

Probability introduces controlled randomness into computation. Instead
of deterministic steps, randomized algorithms use random choices to
achieve speed, simplicity, or robustness. This section bridges
probability theory and algorithm design , teaching how to model,
analyze, and exploit randomness.

We'll cover:

\begin{itemize}
\tightlist
\item
  Probability Basics
\item
  Expected Value
\item
  Monte Carlo and Las Vegas Algorithms
\item
  Randomized Data Structures and Algorithms
\end{itemize}

\subsubsection{1. Probability Basics}\label{probability-basics-1}

Every event has a probability between 0 and 1.\\
If a sample space has \(n\) equally likely outcomes and \(k\) of them
satisfy a condition, then

\[
P(E) = \frac{k}{n}
\]

Examples

\begin{itemize}
\tightlist
\item
  Rolling a fair die: \(P(\text{even}) = \frac{3}{6} = \frac{1}{2}\)
\item
  Drawing an ace from a deck:
  \(P(\text{ace}) = \frac{4}{52} = \frac{1}{13}\)
\end{itemize}

Key Rules

\begin{itemize}
\tightlist
\item
  Complement: \(P(\bar{E}) = 1 - P(E)\)\\
\item
  Addition: \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)\\
\item
  Multiplication: \(P(A \cap B) = P(A) \cdot P(B \mid A)\)
\end{itemize}

\subsubsection{2. Expected Value}\label{expected-value}

The expected value is the weighted average of outcomes.

\[
E[X] = \sum_{i} P(x_i) \cdot x_i
\]

Example: Expected value of a die: \[
E[X] = \frac{1+2+3+4+5+6}{6} = 3.5
\]

Properties:

\begin{itemize}
\tightlist
\item
  Linearity: \(E[aX + bY] = aE[X] + bE[Y]\)
\item
  Useful for average-case analysis
\end{itemize}

In algorithms:

\begin{itemize}
\tightlist
\item
  Expected number of comparisons in QuickSort is \(O(n \log n)\)
\item
  Expected time for hash table lookup is \(O(1)\)
\end{itemize}

\subsubsection{3. Monte Carlo vs Las
Vegas}\label{monte-carlo-vs-las-vegas}

Randomized algorithms are broadly two types:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1807}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3855}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1687}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2651}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Runtime
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Monte Carlo & May be wrong (probabilistically) & Fixed & Miller-Rabin
Primality \\
Las Vegas & Always correct & Random runtime & Randomized QuickSort \\
\end{longtable}

Monte Carlo:

\begin{itemize}
\tightlist
\item
  Faster, approximate
\item
  You can control error probability
\item
  E.g. primality test returns ``probably prime''
\end{itemize}

Las Vegas:

\begin{itemize}
\tightlist
\item
  Output guaranteed correct
\item
  Runtime varies by luck
\item
  E.g. QuickSort with random pivot
\end{itemize}

\subsubsection{4. Randomization in
Algorithms}\label{randomization-in-algorithms}

Randomization helps break worst-case patterns.

\subsubsection{A. Randomized QuickSort}\label{a.-randomized-quicksort}

Pick a random pivot instead of first element. Expected time becomes (
O\(n \log n\) ) regardless of input order.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ l}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{l }\OperatorTok{+}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{r }\OperatorTok{{-}}\NormalTok{ l }\OperatorTok{+} \DecValTok{1}\OperatorTok{)];}
    \CommentTok{// move pivot to end, then normal partition}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This avoids adversarial inputs like sorted arrays.

\subsubsection{B. Randomized Hashing}\label{b.-randomized-hashing}

Hash collisions can be exploited by adversaries. Using random
coefficients in hash functions makes attacks infeasible.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ hash}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ p}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{a }\OperatorTok{*}\NormalTok{ x }\OperatorTok{+}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ p}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pick random ( a, b ) for robustness.

\subsubsection{C. Randomized Data
Structures}\label{c.-randomized-data-structures}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Skip List: uses random levels for nodes Expected ( O\(\log n\) )
  search/insert/delete
\item
  Treap: randomized heap priority + BST order Maintains balance in
  expectation
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{,}\NormalTok{ priority}\OperatorTok{;}
\NormalTok{    Node }\OperatorTok{*}\NormalTok{l}\OperatorTok{,} \OperatorTok{*}\NormalTok{r}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Randomized balancing gives good average performance without rotation
logic.

\subsubsection{D. Random Sampling}\label{d.-random-sampling}

Pick random elements efficiently:

\begin{itemize}
\tightlist
\item
  Reservoir Sampling: sample ( k ) items from a stream of unknown size-
  Shuffle: Fisher-Yates Algorithm
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Probabilistic
Guarantees}\label{probabilistic-guarantees}

Randomized algorithms often use Chernoff bounds and Markov's inequality
to bound errors:

\begin{itemize}
\tightlist
\item
  Markov: \(P(X \ge kE[X]) \le \frac{1}{k}\)
\item
  Chebyshev: \(P(|X - E[X]| \ge c\sigma) \le \frac{1}{c^2}\)
\item
  Chernoff: Exponentially small tail bounds
\end{itemize}

These ensure ``with high probability'' (\(1 - \frac{1}{n^c}\))
guarantees.

\subsubsection{6. Tiny Code}\label{tiny-code-53}

Randomized QuickSort:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ partition}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ pivotIdx }\OperatorTok{=}\NormalTok{ low }\OperatorTok{+}\NormalTok{ rand}\OperatorTok{()} \OperatorTok{\%} \OperatorTok{(}\NormalTok{high }\OperatorTok{{-}}\NormalTok{ low }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    swap}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{pivotIdx}\OperatorTok{],}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]);}
    \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{],}\NormalTok{ i }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ low}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ pivot}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{++],}\NormalTok{ arr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
    \OperatorTok{\}}
\NormalTok{    swap}\OperatorTok{(}\NormalTok{arr}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ arr}\OperatorTok{[}\NormalTok{high}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ i}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ quicksort}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ arr}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ low}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{low }\OperatorTok{\textless{}}\NormalTok{ high}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ pi }\OperatorTok{=}\NormalTok{ partition}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
\NormalTok{        quicksort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
\NormalTok{        quicksort}\OperatorTok{(}\NormalTok{arr}\OperatorTok{,}\NormalTok{ pi }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-15}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3968}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3175}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expected Value & Weighted average outcome & Analyze average case \\
Monte Carlo & Probabilistic correctness & Primality test \\
Las Vegas & Probabilistic runtime & QuickSort \\
Random Pivot & Break worst-case & Sorting \\
Skip List / Treap & Random balancing & Data Structures \\
Reservoir Sampling & Stream selection & Large data \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-53}

Randomization is not ``luck'' , it's a design principle. It transforms
rigid algorithms into adaptive, robust systems. In complexity theory,
randomness helps achieve bounds impossible deterministically.

\begin{quote}
``A bit of randomness turns worst cases into best friends.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-53}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate rolling two dice and compute expected sum.
\item
  Implement randomized QuickSort and measure average runtime.
\item
  Write a Monte Carlo primality checker.
\item
  Create a random hash function for integers.
\item
  Implement reservoir sampling for a large input stream.
\end{enumerate}

These experiments show how uncertainty can become a powerful ally in
algorithm design.

\subsection{55. Sieve Methods and Modular
Math}\label{sieve-methods-and-modular-math}

Sieve methods are essential tools in number theory for generating prime
numbers, prime factors, and function values (φ, μ) efficiently. Combined
with modular arithmetic, they form the backbone of algorithms in
cryptography, combinatorics, and competitive programming.

This section introduces:

\begin{itemize}
\tightlist
\item
  Sieve of Eratosthenes- Optimized Linear Sieve- Sieve for Smallest
  Prime Factor (SPF)- Euler's Totient Function (φ)- Modular Applications
\end{itemize}

\subsubsection{1. The Sieve of
Eratosthenes}\label{the-sieve-of-eratosthenes}

The classic algorithm to find all primes ≤ ( n ).

Idea: Start from 2, mark all multiples as composite. Continue to √n.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ sieve}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ primes}\OperatorTok{;}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{bool}\OperatorTok{\textgreater{}}\NormalTok{ is\_prime}\OperatorTok{(}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);}
\NormalTok{    is\_prime}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ is\_prime}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_prime}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{*}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j }\OperatorTok{+=}\NormalTok{ i}\OperatorTok{)}
\NormalTok{                is\_prime}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_prime}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ primes}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ primes}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log \log n\) )

Space: ( O(n) )

Example: Primes up to 20 → 2, 3, 5, 7, 11, 13, 17, 19

\subsubsection{2. Linear Sieve (O(n))}\label{linear-sieve-on}

Unlike the basic sieve, each number is marked exactly once by its
smallest prime factor (SPF).

Idea:

\begin{itemize}
\tightlist
\item
  For each prime ( p ), mark \(p \times i\) only once.- Use
  \texttt{spf{[}i{]}} to store smallest prime factor.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \FloatTok{1e6}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ spf}\OperatorTok{[}\NormalTok{N }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ primes}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ linear\_sieve}\OperatorTok{()} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{spf}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            spf}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{            primes}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
        \OperatorTok{\}}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ p }\OperatorTok{:}\NormalTok{ primes}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p }\OperatorTok{\textgreater{}}\NormalTok{ spf}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{||} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ i }\OperatorTok{*}\NormalTok{ p }\OperatorTok{\textgreater{}}\NormalTok{ N}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{            spf}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=}\NormalTok{ p}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Benefits:

\begin{itemize}
\tightlist
\item
  Get primes, SPF, and factorizations in ( O(n) ).- Ideal for problems
  needing many factorizations.
\end{itemize}

\subsubsection{3. Smallest Prime Factor (SPF)
Table}\label{smallest-prime-factor-spf-table}

With \texttt{spf{[}{]}}, factorization becomes ( O\(\log n\) ).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ factorize}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ f}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{x }\OperatorTok{!=} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        f}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{spf}\OperatorTok{[}\NormalTok{x}\OperatorTok{]);}
\NormalTok{        x }\OperatorTok{/=}\NormalTok{ spf}\OperatorTok{[}\NormalTok{x}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ f}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example: spf{[}12{]} = 2 → factors = {[}2, 2, 3{]}

\subsubsection{\texorpdfstring{4. Euler's Totient Function ( \varphi(n)
)}{4. Euler's Totient Function ( (n) )}}\label{eulers-totient-function-n}

The number of integers ≤ ( n ) that are coprime with ( n ).

Formula: \[
\varphi(n) = n \prod_{p|n} \left(1 - \frac{1}{p}\right)
\]

Properties:

\begin{itemize}
\tightlist
\item
  \(\varphi(p) = p - 1\) if \(p\) is prime
\item
  Multiplicative: if \(\gcd(a, b) = 1\), then
  \(\varphi(ab) = \varphi(a)\varphi(b)\)
\end{itemize}

Implementation (Linear Sieve):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{int}\NormalTok{ N }\OperatorTok{=} \FloatTok{1e6}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ phi}\OperatorTok{[}\NormalTok{N }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\DataTypeTok{bool}\NormalTok{ is\_comp}\OperatorTok{[}\NormalTok{N }\OperatorTok{+} \DecValTok{1}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ primes}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ phi\_sieve}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    phi}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{is\_comp}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            primes}\OperatorTok{.}\NormalTok{push\_back}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
\NormalTok{            phi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ p }\OperatorTok{:}\NormalTok{ primes}\OperatorTok{)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ i }\OperatorTok{*}\NormalTok{ p }\OperatorTok{\textgreater{}}\NormalTok{ N}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{            is\_comp}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=} \KeywordTok{true}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\%}\NormalTok{ p }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                phi}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=}\NormalTok{ phi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*}\NormalTok{ p}\OperatorTok{;}
                \ControlFlowTok{break}\OperatorTok{;}
            \OperatorTok{\}} \ControlFlowTok{else} \OperatorTok{\{}
\NormalTok{                phi}\OperatorTok{[}\NormalTok{i }\OperatorTok{*}\NormalTok{ p}\OperatorTok{]} \OperatorTok{=}\NormalTok{ phi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*} \OperatorTok{(}\NormalTok{p }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example:

\begin{itemize}
\tightlist
\item
  \(\varphi(6) = 6(1 - \frac{1}{2})(1 - \frac{1}{3}) = 2\)
\item
  Numbers coprime with 6: 1, 5
\end{itemize}

\subsubsection{5. Modular Math
Applications}\label{modular-math-applications}

Once we have primes and totients, we can do many modular computations.

\subsubsection{A. Fermat's Little
Theorem}\label{a.-fermats-little-theorem}

If ( p ) is prime, \[
a^{p-1} \equiv 1 \pmod{p}
\] Hence, \[
a^{-1} \equiv a^{p-2} \pmod{p}
\]

Used in: modular inverses, combinatorics.

\subsubsection{B. Euler's Theorem}\label{b.-eulers-theorem}

If \(\gcd(a, n) = 1\), then

\[
a^{\varphi(n)} \equiv 1 \pmod{n}
\]

Generalizes Fermat's theorem to composite moduli.

\subsubsection{C. Modular Exponentiation with Totient
Reduction}\label{c.-modular-exponentiation-with-totient-reduction}

For very large powers:

\[
a^b \bmod n = a^{b \bmod \varphi(n)} \bmod n
\]

(when \(a\) and \(n\) are coprime)

\subsubsection{6. Tiny Code}\label{tiny-code-54}

Primes up to n:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{auto}\NormalTok{ primes }\OperatorTok{=}\NormalTok{ sieve}\OperatorTok{(}\DecValTok{100}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Totients up to n:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{phi\_sieve}\OperatorTok{();}
\NormalTok{cout }\OperatorTok{\textless{}\textless{}}\NormalTok{ phi}\OperatorTok{[}\DecValTok{10}\OperatorTok{];} \CommentTok{// 4}
\end{Highlighting}
\end{Shaded}

Factorization:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{auto}\NormalTok{ f }\OperatorTok{=}\NormalTok{ factorize}\OperatorTok{(}\DecValTok{60}\OperatorTok{);} \CommentTok{// [2, 2, 3, 5]}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-16}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1972}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2958}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2535}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2535}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Concept
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Eratosthenes & Mark multiples & (O\(n \log \log n\)) & Simple prime
gen \\
Linear Sieve & Mark once & (O(n)) & Prime + SPF \\
SPF Table & Smallest prime factor & (O(1)) query & Fast factorization \\
φ(n) & Coprime count & (O(n)) & Modular exponent \\
Fermat / Euler & Inverses, reduction & (O\(\log n\)) & Modular
arithmetic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-54}

Sieve methods are the fastest way to preprocess arithmetic information.
They unlock efficient solutions to problems involving primes, divisors,
modular equations, and cryptography.

\begin{quote}
``Before you can reason about numbers, you must first sieve them
clean.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-54}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate all primes \(\le 10^6\) using a linear sieve.
\item
  Factorize \(840\) using the SPF array.
\item
  Compute \(\varphi(n)\) for \(n = 1..20\).
\item
  Verify \(a^{\varphi(n)} \equiv 1 \pmod{n}\) for \(a = 3\), \(n = 10\).
\item
  Solve \(a^b \bmod n\) with \(b\) very large using \(\varphi(n)\).
\end{enumerate}

Sieve once, and modular math becomes effortless forever after.

\subsection{56. Linear Algebra (Gaussian Elimination, LU,
SVD)}\label{linear-algebra-gaussian-elimination-lu-svd}

Linear algebra gives algorithms their mathematical backbone. From
solving equations to powering ML models, it's the hidden engine behind
optimization, geometry, and numerical computation.

In this section, we'll focus on the algorithmic toolkit:

\begin{itemize}
\tightlist
\item
  Gaussian Elimination (solve systems, invert matrices)
\item
  LU Decomposition (efficient repeated solving)
\item
  SVD (Singular Value Decomposition) overview
\end{itemize}

You'll see how algebra becomes code , step by step.

\subsubsection{1. Systems of Linear
Equations}\label{systems-of-linear-equations}

We want to solve: \[
A \cdot x = b
\] where ( A ) is an \(n \times n\) matrix, and ( x, b ) are vectors.

For example: \[\begin{cases}
2x + 3y = 8 \
x + 2y = 5
\end{cases}\]

The solution is the intersection of two lines. In general, \(A^{-1}b\)
gives ( x ), but we usually solve it more directly using Gaussian
elimination.

\subsubsection{2. Gaussian Elimination (Row
Reduction)}\label{gaussian-elimination-row-reduction}

Idea: Transform ( {[}A\textbar b{]} ) (augmented matrix) into
upper-triangular form, then back-substitute.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each row, select a pivot (non-zero leading element).
\item
  Eliminate below it using row operations.
\item
  After all pivots, back-substitute to get the solution.
\end{enumerate}

\subsubsection{A. Implementation (C)}\label{a.-implementation-c}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{const} \DataTypeTok{double}\NormalTok{ EPS }\OperatorTok{=} \FloatTok{1e{-}9}\OperatorTok{;}

\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ gauss}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ A}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ A}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \CommentTok{// 1. Find pivot}
        \DataTypeTok{int}\NormalTok{ pivot }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textgreater{}}\NormalTok{ fabs}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{pivot}\OperatorTok{][}\NormalTok{i}\OperatorTok{]))}
\NormalTok{                pivot }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;}
\NormalTok{        swap}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ A}\OperatorTok{[}\NormalTok{pivot}\OperatorTok{]);}
\NormalTok{        swap}\OperatorTok{(}\NormalTok{b}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ b}\OperatorTok{[}\NormalTok{pivot}\OperatorTok{]);}

        \CommentTok{// 2. Normalize pivot row}
        \DataTypeTok{double}\NormalTok{ div }\OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{div}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ EPS}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{/=}\NormalTok{ div}\OperatorTok{;}
\NormalTok{        b}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/=}\NormalTok{ div}\OperatorTok{;}

        \CommentTok{// 3. Eliminate below}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ factor }\OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)}\NormalTok{ A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ factor }\OperatorTok{*}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
\NormalTok{            b}\OperatorTok{[}\NormalTok{j}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ factor }\OperatorTok{*}\NormalTok{ b}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \CommentTok{// 4. Back substitution}
\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ x}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
\NormalTok{        x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ b}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{            x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{{-}=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ x}\OperatorTok{[}\NormalTok{j}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time complexity: ( O\(n^3\) )

\subsubsection{B. Example}\label{b.-example-5}

Solve: \[\begin{cases}
2x + 3y = 8 \
x + 2y = 5
\end{cases}\]

Augmented matrix: \[\begin{bmatrix}
2 & 3 & | & 8 \
1 & 2 & | & 5
\end{bmatrix}\]

Reduce:

\begin{itemize}
\tightlist
\item
  Row2 ← Row2 − ½ Row1 → \([1, 2 | 5] \to [0, 0.5 | 1]\)- Back
  substitute → ( y = 2, x = 1 )
\end{itemize}

\subsubsection{3. LU Decomposition}\label{lu-decomposition}

LU factorization expresses: \[
A = L \cdot U
\] where ( L ) is lower-triangular (1s on diagonal), ( U ) is
upper-triangular.

This allows solving ( A x = b ) in two triangular solves:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve ( L y = b )
\item
  Solve ( U x = y )
\end{enumerate}

Efficient when solving for multiple b's (same A).

\subsubsection{A. Decomposition
Algorithm}\label{a.-decomposition-algorithm}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ lu\_decompose}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ A}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ L}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}\&}\NormalTok{ U}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ A}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
\NormalTok{    L}\OperatorTok{.}\NormalTok{assign}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}(}\NormalTok{n}\OperatorTok{,} \DecValTok{0}\OperatorTok{));}
\NormalTok{    U}\OperatorTok{.}\NormalTok{assign}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}(}\NormalTok{n}\OperatorTok{,} \DecValTok{0}\OperatorTok{));}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \CommentTok{// Upper}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{                sum }\OperatorTok{+=}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ U}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{k}\OperatorTok{];}
\NormalTok{            U}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sum}\OperatorTok{;}
        \OperatorTok{\}}
        \CommentTok{// Lower}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ k}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{==}\NormalTok{ k}\OperatorTok{)}\NormalTok{ L}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{else} \OperatorTok{\{}
                \DataTypeTok{double}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
                \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ i}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{                    sum }\OperatorTok{+=}\NormalTok{ L}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ U}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
\NormalTok{                L}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{{-}}\NormalTok{ sum}\OperatorTok{)} \OperatorTok{/}\NormalTok{ U}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Solve with forward + backward substitution.

\subsubsection{4. Singular Value Decomposition
(SVD)}\label{singular-value-decomposition-svd}

SVD generalizes diagonalization for non-square matrices: \[
A = U \Sigma V^T
\]

Where:

\begin{itemize}
\item
  ( U ): left singular vectors (orthogonal)- \(\Sigma\): diagonal of
  singular values- \(V^T\): right singular vectors Applications:
\item
  Data compression (PCA)- Noise reduction- Rank estimation-
  Pseudoinverse \(A^+ = V \Sigma^{-1} U^T\) In practice, use libraries
  (e.g.~LAPACK, Eigen).
\end{itemize}

\subsubsection{5. Numerical Stability and
Pivoting}\label{numerical-stability-and-pivoting}

In floating-point math:

\begin{itemize}
\tightlist
\item
  Always pick largest pivot (partial pivoting)- Avoid dividing by small
  numbers- Use EPS = 1e-9 threshold Small numerical errors can amplify
  quickly , stability is key.
\end{itemize}

\subsubsection{6. Tiny Code}\label{tiny-code-55}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ A }\OperatorTok{=} \OperatorTok{\{\{}\DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{\},} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{\}\};}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{}}\NormalTok{ b }\OperatorTok{=} \OperatorTok{\{}\DecValTok{8}\OperatorTok{,} \DecValTok{5}\OperatorTok{\};}
\KeywordTok{auto}\NormalTok{ x }\OperatorTok{=}\NormalTok{ gauss}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
\CommentTok{// Output: x = [1, 2]}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-17}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2800}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gaussian Elimination & Solve Ax=b & (O\(n^3\)) & Direct method \\
LU Decomposition & Repeated solves & (O\(n^3\)) & Triangular
factorization \\
SVD & General decomposition & (O\(n^3\)) & Robust, versatile \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-55}

Linear algebra is the language of algorithms , it solves equations,
optimizes functions, and projects data. Whether building solvers or
neural networks, these methods are your foundation.

\begin{quote}
``Every algorithm lives in a vector space , it just needs a basis to
express itself.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-55}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve a 3×3 linear system with Gaussian elimination.
\item
  Implement LU decomposition and test \(L \cdot U = A\).
\item
  Use LU to solve multiple ( b ) vectors.
\item
  Explore SVD using a math library; compute singular values of a 2×2
  matrix.
\item
  Compare results between naive and pivoted elimination for unstable
  systems.
\end{enumerate}

Start with row operations , and you'll see how geometry and algebra
merge into code.

\subsection{57. FFT and NTT (Fast
Transforms)}\label{fft-and-ntt-fast-transforms}

The Fast Fourier Transform (FFT) is one of the most beautiful and
practical algorithms ever invented. It converts data between time (or
coefficient) domain and frequency (or point) domain efficiently. The
Number Theoretic Transform (NTT) is its modular counterpart for integer
arithmetic , ideal for polynomial multiplication under a modulus.

This section covers:

\begin{itemize}
\tightlist
\item
  Why we need transforms- Discrete Fourier Transform (DFT)- Cooley-Tukey
  FFT (complex numbers)- NTT (modular version)- Applications (polynomial
  multiplication, convolution)
\end{itemize}

\subsubsection{1. Motivation}\label{motivation}

Suppose you want to multiply two polynomials: \[
A(x) = a_0 + a_1x + a_2x^2
\]

\[
B(x) = b_0 + b_1x + b_2x^2
\]

Their product has coefficients: \[
c_k = \sum_{i+j=k} a_i \cdot b_j
\]

This is convolution: \[
C = A * B
\] Naively, this takes ( O\(n^2\) ). FFT reduces it to ( O\(n \log n\)
).

\subsubsection{2. Discrete Fourier Transform
(DFT)}\label{discrete-fourier-transform-dft}

The DFT maps coefficients \(a_0, a_1, \ldots, a_{n-1}\) to evaluations
at ( n )-th roots of unity:

\[
A_k = \sum_{j=0}^{n-1} a_j \cdot e^{-2\pi i \cdot jk / n}
\]

and the inverse transform recovers \(a_j\) from \(A_k\).

\subsubsection{3. Cooley-Tukey FFT}\label{cooley-tukey-fft}

Key idea: recursively split the sum into even and odd parts:

\[
A_k = A_{even}(w_n^2) + w_n^k \cdot A_{odd}(w_n^2)
\]

Where \(w_n = e^{-2\pi i / n}\) is an ( n )-th root of unity.

\subsubsection{Implementation (C++)}\label{implementation-c}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}complex\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}vector\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}cmath\textgreater{}}
\KeywordTok{using} \KeywordTok{namespace}\NormalTok{ std}\OperatorTok{;}

\KeywordTok{using}\NormalTok{ cd }\OperatorTok{=}\NormalTok{ complex}\OperatorTok{\textless{}}\DataTypeTok{double}\OperatorTok{\textgreater{};}
\AttributeTok{const} \DataTypeTok{double}\NormalTok{ PI }\OperatorTok{=}\NormalTok{ acos}\OperatorTok{({-}}\DecValTok{1}\OperatorTok{);}

\DataTypeTok{void}\NormalTok{ fft}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{cd}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{a}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ invert}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ bit }\OperatorTok{=}\NormalTok{ n }\OperatorTok{\textgreater{}\textgreater{}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ j }\OperatorTok{\&}\NormalTok{ bit}\OperatorTok{;}\NormalTok{ bit }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{)}\NormalTok{ j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
\NormalTok{        j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
    \OperatorTok{\}}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}\textless{}=} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ ang }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ PI }\OperatorTok{/}\NormalTok{ len }\OperatorTok{*} \OperatorTok{(}\NormalTok{invert }\OperatorTok{?} \OperatorTok{{-}}\DecValTok{1} \OperatorTok{:} \DecValTok{1}\OperatorTok{);}
\NormalTok{        cd wlen}\OperatorTok{(}\NormalTok{cos}\OperatorTok{(}\NormalTok{ang}\OperatorTok{),}\NormalTok{ sin}\OperatorTok{(}\NormalTok{ang}\OperatorTok{));}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ len}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            cd w}\OperatorTok{(}\DecValTok{1}\OperatorTok{);}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{                cd u }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{],}\NormalTok{ v }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{*}\NormalTok{ w}\OperatorTok{;}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v}\OperatorTok{;}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v}\OperatorTok{;}
\NormalTok{                w }\OperatorTok{*=}\NormalTok{ wlen}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}

    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{invert}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{cd }\OperatorTok{\&}\NormalTok{x }\OperatorTok{:}\NormalTok{ a}\OperatorTok{)}\NormalTok{ x }\OperatorTok{/=}\NormalTok{ n}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Polynomial Multiplication with
FFT}\label{polynomial-multiplication-with-fft}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}}\NormalTok{ multiply}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}} \AttributeTok{const}\OperatorTok{\&}\NormalTok{ a}\OperatorTok{,}\NormalTok{ vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}} \AttributeTok{const}\OperatorTok{\&}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\NormalTok{cd}\OperatorTok{\textgreater{}}\NormalTok{ fa}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ a}\OperatorTok{.}\NormalTok{end}\OperatorTok{()),}\NormalTok{ fb}\OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ b}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)}\NormalTok{a}\OperatorTok{.}\NormalTok{size}\OperatorTok{()} \OperatorTok{+} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)}\NormalTok{b}\OperatorTok{.}\NormalTok{size}\OperatorTok{())}\NormalTok{ n }\OperatorTok{\textless{}\textless{}=} \DecValTok{1}\OperatorTok{;}
\NormalTok{    fa}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
\NormalTok{    fb}\OperatorTok{.}\NormalTok{resize}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}

\NormalTok{    fft}\OperatorTok{(}\NormalTok{fa}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
\NormalTok{    fft}\OperatorTok{(}\NormalTok{fb}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ fa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*=}\NormalTok{ fb}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{    fft}\OperatorTok{(}\NormalTok{fa}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);}

\NormalTok{    vector}\OperatorTok{\textless{}}\DataTypeTok{long} \DataTypeTok{long}\OperatorTok{\textgreater{}}\NormalTok{ result}\OperatorTok{(}\NormalTok{n}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        result}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ llround}\OperatorTok{(}\NormalTok{fa}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{real}\OperatorTok{());}
    \ControlFlowTok{return}\NormalTok{ result}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity: ( O\(n \log n\) )

\subsubsection{4. Number Theoretic Transform
(NTT)}\label{number-theoretic-transform-ntt}

FFT uses complex numbers , NTT uses modular arithmetic with roots of
unity mod p. We need a prime ( p ) such that: \[
p = c \cdot 2^k + 1
\] so a primitive root ( g ) exists.

Popular choices:

\begin{itemize}
\tightlist
\item
  ( p = 998244353, g = 3 )- ( p = 7340033, g = 3 )
\end{itemize}

\subsubsection{Implementation (NTT)}\label{implementation-ntt}

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{const} \DataTypeTok{int}\NormalTok{ MOD }\OperatorTok{=} \DecValTok{998244353}\OperatorTok{;}
\AttributeTok{const} \DataTypeTok{int}\NormalTok{ G }\OperatorTok{=} \DecValTok{3}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ modpow}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ res }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{b}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{b }\OperatorTok{\&} \DecValTok{1}\OperatorTok{)}\NormalTok{ res }\OperatorTok{=}\NormalTok{ res }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        a }\OperatorTok{=} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ a }\OperatorTok{*}\NormalTok{ a }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{        b }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ res}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ ntt}\OperatorTok{(}\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}} \OperatorTok{\&}\NormalTok{a}\OperatorTok{,} \DataTypeTok{bool}\NormalTok{ invert}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{size}\OperatorTok{();}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ bit }\OperatorTok{=}\NormalTok{ n }\OperatorTok{\textgreater{}\textgreater{}} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(;}\NormalTok{ j }\OperatorTok{\&}\NormalTok{ bit}\OperatorTok{;}\NormalTok{ bit }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{1}\OperatorTok{)}\NormalTok{ j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
\NormalTok{        j }\OperatorTok{\^{}=}\NormalTok{ bit}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ j}\OperatorTok{)}\NormalTok{ swap}\OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ a}\OperatorTok{[}\NormalTok{j}\OperatorTok{]);}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ len }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ len }\OperatorTok{\textless{}\textless{}=} \DecValTok{1}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ wlen }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{G}\OperatorTok{,} \OperatorTok{(}\NormalTok{MOD }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{)} \OperatorTok{/}\NormalTok{ len}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{invert}\OperatorTok{)}\NormalTok{ wlen }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{wlen}\OperatorTok{,}\NormalTok{ MOD }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ len}\OperatorTok{)} \OperatorTok{\{}
            \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ w }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
                \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{];}
                \DataTypeTok{int}\NormalTok{ v }\OperatorTok{=} \OperatorTok{(}\DataTypeTok{int}\OperatorTok{)(}\NormalTok{a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{*}\NormalTok{ w }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{);}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v }\OperatorTok{\textless{}}\NormalTok{ MOD }\OperatorTok{?}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v }\OperatorTok{:}\NormalTok{ u }\OperatorTok{+}\NormalTok{ v }\OperatorTok{{-}}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{                a}\OperatorTok{[}\NormalTok{i }\OperatorTok{+}\NormalTok{ j }\OperatorTok{+}\NormalTok{ len }\OperatorTok{/} \DecValTok{2}\OperatorTok{]} \OperatorTok{=}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v }\OperatorTok{\textgreater{}=} \DecValTok{0} \OperatorTok{?}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v }\OperatorTok{:}\NormalTok{ u }\OperatorTok{{-}}\NormalTok{ v }\OperatorTok{+}\NormalTok{ MOD}\OperatorTok{;}
\NormalTok{                w }\OperatorTok{=}\NormalTok{ w }\OperatorTok{*}\NormalTok{ wlen }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{invert}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ inv\_n }\OperatorTok{=}\NormalTok{ modpow}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ MOD }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int} \OperatorTok{\&}\NormalTok{x }\OperatorTok{:}\NormalTok{ a}\OperatorTok{)}\NormalTok{ x }\OperatorTok{=} \DecValTok{1}\BuiltInTok{LL} \OperatorTok{*}\NormalTok{ x }\OperatorTok{*}\NormalTok{ inv\_n }\OperatorTok{\%}\NormalTok{ MOD}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Applications}\label{applications-7}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Polynomial Multiplication: ( O\(n \log n\) )
\item
  Convolution: digital signal processing
\item
  Big Integer Multiplication (Karatsuba, FFT)
\item
  Subset Convolution and combinatorial transforms
\item
  Number-theoretic sums (NTT-friendly modulus)
\end{enumerate}

\subsubsection{6. Tiny Code}\label{tiny-code-56}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ A }\OperatorTok{=} \OperatorTok{\{}\DecValTok{1}\OperatorTok{,} \DecValTok{2}\OperatorTok{,} \DecValTok{3}\OperatorTok{\};}
\NormalTok{vector}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{\textgreater{}}\NormalTok{ B }\OperatorTok{=} \OperatorTok{\{}\DecValTok{4}\OperatorTok{,} \DecValTok{5}\OperatorTok{,} \DecValTok{6}\OperatorTok{\};}
\CommentTok{// Result = \{4, 13, 28, 27, 18\}}
\KeywordTok{auto}\NormalTok{ C }\OperatorTok{=}\NormalTok{ multiply}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ B}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-18}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Domain & Complexity & Type \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFT & Complex & ( O\(n^2\) ) & Naive \\
FFT & Complex & ( O\(n \log n\) ) & Recursive \\
NTT & Modular & ( O\(n \log n\) ) & Integer arithmetic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-56}

FFT and NTT bring polynomial algebra to life. They turn slow
convolutions into lightning-fast transforms. From multiplying huge
integers to compressing signals, they're the ultimate divide-and-conquer
on structure.

\begin{quote}
``To multiply polynomials fast, you first turn them into music , then
back again.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-56}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiply (\(1 + 2x + 3x^2\)) and (\(4 + 5x + 6x^2\)) using FFT.
\item
  Implement NTT over 998244353 and verify results mod p.
\item
  Compare ( O\(n^2\) ) vs FFT performance for n = 1024.
\item
  Experiment with inverse FFT (invert = true).
\item
  Explore circular convolution for signal data.
\end{enumerate}

Once you master FFT/NTT, you hold the power of speed in algebraic
computation.

\subsection{58. Numerical Methods (Newton, Simpson,
Runge-Kutta)}\label{numerical-methods-newton-simpson-runge-kutta}

Numerical methods let us approximate solutions when exact algebraic
answers are hard or impossible. They are the foundation of scientific
computing, simulation, and optimization , bridging the gap between
continuous math and discrete computation.

In this section, we'll explore three classics:

\begin{itemize}
\tightlist
\item
  Newton-Raphson: root finding- Simpson's Rule: numerical integration-
  Runge-Kutta (RK4): solving differential equations These algorithms
  showcase how iteration, approximation, and convergence build powerful
  tools.
\end{itemize}

\subsubsection{1. Newton-Raphson Method}\label{newton-raphson-method}

Used to find a root of ( f(x) = 0 ). Starting from a guess \(x_0\),
iteratively refine:

\[
x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}
\]

Convergence is quadratic if ( f ) is smooth and \(x_0\) is close enough.

\subsubsection{A. Example}\label{a.-example}

Solve ( f(x) = x\^{}2 - 2 = 0 ) We know root = \(\sqrt{2}\)

Start \(x_0 = 1\)

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Iter & \(x_n\) & (f\(x_n\)) & (f'\(x_n\)) & \(x_{n+1}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1.000 & -1.000 & 2.000 & 1.500 \\
1 & 1.500 & 0.250 & 3.000 & 1.417 \\
2 & 1.417 & 0.006 & 2.834 & 1.414 \\
\end{longtable}

Converged: \(1.414 \approx \sqrt{2}\)

\subsubsection{B. Implementation}\label{b.-implementation-8}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{*}\NormalTok{ x }\OperatorTok{{-}} \DecValTok{2}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{double}\NormalTok{ df}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \DecValTok{2} \OperatorTok{*}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ newton}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x0}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{20}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ fx }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x0}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ dfx }\OperatorTok{=}\NormalTok{ df}\OperatorTok{(}\NormalTok{x0}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{fx}\OperatorTok{)} \OperatorTok{\textless{}} \FloatTok{1e{-}9}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{        x0 }\OperatorTok{=}\NormalTok{ x0 }\OperatorTok{{-}}\NormalTok{ fx }\OperatorTok{/}\NormalTok{ dfx}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ x0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Root: }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ newton}\OperatorTok{(}\FloatTok{1.0}\OperatorTok{));} \CommentTok{// 1.414214}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O(k) ) iterations, each ( O(1) )

\subsubsection{2. Simpson's Rule (Numerical
Integration)}\label{simpsons-rule-numerical-integration}

When you can't integrate ( f(x) ) analytically, approximate the area
under the curve.

Divide interval ({[}a, b{]}) into even ( n ) subintervals (width ( h )).

\[
I \approx \frac{h}{3} \Big( f(a) + 4 \sum f(x_{odd}) + 2 \sum f(x_{even}) + f(b) \Big)
\]

\subsubsection{A. Implementation}\label{a.-implementation-2}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{*}\NormalTok{ x}\OperatorTok{;} \OperatorTok{\}} \CommentTok{// integrate x\^{}2}

\DataTypeTok{double}\NormalTok{ simpson}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ h }\OperatorTok{=} \OperatorTok{(}\NormalTok{b }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{)} \OperatorTok{/}\NormalTok{ n}\OperatorTok{;}
    \DataTypeTok{double}\NormalTok{ s }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{a}\OperatorTok{)} \OperatorTok{+}\NormalTok{ f}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ x }\OperatorTok{=}\NormalTok{ a }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*}\NormalTok{ h}\OperatorTok{;}
\NormalTok{        s }\OperatorTok{+=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{)} \OperatorTok{*} \OperatorTok{(}\NormalTok{i }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0} \OperatorTok{?} \DecValTok{2} \OperatorTok{:} \DecValTok{4}\OperatorTok{);}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ s }\OperatorTok{*}\NormalTok{ h }\OperatorTok{/} \DecValTok{3}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"∫₀¹ x² dx ≈ }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ simpson}\OperatorTok{(}\DecValTok{0}\OperatorTok{,} \DecValTok{1}\OperatorTok{,} \DecValTok{100}\OperatorTok{));} \CommentTok{// \textasciitilde{}0.333333}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Accuracy: ( O\(h^4\) ) Note: ( n ) must be even.

\subsubsection{B. Example}\label{b.-example-6}

\[
\int_0^1 x^2 dx = \frac{1}{3}
\] With ( n = 100 ), Simpson gives ( 0.333333 ).

\subsubsection{3. Runge-Kutta (RK4)}\label{runge-kutta-rk4}

Used to solve first-order ODEs: \[
y' = f(x, y), \quad y(x_0) = y_0
\]

RK4 Formula:

\[\begin{aligned}
k_1 &= f(x_n, y_n) \
k_2 &= f(x_n + \frac{h}{2}, y_n + \frac{h}{2}k_1) \
k_3 &= f(x_n + \frac{h}{2}, y_n + \frac{h}{2}k_2) \
k_4 &= f(x_n + h, y_n + hk_3) \
y_{n+1} &= y_n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{aligned}\]

Accuracy: ( O\(h^4\) )

\subsubsection{A. Example}\label{a.-example-1}

Solve ( y' = x + y ), ( y(0) = 1 ), step ( h = 0.1 ).

Each iteration refines ( y ) with weighted slope average.

\subsubsection{B. Implementation}\label{b.-implementation-9}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{+}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ runge\_kutta}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x0}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y0}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ h}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ xn}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ x }\OperatorTok{=}\NormalTok{ x0}\OperatorTok{,}\NormalTok{ y }\OperatorTok{=}\NormalTok{ y0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{x }\OperatorTok{\textless{}}\NormalTok{ xn}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ k1 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ k2 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x }\OperatorTok{+}\NormalTok{ h }\OperatorTok{/} \DecValTok{2}\OperatorTok{,}\NormalTok{ y }\OperatorTok{+}\NormalTok{ h }\OperatorTok{*}\NormalTok{ k1 }\OperatorTok{/} \DecValTok{2}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ k3 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x }\OperatorTok{+}\NormalTok{ h }\OperatorTok{/} \DecValTok{2}\OperatorTok{,}\NormalTok{ y }\OperatorTok{+}\NormalTok{ h }\OperatorTok{*}\NormalTok{ k2 }\OperatorTok{/} \DecValTok{2}\OperatorTok{);}
        \DataTypeTok{double}\NormalTok{ k4 }\OperatorTok{=}\NormalTok{ f}\OperatorTok{(}\NormalTok{x }\OperatorTok{+}\NormalTok{ h}\OperatorTok{,}\NormalTok{ y }\OperatorTok{+}\NormalTok{ h }\OperatorTok{*}\NormalTok{ k3}\OperatorTok{);}
\NormalTok{        y }\OperatorTok{+=}\NormalTok{ h }\OperatorTok{*} \OperatorTok{(}\NormalTok{k1 }\OperatorTok{+} \DecValTok{2}\OperatorTok{*}\NormalTok{k2 }\OperatorTok{+} \DecValTok{2}\OperatorTok{*}\NormalTok{k3 }\OperatorTok{+}\NormalTok{ k4}\OperatorTok{)} \OperatorTok{/} \DecValTok{6}\OperatorTok{;}
\NormalTok{        x }\OperatorTok{+=}\NormalTok{ h}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"y(0.1) ≈ }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ runge\_kutta}\OperatorTok{(}\DecValTok{0}\OperatorTok{,} \DecValTok{1}\OperatorTok{,} \FloatTok{0.1}\OperatorTok{,} \FloatTok{0.1}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Tiny Code Summary}\label{tiny-code-summary}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2208}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1558}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3377}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1169}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1688}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Accuracy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Newton-Raphson & Root finding & \(x_{n+1}=x_n-\frac{f}{f'}\) & Quadratic
& Iterative \\
Simpson's Rule & Integration & (h/3(\ldots)) & (O\(h^4\)) &
Deterministic \\
Runge-Kutta (RK4) & ODEs & Weighted slope avg & (O\(h^4\)) &
Iterative \\
\end{longtable}

\subsubsection{5. Numerical Stability}\label{numerical-stability}

\begin{itemize}
\tightlist
\item
  Small step ( h ): better accuracy, more cost- Large ( h ): faster,
  less stable- Always check convergence
  (\(|x_{n+1} - x_n| < \varepsilon\))- Avoid division by small
  derivatives in Newton's method
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-57}

Numerical methods let computers simulate the continuous world. From
physics to AI training, they solve what calculus cannot symbolically.

\begin{quote}
``When equations won't talk, iterate , and they'll whisper their
answers.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-57}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use Newton's method for \(\cos x - x = 0\).
\item
  Approximate \(\displaystyle \int_0^{\pi/2} \sin x\,dx\) with Simpson's
  rule.
\item
  Solve \(y' = y - x^2 + 1,\ y(0) = 0.5\) using RK4.
\item
  Compare RK4 with Euler's method for the same ODE.
\item
  Experiment with step sizes \(h \in \{0.1, 0.01, 0.001\}\) and observe
  convergence.
\end{enumerate}

Numerical thinking turns continuous problems into iterative algorithms ,
precise enough to power every simulation and solver you'll ever write.

\subsection{59. Mathematical Optimization (Simplex, Gradient,
Convex)}\label{mathematical-optimization-simplex-gradient-convex}

Mathematical optimization is about finding the best solution , smallest
cost, largest profit, shortest path , under given constraints. It's the
heart of machine learning, operations research, and engineering design.

In this section, we'll explore three pillars:

\begin{itemize}
\tightlist
\item
  Simplex Method , for linear programs
\item
  Gradient Descent , for continuous optimization
\item
  Convex Optimization , the theory ensuring global optima
\end{itemize}

\subsubsection{1. What Is Optimization?}\label{what-is-optimization}

A general optimization problem looks like:

\[
\min_x \ f(x)
\] subject to constraints: \[
g_i(x) \le 0, \quad h_j(x) = 0
\]

When ( f ) and \(g_i, h_j\) are linear, it's a Linear Program (LP). When
( f ) is differentiable, we can use gradients. When ( f ) is convex,
every local minimum is global , the ideal world.

\subsubsection{2. The Simplex Method (Linear
Programming)}\label{the-simplex-method-linear-programming}

A linear program has the form:

\[
\max \ c^T x
\] subject to \[
A x \le b, \quad x \ge 0
\]

Geometrically, each constraint forms a half-space. The feasible region
is a convex polytope, and the optimum lies at a vertex.

\subsubsection{A. Example}\label{a.-example-2}

Maximize ( z = 3x + 2y ) subject to \[\begin{cases}
2x + y \le 18 \
2x + 3y \le 42 \
x, y \ge 0
\end{cases}\]

Solution: ( x=9, y=8 ), ( z=43 )

\subsubsection{B. Algorithm (Sketch)}\label{b.-algorithm-sketch}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Convert inequalities to equalities by adding slack variables.
\item
  Initialize at a vertex (basic feasible solution).
\item
  At each step:

  \begin{itemize}
  \tightlist
  \item
    Choose entering variable (most negative coefficient in objective). -
    Choose leaving variable (min ratio test). - Pivot to new vertex.4.
    Repeat until optimal.
  \end{itemize}
\end{enumerate}

\subsubsection{C. Implementation (Simplified
Pseudocode)}\label{c.-implementation-simplified-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Basic simplex{-}like outline}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{exists negative coefficient in objective row}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    choose entering column j}\OperatorTok{;}
\NormalTok{    choose leaving row i }\OperatorTok{(}\NormalTok{min b}\OperatorTok{[}\NormalTok{i}\OperatorTok{]/}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]);}
\NormalTok{    pivot}\OperatorTok{(}\NormalTok{i}\OperatorTok{,}\NormalTok{ j}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Libraries (like \texttt{GLPK} or \texttt{Eigen}) handle full
implementations.

Time Complexity: worst ( O\(2^n\) ), but fast in practice.

\subsubsection{3. Gradient Descent}\label{gradient-descent}

For differentiable ( f(x) ), we move opposite the gradient:

\[
x_{k+1} = x_k - \eta \nabla f(x_k)
\]

where \(\eta\) is the learning rate.

Intuition: ( \nabla f(x) ) points uphill, so step opposite it.

\subsubsection{A. Example}\label{a.-example-3}

Minimize ( f(x) = (x-3)\^{}2 )

\[
f'(x) = 2(x-3)
\]

Start \(x_0 = 0\), \(\eta = 0.1\)

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Iter & \(x_k\) & (f\(x_k\)) & Gradient & New (x) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0 & 9 & -6 & 0.6 \\
1 & 0.6 & 5.76 & -4.8 & 1.08 \\
2 & 1.08 & 3.69 & -3.84 & 1.46 \\
\ldots{} & →3 & →0 & →0 & →3 \\
\end{longtable}

Converges to ( x = 3 )

\subsubsection{B. Implementation}\label{b.-implementation-10}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}

\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}} \DecValTok{3}\OperatorTok{)} \OperatorTok{*} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}} \DecValTok{3}\OperatorTok{);} \OperatorTok{\}}
\DataTypeTok{double}\NormalTok{ df}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return} \DecValTok{2} \OperatorTok{*} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}} \DecValTok{3}\OperatorTok{);} \OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ gradient\_descent}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x0}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ lr}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}} \DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ g }\OperatorTok{=}\NormalTok{ df}\OperatorTok{(}\NormalTok{x0}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{fabs}\OperatorTok{(}\NormalTok{g}\OperatorTok{)} \OperatorTok{\textless{}} \FloatTok{1e{-}6}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
\NormalTok{        x0 }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ g}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ x0}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Min at x = }\SpecialCharTok{\%.6f\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ gradient\_descent}\OperatorTok{(}\DecValTok{0}\OperatorTok{,} \FloatTok{0.1}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{C. Variants}\label{c.-variants}

\begin{itemize}
\tightlist
\item
  Momentum: ( v = \beta v + \(1-\beta\)\nabla f(x) )- Adam: adaptive
  learning rates- Stochastic Gradient Descent (SGD): random subset of
  data All used heavily in machine learning.
\end{itemize}

\subsubsection{4. Convex Optimization}\label{convex-optimization}

A function ( f ) is convex if: \[
f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda)f(y)
\]

This means any local minimum is global.

Examples:

\begin{itemize}
\tightlist
\item
  ( f(x) = x\^{}2 ) (convex)- ( f(x) = x\^{}3 ) (not convex) For convex
  functions with linear constraints, gradient-based methods always
  converge to the global optimum.
\end{itemize}

\subsubsection{A. Checking Convexity}\label{a.-checking-convexity}

\begin{itemize}
\tightlist
\item
  1D: ( f'\,'(x) \ge 0 )- Multivariate: Hessian ( \nabla\^{}2 f(x) ) is
  positive semidefinite
\end{itemize}

\subsubsection{5. Applications}\label{applications-8}

\begin{itemize}
\tightlist
\item
  Linear Programming (Simplex): logistics, scheduling- Quadratic
  Programming: portfolio optimization- Gradient Methods: ML, curve
  fitting- Convex Programs: control systems, regularization
\end{itemize}

\subsubsection{6. Tiny Code}\label{tiny-code-57}

Simple gradient descent to minimize ( f(x,y)=x\textsuperscript{2+y}2 ):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ f}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y}\OperatorTok{)} \OperatorTok{\{} \ControlFlowTok{return}\NormalTok{ x}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ y}\OperatorTok{*}\NormalTok{y}\OperatorTok{;} \OperatorTok{\}}
\DataTypeTok{void}\NormalTok{ grad}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{,} \DataTypeTok{double}\NormalTok{ y}\OperatorTok{,} \DataTypeTok{double} \OperatorTok{*}\NormalTok{gx}\OperatorTok{,} \DataTypeTok{double} \OperatorTok{*}\NormalTok{gy}\OperatorTok{)} \OperatorTok{\{}
    \OperatorTok{*}\NormalTok{gx }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{x}\OperatorTok{;} \OperatorTok{*}\NormalTok{gy }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{y}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ optimize}\OperatorTok{()} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ x}\OperatorTok{=}\DecValTok{5}\OperatorTok{,}\NormalTok{ y}\OperatorTok{=}\DecValTok{3}\OperatorTok{,}\NormalTok{ lr}\OperatorTok{=}\FloatTok{0.1}\OperatorTok{;}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\DecValTok{100}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)\{}
        \DataTypeTok{double}\NormalTok{ gx}\OperatorTok{,}\NormalTok{ gy}\OperatorTok{;}
\NormalTok{        grad}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{,} \OperatorTok{\&}\NormalTok{gx}\OperatorTok{,} \OperatorTok{\&}\NormalTok{gy}\OperatorTok{);}
\NormalTok{        x }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ gx}\OperatorTok{;}
\NormalTok{        y }\OperatorTok{{-}=}\NormalTok{ lr }\OperatorTok{*}\NormalTok{ gy}\OperatorTok{;}
    \OperatorTok{\}}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"Min at (}\SpecialCharTok{\%.3f}\StringTok{, }\SpecialCharTok{\%.3f}\StringTok{)}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Summary}\label{summary-19}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2025}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1266}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3671}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3038}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Simplex & Linear & Polynomial (average case) & LP solver \\
Gradient Descent & Continuous & \(O(k)\) & Needs step size \\
Convex Methods & Convex & \(O(k \log \frac{1}{\varepsilon})\) & Global
optima guaranteed \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-58}

Optimization turns math into decisions. From fitting curves to planning
resources, it formalizes trade-offs and efficiency. It's where
computation meets purpose , finding the best in all possible worlds.

\begin{quote}
``Every algorithm is, at heart, an optimizer , searching for something
better.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-58}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve a linear program with 2 constraints manually via Simplex.
\item
  Implement gradient descent for \(f(x) = (x - 5)^2 + 2\).
\item
  Add momentum to your gradient descent loop.
\item
  Check convexity by plotting \(f(x) = x^4 - 3x^2\).
\item
  Experiment with learning rates: too small leads to slow convergence;
  too large can diverge.
\end{enumerate}

Mastering optimization means mastering how algorithms improve themselves
, step by step, iteration by iteration.

\subsection{60. Algebraic Tricks and Transform
Techniques}\label{algebraic-tricks-and-transform-techniques}

In algorithm design, algebra isn't just theory , it's a toolbox for
transforming problems. By expressing computations algebraically, we can
simplify, accelerate, or generalize solutions. This section surveys
common algebraic techniques that turn hard problems into manageable
ones.

We'll explore:

\begin{itemize}
\tightlist
\item
  Algebraic identities and factorizations
\item
  Generating functions and transforms
\item
  Convolution tricks
\item
  Polynomial methods and FFT applications
\item
  Matrix and linear transforms for acceleration
\end{itemize}

\subsubsection{1. Algebraic Identities}\label{algebraic-identities}

These let you rewrite or decompose expressions to reveal structure or
reduce complexity.

Classic Forms:

\begin{itemize}
\tightlist
\item
  Difference of squares: \[
  a^2 - b^2 = (a-b)(a+b)
  \]
\item
  Sum of cubes: \[
  a^3 + b^3 = (a+b)(a^2 - ab + b^2)
  \]
\item
  Square of sum: \[
  (a+b)^2 = a^2 + 2ab + b^2
  \]
\end{itemize}

Used in dynamic programming, geometry, and optimization when simplifying
recurrence terms or constraints.

Example: Transforming \((x+y)^2\) lets you compute both \(x^2 + y^2\)
and cross terms efficiently.

\subsubsection{2. Generating Functions}\label{generating-functions}

A generating function encodes a sequence \(a_0, a_1, a_2, \ldots\) into
a formal power series:

\[
G(x) = a_0 + a_1x + a_2x^2 + \ldots
\]

They turn recurrence relations and counting problems into algebraic
equations.

Example: Fibonacci sequence \[
F(x) = F_0 + F_1x + F_2x^2 + \ldots
\] with recurrence \(F_n = F_{n-1} + F_{n-2}\)

Solve algebraically: \[
F(x) = \frac{x}{1 - x - x^2}
\]

Applications: combinatorics, probability, counting partitions.

\subsubsection{3. Convolution Tricks}\label{convolution-tricks}

Convolution arises in combining sequences: \[
(c_n) = (a * b)*n = \sum*{i=0}^{n} a_i b_{n-i}
\]

Naive computation: ( O\(n^2\) ) Using Fast Fourier Transform (FFT): (
O\(n \log n\) )

Example: Polynomial multiplication Let \[
A(x) = a_0 + a_1x + a_2x^2, \quad B(x) = b_0 + b_1x + b_2x^2
\] Then ( C(x) = A(x)B(x) ) gives coefficients by convolution.

This trick is used in:

\begin{itemize}
\tightlist
\item
  Large integer multiplication- Pattern matching (cross-correlation)-
  Subset sum acceleration
\end{itemize}

\subsubsection{4. Polynomial Methods}\label{polynomial-methods}

Many algorithmic problems can be represented as polynomials, where
coefficients encode combinatorial structure.

\subsubsection{A. Polynomial
Interpolation}\label{a.-polynomial-interpolation}

Given ( n+1 ) points, there's a unique degree-( n ) polynomial passing
through them.

Used in error correction, FFT-based reconstruction, and number-theoretic
transforms.

Lagrange Interpolation: \[
P(x) = \sum_i y_i \prod_{j \ne i} \frac{x - x_j}{x_i - x_j}
\]

\subsubsection{B. Root Representation}\label{b.-root-representation}

Solve equations or check identities by working modulo a polynomial. Used
in finite fields and coding theory (e.g., Reed-Solomon).

\subsubsection{5. Transform Techniques}\label{transform-techniques}

Transforms convert problems to simpler domains where operations become
efficient.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2828}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2020}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2828}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2323}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Transform
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Converts
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Property
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Used In
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
FFT / NTT & Time ↔ Frequency & Convolution → Multiplication & Signal,
polynomial mult \\
Z-Transform & Sequence ↔ Function & Recurrence solving & DSP, control \\
Laplace Transform & Function ↔ Algebraic & Diff. eq. → Algebraic eq. &
Continuous systems \\
Walsh-Hadamard Transform & Boolean vectors & XOR convolution & Subset
sum, SOS DP \\
\end{longtable}

Example: Subset Convolution via FWT

For all subsets ( S ): \[
f'(S) = \sum_{T \subseteq S} f(T)
\]

Use Fast Walsh-Hadamard Transform (FWHT) to compute in ( O\(n2^n\) )
instead of ( O\(3^n\) ).

\subsubsection{6. Matrix Tricks}\label{matrix-tricks}

Matrix algebra enables transformations and compact formulations.

\begin{itemize}
\tightlist
\item
  Matrix exponentiation: solve recurrences in \(O(\log n)\)
\item
  Diagonalization: \(A = P D P^{-1}\), then \(A^k = P D^k P^{-1}\)
\item
  Fast power: speeds up Fibonacci, linear recurrences, Markov chains
\end{itemize}

Example: Fibonacci

\[
\begin{bmatrix}
F_{n+1} \\
F_n
\end{bmatrix}
=
\begin{bmatrix}
1 & 1 \\
1 & 0
\end{bmatrix}^n
\begin{bmatrix}
1 \\
0
\end{bmatrix}
\]

\subsubsection{7. Tiny Code}\label{tiny-code-58}

Polynomial Multiplication via FFT (Pseudo-C):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Outline using complex FFT library}
\NormalTok{fft}\OperatorTok{(}\NormalTok{A}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
\NormalTok{fft}\OperatorTok{(}\NormalTok{B}\OperatorTok{,} \KeywordTok{false}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{    C}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{*}\NormalTok{ B}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{fft}\OperatorTok{(}\NormalTok{C}\OperatorTok{,} \KeywordTok{true}\OperatorTok{);} \CommentTok{// inverse}
\end{Highlighting}
\end{Shaded}

Matrix Power (Fibonacci):

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ matmul}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ A}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{],} \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ B}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{])} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ C}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{\{}\DecValTok{0}\OperatorTok{\}\};}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\DecValTok{2}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}}\DecValTok{2}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}
            \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{k}\OperatorTok{\textless{}}\DecValTok{2}\OperatorTok{;}\NormalTok{k}\OperatorTok{++)}
\NormalTok{                C}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ A}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{k}\OperatorTok{]*}\NormalTok{B}\OperatorTok{[}\NormalTok{k}\OperatorTok{][}\NormalTok{j}\OperatorTok{];}
\NormalTok{    memcpy}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ C}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{C}\OperatorTok{));}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ matpow}\OperatorTok{(}\DataTypeTok{long} \DataTypeTok{long}\NormalTok{ A}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{long} \DataTypeTok{long}\NormalTok{ R}\OperatorTok{[}\DecValTok{2}\OperatorTok{][}\DecValTok{2}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{\{}\DecValTok{1}\OperatorTok{,}\DecValTok{0}\OperatorTok{\},\{}\DecValTok{0}\OperatorTok{,}\DecValTok{1}\OperatorTok{\}\};}
    \ControlFlowTok{while}\OperatorTok{(}\NormalTok{n}\OperatorTok{)\{}
        \ControlFlowTok{if}\OperatorTok{(}\NormalTok{n}\OperatorTok{\&}\DecValTok{1}\OperatorTok{)}\NormalTok{ matmul}\OperatorTok{(}\NormalTok{R}\OperatorTok{,}\NormalTok{A}\OperatorTok{);}
\NormalTok{        matmul}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{A}\OperatorTok{);}
\NormalTok{        n}\OperatorTok{\textgreater{}\textgreater{}=}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
\NormalTok{    memcpy}\OperatorTok{(}\NormalTok{A}\OperatorTok{,}\NormalTok{ R}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{R}\OperatorTok{));}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Summary}\label{summary-20}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3056}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3611}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Speedup
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Algebraic Identities & Simplify expressions & Constant factor \\
Generating Functions & Solve recurrences & Conceptual \\
FFT / Convolution & Combine sequences fast & (O\(n^2\)
\to O\(n \log n\)) \\
Polynomial Interpolation & Reconstruction & (O\(n^2\)
\to O\(n \log^2 n\)) \\
Matrix Tricks & Accelerate recurrences & (O(n) \to O\(\log n\)) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-59}

Algebra turns computation into structure. By rewriting problems in
algebraic form, you reveal hidden symmetries, exploit fast transforms,
and find elegant solutions. It's not magic , it's the math beneath
performance.

\begin{quote}
``The smartest code is often the one that solves itself on paper
first.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-59}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiply two polynomials using FFT.
\item
  Represent Fibonacci as a matrix and compute \(F_{100}\).
\item
  Use generating functions to count coin change ways.
\item
  Implement subset sum via Walsh-Hadamard transform.
\item
  Derive a recurrence and solve it algebraically.
\end{enumerate}

Understanding algebraic tricks makes you not just a coder, but a
mathematical engineer , bending structure to will.

\section{Chapter 7. Strings and Text
Algorithms}\label{chapter-7.-strings-and-text-algorithms-1}

\subsection{61. String Matching (KMP, Z, Rabin-Karp,
Boyer-Moore)}\label{string-matching-kmp-z-rabin-karp-boyer-moore}

String matching is one of the oldest and most fundamental problems in
computer science: given a text ( T ) of length ( n ) and a pattern ( P )
of length ( m ), find all positions where ( P ) appears in ( T ).

This section walks you through both naive and efficient algorithms ,
from the straightforward brute-force method to elegant linear-time
solutions like KMP and Z-algorithm, and clever heuristics like
Boyer-Moore and Rabin-Karp.

\subsubsection{1. Problem Setup}\label{problem-setup}

We're given:

\begin{itemize}
\tightlist
\item
  Text: \(T = t_1 t_2 \ldots t_n\)- Pattern: \(P = p_1 p_2 \ldots p_m\)
  Goal: find all ( i ) such that \[
  T[i \ldots i+m-1] = P[1 \ldots m]
  \]
\end{itemize}

Naive solution: compare ( P ) with every substring of ( T ) Time
complexity: ( O(nm) )

We'll now see how to reduce it to ( O(n + m) ) or close.

\subsubsection{2. Knuth-Morris-Pratt
(KMP)}\label{knuth-morris-pratt-kmp}

KMP avoids rechecking characters by precomputing overlaps within the
pattern.

It builds a prefix-function (also called failure function), which tells
how much to shift when a mismatch happens.

\subsubsection{A. Prefix Function}\label{a.-prefix-function}

For each position ( i ), compute \(\pi[i]\) = length of longest prefix
that's also a suffix of ( P{[}1..i{]} ).

Example: Pattern \texttt{ababc}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
i & P{[}i{]} & π{[}i{]} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & a & 0 \\
2 & b & 0 \\
3 & a & 1 \\
4 & b & 2 \\
5 & c & 0 \\
\end{longtable}

\subsubsection{B. Search Phase}\label{b.-search-phase}

Use \(\pi[]\) to skip mismatched prefixes in the text.

Time Complexity: ( O(n + m) ) Space: ( O(m) )

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ compute\_pi}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ pi}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    pi}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k }\OperatorTok{=}\NormalTok{ pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{==}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
\NormalTok{        pi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ k}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ kmp\_search}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{t}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{t}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ pi}\OperatorTok{[}\NormalTok{m}\OperatorTok{];}\NormalTok{ compute\_pi}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ m}\OperatorTok{,}\NormalTok{ pi}\OperatorTok{);}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k }\OperatorTok{=}\NormalTok{ pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{k}\OperatorTok{]} \OperatorTok{==}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k }\OperatorTok{==}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            printf}\OperatorTok{(}\StringTok{"Found at }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ i }\OperatorTok{{-}}\NormalTok{ m }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{            k }\OperatorTok{=}\NormalTok{ pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Z-Algorithm}\label{z-algorithm-1}

Z-algorithm computes the Z-array,\\
where \(Z[i]\) = length of the longest substring starting at \(i\) that
matches the prefix of \(P\).

To match \(P\) in \(T\), build the string:

\[
S = P + \# + T
\]

Then every \(i\) where \(Z[i] = |P|\) corresponds to a match.

Time: \(O(n + m)\)\\
Simple and elegant.

Example:

\begin{verbatim}
P = "aba", T = "ababa"
S = "aba#ababa"
Z = [0,0,1,0,3,0,1,0]
Match at index 0, 2
\end{verbatim}

\subsubsection{4. Rabin-Karp (Rolling
Hash)}\label{rabin-karp-rolling-hash}

Instead of comparing strings character-by-character, compute a hash for
each window in ( T ), and compare hashes.

\[
h(s_1s_2\ldots s_m) = (s_1b^{m-1} + s_2b^{m-2} + \ldots + s_m) \bmod M
\]

Use a rolling hash to update in ( O(1) ) per shift.

Time: average ( O(n + m) ), worst ( O(nm) ) Good for multiple pattern
search.

Tiny Code (Rolling Hash)

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define B }\DecValTok{256}
\PreprocessorTok{\#define M }\DecValTok{101}

\DataTypeTok{void}\NormalTok{ rabin\_karp}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{t}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{t}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ h }\OperatorTok{=} \DecValTok{1}\OperatorTok{,}\NormalTok{ pHash }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ tHash }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ h }\OperatorTok{=} \OperatorTok{(}\NormalTok{h}\OperatorTok{*}\NormalTok{B}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        pHash }\OperatorTok{=} \OperatorTok{(}\NormalTok{B}\OperatorTok{*}\NormalTok{pHash }\OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
\NormalTok{        tHash }\OperatorTok{=} \OperatorTok{(}\NormalTok{B}\OperatorTok{*}\NormalTok{tHash }\OperatorTok{+}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{{-}}\NormalTok{m}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{pHash }\OperatorTok{==}\NormalTok{ tHash }\OperatorTok{\&\&}\NormalTok{ strncmp}\OperatorTok{(\&}\NormalTok{t}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ p}\OperatorTok{,}\NormalTok{ m}\OperatorTok{)} \OperatorTok{==} \DecValTok{0}\OperatorTok{)}
\NormalTok{            printf}\OperatorTok{(}\StringTok{"Found at }\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ i}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{{-}}\NormalTok{m}\OperatorTok{)}
\NormalTok{            tHash }\OperatorTok{=} \OperatorTok{(}\NormalTok{B}\OperatorTok{*(}\NormalTok{tHash }\OperatorTok{{-}}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{]*}\NormalTok{h}\OperatorTok{)} \OperatorTok{+}\NormalTok{ t}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\NormalTok{m}\OperatorTok{])} \OperatorTok{\%}\NormalTok{ M}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{tHash }\OperatorTok{\textless{}} \DecValTok{0}\OperatorTok{)}\NormalTok{ tHash }\OperatorTok{+=}\NormalTok{ M}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Boyer-Moore (Heuristic
Skipping)}\label{boyer-moore-heuristic-skipping}

Boyer-Moore compares from right to left and uses two heuristics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Bad Character Rule When mismatch at ( j ), shift pattern so next
  occurrence of ( T{[}i{]} ) in ( P ) aligns.
\item
  Good Suffix Rule Shift pattern so a suffix of matched portion aligns
  with another occurrence.
\end{enumerate}

Time: ( O(n/m) ) on average Practical and fast, especially for English
text.

\subsubsection{6. Summary}\label{summary-21}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1642}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1940}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2687}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1940}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive & (O(nm)) & (O(1)) & Direct compare & Simple cases \\
KMP & (O(n+m)) & (O(m)) & Prefix overlap & General use \\
Z & (O(n+m)) & (O(n+m)) & Prefix matching & Pattern prep \\
Rabin-Karp & (O(n+m)) avg & (O(1)) & Hashing & Multi-pattern \\
Boyer-Moore & (O(n/m)) avg & (O\(m+\sigma\)) & Right-to-left skip & Long
texts \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-60}

String matching powers text editors, DNA search, spam filters, and
search engines. These algorithms show how structure and clever
preprocessing turn brute force into elegance.

\begin{quote}
``To find is human, to match efficiently is divine.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-60}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement KMP and print all matches in a sentence.
\item
  Use Rabin-Karp to find multiple keywords.
\item
  Compare running times on large text files.
\item
  Modify KMP for case-insensitive matching.
\item
  Visualize prefix function computation step-by-step.
\end{enumerate}

By mastering these, you'll wield the foundation of pattern discovery ,
the art of finding order in streams of symbols.

\subsection{62. Multi-Pattern Search
(Aho-Corasick)}\label{multi-pattern-search-aho-corasick}

So far, we've matched one pattern against a text. But what if we have
many patterns , say, a dictionary of keywords , and we want to find all
occurrences of all patterns in a single pass?

That's where the Aho-Corasick algorithm shines. It builds a trie with
failure links, turning multiple patterns into one efficient automaton.
Think of it as ``KMP for many words at once.''

\subsubsection{1. Problem Setup}\label{problem-setup-1}

Given:

\begin{itemize}
\tightlist
\item
  A text ( T ) of length ( n )- A set of patterns
  \({ P_1, P_2, \ldots, P_k }\) with total length \(m = \sum |P_i|\)
\end{itemize}

Goal: find all occurrences of every \(P_i\) in ( T ).

Naive solution: Run KMP for each pattern , ( O(kn) )

Better idea: Merge all patterns into a trie, and use failure links to
transition on mismatches.

Aho-Corasick achieves O(n + m + z), where ( z ) = number of matches
reported.

\subsubsection{2. Trie Construction}\label{trie-construction}

Each pattern is inserted into a trie node-by-node.

Example Patterns:

\begin{verbatim}
he, she, his, hers
\end{verbatim}

Trie:

\begin{verbatim}
(root)
 ├─ h ─ e*
 │   └─ r ─ s*
 ├─ s ─ h ─ e*
 └─ h ─ i ─ s*
\end{verbatim}

Each node may mark an output (end of pattern).

\subsubsection{3. Failure Links}\label{failure-links}

Failure link of a node points to the longest proper suffix that's also a
prefix in the trie.

These links let us ``fall back'' like KMP.

When mismatch happens, follow failure link to find next possible match.

\subsubsection{Building Failure Links
(BFS)}\label{building-failure-links-bfs}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Root's failure = null
\item
  Children of root → failure = root
\item
  BFS over nodes:

  \begin{itemize}
  \tightlist
  \item
    For each edge ( (u, c) → v ): follow failure links from ( u ) until
    you find ( f ) with edge ( c ) then \(v.\text{fail} = f.c\)
  \end{itemize}
\end{enumerate}

\subsubsection{Example}\label{example-5}

For ``he'', ``she'', ``his'', ``hers'':

\begin{itemize}
\tightlist
\item
  \texttt{fail("he")\ =\ root}- \texttt{fail("hers")\ =\ "rs"} path
  invalid → fallback to \texttt{"s"} if exists So failure links connect
  partial suffixes.
\end{itemize}

\subsubsection{4. Matching Phase}\label{matching-phase}

Now we can process the text in one pass:

\begin{verbatim}
state = root
for each character c in text:
    while state has no child c and state != root:
        state = state.fail
    if state has child c:
        state = state.child[c]
    else:
        state = root
    if state.output:
        report matches at this position
\end{verbatim}

Each transition costs O(1) amortized. No backtracking , fully linear
time.

\subsubsection{5. Example Walkthrough}\label{example-walkthrough}

Patterns: \texttt{he}, \texttt{she}, \texttt{his}, \texttt{hers} Text:
\texttt{ahishers}

At each character:

\begin{verbatim}
a → root (no match)
h → go to h
i → go to hi
s → go to his → output "his"
h → fallback → h
e → he → output "he"
r → her → continue
s → hers → output "hers"
\end{verbatim}

Outputs: \texttt{"his"}, \texttt{"he"}, \texttt{"hers"}

\subsubsection{6. Tiny Code (C Implementation
Sketch)}\label{tiny-code-c-implementation-sketch}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define ALPHA }\DecValTok{26}

\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{next}\OperatorTok{[}\NormalTok{ALPHA}\OperatorTok{];}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{fail}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ out}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{Node}\OperatorTok{*}\NormalTok{ newNode}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    Node }\OperatorTok{*}\NormalTok{n }\OperatorTok{=}\NormalTok{ calloc}\OperatorTok{(}\DecValTok{1}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Node}\OperatorTok{));}
    \ControlFlowTok{return}\NormalTok{ n}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ insert}\OperatorTok{(}\NormalTok{Node }\OperatorTok{*}\NormalTok{root}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ c }\OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{{-}} \CharTok{\textquotesingle{}a\textquotesingle{}}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{root}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{])}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{=}\NormalTok{ newNode}\OperatorTok{();}
\NormalTok{        root }\OperatorTok{=}\NormalTok{ root}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    root}\OperatorTok{{-}\textgreater{}}\NormalTok{out }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ build\_failures}\OperatorTok{(}\NormalTok{Node }\OperatorTok{*}\NormalTok{root}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Node }\OperatorTok{*}\NormalTok{q}\OperatorTok{[}\DecValTok{10000}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ front}\OperatorTok{=}\DecValTok{0}\OperatorTok{,}\NormalTok{ back}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}
\NormalTok{    root}\OperatorTok{{-}\textgreater{}}\NormalTok{fail }\OperatorTok{=}\NormalTok{ root}\OperatorTok{;}
\NormalTok{    q}\OperatorTok{[}\NormalTok{back}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ root}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{front }\OperatorTok{\textless{}}\NormalTok{ back}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        Node }\OperatorTok{*}\NormalTok{u }\OperatorTok{=}\NormalTok{ q}\OperatorTok{[}\NormalTok{front}\OperatorTok{++];}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ c}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ c}\OperatorTok{\textless{}}\NormalTok{ALPHA}\OperatorTok{;}\NormalTok{ c}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{            Node }\OperatorTok{*}\NormalTok{v }\OperatorTok{=}\NormalTok{ u}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{];}
            \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{v}\OperatorTok{)} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{            Node }\OperatorTok{*}\NormalTok{f }\OperatorTok{=}\NormalTok{ u}\OperatorTok{{-}\textgreater{}}\NormalTok{fail}\OperatorTok{;}
            \ControlFlowTok{while} \OperatorTok{(}\NormalTok{f }\OperatorTok{!=}\NormalTok{ root }\OperatorTok{\&\&} \OperatorTok{!}\NormalTok{f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{])}\NormalTok{ f }\OperatorTok{=}\NormalTok{ f}\OperatorTok{{-}\textgreater{}}\NormalTok{fail}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{\&\&}\NormalTok{ f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{]} \OperatorTok{!=}\NormalTok{ v}\OperatorTok{)}\NormalTok{ v}\OperatorTok{{-}\textgreater{}}\NormalTok{fail }\OperatorTok{=}\NormalTok{ f}\OperatorTok{{-}\textgreater{}}\NormalTok{next}\OperatorTok{[}\NormalTok{c}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ v}\OperatorTok{{-}\textgreater{}}\NormalTok{fail }\OperatorTok{=}\NormalTok{ root}\OperatorTok{;}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{v}\OperatorTok{{-}\textgreater{}}\NormalTok{fail}\OperatorTok{{-}\textgreater{}}\NormalTok{out}\OperatorTok{)}\NormalTok{ v}\OperatorTok{{-}\textgreater{}}\NormalTok{out }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}
\NormalTok{            q}\OperatorTok{[}\NormalTok{back}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ v}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Complexity}\label{complexity-3}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Phase & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trie Build & ( O(m) ) & ( O(m) ) \\
Failure Links & ( O(m) ) & ( O(m) ) \\
Search & ( O(n + z) ) & ( O(1) ) \\
\end{longtable}

Total: O(n + m + z)

\subsubsection{8. Summary}\label{summary-22}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Purpose \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trie & Merge patterns \\
Fail Links & Handle mismatches \\
Outputs & Collect matches \\
BFS & Build efficiently \\
One Pass & Match all patterns \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-61}

Aho-Corasick is the core of:

\begin{itemize}
\tightlist
\item
  Spam filters- Intrusion detection (e.g., Snort IDS)- Keyword search in
  compilers- DNA sequence scanners It's a masterclass in blending
  automata theory with practical efficiency.
\end{itemize}

\begin{quote}
``Why search one word at a time when your algorithm can read the whole
dictionary?''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-61}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build an automaton for words \{``he'', ``she'', ``hers''\} and trace
  it manually.
\item
  Modify code for uppercase letters.
\item
  Extend to report overlapping matches.
\item
  Measure runtime vs.~naive multi-search.
\item
  Visualize the failure links in a graph.
\end{enumerate}

Once you grasp Aho-Corasick, you'll see pattern search not as a loop ,
but as a machine that reads and recognizes.

\subsection{63. Suffix Structures (Suffix Array, Suffix Tree,
LCP)}\label{suffix-structures-suffix-array-suffix-tree-lcp}

Suffix-based data structures are among the most powerful tools in string
algorithms. They enable fast searching, substring queries, pattern
matching, and lexicographic operations , all from one fundamental idea:

\begin{quote}
Represent all suffixes of a string in a structured form.
\end{quote}

In this section, we explore three key constructs:

\begin{itemize}
\tightlist
\item
  Suffix Array (SA) - lexicographically sorted suffix indices- Longest
  Common Prefix (LCP) array - shared prefix lengths between neighbors-
  Suffix Tree - compressed trie of all suffixes Together, they power
  many advanced algorithms in text processing, bioinformatics, and
  compression.
\end{itemize}

\subsubsection{1. Suffix Array (SA)}\label{suffix-array-sa}

A suffix array stores all suffixes of a string in lexicographic order,
represented by their starting indices.

Example: String \texttt{banana\$} All suffixes:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Index & Suffix \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & banana\$ \\
1 & anana\$ \\
2 & nana\$ \\
3 & ana\$ \\
4 & na\$ \\
5 & a\$ \\
6 & \$ \\
\end{longtable}

Sort them:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Sorted Order & Suffix & Index \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & \texttt{\$} & 6 \\
1 & \texttt{a\$} & 5 \\
2 & \texttt{ana\$} & 3 \\
3 & \texttt{anana\$} & 1 \\
4 & \texttt{banana\$} & 0 \\
5 & \texttt{na\$} & 4 \\
6 & \texttt{nana\$} & 2 \\
\end{longtable}

Suffix Array: \texttt{{[}6,\ 5,\ 3,\ 1,\ 0,\ 4,\ 2{]}}

\subsubsection{Construction (Prefix
Doubling)}\label{construction-prefix-doubling}

We iteratively sort suffixes by first 2ⁱ characters, using radix sort on
pairs of ranks.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Assign initial rank by character.
\item
  Sort by (rank{[}i{]}, rank{[}i+k{]}).
\item
  Repeat doubling \(k \leftarrow 2k\) until all ranks distinct.
\end{enumerate}

Time Complexity: ( O\(n \log n\) ) Space: ( O(n) )

Tiny Code (C, Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{int}\NormalTok{ idx}\OperatorTok{,}\NormalTok{ rank}\OperatorTok{[}\DecValTok{2}\OperatorTok{];} \OperatorTok{\}}\NormalTok{ Suffix}\OperatorTok{;}
\DataTypeTok{int}\NormalTok{ cmp}\OperatorTok{(}\NormalTok{Suffix a}\OperatorTok{,}\NormalTok{ Suffix b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]==}\NormalTok{b}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{])} \OperatorTok{?} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]{-}}\NormalTok{b}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{])} \OperatorTok{:} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]{-}}\NormalTok{b}\OperatorTok{.}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ buildSA}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    Suffix suf}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{        suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{        suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{)} \OperatorTok{?}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{]} \OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{2}\OperatorTok{;}\NormalTok{ k }\OperatorTok{\textless{}} \DecValTok{2}\OperatorTok{*}\NormalTok{n}\OperatorTok{;}\NormalTok{ k }\OperatorTok{*=} \DecValTok{2}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        qsort}\OperatorTok{(}\NormalTok{suf}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Suffix}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{);}
        \DataTypeTok{int}\NormalTok{ r }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ rank}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}\NormalTok{ rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{idx}\OperatorTok{]=}\DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]!=}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{||}\NormalTok{ suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]!=}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{])}\NormalTok{ r}\OperatorTok{++;}
\NormalTok{            rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{]=}\NormalTok{r}\OperatorTok{;}
        \OperatorTok{\}}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)\{}
\NormalTok{            suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{];}
\NormalTok{            suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{rank}\OperatorTok{[}\DecValTok{1}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{+}\NormalTok{k}\OperatorTok{/}\DecValTok{2}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{)?}\NormalTok{rank}\OperatorTok{[}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{+}\NormalTok{k}\OperatorTok{/}\DecValTok{2}\OperatorTok{]:{-}}\DecValTok{1}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}\NormalTok{ sa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]=}\NormalTok{suf}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{idx}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{2. Longest Common Prefix
(LCP)}\label{longest-common-prefix-lcp}

The LCP array stores the length of the longest common prefix between
consecutive suffixes in SA order.

Example: \texttt{banana\$}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
SA & Suffix & LCP \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
6 & \$ & 0 \\
5 & a\$ & 0 \\
3 & ana\$ & 1 \\
1 & anana\$ & 3 \\
0 & banana\$ & 0 \\
4 & na\$ & 0 \\
2 & nana\$ & 2 \\
\end{longtable}

So LCP = \texttt{{[}0,0,1,3,0,0,2{]}}

\subsubsection{Kasai's Algorithm (Build in
O(n))}\label{kasais-algorithm-build-in-on}

We compute LCP in one pass using inverse SA:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ buildLCP}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ lcp}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ rank}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}\NormalTok{ rank}\OperatorTok{[}\NormalTok{sa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]=}\NormalTok{i}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]==}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;} \ControlFlowTok{continue}\OperatorTok{;} \OperatorTok{\}}
        \DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ sa}\OperatorTok{[}\NormalTok{rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]+}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i}\OperatorTok{+}\NormalTok{k}\OperatorTok{\textless{}}\NormalTok{n }\OperatorTok{\&\&}\NormalTok{ j}\OperatorTok{+}\NormalTok{k}\OperatorTok{\textless{}}\NormalTok{n }\OperatorTok{\&\&}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\NormalTok{k}\OperatorTok{]==}\NormalTok{s}\OperatorTok{[}\NormalTok{j}\OperatorTok{+}\NormalTok{k}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
\NormalTok{        lcp}\OperatorTok{[}\NormalTok{rank}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]=}\NormalTok{k}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{k}\OperatorTok{\textgreater{}}\DecValTok{0}\OperatorTok{)}\NormalTok{ k}\OperatorTok{{-}{-};}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O(n) )

\subsubsection{3. Suffix Tree}\label{suffix-tree}

A suffix tree is a compressed trie of all suffixes.

Each edge holds a substring interval, not individual characters. This
gives:

\begin{itemize}
\tightlist
\item
  Construction in ( O(n) ) (Ukkonen's algorithm)- Pattern search in (
  O(m) )- Many advanced uses (e.g., longest repeated substring) Example:
  String: \texttt{banana\$} Suffix tree edges:
\end{itemize}

\begin{verbatim}
(root)
 ├─ b[0:0] → ...
 ├─ a[1:1] → ...
 ├─ n[2:2] → ...
\end{verbatim}

Edges compress consecutive letters into intervals like
\texttt{{[}start:end{]}}.

\subsubsection{Comparison}\label{comparison-23}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Structure & Space & Build Time & Search \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Suffix Array & ( O(n) ) & ( O\(n \log n\) ) & ( O\(m \log n\) ) \\
LCP Array & ( O(n) ) & ( O(n) ) & Range queries \\
Suffix Tree & ( O(n) ) & ( O(n) ) & ( O(m) ) \\
\end{longtable}

Suffix Array + LCP ≈ compact Suffix Tree.

\subsubsection{4. Applications}\label{applications-9}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Substring search - binary search in SA
\item
  Longest repeated substring - max(LCP)
\item
  Lexicographic order - direct from SA
\item
  Distinct substrings count = ( n(n+1)/2 - \sum LCP{[}i{]} )
\item
  Pattern frequency - range query in SA using LCP
\end{enumerate}

\subsubsection{5. Tiny Code (Search via
SA)}\label{tiny-code-search-via-sa}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ searchSA}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{t}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{p}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[])} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ l}\OperatorTok{=}\DecValTok{0}\OperatorTok{,}\NormalTok{ r}\OperatorTok{=}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ m}\OperatorTok{=}\NormalTok{strlen}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{l }\OperatorTok{\textless{}=}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=} \OperatorTok{(}\NormalTok{l}\OperatorTok{+}\NormalTok{r}\OperatorTok{)/}\DecValTok{2}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ cmp }\OperatorTok{=}\NormalTok{ strncmp}\OperatorTok{(}\NormalTok{t}\OperatorTok{+}\NormalTok{sa}\OperatorTok{[}\NormalTok{mid}\OperatorTok{],}\NormalTok{ p}\OperatorTok{,}\NormalTok{ m}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cmp}\OperatorTok{==}\DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ sa}\OperatorTok{[}\NormalTok{mid}\OperatorTok{];}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cmp}\OperatorTok{\textless{}}\DecValTok{0}\OperatorTok{)}\NormalTok{ l}\OperatorTok{=}\NormalTok{mid}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{else}\NormalTok{ r}\OperatorTok{=}\NormalTok{mid}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{6. Summary}\label{summary-23}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Concept & Purpose & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Suffix Array & Sorted suffix indices & ( O\(n \log n\) ) \\
LCP Array & Adjacent suffix overlap & ( O(n) ) \\
Suffix Tree & Compressed trie of suffixes & ( O(n) ) \\
\end{longtable}

Together they form the core of advanced string algorithms.

\subsubsection{Why It Matters}\label{why-it-matters-62}

Suffix structures reveal hidden order in strings. They turn raw text
into searchable, analyzable data , ideal for compression, search
engines, and DNA analysis.

\begin{quote}
``All suffixes, perfectly sorted , the DNA of text.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-62}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build suffix array for \texttt{banana\$} by hand.
\item
  Write code to compute LCP and longest repeated substring.
\item
  Search multiple patterns using binary search on SA.
\item
  Count distinct substrings from SA + LCP.
\item
  Compare SA-based vs.~tree-based search performance.
\end{enumerate}

Mastering suffix structures equips you to tackle problems that were once
``too big'' for brute force , now solvable with elegance and order.

\subsection{64. Palindromes and Periodicity
(Manacher)}\label{palindromes-and-periodicity-manacher}

Palindromes are symmetric strings that read the same forwards and
backwards , like ``level'', ``racecar'', or ``madam''. They arise
naturally in text analysis, bioinformatics, and even in data
compression.

This section introduces efficient algorithms to detect and analyze
palindromic structure and periodicity in strings, including the
legendary Manacher's Algorithm, which finds all palindromic substrings
in linear time.

\subsubsection{1. What Is a Palindrome?}\label{what-is-a-palindrome}

A string ( S ) is a palindrome if: \[
S[i] = S[n - i + 1] \quad \text{for all } i
\]

Examples:

\begin{itemize}
\tightlist
\item
  \texttt{"abba"} is even-length palindrome- \texttt{"aba"} is
  odd-length palindrome A string may contain many palindromic substrings
  , our goal is to find all centers efficiently.
\end{itemize}

\subsubsection{2. Naive Approach}\label{naive-approach}

For each center (between characters or at characters), expand outward
while characters match.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each center c}\OperatorTok{:}
\NormalTok{    expand left}\OperatorTok{,}\NormalTok{ right }\ControlFlowTok{while}\NormalTok{ S}\OperatorTok{[}\NormalTok{l}\OperatorTok{]} \OperatorTok{==}\NormalTok{ S}\OperatorTok{[}\NormalTok{r}\OperatorTok{]}
\end{Highlighting}
\end{Shaded}

Complexity: ( O\(n^2\) ) , too slow for large strings.

We need something faster , that's where Manacher's Algorithm steps in.

\subsubsection{3. Manacher's Algorithm
(O(n))}\label{manachers-algorithm-on}

Manacher's Algorithm finds the radius of the longest palindrome centered
at each position in linear time.

It cleverly reuses previous computations using mirror symmetry and a
current right boundary.

\subsubsection{Step-by-Step}\label{step-by-step}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Preprocess string to handle even-length palindromes: Insert
  \texttt{\#} between characters.

  Example:

\begin{verbatim}
S = "abba"
T = "^#a#b#b#a#$"
\end{verbatim}

  (\texttt{\^{}} and \texttt{\$} are sentinels)
\item
  Maintain:

  \begin{itemize}
  \tightlist
  \item
    \texttt{C}: center of rightmost palindrome - \texttt{R}: right
    boundary - \texttt{P{[}i{]}}: palindrome radius at \texttt{i}
  \end{itemize}
\item
  For each position \texttt{i}:

  \begin{itemize}
  \tightlist
  \item
    mirror position \texttt{mirror\ =\ 2*C\ -\ i} - initialize
    \texttt{P{[}i{]}\ =\ min(R\ -\ i,\ P{[}mirror{]})} - expand around
    \texttt{i} while characters match - if new palindrome extends past
    \texttt{R}, update \texttt{C} and \texttt{R}
  \end{itemize}
\item
  The maximum value of \texttt{P{[}i{]}} gives the longest palindrome.
\end{enumerate}

\subsubsection{Example}\label{example-6}

\begin{verbatim}
S = "abba"
T = "^#a#b#b#a#$"
P = [0,0,1,0,3,0,3,0,1,0,0]
Longest radius = 3 → "abba"
\end{verbatim}

Tiny Code (C Implementation)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ manacher}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
    \DataTypeTok{char}\NormalTok{ t}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{n }\OperatorTok{+} \DecValTok{3}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ p}\OperatorTok{[}\DecValTok{2}\OperatorTok{*}\NormalTok{n }\OperatorTok{+} \DecValTok{3}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}\^{}\textquotesingle{}}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}\#\textquotesingle{}}\OperatorTok{;}
\NormalTok{        t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ s}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
\NormalTok{    t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}\#\textquotesingle{}}\OperatorTok{;}\NormalTok{ t}\OperatorTok{[}\NormalTok{m}\OperatorTok{++]} \OperatorTok{=} \CharTok{\textquotesingle{}$\textquotesingle{}}\OperatorTok{;}
\NormalTok{    t}\OperatorTok{[}\NormalTok{m}\OperatorTok{]} \OperatorTok{=} \CharTok{\textquotesingle{}}\SpecialCharTok{\textbackslash{}0}\CharTok{\textquotesingle{}}\OperatorTok{;}
    
    \DataTypeTok{int}\NormalTok{ c }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ r }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ maxLen }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\NormalTok{m}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ mirror }\OperatorTok{=} \DecValTok{2}\OperatorTok{*}\NormalTok{c }\OperatorTok{{-}}\NormalTok{ i}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ r}\OperatorTok{)}
\NormalTok{            p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \OperatorTok{(}\NormalTok{r }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ p}\OperatorTok{[}\NormalTok{mirror}\OperatorTok{])} \OperatorTok{?} \OperatorTok{(}\NormalTok{r }\OperatorTok{{-}}\NormalTok{ i}\OperatorTok{)} \OperatorTok{:}\NormalTok{ p}\OperatorTok{[}\NormalTok{mirror}\OperatorTok{];}
        \ControlFlowTok{else}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{t}\OperatorTok{[}\NormalTok{i }\OperatorTok{+} \DecValTok{1} \OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]]} \OperatorTok{==}\NormalTok{ t}\OperatorTok{[}\NormalTok{i }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]])}
\NormalTok{            p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]++;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{i }\OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{            c }\OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{            r }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
        \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{p}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ maxLen}\OperatorTok{)}\NormalTok{ maxLen }\OperatorTok{=}\NormalTok{ p}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ maxLen}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O(n) ) Space: ( O(n) )

\subsubsection{4. Periodicity and
Repetition}\label{periodicity-and-repetition}

A string ( S ) has a period ( p ) if: \[
S[i] = S[i + p] \text{ for all valid } i
\]

Example: \texttt{abcabcabc} has period 3 (\texttt{abc}).

Checking Periodicity:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build prefix function (as in KMP).
\item
  Let ( n = \textbar S\textbar{} ), \(p = n - \pi[n-1]\).
\item
  If \(n \mod p = 0\), period = ( p ).
\end{enumerate}

Example:

\begin{verbatim}
S = "ababab"
π = [0,0,1,2,3,4]
p = 6 - 4 = 2
6 mod 2 = 0 → periodic
\end{verbatim}

Tiny Code (Check Periodicity)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ period}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{s}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{s}\OperatorTok{),}\NormalTok{ pi}\OperatorTok{[}\NormalTok{n}\OperatorTok{];}
\NormalTok{    pi}\OperatorTok{[}\DecValTok{0}\OperatorTok{]=}\DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{,}\NormalTok{k}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)\{}
        \ControlFlowTok{while}\OperatorTok{(}\NormalTok{k}\OperatorTok{\textgreater{}}\DecValTok{0} \OperatorTok{\&\&}\NormalTok{ s}\OperatorTok{[}\NormalTok{k}\OperatorTok{]!=}\NormalTok{s}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{=}\NormalTok{pi}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
        \ControlFlowTok{if}\OperatorTok{(}\NormalTok{s}\OperatorTok{[}\NormalTok{k}\OperatorTok{]==}\NormalTok{s}\OperatorTok{[}\NormalTok{i}\OperatorTok{])}\NormalTok{ k}\OperatorTok{++;}
\NormalTok{        pi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]=}\NormalTok{k}\OperatorTok{;}
    \OperatorTok{\}}
    \DataTypeTok{int}\NormalTok{ p }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ pi}\OperatorTok{[}\NormalTok{n}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{n }\OperatorTok{\%}\NormalTok{ p }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \OperatorTok{?}\NormalTok{ p }\OperatorTok{:}\NormalTok{ n}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Applications}\label{applications-10}

\begin{itemize}
\tightlist
\item
  Palindrome Queries: is substring ( S{[}l:r{]} ) palindrome? →
  precompute radii- Longest Palindromic Substring- DNA Symmetry
  Analysis- Pattern Compression / Period Detection- String Regularity
  Tests
\end{itemize}

\subsubsection{6. Summary}\label{summary-24}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Concept & Purpose & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive Expand & Simple palindrome check & ( O\(n^2\) ) \\
Manacher & Longest palindromic substring & ( O(n) ) \\
KMP Prefix & Period detection & ( O(n) ) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-63}

Palindromes reveal hidden symmetries. Manacher's algorithm is a gem , a
linear-time mirror-based solution to a quadratic problem.

\begin{quote}
``In every word, there may hide a reflection.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-63}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run Manacher's algorithm on \texttt{"abacdfgdcaba"}.
\item
  Modify code to print all palindromic substrings.
\item
  Use prefix function to find smallest period.
\item
  Combine both to find palindromic periodic substrings.
\item
  Compare runtime vs.~naive expand method.
\end{enumerate}

Understanding palindromes and periodicity teaches how structure emerges
from repetition , a central theme in all of algorithmic design.

\subsection{65. Edit Distance and
Alignment}\label{edit-distance-and-alignment}

Edit distance measures how different two strings are , the minimal
number of operations needed to turn one into the other. It's a
cornerstone of spell checking, DNA sequence alignment, plagiarism
detection, and fuzzy search.

The most common form is the Levenshtein distance, using:

\begin{itemize}
\tightlist
\item
  Insertion (add a character)- Deletion (remove a character)-
  Substitution (replace a character) We'll also touch on alignment,
  which generalizes this idea with custom scoring and penalties.
\end{itemize}

\subsubsection{1. Problem Definition}\label{problem-definition-1}

Given two strings ( A ) and ( B ), find the minimum number of edits to
convert \(A \to B\).

If ( A = ``kitten'' ) ( B = ``sitting'' )

One optimal sequence:

\begin{verbatim}
kitten → sitten (substitute 'k'→'s')
sitten → sittin (substitute 'e'→'i')
sittin → sitting (insert 'g')
\end{verbatim}

So edit distance = 3.

\subsubsection{2. Dynamic Programming
Solution}\label{dynamic-programming-solution}

Let \(dp[i][j]\) be the minimum edits to convert
\(A[0..i-1] \to B[0..j-1]\).

Recurrence: \[
dp[i][j] =
\begin{cases}
dp[i-1][j-1], & \text{if } A[i-1] = B[j-1], \\
1 + \min\big(dp[i-1][j],\, dp[i][j-1],\, dp[i-1][j-1]\big), & \text{otherwise}
\end{cases}
\]

Where: - \(dp[i-1][j]\): delete from \(A\) - \(dp[i][j-1]\): insert into
\(A\) - \(dp[i-1][j-1]\): substitute

Base cases: \[
dp[0][j] = j,\quad dp[i][0] = i
\]

Time complexity: \(O(|A||B|)\)

\subsubsection{Example}\label{example-7}

A = \texttt{kitten}, B = \texttt{sitting}

\begin{longtable}[]{@{}lllllllll@{}}
\toprule\noalign{}
& ``\,'' & s & i & t & t & i & n & g \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``\,'' & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
k & 1 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
i & 2 & 2 & 1 & 2 & 3 & 4 & 5 & 6 \\
t & 3 & 3 & 2 & 1 & 2 & 3 & 4 & 5 \\
t & 4 & 4 & 3 & 2 & 1 & 2 & 3 & 4 \\
e & 5 & 5 & 4 & 3 & 2 & 2 & 3 & 4 \\
n & 6 & 6 & 5 & 4 & 3 & 3 & 2 & 3 \\
\end{longtable}

Edit distance = 3

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}stdio.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}string.h\textgreater{}}
\PreprocessorTok{\#define MIN3}\OperatorTok{(}\PreprocessorTok{a}\OperatorTok{,}\PreprocessorTok{b}\OperatorTok{,}\PreprocessorTok{c}\OperatorTok{)}\PreprocessorTok{ }\OperatorTok{((}\PreprocessorTok{a}\OperatorTok{\textless{}}\PreprocessorTok{b}\OperatorTok{)?((}\PreprocessorTok{a}\OperatorTok{\textless{}}\PreprocessorTok{c}\OperatorTok{)?}\PreprocessorTok{a}\OperatorTok{:}\PreprocessorTok{c}\OperatorTok{):((}\PreprocessorTok{b}\OperatorTok{\textless{}}\PreprocessorTok{c}\OperatorTok{)?}\PreprocessorTok{b}\OperatorTok{:}\PreprocessorTok{c}\OperatorTok{))}

\DataTypeTok{int}\NormalTok{ edit\_distance}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{A}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{B}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{A}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{B}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}=}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]=}\NormalTok{i}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]=}\NormalTok{j}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}=}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]==}\NormalTok{B}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]=}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}
\NormalTok{                dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]=}\DecValTok{1}\OperatorTok{+}\NormalTok{MIN3}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ main}\OperatorTok{()} \OperatorTok{\{}
\NormalTok{    printf}\OperatorTok{(}\StringTok{"}\SpecialCharTok{\%d\textbackslash{}n}\StringTok{"}\OperatorTok{,}\NormalTok{ edit\_distance}\OperatorTok{(}\StringTok{"kitten"}\OperatorTok{,}\StringTok{"sitting"}\OperatorTok{));} \CommentTok{// 3}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Space Optimization}\label{space-optimization}

We only need the previous row to compute the current row.

So,\\
Space complexity: \(O(\min(|A|, |B|))\)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ edit\_distance\_opt}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{A}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{B}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n}\OperatorTok{=}\NormalTok{strlen}\OperatorTok{(}\NormalTok{A}\OperatorTok{),}\NormalTok{ m}\OperatorTok{=}\NormalTok{strlen}\OperatorTok{(}\NormalTok{B}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ prev}\OperatorTok{[}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{],}\NormalTok{ curr}\OperatorTok{[}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)}\NormalTok{ prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{]=}\NormalTok{j}\OperatorTok{;}
    \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ i}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{i}\OperatorTok{\textless{}=}\NormalTok{n}\OperatorTok{;}\NormalTok{i}\OperatorTok{++)\{}
\NormalTok{        curr}\OperatorTok{[}\DecValTok{0}\OperatorTok{]=}\NormalTok{i}\OperatorTok{;}
        \ControlFlowTok{for}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ j}\OperatorTok{=}\DecValTok{1}\OperatorTok{;}\NormalTok{j}\OperatorTok{\textless{}=}\NormalTok{m}\OperatorTok{;}\NormalTok{j}\OperatorTok{++)\{}
            \ControlFlowTok{if}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]==}\NormalTok{B}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ curr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]=}\NormalTok{prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ curr}\OperatorTok{[}\NormalTok{j}\OperatorTok{]=}\DecValTok{1}\OperatorTok{+}\NormalTok{MIN3}\OperatorTok{(}\NormalTok{prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{],}\NormalTok{ curr}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ prev}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
        \OperatorTok{\}}
\NormalTok{        memcpy}\OperatorTok{(}\NormalTok{prev}\OperatorTok{,}\NormalTok{curr}\OperatorTok{,}\KeywordTok{sizeof}\OperatorTok{(}\NormalTok{curr}\OperatorTok{));}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ prev}\OperatorTok{[}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Alignment}\label{alignment}

Alignment shows which characters correspond between two strings. Used in
bioinformatics (e.g., DNA sequence alignment).

Each operation has a cost:

\begin{itemize}
\tightlist
\item
  Match: 0
\item
  Mismatch: 1
\item
  Gap (insert/delete): 1 We fill the DP table similarly, but track
  choices to trace back alignment.
\end{itemize}

\subsubsection{Example Alignment}\label{example-alignment}

\begin{verbatim}
A: kitten-
B: sitt-ing
\end{verbatim}

We can visualize the transformation path by backtracking dp table.

\subsubsection{Scoring Alignment (General
Form)}\label{scoring-alignment-general-form}

We can generalize: \[
dp[i][j] = \min \begin{cases}
dp[i-1][j-1] + cost(A_i,B_j) \
dp[i-1][j] + gap \
dp[i][j-1] + gap
\end{cases}
\]

Used in Needleman-Wunsch (global alignment) and Smith-Waterman (local
alignment).

\subsubsection{5. Variants}\label{variants}

\begin{itemize}
\tightlist
\item
  Damerau-Levenshtein: adds transposition (swap adjacent chars)- Hamming
  Distance: only substitutions, equal-length strings- Weighted Distance:
  different operation costs- Local Alignment: only best matching
  substrings
\end{itemize}

\subsubsection{6. Summary}\label{summary-25}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3678}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2644}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0805}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2874}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Operations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Levenshtein & insert, delete, replace & (O(nm)) & Spell check, fuzzy
search \\
Hamming & substitution only & (O(n)) & DNA, binary strings \\
Alignment (Needleman-Wunsch) & with scoring & (O(nm)) &
Bioinformatics \\
Local Alignment (Smith-Waterman) & best substring & (O(nm)) & DNA
regions \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-64}

Edit distance transforms ``difference'' into data. It quantifies how far
apart two strings are, enabling flexible, robust comparisons.

\begin{quote}
``Similarity isn't perfection , it's the cost of becoming alike.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-64}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute edit distance between ``intention'' and ``execution''.
\item
  Trace back operations to show alignment.
\item
  Modify costs (insertion=2, deletion=1, substitution=2) and compare
  results.
\item
  Implement Hamming distance for equal-length strings.
\item
  Explore Smith-Waterman for longest common substring.
\end{enumerate}

Once you master edit distance, you can build tools that understand
typos, align genomes, and search imperfectly , perfectly.

\subsection{66. Compression (Huffman, Arithmetic, LZ77,
BWT)}\label{compression-huffman-arithmetic-lz77-bwt}

Compression algorithms let us encode information efficiently, reducing
storage or transmission cost without losing meaning. They turn patterns
and redundancy into shorter representations , the essence of data
compression.

This section introduces the key families of lossless compression
algorithms that form the backbone of formats like ZIP, PNG, and GZIP.

We'll explore:

\begin{itemize}
\tightlist
\item
  Huffman Coding (prefix-free variable-length codes)
\item
  Arithmetic Coding (fractional interval encoding)
\item
  LZ77 / LZ78 (dictionary-based methods)
\item
  Burrows-Wheeler Transform (BWT) (reversible sorting transform)
\end{itemize}

\subsubsection{1. Huffman Coding}\label{huffman-coding}

Huffman coding assigns shorter codes to frequent symbols, and longer
codes to rare ones , achieving optimal compression among prefix-free
codes.

\subsubsection{A. Algorithm}\label{a.-algorithm-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Count frequencies of all symbols.
\item
  Build a min-heap of nodes \texttt{(symbol,\ freq)}.
\item
  While heap size \textgreater{} 1:

  \begin{itemize}
  \tightlist
  \item
    Extract two smallest nodes \texttt{a}, \texttt{b}. - Create new node
    with \texttt{freq\ =\ a.freq\ +\ b.freq}. - Push back into heap.4.
    Assign \texttt{0} to left, \texttt{1} to right.
  \end{itemize}
\item
  Traverse tree , collect codes.
\end{enumerate}

Each symbol gets a unique prefix code (no code is prefix of another).

\subsubsection{B. Example}\label{b.-example-7}

Text: \texttt{ABRACADABRA}

Frequencies:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Symbol & Count \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 5 \\
B & 2 \\
R & 2 \\
C & 1 \\
D & 1 \\
\end{longtable}

Building tree gives codes like:

\begin{verbatim}
A: 0  
B: 101  
R: 100  
C: 1110  
D: 1111
\end{verbatim}

Encoded text: \texttt{0\ 101\ 100\ 0\ 1110\ 0\ 1111\ 0\ 101\ 100\ 0}
Compression achieved!

Tiny Code (C, Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{char}\NormalTok{ ch}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ freq}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{left}\OperatorTok{,} \OperatorTok{*}\NormalTok{right}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Use a min-heap (priority queue) to build the tree. Traverse recursively
to print codewords.

Complexity: (O\(n \log n\))

\subsubsection{2. Arithmetic Coding}\label{arithmetic-coding}

Instead of mapping symbols to bit strings, arithmetic coding maps the
entire message to a single number in {[}0,1).

We start with interval ({[}0,1)), and iteratively narrow it based on
symbol probabilities.

\subsubsection{Example}\label{example-8}

Symbols: \{A: 0.5, B: 0.3, C: 0.2\} Message: \texttt{ABC}

Intervals:

\begin{verbatim}
Start: [0, 1)
A → [0, 0.5)
B → [0.25, 0.4)
C → [0.34, 0.37)
\end{verbatim}

Final code = any number in {[}0.34, 0.37) (e.g.~0.35)

Decoding reverses this process.

Advantage: achieves near-optimal entropy compression. Used in: JPEG2000,
H.264

Time Complexity: ( O(n) )

\subsubsection{3. LZ77 (Sliding Window
Compression)}\label{lz77-sliding-window-compression}

LZ77 replaces repeated substrings with back-references
\texttt{(offset,\ length,\ next\_char)} pointing into a sliding window.

\subsubsection{Example}\label{example-9}

Text: \texttt{abcabcabcx}

Window slides; when \texttt{abc} repeats:

\begin{verbatim}
(0,0,'a'), (0,0,'b'), (0,0,'c'),
(3,3,'x')  // "abc" repeats from 3 chars back
\end{verbatim}

So sequence is compressed as references to earlier substrings.

Used in: DEFLATE (ZIP, GZIP), PNG

Time: ( O(n) ), Space: proportional to window size.

\subsubsection{Tiny Code (Conceptual)}\label{tiny-code-conceptual}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Token }\OperatorTok{\{} \DataTypeTok{int}\NormalTok{ offset}\OperatorTok{,}\NormalTok{ length}\OperatorTok{;} \DataTypeTok{char}\NormalTok{ next}\OperatorTok{;} \OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Search previous window for longest match before emitting token.

\subsubsection{4. LZ78 (Dictionary-Based)}\label{lz78-dictionary-based}

Instead of sliding window, LZ78 builds an explicit dictionary of
substrings.

Algorithm:

\begin{itemize}
\tightlist
\item
  Start with empty dictionary.- Read input, find longest prefix in
  dictionary.- Output \texttt{(index,\ next\_char)} and insert new
  entry. Example:
\end{itemize}

\begin{verbatim}
Input: ABAABABAABAB
Output: (0,A), (0,B), (1,B), (2,A), (4,A), (3,B)
\end{verbatim}

Used in: LZW (GIF, TIFF)

\subsubsection{5. Burrows-Wheeler Transform
(BWT)}\label{burrows-wheeler-transform-bwt}

BWT is not compression itself , it permutes text to cluster similar
characters, making it more compressible by run-length or Huffman coding.

\subsubsection{Steps}\label{steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate all rotations of string.
\item
  Sort them lexicographically.
\item
  Take last column as output.
\end{enumerate}

Example: \texttt{banana\$}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Rotations & Sorted \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
banana\$ & \(banana |
| anana\)b \\
a\(banan   | na\)bana & \\
\(banana   | nana\)ba & \\
\end{longtable}

Last column: \texttt{annb\$aa} BWT(``banana\(") = "annb\)aa''

Reversible with index of original row.

Used in: bzip2, FM-index (bioinformatics)

\subsubsection{6. Summary}\label{summary-26}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1408}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3944}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1831}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2817}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Huffman & Variable-length prefix codes & (O\(n \log n\)) & General
compression \\
Arithmetic & Interval encoding & (O(n)) & Near-optimal entropy \\
LZ77 & Sliding window matches & (O(n)) & ZIP, PNG \\
LZ78 & Dictionary building & (O(n)) & GIF, TIFF \\
BWT & Permute for clustering & (O\(n \log n\)) & bzip2 \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-65}

Compression algorithms reveal structure in data , they exploit patterns
that humans can't see. They're also a window into information theory,
showing how close we can get to the entropy limit.

\begin{quote}
``To compress is to understand , every bit saved is a pattern found.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-65}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a Huffman tree for \texttt{MISSISSIPPI}.
\item
  Implement a simple LZ77 encoder for repeating patterns.
\item
  Apply BWT and observe clustering of symbols.
\item
  Compare Huffman and Arithmetic outputs on same input.
\item
  Explore DEFLATE format combining LZ77 + Huffman.
\end{enumerate}

Understanding compression means learning to see redundancy , the key to
efficient storage, transmission, and understanding itself.

\subsection{67. Cryptographic Hashes and
Checksums}\label{cryptographic-hashes-and-checksums}

In algorithms, hashing helps us map data to fixed-size values. But when
used for security and verification, hashing becomes a cryptographic
tool. This section explores cryptographic hashes and checksums ,
algorithms that verify integrity, detect corruption, and secure data.

We'll look at:

\begin{itemize}
\tightlist
\item
  Simple checksums (parity, CRC)- Cryptographic hash functions (MD5, SHA
  family, BLAKE3)- Properties like collision resistance and preimage
  resistance- Practical uses in verification, signing, and storage
\end{itemize}

\subsubsection{1. Checksums}\label{checksums}

Checksums are lightweight methods to detect accidental errors in data
(not secure against attackers). They're used in filesystems, networking,
and storage to verify integrity.

\subsubsection{A. Parity Bit}\label{a.-parity-bit}

Adds one bit to make total 1s even or odd. Used in memory or
communication to detect single-bit errors.

Example: Data = \texttt{1011} → has three 1s. Add parity bit \texttt{1}
to make total 4 (even parity).

Limitation: Only detects odd number of bit errors.

\subsubsection{B. Modular Sum (Simple
Checksum)}\label{b.-modular-sum-simple-checksum}

Sum all bytes (mod 256 or 65536).

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{uint8\_t}\NormalTok{ checksum}\OperatorTok{(}\DataTypeTok{uint8\_t} \OperatorTok{*}\NormalTok{data}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{uint32\_t}\NormalTok{ sum }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ sum }\OperatorTok{+=}\NormalTok{ data}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \ControlFlowTok{return} \OperatorTok{(}\DataTypeTok{uint8\_t}\OperatorTok{)(}\NormalTok{sum }\OperatorTok{\%} \DecValTok{256}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use: Simple file or packet validation.

\subsubsection{C. CRC (Cyclic Redundancy
Check)}\label{c.-crc-cyclic-redundancy-check}

CRCs treat bits as coefficients of a polynomial. Divide by a generator
polynomial, remainder = CRC code.

Used in Ethernet, ZIP, and PNG.

Example: CRC-32, CRC-16.

Fast hardware and table-driven implementations available.

Key Property:

\begin{itemize}
\tightlist
\item
  Detects most burst errors- Not cryptographically secure
\end{itemize}

\subsubsection{2. Cryptographic Hash
Functions}\label{cryptographic-hash-functions}

A cryptographic hash function ( h(x) ) maps any input to a fixed-size
output such that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Deterministic: same input → same output
\item
  Fast computation
\item
  Preimage resistance: hard to find ( x ) given ( h(x) )
\item
  Second-preimage resistance: hard to find \(x' \neq x\) with ( h(x') =
  h(x) )
\item
  Collision resistance: hard to find any two distinct inputs with same
  hash
\end{enumerate}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Output (bits) & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MD5 & 128 & Broken (collisions found) \\
SHA-1 & 160 & Deprecated \\
SHA-256 & 256 & Standard (SHA-2 family) \\
SHA-3 & 256 & Keccak-based sponge \\
BLAKE3 & 256 & Fast, parallel, modern \\
\end{longtable}

\subsubsection{Example}\label{example-10}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h("hello") = 2cf24dba5fb0a... (SHA{-}256)}
\end{Highlighting}
\end{Shaded}

Change one letter, hash changes completely (avalanche effect):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h("Hello") = 185f8db32271f... }
\end{Highlighting}
\end{Shaded}

Even small changes → big differences.

\subsubsection{Tiny Code (C, using
pseudo-interface)}\label{tiny-code-c-using-pseudo-interface}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}openssl/sha.h\textgreater{}}

\DataTypeTok{unsigned} \DataTypeTok{char}\NormalTok{ hash}\OperatorTok{[}\NormalTok{SHA256\_DIGEST\_LENGTH}\OperatorTok{];}
\NormalTok{SHA256}\OperatorTok{((}\DataTypeTok{unsigned} \DataTypeTok{char}\OperatorTok{*)}\StringTok{"hello"}\OperatorTok{,} \DecValTok{5}\OperatorTok{,}\NormalTok{ hash}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Print hash as hex string to verify.

\subsubsection{3. Applications}\label{applications-11}

\begin{itemize}
\tightlist
\item
  Data integrity: verify files (e.g., SHA256SUM)- Digital signatures:
  sign hashes, not raw data- Password storage: store hashes, not
  plaintext- Deduplication: detect identical files via hashes-
  Blockchain: link blocks with hash pointers- Git: stores objects via
  SHA-1 identifiers
\end{itemize}

\subsubsection{4. Hash Collisions}\label{hash-collisions}

A collision occurs when ( h(x) = h(y) ) for \(x \neq y\). Good
cryptographic hashes make this computationally infeasible.

By the birthday paradox, collisions appear after \(2^{n/2}\) operations
for an ( n )-bit hash.

Hence, SHA-256 → \textasciitilde{}\(2^{128}\) effort to collide.

\subsubsection{5. Checksums vs Hashes}\label{checksums-vs-hashes}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Checksum & Cryptographic Hash \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Goal & Detect errors & Ensure integrity and authenticity \\
Resistance & Low & High \\
Output Size & Small & 128-512 bits \\
Performance & Very fast & Fast but secure \\
Example & CRC32 & SHA-256, BLAKE3 \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-66}

Checksums catch accidental corruption, hashes protect against malicious
tampering. Together, they guard the trustworthiness of data , the
foundation of secure systems.

\begin{quote}
``Integrity is invisible , until it's lost.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-66}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute CRC32 of a text file, flip one bit, and recompute.
\item
  Use \texttt{sha256sum} to verify file integrity.
\item
  Experiment: change one character in input, observe avalanche.
\item
  Compare performance of SHA-256 and BLAKE3.
\item
  Research how Git uses SHA-1 to track versions.
\end{enumerate}

By learning hashes, you master one of the pillars of security , proof
that something hasn't changed, even when everything else does.

\subsection{68. Approximate and Streaming
Matching}\label{approximate-and-streaming-matching}

Exact string matching (like KMP or Boyer-Moore) demands perfect
alignment between pattern and text. But what if errors, noise, or
incomplete data exist?

That's where approximate matching and streaming matching come in. These
algorithms let you search efficiently even when:

\begin{itemize}
\tightlist
\item
  The pattern might contain typos or mutations- The text arrives in a
  stream (too large to store entirely)- You want to match ``close
  enough,'' not ``exactly'' They're crucial in search engines, spell
  checkers, bioinformatics, and real-time monitoring systems.
\end{itemize}

\subsubsection{1. Approximate String
Matching}\label{approximate-string-matching}

Approximate string matching finds occurrences of a pattern in a text
allowing mismatches, insertions, or deletions , often measured by edit
distance.

\subsubsection{A. Dynamic Programming (Levenshtein
Distance)}\label{a.-dynamic-programming-levenshtein-distance}

Given two strings \(A\) and \(B\), the edit distance is the minimum
number of insertions, deletions, or substitutions to turn \(A\) into
\(B\).

We can build a DP table \(dp[i][j]\):

\begin{itemize}
\tightlist
\item
  \(dp[i][0] = i\) (delete all characters)\\
\item
  \(dp[0][j] = j\) (insert all characters)\\
\item
  If \(A[i] = B[j]\), then \(dp[i][j] = dp[i-1][j-1]\)\\
\item
  Else \(dp[i][j] = 1 + \min(dp[i-1][j],\, dp[i][j-1],\, dp[i-1][j-1])\)
\end{itemize}

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ edit\_distance}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{a}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{a}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{b}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{a}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ b}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{];}
            \ControlFlowTok{else}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{fmin}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{],}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]),}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]);}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This computes Levenshtein distance in ( O(nm) ) time.

\subsubsection{B. Bitap Algorithm
(Shift-Or)}\label{b.-bitap-algorithm-shift-or}

When pattern length is small, Bitap uses bitmasks to track mismatches.
It efficiently supports up to k errors and runs in near linear time for
small patterns.

Used in grep -E, ag, and fuzzy searching systems.

Idea: Maintain a bitmask where 1 = mismatch, 0 = match. Shift and OR
masks as we scan text.

\subsubsection{C. k-Approximate
Matching}\label{c.-k-approximate-matching}

Find all positions where edit distance ≤ k. Efficient for small ( k )
(e.g., spell correction: edit distance ≤ 2).

Applications:

\begin{itemize}
\tightlist
\item
  Typo-tolerant search- DNA sequence matching- Autocomplete systems
\end{itemize}

\subsubsection{2. Streaming Matching}\label{streaming-matching}

In streaming, the text is too large or unbounded, so we must process
input online. We can't store everything , only summaries or sketches.

\subsubsection{A. Rolling Hash (Rabin-Karp
style)}\label{a.-rolling-hash-rabin-karp-style}

Maintains a moving hash of recent characters. When new character
arrives, update hash in ( O(1) ). Compare with pattern's hash for
possible match.

Good for sliding window matching.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hash }\OperatorTok{=} \OperatorTok{(}\NormalTok{base }\OperatorTok{*} \OperatorTok{(}\NormalTok{hash }\OperatorTok{{-}}\NormalTok{ old\_char }\OperatorTok{*}\NormalTok{ base}\OperatorTok{\^{}(}\NormalTok{m}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{))} \OperatorTok{+}\NormalTok{ new\_char}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ mod}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Fingerprinting (Karp-Rabin
Fingerprint)}\label{b.-fingerprinting-karp-rabin-fingerprint}

A compact representation of a substring. If fingerprints match, do full
verification (avoid false positives). Used in streaming algorithms and
chunking.

\subsubsection{C. Sketch-Based Matching}\label{c.-sketch-based-matching}

Algorithms like Count-Min Sketch or SimHash build summaries of large
data. They help approximate similarity between streams.

Applications:

\begin{itemize}
\tightlist
\item
  Near-duplicate detection (SimHash in Google)- Network anomaly
  detection- Real-time log matching
\end{itemize}

\subsubsection{3. Approximate Matching in
Practice}\label{approximate-matching-in-practice}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3492}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Domain
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Spell Checking & ``recieve'' → ``receive'' & Edit Distance \\
DNA Alignment & Find similar sequences & Smith-Waterman \\
Autocomplete & Suggest close matches & Fuzzy Search \\
Logs \& Streams & Online pattern alerts & Streaming Bitap, Karp-Rabin \\
Near-Duplicate & Detect similar text & SimHash, MinHash \\
\end{longtable}

\subsubsection{4. Complexity}\label{complexity-4}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Levenshtein DP & (O(nm)) & (O(nm)) & Exact distance \\
Bitap & (O(n)) & (O(1)) & For small patterns \\
Rolling Hash & (O(n)) & (O(1)) & Probabilistic match \\
SimHash & (O(n)) & (O(1)) & Approximate similarity \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-67}

Real-world data is messy , typos, noise, loss, corruption. Approximate
matching lets you build algorithms that forgive errors and adapt to
streams. It powers everything from search engines to genomics, ensuring
your algorithms stay practical in an imperfect world.

\subsubsection{Try It Yourself}\label{try-it-yourself-67}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute edit distance between ``kitten'' and ``sitting.''
\item
  Implement fuzzy search that returns words with ≤1 typo.
\item
  Use rolling hash to detect repeated substrings in a stream.
\item
  Experiment with SimHash to compare document similarity.
\item
  Observe how small typos affect fuzzy vs exact search.
\end{enumerate}

\subsection{69. Bioinformatics Alignment (Needleman-Wunsch,
Smith-Waterman)}\label{bioinformatics-alignment-needleman-wunsch-smith-waterman}

In bioinformatics, comparing DNA, RNA, or protein sequences is like
comparing strings , but with biological meaning. Each sequence is made
of letters (A, C, G, T for DNA; amino acids for proteins). To analyze
similarity, scientists use sequence alignment algorithms that handle
insertions, deletions, and substitutions.

Two fundamental methods dominate:

\begin{itemize}
\tightlist
\item
  Needleman-Wunsch for global alignment- Smith-Waterman for local
  alignment
\end{itemize}

\subsubsection{1. Sequence Alignment}\label{sequence-alignment}

Alignment means placing two sequences side by side to maximize matches
and minimize gaps or mismatches.

For example:

\begin{verbatim}
A C G T G A
| | |   | |
A C G A G A
\end{verbatim}

Here, mismatches and gaps may occur, but the alignment finds the best
possible match under a scoring system.

\subsubsection{Scoring System}\label{scoring-system}

Alignment uses scores instead of just counts. Typical scheme:

\begin{itemize}
\tightlist
\item
  Match: +1- Mismatch: -1- Gap (insertion or deletion): -2 You can
  adjust weights depending on the biological context.
\end{itemize}

\subsubsection{2. Needleman-Wunsch (Global
Alignment)}\label{needleman-wunsch-global-alignment}

Used when you want to align entire sequences , from start to end.

It uses dynamic programming to build a score table ( dp{[}i{]}{[}j{]} ),
where each cell represents the best score for aligning prefixes (
A{[}1..i{]} ) and ( B{[}1..j{]} ).

Recurrence:

\[dp[i][j] = \max
\begin{cases}
dp[i-1][j-1] + \text{score}(A_i, B_j) \
dp[i-1][j] + \text{gap penalty} \
dp[i][j-1] + \text{gap penalty}
\end{cases}\]

Base cases: \[
dp[0][j] = j \times \text{gap penalty}, \quad dp[i][0] = i \times \text{gap penalty}
\]

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ max3}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ a}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ b}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textgreater{}}\NormalTok{ b }\OperatorTok{?} \OperatorTok{(}\NormalTok{a }\OperatorTok{\textgreater{}}\NormalTok{ c }\OperatorTok{?}\NormalTok{ a }\OperatorTok{:}\NormalTok{ c}\OperatorTok{)} \OperatorTok{:} \OperatorTok{(}\NormalTok{b }\OperatorTok{\textgreater{}}\NormalTok{ c }\OperatorTok{?}\NormalTok{ b }\OperatorTok{:}\NormalTok{ c}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ needleman\_wunsch}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{A}\OperatorTok{,} \DataTypeTok{char} \OperatorTok{*}\NormalTok{B}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ match}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ mismatch}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ gap}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ n }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{A}\OperatorTok{),}\NormalTok{ m }\OperatorTok{=}\NormalTok{ strlen}\OperatorTok{(}\NormalTok{B}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{+}\DecValTok{1}\OperatorTok{][}\NormalTok{m}\OperatorTok{+}\DecValTok{1}\OperatorTok{];}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\DecValTok{0}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i }\OperatorTok{*}\NormalTok{ gap}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}\NormalTok{ dp}\OperatorTok{[}\DecValTok{0}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ j }\OperatorTok{*}\NormalTok{ gap}\OperatorTok{;}

    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}=}\NormalTok{ m}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{int}\NormalTok{ s }\OperatorTok{=} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{==}\NormalTok{ B}\OperatorTok{[}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{])} \OperatorTok{?}\NormalTok{ match }\OperatorTok{:}\NormalTok{ mismatch}\OperatorTok{;}
\NormalTok{            dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{=}\NormalTok{ max3}\OperatorTok{(}\NormalTok{dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ s}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{+}\NormalTok{ gap}\OperatorTok{,}\NormalTok{ dp}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{j}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{]} \OperatorTok{+}\NormalTok{ gap}\OperatorTok{);}
        \OperatorTok{\}}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ dp}\OperatorTok{[}\NormalTok{n}\OperatorTok{][}\NormalTok{m}\OperatorTok{];}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Example:

\begin{verbatim}
A = "ACGT"
B = "AGT"
match = +1, mismatch = -1, gap = -2
\end{verbatim}

Produces optimal alignment:

\begin{verbatim}
A C G T
A - G T
\end{verbatim}

\subsubsection{3. Smith-Waterman (Local
Alignment)}\label{smith-waterman-local-alignment}

Used when sequences may have similar segments, not full-length
similarity. Perfect for finding motifs or conserved regions.

Recurrence is similar, but with local reset to zero:

\[dp[i][j] = \max
\begin{cases}
0, \
dp[i-1][j-1] + \text{score}(A_i, B_j), \
dp[i-1][j] + \text{gap penalty}, \
dp[i][j-1] + \text{gap penalty}
\end{cases}\]

Final answer = maximum value in the table (not necessarily at the end).

It finds the best substring alignment.

\subsubsection{Example}\label{example-11}

\begin{verbatim}
A = "ACGTTG"
B = "CGT"
\end{verbatim}

Smith-Waterman finds best local match:

\begin{verbatim}
A C G T
  | | |
  C G T
\end{verbatim}

Unlike global alignment, extra prefixes or suffixes are ignored.

\subsubsection{4. Variants and
Extensions}\label{variants-and-extensions}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6429}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Needleman-Wunsch & Global & Aligns full sequences \\
Smith-Waterman & Local & Finds similar subsequences \\
Gotoh Algorithm & Global & Uses affine gap penalty (opening +
extension) \\
BLAST & Heuristic & Speeds up search for large databases \\
\end{longtable}

BLAST (Basic Local Alignment Search Tool) uses word seeds and extension,
trading exactness for speed , essential for large genome databases.

\subsubsection{5. Complexity}\label{complexity-5}

Both Needleman-Wunsch and Smith-Waterman run in:

\begin{itemize}
\tightlist
\item
  Time: ( O(nm) )- Space: ( O(nm) ) But optimized versions use banded DP
  or Hirschberg's algorithm to cut memory to ( O(n + m) ).
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-68}

Sequence alignment bridges computer science and biology. It's how we:

\begin{itemize}
\tightlist
\item
  Compare species- Identify genes- Detect mutations- Trace ancestry-
  Build phylogenetic trees The idea of ``minimum edit cost'' echoes
  everywhere , from spell checkers to DNA analysis.
\end{itemize}

\begin{quote}
``In biology, similarity is a story. Alignment is how we read it.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-68}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Needleman-Wunsch for short DNA sequences.
\item
  Change gap penalties , see how alignment shifts.
\item
  Compare outputs from global and local alignment.
\item
  Use real sequences from GenBank to test.
\item
  Explore BLAST online and compare to exact alignment results.
\end{enumerate}

\subsection{70. Text Indexing and Search
Structures}\label{text-indexing-and-search-structures}

When text becomes large , think books, databases, or the entire web ,
searching naively for patterns (O(nm)) is far too slow. We need indexing
structures that let us search fast, often in O(m) or O(log n) time.

This section covers the backbone of search engines and string
processing:

\begin{itemize}
\tightlist
\item
  Suffix Arrays- Suffix Trees- Inverted Indexes- Tries and Prefix Trees-
  Compressed Indexes like FM-Index (Burrows-Wheeler)
\end{itemize}

\subsubsection{1. Why Index?}\label{why-index}

A text index is like a table of contents , it doesn't store the book,
but lets you jump straight to what you want.

If you have a text of length ( n ), and you'll run many queries, it's
worth building an index (even if it costs ( O\(n \log n\) ) to build).

Without indexing: each query takes ( O(nm) ). With indexing: each query
can take ( O(m) ) or less.

\subsubsection{2. Suffix Array}\label{suffix-array}

A suffix array is a sorted array of all suffixes of a string.

For text \texttt{"banana"}, suffixes are:

\begin{verbatim}
0: banana  
1: anana  
2: nana  
3: ana  
4: na  
5: a
\end{verbatim}

Sorted lexicographically:

\begin{verbatim}
5: a  
3: ana  
1: anana  
0: banana  
4: na  
2: nana
\end{verbatim}

Suffix Array = \texttt{{[}5,\ 3,\ 1,\ 0,\ 4,\ 2{]}}

To search, binary search over the suffix array using your pattern , (
O\(m \log n\) ).

Tiny Code (C) (naive construction)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ cmp}\OperatorTok{(}\DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{a}\OperatorTok{,} \DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{b}\OperatorTok{,} \DataTypeTok{void} \OperatorTok{*}\NormalTok{txt}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \OperatorTok{*(}\DataTypeTok{int}\OperatorTok{*)}\NormalTok{a}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \OperatorTok{*(}\DataTypeTok{int}\OperatorTok{*)}\NormalTok{b}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ strcmp}\OperatorTok{((}\DataTypeTok{char}\OperatorTok{*)}\NormalTok{txt }\OperatorTok{+}\NormalTok{ i}\OperatorTok{,} \OperatorTok{(}\DataTypeTok{char}\OperatorTok{*)}\NormalTok{txt }\OperatorTok{+}\NormalTok{ j}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ build\_suffix\_array}\OperatorTok{(}\DataTypeTok{char} \OperatorTok{*}\NormalTok{txt}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ sa}\OperatorTok{[])} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ sa}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ i}\OperatorTok{;}
\NormalTok{    qsort\_r}\OperatorTok{(}\NormalTok{sa}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\DataTypeTok{int}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{,}\NormalTok{ txt}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Modern methods like prefix doubling or radix sort build it in (
O\(n \log n\) ).

Applications:

\begin{itemize}
\tightlist
\item
  Fast substring search- Longest common prefix (LCP) array- Pattern
  matching in DNA sequences- Plagiarism detection
\end{itemize}

\subsubsection{3. Suffix Tree}\label{suffix-tree-1}

A suffix tree is a compressed trie of all suffixes , each edge stores
multiple characters.

For \texttt{"banana"}, you'd build a tree where each leaf corresponds to
a suffix index.

Advantages:

\begin{itemize}
\tightlist
\item
  Pattern search in ( O(m) )- Space ( O(n) ) (with compression) Built
  using Ukkonen's algorithm in ( O(n) ).
\end{itemize}

Use Suffix Array + LCP as a space-efficient alternative.

\subsubsection{4. FM-Index (Burrows-Wheeler
Transform)}\label{fm-index-burrows-wheeler-transform}

Used in compressed full-text search (e.g., Bowtie, BWA). Combines:

\begin{itemize}
\tightlist
\item
  Burrows-Wheeler Transform (BWT)- Rank/select bitvectors Supports
  pattern search in O(m) time with very low memory.
\end{itemize}

Idea: transform text so similar substrings cluster together, enabling
compression and backward search.

Applications:

\begin{itemize}
\tightlist
\item
  DNA alignment- Large text archives- Memory-constrained search
\end{itemize}

\subsubsection{5. Inverted Index}\label{inverted-index}

Used in search engines. Instead of suffixes, it indexes words.

For example, text corpus:

\begin{verbatim}
doc1: quick brown fox  
doc2: quick red fox
\end{verbatim}

Inverted index:

\begin{verbatim}
"quick" → [doc1, doc2]
"brown" → [doc1]
"red"   → [doc2]
"fox"   → [doc1, doc2]
\end{verbatim}

Now searching ``quick fox'' becomes set intersection of lists.

Used with ranking functions (TF-IDF, BM25).

\subsubsection{6. Tries and Prefix Trees}\label{tries-and-prefix-trees}

A trie stores strings character by character. Each node = prefix.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{child}\OperatorTok{[}\DecValTok{26}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ end}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Perfect for:

\begin{itemize}
\tightlist
\item
  Autocomplete- Prefix search- Spell checkers Search: O(m), where m =
  pattern length.
\end{itemize}

Compressed tries (Patricia trees) reduce space.

\subsubsection{7. Comparing Structures}\label{comparing-structures}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Structure & Search Time & Build Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trie & O(m) & O(n) & High & Prefix queries \\
Suffix Array & O(m log n) & O(n log n) & Medium & Sorted suffixes \\
Suffix Tree & O(m) & O(n) & High & Rich structure \\
FM-Index & O(m) & O(n) & Low & Compressed \\
Inverted Index & O(k) & O(N) & Medium & Word-based \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-69}

Text indexing is the backbone of search engines, DNA alignment, and
autocomplete systems. Without it, Google searches, code lookups, or
genome scans would take minutes, not milliseconds.

\begin{quote}
``Indexing turns oceans of text into navigable maps.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-69}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a suffix array for ``banana'' and perform binary search for
  ``ana.''
\item
  Construct a trie for a dictionary and query prefixes.
\item
  Write a simple inverted index for a few documents.
\item
  Compare memory usage of suffix tree vs suffix array.
\item
  Experiment with FM-index using an online demo (like BWT explorer).
\end{enumerate}

\section{Chapter 8. Geometry, Graphics, and Spatial
Algorithms}\label{chapter-8.-geometry-graphics-and-spatial-algorithms-1}

\subsection{71. Convex Hull (Graham, Andrew,
Chan)}\label{convex-hull-graham-andrew-chan}

In computational geometry, the convex hull of a set of points is the
smallest convex polygon that contains all the points. Intuitively,
imagine stretching a rubber band around a set of nails on a board , the
shape the band takes is the convex hull.

Convex hulls are foundational for many geometric algorithms, like
closest pair, Voronoi diagrams, and collision detection.

In this section, we'll explore three classical algorithms:

\begin{itemize}
\tightlist
\item
  Graham Scan - elegant and simple (O(n log n))- Andrew's Monotone Chain
  - robust and practical (O(n log n))- Chan's Algorithm - advanced and
  optimal (O(n log h), where h = number of hull points)
\end{itemize}

\subsubsection{1. Definition}\label{definition-1}

Given a set of points \(P = {p_1, p_2, ..., p_n}\), the convex hull, (
\text{CH}(P) ), is the smallest convex polygon enclosing all points.

Formally: \[
\text{CH}(P) = \bigcap {C \subseteq \mathbb{R}^2 \mid C \text{ is convex and } P \subseteq C }
\]

A polygon is convex if every line segment between two points of the
polygon lies entirely inside it.

\subsubsection{2. Orientation Test}\label{orientation-test}

All convex hull algorithms rely on an orientation test using cross
product: Given three points ( a, b, c ):

\[
\text{cross}(a,b,c) = (b_x - a_x)(c_y - a_y) - (b_y - a_y)(c_x - a_x)
\]

\begin{itemize}
\tightlist
\item
  \texttt{\textgreater{}\ 0} → counter-clockwise turn-
  \texttt{\textless{}\ 0} → clockwise turn- \texttt{=\ 0} → collinear
\end{itemize}

\subsubsection{3. Graham Scan}\label{graham-scan}

One of the earliest convex hull algorithms.

Idea:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Pick the lowest point (and leftmost if tie).
\item
  Sort all other points by polar angle with respect to it.
\item
  Traverse points and maintain a stack:

  \begin{itemize}
  \tightlist
  \item
    Add point - While last three points make a right turn, pop middle
    one4. Remaining points form convex hull in CCW order.
  \end{itemize}
\end{enumerate}

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\DataTypeTok{double}\NormalTok{ cross}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ cmp}\OperatorTok{(}\DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{p1}\OperatorTok{,} \DataTypeTok{const} \DataTypeTok{void} \OperatorTok{*}\NormalTok{p2}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Point }\OperatorTok{*}\NormalTok{a }\OperatorTok{=} \OperatorTok{(}\NormalTok{Point}\OperatorTok{*)}\NormalTok{p1}\OperatorTok{,} \OperatorTok{*}\NormalTok{b }\OperatorTok{=} \OperatorTok{(}\NormalTok{Point}\OperatorTok{*)}\NormalTok{p2}\OperatorTok{;}
    \CommentTok{// Compare by polar angle or distance}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{a}\OperatorTok{{-}\textgreater{}}\NormalTok{y }\OperatorTok{!=}\NormalTok{ b}\OperatorTok{{-}\textgreater{}}\NormalTok{y}\OperatorTok{)} \OperatorTok{?} \OperatorTok{(}\NormalTok{a}\OperatorTok{{-}\textgreater{}}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{{-}\textgreater{}}\NormalTok{y}\OperatorTok{)} \OperatorTok{:} \OperatorTok{(}\NormalTok{a}\OperatorTok{{-}\textgreater{}}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{{-}\textgreater{}}\NormalTok{x}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ graham\_scan}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,}\NormalTok{ Point hull}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    qsort}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Point}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ top }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{top }\OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&}\NormalTok{ cross}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{top}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{[}\NormalTok{top}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textless{}=} \DecValTok{0}\OperatorTok{)}
\NormalTok{            top}\OperatorTok{{-}{-};}
\NormalTok{        hull}\OperatorTok{[}\NormalTok{top}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ top}\OperatorTok{;} \CommentTok{// number of hull points}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Complexity:

\begin{itemize}
\tightlist
\item
  Sorting: ( O\(n \log n\) )- Scanning: ( O(n) ) → Total: O(n log n)
\end{itemize}

\subsubsection{Example}\label{example-12}

Input:

\begin{verbatim}
(0, 0), (1, 1), (2, 2), (2, 0), (0, 2)
\end{verbatim}

Hull (CCW):

\begin{verbatim}
(0,0) → (2,0) → (2,2) → (0,2)
\end{verbatim}

\subsubsection{4. Andrew's Monotone Chain}\label{andrews-monotone-chain}

Simpler and more robust for floating-point coordinates. Builds lower and
upper hulls separately.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points lexicographically (x, then y).
\item
  Build lower hull (left-to-right)
\item
  Build upper hull (right-to-left)
\item
  Concatenate (excluding duplicates)
\end{enumerate}

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{int}\NormalTok{ monotone\_chain}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,}\NormalTok{ Point hull}\OperatorTok{[])} \OperatorTok{\{}
\NormalTok{    qsort}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ n}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Point}\OperatorTok{),}\NormalTok{ cmp}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ k }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \CommentTok{// Lower hull}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}=} \DecValTok{2} \OperatorTok{\&\&}\NormalTok{ cross}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textless{}=} \DecValTok{0}\OperatorTok{)}\NormalTok{ k}\OperatorTok{{-}{-};}
\NormalTok{        hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \CommentTok{// Upper hull}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=}\NormalTok{ n}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{,}\NormalTok{ t }\OperatorTok{=}\NormalTok{ k}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textgreater{}=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{{-}{-})} \OperatorTok{\{}
        \ControlFlowTok{while} \OperatorTok{(}\NormalTok{k }\OperatorTok{\textgreater{}=}\NormalTok{ t }\OperatorTok{\&\&}\NormalTok{ cross}\OperatorTok{(}\NormalTok{hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{2}\OperatorTok{],}\NormalTok{ hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{\textless{}=} \DecValTok{0}\OperatorTok{)}\NormalTok{ k}\OperatorTok{{-}{-};}
\NormalTok{        hull}\OperatorTok{[}\NormalTok{k}\OperatorTok{++]} \OperatorTok{=}\NormalTok{ pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ k}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;} \CommentTok{// last point == first point}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log n\) )

\subsubsection{5. Chan's Algorithm}\label{chans-algorithm}

When \(h \ll n\), Chan's method achieves ( O\(n \log h\) ):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Partition points into groups of size ( m ).
\item
  Compute hulls for each group (Graham).
\item
  Merge hulls with Jarvis March (gift wrapping).
\item
  Choose ( m ) cleverly (\(m = 2^k\)) to ensure ( O\(n \log h\) ).
\end{enumerate}

Used in: large-scale geometric processing.

\subsubsection{6. Applications}\label{applications-12}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Computer Graphics & Shape boundary, hitboxes \\
GIS / Mapping & Region boundaries \\
Robotics & Obstacle envelopes \\
Clustering & Outlier detection \\
Data Analysis & Minimal bounding shape \\
\end{longtable}

\subsubsection{7. Complexity Summary}\label{complexity-summary}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Graham Scan & ( O\(n \log n\) ) & ( O(n) ) & Simple, classic \\
Monotone Chain & ( O\(n \log n\) ) & ( O(n) ) & Stable, robust \\
Chan's Algorithm & ( O\(n \log h\) ) & ( O(n) ) & Best asymptotic \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-70}

Convex hulls are one of the cornerstones of computational geometry. They
teach sorting, cross products, and geometric reasoning , and form the
basis for many spatial algorithms.

\begin{quote}
``Every scattered set hides a simple shape. The convex hull is that
hidden simplicity.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-70}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Graham Scan for 10 random points.
\item
  Plot the points and verify the hull.
\item
  Compare results with Andrew's Monotone Chain.
\item
  Test with collinear and duplicate points.
\item
  Explore 3D convex hulls (QuickHull, Gift Wrapping) next.
\end{enumerate}

\subsection{72. Closest Pair and Segment
Intersection}\label{closest-pair-and-segment-intersection}

Geometric problems often ask: \emph{what's the shortest distance between
two points?} or \emph{do these segments cross?} These are classic
building blocks in computational geometry , essential for collision
detection, graphics, clustering, and path planning.

This section covers two foundational problems:

\begin{itemize}
\tightlist
\item
  Closest Pair of Points - find two points with minimum Euclidean
  distance- Segment Intersection - determine if (and where) two line
  segments intersect
\end{itemize}

\subsubsection{1. Closest Pair of
Points}\label{closest-pair-of-points-1}

Given ( n ) points in 2D, find a pair with the smallest distance. The
brute force solution is ( O\(n^2\) ), but using Divide and Conquer, we
can solve it in O(n log n).

\subsubsection{A. Divide and Conquer
Algorithm}\label{a.-divide-and-conquer-algorithm}

Idea:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points by x-coordinate.
\item
  Split into left and right halves.
\item
  Recursively find closest pairs in each half (distance = ( d )).
\item
  Merge step: check pairs across the split line within ( d ).
\end{enumerate}

In merge step, we only need to check at most 6 neighbors per point (by
geometric packing).

Tiny Code (C, Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}math.h\textgreater{}}
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\DataTypeTok{double}\NormalTok{ dist}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ dx }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ dy }\OperatorTok{=}\NormalTok{ a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{;}
    \ControlFlowTok{return}\NormalTok{ sqrt}\OperatorTok{(}\NormalTok{dx}\OperatorTok{*}\NormalTok{dx }\OperatorTok{+}\NormalTok{ dy}\OperatorTok{*}\NormalTok{dy}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{double}\NormalTok{ brute\_force}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ d }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
        \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)}
\NormalTok{            d }\OperatorTok{=}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{d}\OperatorTok{,}\NormalTok{ dist}\OperatorTok{(}\NormalTok{pts}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ pts}\OperatorTok{[}\NormalTok{j}\OperatorTok{]));}
    \ControlFlowTok{return}\NormalTok{ d}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Recursive divide and merge:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ closest\_pair}\OperatorTok{(}\NormalTok{Point pts}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textless{}=} \DecValTok{3}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ brute\_force}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{double}\NormalTok{ d }\OperatorTok{=}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{closest\_pair}\OperatorTok{(}\NormalTok{pts}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{),}
\NormalTok{                    closest\_pair}\OperatorTok{(}\NormalTok{pts }\OperatorTok{+}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ mid}\OperatorTok{));}
    \CommentTok{// merge step: check strip points within distance d}
    \CommentTok{// sort by y, check neighbors}
    \ControlFlowTok{return}\NormalTok{ d}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Time Complexity: ( O\(n \log n\) )

Example:

Points:

\begin{verbatim}
(2,3), (12,30), (40,50), (5,1), (12,10), (3,4)
\end{verbatim}

Closest pair: (2,3) and (3,4), distance = √2

\subsubsection{B. Sweep Line Variant}\label{b.-sweep-line-variant}

Another method uses a line sweep and a balanced tree to keep active
points. As you move from left to right, maintain a window of recent
points within ( d ).

Used in large-scale spatial systems.

\subsubsection{Applications}\label{applications-13}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Clustering & Find nearest neighbors \\
Robotics & Avoid collisions \\
GIS & Nearest city search \\
Networking & Sensor proximity \\
\end{longtable}

\subsubsection{2. Segment Intersection}\label{segment-intersection}

Given two segments ( AB ) and ( CD ), determine whether they intersect.
It's the core of geometry engines and vector graphics systems.

\subsubsection{A. Orientation Test}\label{a.-orientation-test}

We use the cross product (orientation) test again. Two segments ( AB )
and ( CD ) intersect if and only if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The segments straddle each other: \[
  \text{orient}(A, B, C) \neq \text{orient}(A, B, D)
  \]
\end{enumerate}

\[
\text{orient}(C, D, A) \neq \text{orient}(C, D, B)
\] 2. Special cases for collinear points (check bounding boxes).

Tiny Code (C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ cross}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)*(}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ a}\OperatorTok{.}\NormalTok{x}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ fmin}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{\textless{}=}\NormalTok{ c}\OperatorTok{.}\NormalTok{x }\OperatorTok{\&\&}\NormalTok{ c}\OperatorTok{.}\NormalTok{x }\OperatorTok{\textless{}=}\NormalTok{ fmax}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{\&\&}
\NormalTok{           fmin}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{\textless{}=}\NormalTok{ c}\OperatorTok{.}\NormalTok{y }\OperatorTok{\&\&}\NormalTok{ c}\OperatorTok{.}\NormalTok{y }\OperatorTok{\textless{}=}\NormalTok{ fmax}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{int}\NormalTok{ intersect}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{,}\NormalTok{ Point d}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ o1 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{);}
    \DataTypeTok{double}\NormalTok{ o2 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ d}\OperatorTok{);}
    \DataTypeTok{double}\NormalTok{ o3 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{ d}\OperatorTok{,}\NormalTok{ a}\OperatorTok{);}
    \DataTypeTok{double}\NormalTok{ o4 }\OperatorTok{=}\NormalTok{ cross}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{ d}\OperatorTok{,}\NormalTok{ b}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o1}\OperatorTok{*}\NormalTok{o2 }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ o3}\OperatorTok{*}\NormalTok{o4 }\OperatorTok{\textless{}} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;} \CommentTok{// general case}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o1 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{b}\OperatorTok{,}\NormalTok{c}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o2 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{a}\OperatorTok{,}\NormalTok{b}\OperatorTok{,}\NormalTok{d}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o3 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{d}\OperatorTok{,}\NormalTok{a}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{o4 }\OperatorTok{==} \DecValTok{0} \OperatorTok{\&\&}\NormalTok{ on\_segment}\OperatorTok{(}\NormalTok{c}\OperatorTok{,}\NormalTok{d}\OperatorTok{,}\NormalTok{b}\OperatorTok{))} \ControlFlowTok{return} \DecValTok{1}\OperatorTok{;}
    \ControlFlowTok{return} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{B. Line Sweep Algorithm
(Bentley-Ottmann)}\label{b.-line-sweep-algorithm-bentley-ottmann}

For multiple segments, check all intersections efficiently. Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort all endpoints by x-coordinate.
\item
  Sweep from left to right.
\item
  Maintain active set (balanced BST).
\item
  Check neighboring segments for intersections.
\end{enumerate}

Time complexity: \(O((n + k) \log n)\), where \(k\) is the number of
intersections.

Used in CAD, map rendering, and collision systems.

\subsubsection{3. Complexity Summary}\label{complexity-summary-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2899}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1884}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2899}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2319}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Naive
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Technique
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Closest Pair & \(O(n^2)\) & \(O(n \log n)\) & Divide \& Conquer \\
Segment Intersection & \(O(n^2)\) & \(O((n + k) \log n)\) & Sweep
Line \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-71}

Geometric algorithms like these teach how to reason spatially , blending
math, sorting, and logic. They power real-world systems where precision
matters: from self-driving cars to game engines.

\begin{quote}
``Every point has a neighbor; every path may cross another , geometry
finds the truth in space.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-71}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement the closest pair algorithm using divide and conquer.
\item
  Visualize all pairwise distances , see which pairs are minimal.
\item
  Test segment intersection on random pairs.
\item
  Modify for 3D line segments using vector cross products.
\item
  Try building a line sweep visualizer to catch intersections
  step-by-step.
\end{enumerate}

\subsection{73. Line Sweep and Plane Sweep
Algorithms}\label{line-sweep-and-plane-sweep-algorithms}

The sweep line (or plane sweep) technique is one of the most powerful
paradigms in computational geometry. It transforms complex spatial
problems into manageable one-dimensional events , by sweeping a line (or
plane) across the input and maintaining a dynamic set of active
elements.

This method underlies many geometric algorithms:

\begin{itemize}
\tightlist
\item
  Event sorting → handle things in order- Active set maintenance → track
  current structure- Updates and queries → respond as the sweep
  progresses Used for intersection detection, closest pair, rectangle
  union, computational geometry in graphics and GIS.
\end{itemize}

\subsubsection{1. The Core Idea}\label{the-core-idea-3}

Imagine a vertical line sweeping from left to right across the plane. At
each ``event'' (like a point or segment endpoint), we update the set of
objects the line currently touches , the active set.

Each event may trigger queries, insertions, or removals.

This approach works because geometry problems often depend only on local
relationships between nearby elements as the sweep advances.

\subsubsection{A. Sweep Line Template}\label{a.-sweep-line-template}

A general structure looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Event }\OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ type}\OperatorTok{;}\NormalTok{ Object }\OperatorTok{*}\NormalTok{obj}\OperatorTok{;} \OperatorTok{\};}
\NormalTok{sort}\OperatorTok{(}\NormalTok{events}\OperatorTok{.}\NormalTok{begin}\OperatorTok{(),}\NormalTok{ events}\OperatorTok{.}\NormalTok{end}\OperatorTok{());}

\NormalTok{ActiveSet S}\OperatorTok{;}

\ControlFlowTok{for} \OperatorTok{(}\NormalTok{Event e }\OperatorTok{:}\NormalTok{ events}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{type }\OperatorTok{==}\NormalTok{ START}\OperatorTok{)}\NormalTok{ S}\OperatorTok{.}\NormalTok{insert}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{obj}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{type }\OperatorTok{==}\NormalTok{ END}\OperatorTok{)}\NormalTok{ S}\OperatorTok{.}\NormalTok{erase}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{obj}\OperatorTok{);}
    \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{type }\OperatorTok{==}\NormalTok{ QUERY}\OperatorTok{)}\NormalTok{ handle\_query}\OperatorTok{(}\NormalTok{S}\OperatorTok{,}\NormalTok{ e}\OperatorTok{.}\NormalTok{obj}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Sorting ensures events are processed in order of increasing x (or
another dimension).

\subsubsection{2. Classic Applications}\label{classic-applications}

Let's explore three foundational problems solvable by sweep techniques.

\subsubsection{A. Segment Intersection
(Bentley-Ottmann)}\label{a.-segment-intersection-bentley-ottmann}

Goal: detect all intersections among ( n ) line segments.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort endpoints by x-coordinate.
\item
  Sweep from left to right.
\item
  Maintain an ordered set of active segments (sorted by y).
\item
  When a new segment starts, check intersection with neighbors above and
  below.
\item
  When segments intersect, record intersection and insert a new event at
  the x-coordinate of intersection.
\end{enumerate}

Complexity: \(O((n + k)\log n)\), where \(k\) is the number of
intersections.

\subsubsection{B. Closest Pair of
Points}\label{b.-closest-pair-of-points}

Sweep line version sorts by x, then slides a vertical line while
maintaining active points within a strip of width ( d ) (current
minimum). Only need to check at most 6-8 nearby points in strip.

Complexity: ( O\(n \log n\) )

\subsubsection{C. Rectangle Union Area}\label{c.-rectangle-union-area}

Given axis-aligned rectangles, compute total area covered.

Idea:

\begin{itemize}
\tightlist
\item
  Treat vertical edges as events (entering/exiting rectangles).- Sweep
  line moves along x-axis.- Maintain y-intervals in active set (using a
  segment tree or interval tree).- At each step, multiply current width
  × height of union of active intervals. Complexity: ( O\(n \log n\) )
\end{itemize}

Tiny Code Sketch (C)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y1}\OperatorTok{,}\NormalTok{ y2}\OperatorTok{;} \DataTypeTok{int}\NormalTok{ type}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Event}\OperatorTok{;}
\NormalTok{Event events}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\DataTypeTok{int}\NormalTok{ n\_events}\OperatorTok{;}

\NormalTok{qsort}\OperatorTok{(}\NormalTok{events}\OperatorTok{,}\NormalTok{ n\_events}\OperatorTok{,} \KeywordTok{sizeof}\OperatorTok{(}\NormalTok{Event}\OperatorTok{),}\NormalTok{ cmp\_by\_x}\OperatorTok{);}

\DataTypeTok{double}\NormalTok{ prev\_x }\OperatorTok{=}\NormalTok{ events}\OperatorTok{[}\DecValTok{0}\OperatorTok{].}\NormalTok{x}\OperatorTok{,}\NormalTok{ area }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{SegmentTree T}\OperatorTok{;}

\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n\_events}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ dx }\OperatorTok{=}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ prev\_x}\OperatorTok{;}
\NormalTok{    area }\OperatorTok{+=}\NormalTok{ dx }\OperatorTok{*}\NormalTok{ T}\OperatorTok{.}\NormalTok{total\_length}\OperatorTok{();} \CommentTok{// current union height}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{type }\OperatorTok{==}\NormalTok{ START}\OperatorTok{)}
\NormalTok{        T}\OperatorTok{.}\NormalTok{insert}\OperatorTok{(}\NormalTok{events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y1}\OperatorTok{,}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y2}\OperatorTok{);}
    \ControlFlowTok{else}
\NormalTok{        T}\OperatorTok{.}\NormalTok{remove}\OperatorTok{(}\NormalTok{events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y1}\OperatorTok{,}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y2}\OperatorTok{);}
\NormalTok{    prev\_x }\OperatorTok{=}\NormalTok{ events}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Other Applications}\label{other-applications}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2836}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5075}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2090}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
K-closest points & Maintain top \(k\) in active set & \(O(n \log n)\) \\
Union of rectangles & Compute covered area & \(O(n \log n)\) \\
Point location & Locate point in planar subdivision & \(O(\log n)\) \\
Visibility graph & Track visible edges & \(O(n \log n)\) \\
\end{longtable}

\subsubsection{4. Plane Sweep Extensions}\label{plane-sweep-extensions}

While line sweep moves in one dimension (x), plane sweep handles 2D or
higher-dimensional spaces, where:

\begin{itemize}
\tightlist
\item
  Events are 2D cells or regions.- Sweep front is a plane instead of a
  line. Used in 3D collision detection, computational topology, and CAD
  systems.
\end{itemize}

\subsubsection{Conceptual Visualization}\label{conceptual-visualization}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort events by one axis (say, x).
\item
  Maintain structure (set, tree, or heap) of intersecting or active
  elements.
\item
  Update at each event and record desired output (intersection, union,
  coverage).
\end{enumerate}

The key is the locality principle: only neighbors in the sweep structure
can change outcomes.

\subsubsection{5. Complexity}\label{complexity-6}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Phase & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sorting events & \(O(n \log n)\) \\
Processing events & \(O(n \log n)\) \\
Total & \(O(n \log n)\) (typical) \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-72}

The sweep line method transforms geometric chaos into order , turning
spatial relationships into sorted sequences. It's the bridge between
geometry and algorithms, blending structure with motion.

\begin{quote}
``A sweep line sees everything , not all at once, but just in time.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-72}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a sweep-line segment intersection finder.
\item
  Compute the union area of 3 rectangles with overlaps.
\item
  Animate the sweep line to visualize event processing.
\item
  Modify for circular or polygonal objects.
\item
  Explore how sweep-line logic applies to time-based events in
  scheduling.
\end{enumerate}

\subsection{74. Delaunay and Voronoi
Diagrams}\label{delaunay-and-voronoi-diagrams}

In geometry and spatial computing, Delaunay triangulations and Voronoi
diagrams are duals , elegant structures that capture proximity,
territory, and connectivity among points.

They're used everywhere: from mesh generation, pathfinding, geospatial
analysis, to computational biology. This section introduces both, their
relationship, and algorithms to construct them efficiently.

\subsubsection{1. Voronoi Diagram}\label{voronoi-diagram}

Given a set of sites (points) \(P = {p_1, p_2, \ldots, p_n}\), the
Voronoi diagram partitions the plane into regions , one per point , so
that every location in a region is closer to its site than to any other.

Formally, the Voronoi cell for \(p_i\) is: \[
V(p_i) = {x \in \mathbb{R}^2 \mid d(x, p_i) \le d(x, p_j), \forall j \neq i }
\]

Each region is convex, and boundaries are formed by perpendicular
bisectors.

\subsubsection{Example}\label{example-13}

For points ( A, B, C ):

\begin{itemize}
\tightlist
\item
  Draw bisectors between each pair.- Intersection points define Voronoi
  vertices.- Resulting polygons cover the plane, one per site. Used to
  model nearest neighbor regions , ``which tower serves which area?''
\end{itemize}

\subsubsection{Properties}\label{properties}

\begin{itemize}
\tightlist
\item
  Every cell is convex.- Neighboring cells share edges.- The diagram's
  vertices are centers of circumcircles through three sites.- Dual graph
  = Delaunay triangulation.
\end{itemize}

\subsubsection{2. Delaunay Triangulation}\label{delaunay-triangulation}

The Delaunay triangulation (DT) connects points so that no point lies
inside the circumcircle of any triangle.

Equivalently, it's the dual graph of the Voronoi diagram.

It tends to avoid skinny triangles , maximizing minimum angles, creating
well-shaped meshes.

\subsubsection{Formal Definition}\label{formal-definition}

A triangulation ( T ) of ( P ) is Delaunay if for every triangle
\(\triangle abc \in T\), no point \(p \in P \setminus {a,b,c}\) lies
inside the circumcircle of \(\triangle abc\).

Why It Matters:

\begin{itemize}
\tightlist
\item
  Avoids sliver triangles.- Used in finite element meshes, terrain
  modeling, and path planning.- Leads to natural neighbor interpolation
  and smooth surfaces.
\end{itemize}

\subsubsection{3. Relationship}\label{relationship}

Voronoi and Delaunay are geometric duals:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Voronoi & Delaunay \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Regions = proximity zones & Triangles = neighbor connections \\
Edges = bisectors & Edges = neighbor pairs \\
Vertices = circumcenters & Faces = circumcircles \\
\end{longtable}

Connecting neighboring Voronoi cells gives Delaunay edges.

\subsubsection{4. Algorithms}\label{algorithms}

Several algorithms can build these diagrams efficiently.

\subsubsection{A. Incremental Insertion}\label{a.-incremental-insertion}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with a super-triangle enclosing all points.
\item
  Insert points one by one.
\item
  Remove triangles whose circumcircle contains the point.
\item
  Re-triangulate the resulting polygonal hole.
\end{enumerate}

Time Complexity: ( O\(n^2\) ), improved to ( O\(n \log n\) ) with
randomization.

\subsubsection{B. Divide and Conquer}\label{b.-divide-and-conquer}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort points by x.
\item
  Recursively build DT for left and right halves.
\item
  Merge by finding common tangents.
\end{enumerate}

Time Complexity: ( O\(n \log n\) ) Elegant, structured, and
deterministic.

\subsubsection{C. Fortune's Sweep Line
Algorithm}\label{c.-fortunes-sweep-line-algorithm}

For Voronoi diagrams, Fortune's algorithm sweeps a line from top to
bottom. Maintains a beach line of parabolic arcs and event queue.

Each event (site or circle) updates the structure , building Voronoi
edges incrementally.

Time Complexity: ( O\(n \log n\) )

\subsubsection{D. Bowyer-Watson (Delaunay via Circumcircle
Test)}\label{d.-bowyer-watson-delaunay-via-circumcircle-test}

A practical incremental version widely used in graphics and simulation.

Steps:

\begin{itemize}
\tightlist
\item
  Start with supertriangle- Insert point- Remove all triangles whose
  circumcircle contains point- Reconnect the resulting cavity
\end{itemize}

Tiny Code (Conceptual)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}\NormalTok{ Point a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{,}\NormalTok{ c}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Triangle}\OperatorTok{;}

\DataTypeTok{bool}\NormalTok{ in\_circle}\OperatorTok{(}\NormalTok{Point a}\OperatorTok{,}\NormalTok{ Point b}\OperatorTok{,}\NormalTok{ Point c}\OperatorTok{,}\NormalTok{ Point p}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ A}\OperatorTok{[}\DecValTok{3}\OperatorTok{][}\DecValTok{3}\OperatorTok{]} \OperatorTok{=} \OperatorTok{\{}
        \OperatorTok{\{}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{,} \OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ a}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{a}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)\},}
        \OperatorTok{\{}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ b}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{,} \OperatorTok{(}\NormalTok{b}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{b}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{b}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)\},}
        \OperatorTok{\{}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{x}\OperatorTok{,}\NormalTok{ c}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{,} \OperatorTok{(}\NormalTok{c}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{c}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ c}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{c}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{{-}} \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{+}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{*}\NormalTok{p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)\}}
    \OperatorTok{\};}
    \ControlFlowTok{return}\NormalTok{ determinant}\OperatorTok{(}\NormalTok{A}\OperatorTok{)} \OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This test ensures Delaunay property.

\subsubsection{5. Applications}\label{applications-14}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Application \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GIS & Nearest facility, region partition \\
Mesh Generation & Finite element methods \\
Robotics & Visibility graphs, navigation \\
Computer Graphics & Terrain triangulation \\
Clustering & Spatial neighbor structure \\
\end{longtable}

\subsubsection{6. Complexity Summary}\label{complexity-summary-2}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Type & Time & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fortune & Voronoi & ( O\(n \log n\) ) & Sweep line \\
Bowyer-Watson & Delaunay & ( O\(n \log n\) ) & Incremental \\
Divide \& Conquer & Delaunay & ( O\(n \log n\) ) & Recursive \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-73}

Voronoi and Delaunay diagrams reveal natural structure in point sets.
They convert distance into geometry, showing how space is divided and
connected. If geometry is the shape of space, these diagrams are its
skeleton.

\begin{quote}
``Every point claims its territory; every territory shapes its
network.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-73}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw Voronoi regions for 5 random points by hand.
\item
  Build Delaunay triangles (connect neighboring sites).
\item
  Verify the empty circumcircle property.
\item
  Use a library (CGAL / SciPy) to visualize both structures.
\item
  Explore how adding new points reshapes the diagrams.
\end{enumerate}

\subsection{75. Point in Polygon and Polygon
Triangulation}\label{point-in-polygon-and-polygon-triangulation}

Geometry often asks two fundamental questions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Is a point inside or outside a polygon?
\item
  How can a complex polygon be broken into triangles for computation?
\end{enumerate}

These are the building blocks of spatial analysis, computer graphics,
and computational geometry.

\subsubsection{1. Point in Polygon (PIP)}\label{point-in-polygon-pip}

Given a polygon defined by vertices ( \(x_1, y_1\), \(x_2, y_2\),
\ldots, \(x_n, y_n\) ) and a test point ( (x, y) ), we want to determine
if the point lies inside, on the boundary, or outside the polygon.

\subsubsection{Methods}\label{methods}

\subsubsection{A. Ray Casting Algorithm}\label{a.-ray-casting-algorithm}

Shoot a ray horizontally to the right of the point. Count how many times
it intersects polygon edges.

\begin{itemize}
\tightlist
\item
  Odd count → Inside- Even count → Outside This is based on the even-odd
  rule.
\end{itemize}

Tiny Code (Ray Casting in C)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ point\_in\_polygon}\OperatorTok{(}\NormalTok{Point p}\OperatorTok{,}\NormalTok{ Point poly}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{bool}\NormalTok{ inside }\OperatorTok{=} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=}\NormalTok{ n }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ j }\OperatorTok{=}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(((}\NormalTok{poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y }\OperatorTok{\textgreater{}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{)} \OperatorTok{!=} \OperatorTok{(}\NormalTok{poly}\OperatorTok{[}\NormalTok{j}\OperatorTok{].}\NormalTok{y }\OperatorTok{\textgreater{}}\NormalTok{ p}\OperatorTok{.}\NormalTok{y}\OperatorTok{))} \OperatorTok{\&\&}
            \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{x }\OperatorTok{\textless{}} \OperatorTok{(}\NormalTok{poly}\OperatorTok{[}\NormalTok{j}\OperatorTok{].}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x}\OperatorTok{)} \OperatorTok{*} 
                   \OperatorTok{(}\NormalTok{p}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y}\OperatorTok{)} \OperatorTok{/} 
                   \OperatorTok{(}\NormalTok{poly}\OperatorTok{[}\NormalTok{j}\OperatorTok{].}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{y}\OperatorTok{)} \OperatorTok{+}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{].}\NormalTok{x}\OperatorTok{))}
\NormalTok{            inside }\OperatorTok{=} \OperatorTok{!}\NormalTok{inside}\OperatorTok{;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ inside}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This toggles \texttt{inside} every time a crossing is found.

\subsubsection{B. Winding Number
Algorithm}\label{b.-winding-number-algorithm}

Counts how many times the polygon winds around the point.

\begin{itemize}
\tightlist
\item
  Nonzero winding number → Inside- Zero → Outside More robust for
  complex polygons with holes or self-intersections.
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Time Complexity & Robustness \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ray Casting & (O(n)) & Simple, may fail on edge cases \\
Winding Number & (O(n)) & More accurate for complex shapes \\
\end{longtable}

\subsubsection{Edge Cases}\label{edge-cases}

Handle:

\begin{itemize}
\tightlist
\item
  Points on edges or vertices- Horizontal edges (special treatment to
  avoid double counting) Numerical precision is key.
\end{itemize}

\subsubsection{Applications}\label{applications-15}

\begin{itemize}
\tightlist
\item
  Hit testing in computer graphics- GIS spatial queries- Collision
  detection
\end{itemize}

\subsubsection{2. Polygon Triangulation}\label{polygon-triangulation-1}

A polygon triangulation divides a polygon into non-overlapping triangles
whose union equals the polygon.

Why triangulate?

\begin{itemize}
\tightlist
\item
  Triangles are simple, stable, and efficient for rendering and
  computation.- Used in graphics pipelines, area computation, physics,
  and mesh generation.
\end{itemize}

\subsubsection{A. Triangulation Basics}\label{a.-triangulation-basics}

For a simple polygon with ( n ) vertices,

\begin{itemize}
\tightlist
\item
  Always possible- Always yields ( n - 2 ) triangles Goal: Find a
  triangulation efficiently and stably.
\end{itemize}

\subsubsection{B. Ear Clipping
Algorithm}\label{b.-ear-clipping-algorithm}

An intuitive and widely used method for triangulation.

\subsubsection{Idea}\label{idea-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find an ear: a triangle formed by three consecutive vertices (
  \(v_{i-1}, v_i, v_{i+1}\) ) such that:

  \begin{itemize}
  \tightlist
  \item
    It is convex - Contains no other vertex inside
  \end{itemize}
\item
  Clip the ear (remove vertex \(v_i\))
\item
  Repeat until only one triangle remains
\end{enumerate}

Time Complexity: ( O\(n^2\) )

Tiny Code (Ear Clipping Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{n }\OperatorTok{\textgreater{}} \DecValTok{3}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{is\_ear}\OperatorTok{(}\NormalTok{i}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{            add\_triangle}\OperatorTok{(}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{,}\NormalTok{ i}\OperatorTok{,}\NormalTok{ i}\OperatorTok{+}\DecValTok{1}\OperatorTok{);}
\NormalTok{            remove\_vertex}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
            \ControlFlowTok{break}\OperatorTok{;}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Helper \texttt{is\_ear()} checks convexity and emptiness.

\subsubsection{C. Dynamic Programming for Convex
Polygons}\label{c.-dynamic-programming-for-convex-polygons}

If the polygon is convex, use DP triangulation:

\[
dp[i][j] = \min_{k \in (i,j)} dp[i][k] + dp[k][j] + cost(i, j, k)
\]

Cost: perimeter or area (for minimum-weight triangulation)

Time Complexity: ( O\(n^3\) ) Space: ( O\(n^2\) )

\subsubsection{D. Divide and Conquer}\label{d.-divide-and-conquer}

Recursively split polygon and triangulate sub-polygons. Useful for
convex or near-convex shapes.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Time & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ear Clipping & (O\(n^2\)) & Simple polygons \\
DP Triangulation & (O\(n^3\)) & Weighted cost \\
Convex Polygon & (O(n)) & Straightforward \\
\end{longtable}

\subsubsection{3. Applications}\label{applications-16}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Usage \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Computer Graphics & Rendering, rasterization \\
Computational Geometry & Area computation, integration \\
Finite Element Analysis & Mesh subdivision \\
Robotics & Path planning, map decomposition \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-74}

Point-in-polygon answers where you are. Triangulation tells you how
space is built. Together, they form the foundation of geometric
reasoning.

\begin{quote}
``From a single point to a thousand triangles, geometry turns space into
structure.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-74}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a non-convex polygon and test random points using the ray casting
  rule.
\item
  Implement the ear clipping algorithm for a simple polygon.
\item
  Visualize how each step removes an ear and simplifies the shape.
\item
  Compare triangulation results for convex vs concave shapes.
\end{enumerate}

\subsection{76. Spatial Data Structures (KD,
R-tree)}\label{spatial-data-structures-kd-r-tree}

When working with geometric data, points, rectangles, or polygons,
efficient lookup and organization are crucial. Spatial data structures
are designed to answer queries like:

\begin{itemize}
\tightlist
\item
  Which objects are near a given point?- Which shapes intersect a
  region?- What's the nearest neighbor? They form the backbone of
  computational geometry, computer graphics, GIS, and search systems.
\end{itemize}

\subsubsection{1. Motivation}\label{motivation-1}

Brute force approaches that check every object have ( O(n) ) or worse
performance. Spatial indexing structures, like KD-Trees and R-Trees,
enable efficient range queries, nearest neighbor searches, and spatial
joins.

\subsubsection{2. KD-Tree (k-dimensional
tree)}\label{kd-tree-k-dimensional-tree}

A KD-tree is a binary tree that recursively partitions space using
axis-aligned hyperplanes.

Each node splits the data by one coordinate axis (x, y, z, \ldots).

\subsubsection{Structure}\label{structure}

\begin{itemize}
\tightlist
\item
  Each node represents a point.- Each level splits by a different axis
  (x, y, x, y, \ldots).- Left child contains points with smaller
  coordinate.- Right child contains larger coordinate.
\end{itemize}

Tiny Code (KD-tree Construction in 2D)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Point}\OperatorTok{;}

\DataTypeTok{int}\NormalTok{ axis}\OperatorTok{;} \CommentTok{// 0 for x, 1 for y}

\NormalTok{KDNode}\OperatorTok{*}\NormalTok{ build}\OperatorTok{(}\NormalTok{Point points}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ depth}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{n }\OperatorTok{==} \DecValTok{0}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ NULL}\OperatorTok{;}
\NormalTok{    axis }\OperatorTok{=}\NormalTok{ depth }\OperatorTok{\%} \DecValTok{2}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ mid }\OperatorTok{=}\NormalTok{ n }\OperatorTok{/} \DecValTok{2}\OperatorTok{;}
\NormalTok{    nth\_element}\OperatorTok{(}\NormalTok{points}\OperatorTok{,}\NormalTok{ points }\OperatorTok{+}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ points }\OperatorTok{+}\NormalTok{ n}\OperatorTok{,}\NormalTok{ compare\_by\_axis}\OperatorTok{);}
\NormalTok{    KDNode}\OperatorTok{*}\NormalTok{ node }\OperatorTok{=}\NormalTok{ new\_node}\OperatorTok{(}\NormalTok{points}\OperatorTok{[}\NormalTok{mid}\OperatorTok{]);}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{left  }\OperatorTok{=}\NormalTok{ build}\OperatorTok{(}\NormalTok{points}\OperatorTok{,}\NormalTok{ mid}\OperatorTok{,}\NormalTok{ depth }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
\NormalTok{    node}\OperatorTok{{-}\textgreater{}}\NormalTok{right }\OperatorTok{=}\NormalTok{ build}\OperatorTok{(}\NormalTok{points }\OperatorTok{+}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}\OperatorTok{,}\NormalTok{ n }\OperatorTok{{-}}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{,}\NormalTok{ depth }\OperatorTok{+} \DecValTok{1}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ node}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Search Complexity:

\begin{itemize}
\tightlist
\item
  Average: ( O\(\log n\) )- Worst-case: ( O(n) )
\end{itemize}

\subsubsection{Queries}\label{queries}

\begin{itemize}
\tightlist
\item
  Range query: Find points in a region.- Nearest neighbor: Search
  branches that might contain closer points.- K-nearest neighbors: Use
  priority queues.
\end{itemize}

\subsubsection{Pros \& Cons}\label{pros-cons}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Efficient for static data & Costly updates \\
Good for low dimensions & Degrades with high dimensions \\
\end{longtable}

\subsubsection{Applications}\label{applications-17}

\begin{itemize}
\tightlist
\item
  Nearest neighbor in ML- Collision detection- Clustering (e.g., k-means
  acceleration)
\end{itemize}

\subsubsection{3. R-Tree (Rectangle Tree)}\label{r-tree-rectangle-tree}

An R-tree is a height-balanced tree for rectangular bounding boxes. It's
the spatial analog of a B-tree.

\subsubsection{Idea}\label{idea-2}

\begin{itemize}
\tightlist
\item
  Store objects or bounding boxes in leaf nodes.- Internal nodes store
  MBRs (Minimum Bounding Rectangles) that cover child boxes.- Query by
  traversing overlapping MBRs.
\end{itemize}

Tiny Code (R-Tree Node Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{}
\NormalTok{    Rectangle mbr}\OperatorTok{;}
\NormalTok{    Node}\OperatorTok{*}\NormalTok{ children}\OperatorTok{[}\NormalTok{MAX\_CHILDREN}\OperatorTok{];}
    \DataTypeTok{int}\NormalTok{ count}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Insertion chooses the child whose MBR expands least to accommodate the
new entry.

\subsubsection{Operations}\label{operations}

\begin{itemize}
\item
  Insert: Choose subtree → Insert → Adjust MBRs- Search: Descend into
  nodes whose MBR intersects query- Split: When full, use heuristics
  (linear, quadratic, R*-Tree) Complexity:
\item
  Query: ( O\(\log n\) )- Insert/Delete: ( O\(\log n\) ) average
\end{itemize}

\subsubsection{Pros \& Cons}\label{pros-cons-1}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Supports dynamic data & Overlaps can degrade performance \\
Ideal for rectangles & Complex split rules \\
\end{longtable}

\subsubsection{Variants}\label{variants-1}

\begin{itemize}
\tightlist
\item
  R*-Tree: Optimized reinsertion, better packing- R+ Tree:
  Non-overlapping partitions- Hilbert R-Tree: Uses space-filling curves
\end{itemize}

\subsubsection{4. Comparison}\label{comparison-24}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & KD-Tree & R-Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Data Type & Points & Rectangles / Regions \\
Dimensionality & Low (2-10) & Medium \\
Use Case & NN, range queries & Spatial joins, overlap queries \\
Updates & Expensive & Dynamic-friendly \\
Balance & Recursive median & B-tree-like \\
\end{longtable}

\subsubsection{5. Other Spatial
Structures}\label{other-spatial-structures}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Structure & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Quadtree & Recursive 2D subdivision into 4 quadrants \\
Octree & 3D analog of quadtree \\
BSP Tree & Binary partition using arbitrary planes \\
Grid Index & Divide space into uniform grid cells \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-18}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Usage \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GIS & Region queries, map intersections \\
Graphics & Ray tracing acceleration \\
Robotics & Collision and path planning \\
ML & Nearest neighbor search \\
Databases & Spatial indexing \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-75}

Spatial structures turn geometry into searchable data. They enable
efficient algorithms for where and what's near, vital for real-time
systems.

\begin{quote}
``Divide space wisely, and queries become whispers instead of shouts.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-75}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a KD-tree for 10 random 2D points.
\item
  Implement nearest neighbor search.
\item
  Insert rectangles into a simple R-tree and query intersection with a
  bounding box.
\item
  Compare query time vs brute force.
\end{enumerate}

\subsection{77. Rasterization and Scanline
Techniques}\label{rasterization-and-scanline-techniques}

When you draw shapes on a screen, triangles, polygons, circles, they
must be converted into pixels. This conversion is called rasterization.
It's the bridge between geometric math and visible images.

Rasterization and scanline algorithms are foundational to computer
graphics, game engines, and rendering pipelines.

\subsubsection{1. What Is Rasterization?}\label{what-is-rasterization}

Rasterization transforms vector shapes (continuous lines and surfaces)
into discrete pixels on a grid.

For example, a triangle defined by vertices
\texttt{(x1,\ y1),\ (x2,\ y2),\ (x3,\ y3)} must be filled pixel by
pixel.

\subsubsection{2. Core Idea}\label{core-idea}

Each shape (line, polygon, circle) is sampled over a grid. The algorithm
decides which pixels are inside, on, or outside the shape.

A rasterizer answers:

\begin{itemize}
\tightlist
\item
  Which pixels should be lit?- What color or depth should each pixel
  have?
\end{itemize}

\subsubsection{3. Line Rasterization (Bresenham's
Algorithm)}\label{line-rasterization-bresenhams-algorithm}

A classic method for drawing straight lines with integer arithmetic.

Key Idea: Move from one pixel to the next, choosing the pixel closest to
the true line path.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ draw\_line}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ x0}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ y0}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ x1}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ y1}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ dx }\OperatorTok{=}\NormalTok{ abs}\OperatorTok{(}\NormalTok{x1 }\OperatorTok{{-}}\NormalTok{ x0}\OperatorTok{),}\NormalTok{ dy }\OperatorTok{=}\NormalTok{ abs}\OperatorTok{(}\NormalTok{y1 }\OperatorTok{{-}}\NormalTok{ y0}\OperatorTok{);}
    \DataTypeTok{int}\NormalTok{ sx }\OperatorTok{=} \OperatorTok{(}\NormalTok{x0 }\OperatorTok{\textless{}}\NormalTok{ x1}\OperatorTok{)} \OperatorTok{?} \DecValTok{1} \OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ sy }\OperatorTok{=} \OperatorTok{(}\NormalTok{y0 }\OperatorTok{\textless{}}\NormalTok{ y1}\OperatorTok{)} \OperatorTok{?} \DecValTok{1} \OperatorTok{:} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ err }\OperatorTok{=}\NormalTok{ dx }\OperatorTok{{-}}\NormalTok{ dy}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\KeywordTok{true}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        plot}\OperatorTok{(}\NormalTok{x0}\OperatorTok{,}\NormalTok{ y0}\OperatorTok{);} \CommentTok{// draw pixel}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{x0 }\OperatorTok{==}\NormalTok{ x1 }\OperatorTok{\&\&}\NormalTok{ y0 }\OperatorTok{==}\NormalTok{ y1}\OperatorTok{)} \ControlFlowTok{break}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ e2 }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ err}\OperatorTok{;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e2 }\OperatorTok{\textgreater{}} \OperatorTok{{-}}\NormalTok{dy}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ err }\OperatorTok{{-}=}\NormalTok{ dy}\OperatorTok{;}\NormalTok{ x0 }\OperatorTok{+=}\NormalTok{ sx}\OperatorTok{;} \OperatorTok{\}}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e2 }\OperatorTok{\textless{}}\NormalTok{ dx}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ err }\OperatorTok{+=}\NormalTok{ dx}\OperatorTok{;}\NormalTok{ y0 }\OperatorTok{+=}\NormalTok{ sy}\OperatorTok{;} \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Why it works: Bresenham avoids floating-point math and keeps the line
visually continuous.

\subsubsection{4. Polygon Rasterization}\label{polygon-rasterization}

To fill shapes, we need scanline algorithms, they sweep a horizontal
line (y-axis) across the shape and fill pixels in between edges.

\subsubsection{Scanline Fill Steps}\label{scanline-fill-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort edges by their y-coordinates.
\item
  Scan each line (y).
\item
  Find intersections with polygon edges.
\item
  Fill between intersection pairs.
\end{enumerate}

This guarantees correct filling for convex and concave polygons.

\subsubsection{Example (Simple Triangle
Rasterization)}\label{example-simple-triangle-rasterization}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ y }\OperatorTok{=}\NormalTok{ y\_min}\OperatorTok{;}\NormalTok{ y }\OperatorTok{\textless{}=}\NormalTok{ y\_max}\OperatorTok{;}\NormalTok{ y}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    find all x}\OperatorTok{{-}}\NormalTok{intersections with polygon edges}\OperatorTok{;}
\NormalTok{    sort x}\OperatorTok{{-}}\NormalTok{intersections}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ count}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=} \DecValTok{2}\OperatorTok{)}
\NormalTok{        draw\_line}\OperatorTok{(}\NormalTok{x}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ y}\OperatorTok{,}\NormalTok{ x}\OperatorTok{[}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\OperatorTok{],}\NormalTok{ y}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Circle Rasterization (Midpoint
Algorithm)}\label{circle-rasterization-midpoint-algorithm}

Use symmetry, a circle is symmetric in 8 octants.

Each step calculates the error term to decide whether to move
horizontally or diagonally.

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ draw\_circle}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ xc}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ yc}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ r}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ x }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ y }\OperatorTok{=}\NormalTok{ r}\OperatorTok{,}\NormalTok{ d }\OperatorTok{=} \DecValTok{3} \OperatorTok{{-}} \DecValTok{2} \OperatorTok{*}\NormalTok{ r}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{y }\OperatorTok{\textgreater{}=}\NormalTok{ x}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        plot\_circle\_points}\OperatorTok{(}\NormalTok{xc}\OperatorTok{,}\NormalTok{ yc}\OperatorTok{,}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}
\NormalTok{        x}\OperatorTok{++;}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{d }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ y}\OperatorTok{{-}{-};}\NormalTok{ d }\OperatorTok{+=} \DecValTok{4} \OperatorTok{*} \OperatorTok{(}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ y}\OperatorTok{)} \OperatorTok{+} \DecValTok{10}\OperatorTok{;} \OperatorTok{\}}
        \ControlFlowTok{else}\NormalTok{ d }\OperatorTok{+=} \DecValTok{4} \OperatorTok{*}\NormalTok{ x }\OperatorTok{+} \DecValTok{6}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{6. Depth and Shading}\label{depth-and-shading}

In 3D graphics, rasterization includes depth testing (Z-buffer) and
color interpolation. Each pixel stores its depth; new pixels overwrite
only if closer.

Interpolated shading (Gouraud, Phong) computes smooth color transitions
across polygons.

\subsubsection{7. Hardware Rasterization}\label{hardware-rasterization}

Modern GPUs perform rasterization in parallel:

\begin{itemize}
\tightlist
\item
  Vertex Shader → Projection- Rasterizer → Pixel Grid- Fragment Shader →
  Color \& Depth Each pixel is processed in fragment shaders for
  lighting, texture, and effects.
\end{itemize}

\subsubsection{8. Optimizations}\label{optimizations}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Technique & Purpose \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bounding Box Clipping & Skip off-screen regions \\
Early Z-Culling & Discard hidden pixels early \\
Edge Functions & Fast inside-test for triangles \\
Barycentric Coordinates & Interpolate depth/color smoothly \\
\end{longtable}

\subsubsection{9. Why It Matters}\label{why-it-matters-76}

Rasterization turns math into imagery. It's the foundation of all visual
computing, renderers, CAD, games, and GUIs. Even with ray tracing
rising, rasterization remains dominant for real-time rendering.

\begin{quote}
``Every pixel you see began as math, it's just geometry painted by
light.''
\end{quote}

\subsubsection{10. Try It Yourself}\label{try-it-yourself-76}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Bresenham's algorithm for lines.
\item
  Write a scanline polygon fill for triangles.
\item
  Extend it with color interpolation using barycentric coordinates.
\item
  Compare performance vs brute force (looping over all pixels).
\end{enumerate}

\subsection{78. Computer Vision (Canny, Hough,
SIFT)}\label{computer-vision-canny-hough-sift}

Computer vision is where algorithms learn to see, to extract structure,
shape, and meaning from images. Behind every object detector, edge map,
and keypoint matcher lies a handful of powerful geometric algorithms.

In this section, we explore four pillars of classical vision: Canny edge
detection, Hough transform, and SIFT (Scale-Invariant Feature
Transform).

\subsubsection{1. The Vision Pipeline}\label{the-vision-pipeline}

Most vision algorithms follow a simple pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Input: Raw pixels (grayscale or color)
\item
  Preprocess: Smoothing or filtering
\item
  Feature extraction: Edges, corners, blobs
\item
  Detection or matching: Shapes, keypoints
\item
  Interpretation: Object recognition, tracking
\end{enumerate}

Canny, Hough, and SIFT live in the feature extraction and detection
stages.

\subsubsection{2. Canny Edge Detector}\label{canny-edge-detector}

Edges mark places where intensity changes sharply, the outlines of
objects. The Canny algorithm (1986) is one of the most robust and widely
used edge detectors.

\subsubsection{Steps}\label{steps-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Smoothing: Apply Gaussian blur to reduce noise.
\item
  Gradient computation:

  \begin{itemize}
  \tightlist
  \item
    Compute \(G_x\) and \(G_y\) via Sobel filters\\
  \item
    Gradient magnitude: \(G = \sqrt{G_x^2 + G_y^2}\)\\
  \item
    Gradient direction: \(\theta = \tan^{-1}\frac{G_y}{G_x}\)
  \end{itemize}
\item
  Non-maximum suppression:

  \begin{itemize}
  \tightlist
  \item
    Keep only local maxima along the gradient direction
  \end{itemize}
\item
  Double thresholding:

  \begin{itemize}
  \tightlist
  \item
    Strong edges (high gradient)\\
  \item
    Weak edges (connected to strong ones)
  \end{itemize}
\item
  Edge tracking by hysteresis:

  \begin{itemize}
  \tightlist
  \item
    Connect weak edges linked to strong edges
  \end{itemize}
\end{enumerate}

\subsubsection{Tiny Code (Pseudocode)}\label{tiny-code-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Image canny}\OperatorTok{(}\NormalTok{Image input}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    Image smoothed }\OperatorTok{=}\NormalTok{ gaussian\_blur}\OperatorTok{(}\NormalTok{input}\OperatorTok{);}
\NormalTok{    Gradient grad }\OperatorTok{=}\NormalTok{ sobel}\OperatorTok{(}\NormalTok{smoothed}\OperatorTok{);}
\NormalTok{    Image suppressed }\OperatorTok{=}\NormalTok{ non\_max\_suppression}\OperatorTok{(}\NormalTok{grad}\OperatorTok{);}
\NormalTok{    Image edges }\OperatorTok{=}\NormalTok{ hysteresis\_threshold}\OperatorTok{(}\NormalTok{suppressed}\OperatorTok{,}\NormalTok{ low}\OperatorTok{,}\NormalTok{ high}\OperatorTok{);}
    \ControlFlowTok{return}\NormalTok{ edges}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why Canny Works}\label{why-canny-works}

Canny maximizes three criteria:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Good detection (low false negatives)
\item
  Good localization (edges close to true edges)
\item
  Single response (no duplicates)
\end{enumerate}

It's a careful balance between sensitivity and stability.

\subsubsection{3. Hough Transform}\label{hough-transform}

Canny finds edge points, Hough connects them into shapes.

The Hough transform detects lines, circles, and other parametric shapes
using voting in parameter space.

\subsubsection{Line Detection}\label{line-detection}

Equation of a line: \[
\rho = x\cos\theta + y\sin\theta
\]

Each edge point votes for all (\(\rho, \theta\)) combinations it could
belong to. Peaks in the accumulator array correspond to strong lines.

Tiny Code (Hough Transform)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each edge point }\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{):}
  \ControlFlowTok{for}\NormalTok{ theta in }\OperatorTok{[}\DecValTok{0}\OperatorTok{,} \DecValTok{180}\OperatorTok{):}
\NormalTok{    rho }\OperatorTok{=}\NormalTok{ x}\OperatorTok{*}\NormalTok{cos}\OperatorTok{(}\NormalTok{theta}\OperatorTok{)} \OperatorTok{+}\NormalTok{ y}\OperatorTok{*}\NormalTok{sin}\OperatorTok{(}\NormalTok{theta}\OperatorTok{);}
\NormalTok{    accumulator}\OperatorTok{[}\NormalTok{rho}\OperatorTok{,}\NormalTok{ theta}\OperatorTok{]++;}
\end{Highlighting}
\end{Shaded}

Then pick (\(\rho, \theta\)) with highest votes.

\subsubsection{Circle Detection}\label{circle-detection}

Use 3D accumulator \(center_x, center_y, radius\). Each edge pixel votes
for possible circle centers.

\subsubsection{Applications}\label{applications-19}

\begin{itemize}
\tightlist
\item
  Lane detection in self-driving- Shape recognition (circles, ellipses)-
  Document analysis (lines, grids)
\end{itemize}

\subsubsection{4. SIFT (Scale-Invariant Feature
Transform)}\label{sift-scale-invariant-feature-transform}

SIFT finds keypoints that remain stable under scale, rotation, and
illumination changes.

It's widely used for image matching, panoramas, 3D reconstruction, and
object recognition.

\subsubsection{Steps}\label{steps-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Scale-space extrema detection

  \begin{itemize}
  \item
    Use Difference of Gaussians (DoG) across scales. - Detect
    maxima/minima in space-scale neighborhood.2. Keypoint localization
  \item
    Refine keypoint position and discard unstable ones.3. Orientation
    assignment
  \item
    Assign dominant gradient direction.4. Descriptor generation
  \item
    Build a 128D histogram of gradient orientations in a local patch.
  \end{itemize}
\end{enumerate}

Tiny Code (Outline)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each octave}\OperatorTok{:}
\NormalTok{  build scale}\OperatorTok{{-}}\NormalTok{space pyramid}
\NormalTok{  find DoG extrema}
\NormalTok{  localize keypoints}
\NormalTok{  assign orientations}
\NormalTok{  compute }\DecValTok{128}\ErrorTok{D}\NormalTok{ descriptor}
\end{Highlighting}
\end{Shaded}

\subsubsection{Properties}\label{properties-1}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Property & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Scale Invariant & Detects features at multiple scales \\
Rotation Invariant & Uses local orientation \\
Robust & Handles lighting, noise, affine transforms \\
\end{longtable}

\subsubsection{5. Comparison}\label{comparison-25}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1268}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2394}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3099}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3239}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Robustness
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Canny & Edge detection & Binary edge map & Sensitive to thresholds \\
Hough & Shape detection & Lines, circles & Needs clean edges \\
SIFT & Feature detection & Keypoints, descriptors & Very robust \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-20}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use Case \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Robotics & Visual SLAM, localization \\
AR / VR & Marker tracking \\
Search & Image matching \\
Medical & Edge segmentation \\
Industry & Quality inspection \\
\end{longtable}

\subsubsection{7. Modern Successors}\label{modern-successors}

\begin{itemize}
\tightlist
\item
  ORB (FAST + BRIEF): Efficient for real-time- SURF: Faster SIFT
  alternative- Harris / FAST: Corner detectors- Deep features: CNN-based
  descriptors
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-77}

These algorithms gave machines their first eyes, before deep learning,
they were how computers recognized structure. Even today, they're used
in preprocessing, embedded systems, and hybrid pipelines.

\begin{quote}
``Before neural nets could dream, vision began with gradients, geometry,
and votes.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-77}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Canny using Sobel and hysteresis.
\item
  Use Hough transform to detect lines in a synthetic image.
\item
  Try OpenCV SIFT to match keypoints between two rotated images.
\item
  Compare edge maps before and after Gaussian blur.
\end{enumerate}

\subsection{79. Pathfinding in Space (A*, RRT,
PRM)}\label{pathfinding-in-space-a-rrt-prm}

When navigating a maze, driving an autonomous car, or moving a robot
arm, the question is the same: How do we find a path from start to goal
efficiently and safely?

Pathfinding algorithms answer this question, balancing optimality,
speed, and adaptability. In this section, we explore three foundational
families:

\begin{itemize}
\tightlist
\item
  A*: Heuristic search in grids and graphs- RRT (Rapidly-Exploring
  Random Tree): Sampling-based exploration- PRM (Probabilistic Roadmap):
  Precomputed navigation networks
\end{itemize}

\subsubsection{1. The Pathfinding
Problem}\label{the-pathfinding-problem}

Given:

\begin{itemize}
\tightlist
\item
  A space (grid, graph, or continuous)- A start node and goal node- A
  cost function (distance, time, energy)- Optional obstacles Find a
  collision-free, low-cost path.
\end{itemize}

\subsubsection{2. A* (A-star) Search}\label{a-a-star-search}

A* combines Dijkstra's algorithm with a heuristic that estimates
remaining cost. It's the most popular graph-based pathfinding algorithm.

\subsubsection{Key Idea}\label{key-idea}

Each node ( n ) has: \[
f(n) = g(n) + h(n)
\]

\begin{itemize}
\tightlist
\item
  ( g(n) ): cost so far- ( h(n) ): estimated cost to goal- ( f(n) ):
  total estimated cost
\end{itemize}

Algorithm

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize priority queue with start node
\item
  While queue not empty:

  \begin{itemize}
  \tightlist
  \item
    Pop node with smallest ( f(n) ) - If goal reached → return path -
    For each neighbor:

    \begin{itemize}
    \tightlist
    \item
      Compute new ( g ), ( f ) - Update queue if better
    \end{itemize}
  \end{itemize}
\end{enumerate}

Tiny Code (Grid A*)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct} \OperatorTok{\{} \DataTypeTok{int}\NormalTok{ x}\OperatorTok{,}\NormalTok{ y}\OperatorTok{;} \DataTypeTok{double}\NormalTok{ g}\OperatorTok{,}\NormalTok{ f}\OperatorTok{;} \OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\DataTypeTok{double}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{Node a}\OperatorTok{,}\NormalTok{ Node b}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{return}\NormalTok{ fabs}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{x }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{x}\OperatorTok{)} \OperatorTok{+}\NormalTok{ fabs}\OperatorTok{(}\NormalTok{a}\OperatorTok{.}\NormalTok{y }\OperatorTok{{-}}\NormalTok{ b}\OperatorTok{.}\NormalTok{y}\OperatorTok{);} \CommentTok{// Manhattan}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ a\_star}\OperatorTok{(}\NormalTok{Node start}\OperatorTok{,}\NormalTok{ Node goal}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    PriorityQueue open}\OperatorTok{;}
\NormalTok{    push}\OperatorTok{(}\NormalTok{open}\OperatorTok{,}\NormalTok{ start}\OperatorTok{);}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{empty}\OperatorTok{(}\NormalTok{open}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        Node cur }\OperatorTok{=}\NormalTok{ pop\_min}\OperatorTok{(}\NormalTok{open}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cur }\OperatorTok{==}\NormalTok{ goal}\OperatorTok{)} \ControlFlowTok{return}\NormalTok{ reconstruct\_path}\OperatorTok{();}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Node n }\OperatorTok{:}\NormalTok{ neighbors}\OperatorTok{(}\NormalTok{cur}\OperatorTok{))} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ tentative\_g }\OperatorTok{=}\NormalTok{ cur}\OperatorTok{.}\NormalTok{g }\OperatorTok{+}\NormalTok{ dist}\OperatorTok{(}\NormalTok{cur}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{tentative\_g }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{.}\NormalTok{g}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                n}\OperatorTok{.}\NormalTok{g }\OperatorTok{=}\NormalTok{ tentative\_g}\OperatorTok{;}
\NormalTok{                n}\OperatorTok{.}\NormalTok{f }\OperatorTok{=}\NormalTok{ n}\OperatorTok{.}\NormalTok{g }\OperatorTok{+}\NormalTok{ heuristic}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\NormalTok{                push}\OperatorTok{(}\NormalTok{open}\OperatorTok{,}\NormalTok{ n}\OperatorTok{);}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Complexity}\label{complexity-7}

\begin{itemize}
\tightlist
\item
  Time: ( O\(E \log V\) )- Space: ( O(V) )- Optimal if ( h(n) ) is
  admissible (never overestimates)
\end{itemize}

\subsubsection{Variants}\label{variants-2}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Variant & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Dijkstra & A* with ( h(n) = 0 ) \\
Greedy Best-First & Uses ( h(n) ) only \\
Weighted A* & Speeds up with tradeoff on optimality \\
Jump Point Search & Optimized for uniform grids \\
\end{longtable}

\subsubsection{3. RRT (Rapidly-Exploring Random
Tree)}\label{rrt-rapidly-exploring-random-tree}

A* struggles in continuous or high-dimensional spaces (e.g.~robot arms).
RRT tackles this with randomized exploration.

\subsubsection{Core Idea}\label{core-idea-1}

\begin{itemize}
\tightlist
\item
  Grow a tree from the start by randomly sampling points.- Extend tree
  toward each sample (step size \(\epsilon\)).- Stop when near the goal.
\end{itemize}

Tiny Code (RRT Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Tree T }\OperatorTok{=} \OperatorTok{\{}\NormalTok{start}\OperatorTok{\};}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ MAX\_ITERS}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    Point q\_rand }\OperatorTok{=}\NormalTok{ random\_point}\OperatorTok{();}
\NormalTok{    Point q\_near }\OperatorTok{=}\NormalTok{ nearest}\OperatorTok{(}\NormalTok{T}\OperatorTok{,}\NormalTok{ q\_rand}\OperatorTok{);}
\NormalTok{    Point q\_new }\OperatorTok{=}\NormalTok{ steer}\OperatorTok{(}\NormalTok{q\_near}\OperatorTok{,}\NormalTok{ q\_rand}\OperatorTok{,}\NormalTok{ step\_size}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{collision\_free}\OperatorTok{(}\NormalTok{q\_near}\OperatorTok{,}\NormalTok{ q\_new}\OperatorTok{))}
\NormalTok{        add\_edge}\OperatorTok{(}\NormalTok{T}\OperatorTok{,}\NormalTok{ q\_near}\OperatorTok{,}\NormalTok{ q\_new}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{distance}\OperatorTok{(}\NormalTok{q\_new}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{)} \OperatorTok{\textless{}}\NormalTok{ eps}\OperatorTok{)}
        \ControlFlowTok{return}\NormalTok{ path}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros \& Cons}\label{pros-cons-2}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Works in continuous space & Paths are suboptimal \\
Handles high dimensions & Randomness may miss narrow passages \\
Simple and fast & Needs post-processing (smoothing) \\
\end{longtable}

\subsubsection{Variants}\label{variants-3}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Variant & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
RRT* & Asymptotically optimal \\
Bi-RRT & Grow from both start and goal \\
Informed RRT* & Focus on promising regions \\
\end{longtable}

\subsubsection{4. PRM (Probabilistic
Roadmap)}\label{prm-probabilistic-roadmap}

PRM builds a graph of feasible configurations, a roadmap, then searches
it.

\subsubsection{Steps}\label{steps-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sample random points in free space
\item
  Connect nearby points with collision-free edges
\item
  Search roadmap (e.g., with A*)
\end{enumerate}

Tiny Code (PRM Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Graph G }\OperatorTok{=} \OperatorTok{\{\};}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    Point p }\OperatorTok{=}\NormalTok{ random\_free\_point}\OperatorTok{();}
\NormalTok{    G}\OperatorTok{.}\NormalTok{add\_vertex}\OperatorTok{(}\NormalTok{p}\OperatorTok{);}
\OperatorTok{\}}
\ControlFlowTok{for}\NormalTok{ each p in G}\OperatorTok{:}
    \ControlFlowTok{for}\NormalTok{ each q near p}\OperatorTok{:}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{collision\_free}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ q}\OperatorTok{))}
\NormalTok{            G}\OperatorTok{.}\NormalTok{add\_edge}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ q}\OperatorTok{);}
\NormalTok{path }\OperatorTok{=}\NormalTok{ a\_star}\OperatorTok{(}\NormalTok{G}\OperatorTok{,}\NormalTok{ start}\OperatorTok{,}\NormalTok{ goal}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros \& Cons}\label{pros-cons-3}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Precomputes reusable roadmap & Needs many samples for coverage \\
Good for multiple queries & Poor for single-query planning \\
Works in high-dim spaces & May need post-smoothing \\
\end{longtable}

\subsubsection{5. Comparison}\label{comparison-26}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1806}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2083}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3472}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Nature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Optimal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A* & Discrete & Deterministic & Yes & Grids, graphs \\
RRT & Continuous & Randomized & No (RRT* = Yes) & Robotics, motion
planning \\
PRM & Continuous & Randomized & Approx. & Multi-query planning \\
\end{longtable}

\subsubsection{6. Applications}\label{applications-21}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Use Case \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Robotics & Arm motion, mobile navigation \\
Games & NPC pathfinding, AI navigation mesh \\
Autonomous vehicles & Route planning \\
Aerospace & Drone and spacecraft trajectory \\
Logistics & Warehouse robot movement \\
\end{longtable}

\subsubsection{Why It Matters}\label{why-it-matters-78}

Pathfinding is decision-making in space, it gives agents the ability to
move, explore, and act purposefully. From Pac-Man to Mars rovers, every
journey starts with an algorithm.

\begin{quote}
``To move with purpose, one must first see the paths that are
possible.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-78}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement A* on a 2D grid with walls.
\item
  Generate an RRT in a 2D obstacle field.
\item
  Build a PRM for a continuous space and run A* on the roadmap.
\item
  Compare speed and path smoothness across methods.
\end{enumerate}

\subsection{80. Computational Geometry Variants and
Applications}\label{computational-geometry-variants-and-applications}

Computational geometry is the study of algorithms on geometric data,
points, lines, polygons, circles, and higher-dimensional shapes. By now,
you've seen core building blocks: convex hulls, intersections, nearest
neighbors, triangulations, and spatial indexing.

This final section brings them together through variants,
generalizations, and real-world applications, showing how geometry
quietly powers modern computing.

\subsubsection{1. Beyond the Plane}\label{beyond-the-plane}

Most examples so far assumed 2D geometry. But real systems often live in
3D or N-D spaces.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1098}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5732}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3171}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Dimension
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example Problems
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typical Uses
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2D & Convex hull, polygon area, line sweep & GIS, CAD, mapping \\
3D & Convex polyhedra, mesh intersection, visibility & Graphics,
simulation \\
N-D & Voronoi in high-D, KD-trees, optimization & ML, robotics, data
science \\
\end{longtable}

Higher dimensions add complexity (and sometimes impossibility):

\begin{itemize}
\tightlist
\item
  Exact geometry often replaced by approximations.- Volume, distance,
  and intersection tests become more expensive.
\end{itemize}

\subsubsection{2. Approximate and Robust
Geometry}\label{approximate-and-robust-geometry}

Real-world geometry faces numerical errors (floating point) and
degenerate cases (collinear, overlapping). To handle this, algorithms
adopt robustness and approximation strategies.

\begin{itemize}
\tightlist
\item
  Epsilon comparisons: treat values within tolerance as equal-
  Orientation tests: robustly compute turn direction via cross product-
  Exact arithmetic: rational or symbolic computation- Grid snapping:
  quantize space for stability Approximate geometry accepts small error
  for large speed-up, essential in graphics and machine learning.
\end{itemize}

\subsubsection{3. Geometric Duality}\label{geometric-duality}

A powerful tool for reasoning about problems: map points to lines, lines
to points. For example:

\begin{itemize}
\item
  A point ( (a, b) ) maps to line ( y = ax - b ).- A line ( y = mx + c )
  maps to point ( (m, -c) ). Applications:
\item
  Transforming line intersection problems into point location problems-
  Simplifying half-plane intersections- Enabling arrangement algorithms
  in computational geometry Duality is a common trick: turn geometry
  upside-down to make it simpler.
\end{itemize}

\subsubsection{4. Geometric Data
Structures}\label{geometric-data-structures}

Recap of core spatial structures and what they're best at:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3284}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2388}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1791}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2537}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stores
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Queries
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Use Case
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
KD-Tree & Points & NN, range & Low-D search \\
R-Tree & Rectangles & Overlaps & Spatial DB \\
Quad/Octree & Space partitions & Point lookup & Graphics, GIS \\
BSP Tree & Polygons & Visibility & Rendering \\
Delaunay Triangulation & Points & Neighbors & Mesh generation \\
Segment Tree & Intervals & Range & Sweep-line events \\
\end{longtable}

\subsubsection{5. Randomized Geometry}\label{randomized-geometry}

Randomness simplifies deterministic geometry:

\begin{itemize}
\tightlist
\item
  Randomized incremental construction (Convex Hulls, Delaunay)- Random
  sampling for approximation (ε-nets, VC dimension)- Monte Carlo
  geometry for probabilistic intersection and coverage Example:
  randomized incremental convex hull builds expected ( O\(n \log n\) )
  structures with elegant proofs.
\end{itemize}

\subsubsection{6. Computational Topology}\label{computational-topology}

Beyond geometry lies shape connectivity, studied by topology. Algorithms
compute connected components, holes, homology, and Betti numbers.

Applications include:

\begin{itemize}
\tightlist
\item
  3D printing (watertightness)- Data analysis (persistent homology)-
  Robotics (free space topology) Geometry meets topology in
  alpha-shapes, simplicial complexes, and manifold reconstruction.
\end{itemize}

\subsubsection{7. Geometry Meets Machine
Learning}\label{geometry-meets-machine-learning}

Many ML methods are geometric at heart:

\begin{itemize}
\tightlist
\item
  Nearest neighbor → Voronoi diagram- SVM → hyperplane separation-
  K-means → Voronoi partitioning- Manifold learning → low-dim geometry-
  Convex optimization → geometric feasibility Visualization tools
  (t-SNE, UMAP) rely on spatial embedding and distance geometry.
\end{itemize}

\subsubsection{8. Applications Across
Fields}\label{applications-across-fields}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1875}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3438}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4688}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Field
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Application
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Geometric Core
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Graphics & Rendering, collision & Triangulation, ray tracing \\
GIS & Maps, roads & Polygons, point-in-region \\
Robotics & Path planning & Obstacles, configuration space \\
Architecture & Modeling & Mesh operations \\
Vision & Object boundaries & Contours, convexity \\
AI & Clustering, similarity & Distance metrics \\
Physics & Simulation & Particle collision \\
Databases & Spatial joins & R-Trees, indexing \\
\end{longtable}

Geometry underpins structure, position, and relationship, the backbone
of spatial reasoning.

\subsubsection{9. Complexity and Open
Problems}\label{complexity-and-open-problems}

Some problems still challenge efficient solutions:

\begin{itemize}
\tightlist
\item
  Point location in dynamic settings- Visibility graphs in complex
  polygons- Motion planning in high dimensions- Geometric median /
  center problems- Approximation guarantees in robust settings These
  remain active areas in computational geometry research.
\end{itemize}

\subsubsection{Tiny Code (Point-in-Polygon via Ray
Casting)}\label{tiny-code-point-in-polygon-via-ray-casting}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ inside}\OperatorTok{(}\NormalTok{Point p}\OperatorTok{,}\NormalTok{ Polygon poly}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ cnt }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ poly}\OperatorTok{.}\NormalTok{n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{        Point a }\OperatorTok{=}\NormalTok{ poly}\OperatorTok{[}\NormalTok{i}\OperatorTok{],}\NormalTok{ b }\OperatorTok{=}\NormalTok{ poly}\OperatorTok{[(}\NormalTok{i }\OperatorTok{+} \DecValTok{1}\OperatorTok{)} \OperatorTok{\%}\NormalTok{ poly}\OperatorTok{.}\NormalTok{n}\OperatorTok{];}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{intersect\_ray}\OperatorTok{(}\NormalTok{p}\OperatorTok{,}\NormalTok{ a}\OperatorTok{,}\NormalTok{ b}\OperatorTok{))}\NormalTok{ cnt}\OperatorTok{++;}
    \OperatorTok{\}}
    \ControlFlowTok{return}\NormalTok{ cnt }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\OperatorTok{;} \CommentTok{// odd crossings = inside}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This small routine appears everywhere, maps, games, GUIs, and physics
engines.

\subsubsection{10. Why It Matters}\label{why-it-matters-79}

Computational geometry is more than shape, it's the mathematics of
space, powering visual computing, spatial data, and intelligent systems.
Everywhere something moves, collides, maps, or recognizes form, geometry
is the invisible hand guiding it.

\begin{quote}
``All computation lives somewhere, and geometry is how we understand the
where.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-79}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement point-in-polygon and test on convex vs concave shapes.
\item
  Visualize a Delaunay triangulation and its Voronoi dual.
\item
  Experiment with KD-trees for nearest neighbor queries.
\item
  Write a small convex hull in 3D using incremental insertion.
\item
  Sketch an RRT path over a geometric map.
\end{enumerate}

\section{Chapter 9. Systems, Databases, and Distributed
Algorithms}\label{chapter-9.-systems-databases-and-distributed-algorithms-1}

\subsection{81. Concurrency Control (2PL, MVCC,
OCC)}\label{concurrency-control-2pl-mvcc-occ}

In multi-user or multi-threaded systems, many operations want to read or
write shared data at the same time. Without discipline, this leads to
chaos, lost updates, dirty reads, or even inconsistent states.

Concurrency control ensures correctness under parallelism, so that the
result is as if each transaction ran alone (a property called
serializability).

This section introduces three foundational techniques:

\begin{itemize}
\tightlist
\item
  2PL - Two-Phase Locking- MVCC - Multi-Version Concurrency Control- OCC
  - Optimistic Concurrency Control
\end{itemize}

\subsubsection{1. The Goal:
Serializability}\label{the-goal-serializability}

We want transactions to behave as if executed in some serial order, even
though they're interleaved.

A schedule is \emph{serializable} if it yields the same result as some
serial order of transactions.

Concurrency control prevents problems like:

\begin{itemize}
\tightlist
\item
  Lost Update: Two writes overwrite each other.- Dirty Read: Read
  uncommitted data.- Non-repeatable Read: Data changes mid-transaction.-
  Phantom Read: New rows appear after a query.
\end{itemize}

\subsubsection{2. Two-Phase Locking (2PL)}\label{two-phase-locking-2pl}

Idea: Use locks to coordinate access. Each transaction has two phases:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Growing phase: acquire locks (shared or exclusive)
\item
  Shrinking phase: release locks (no new locks allowed after release)
\end{enumerate}

This ensures conflict-serializability.

\subsubsection{Lock Types}\label{lock-types}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Type & Operation & Shared? & Exclusive? \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Shared (S) & Read & Yes & No \\
Exclusive (X) & Write & No & No \\
\end{longtable}

If a transaction needs to read: request S-lock. If it needs to write:
request X-lock.

Tiny Code (Lock Manager Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ acquire\_lock}\OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{T}\OperatorTok{,}\NormalTok{ Item }\OperatorTok{*}\NormalTok{X}\OperatorTok{,}\NormalTok{ LockType type}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{conflict\_exists}\OperatorTok{(}\NormalTok{X}\OperatorTok{,}\NormalTok{ type}\OperatorTok{))}
\NormalTok{        wait}\OperatorTok{();}
\NormalTok{    add\_lock}\OperatorTok{(}\NormalTok{X}\OperatorTok{,}\NormalTok{ T}\OperatorTok{,}\NormalTok{ type}\OperatorTok{);}
\OperatorTok{\}}

\DataTypeTok{void}\NormalTok{ release\_all}\OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{T}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Lock }\OperatorTok{*}\NormalTok{l in T}\OperatorTok{{-}\textgreater{}}\NormalTok{locks}\OperatorTok{)}
\NormalTok{        unlock}\OperatorTok{(}\NormalTok{l}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Example}\label{example-14}

\begin{verbatim}
T1: read(A); write(A)
T2: read(A); write(A)
\end{verbatim}

Without locks → race condition. With 2PL → one must wait → consistent.

\subsubsection{Variants}\label{variants-4}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2703}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7297}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strict 2PL & Holds all locks until commit → avoids cascading aborts \\
Rigorous 2PL & Same as Strict, all locks released at end \\
Conservative 2PL & Acquires all locks before execution \\
\end{longtable}

\subsubsection{Pros \& Cons}\label{pros-cons-4}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Guarantees serializability & Can cause deadlocks \\
Simple concept & Blocking, contention under load \\
\end{longtable}

\subsubsection{3. Multi-Version Concurrency Control
(MVCC)}\label{multi-version-concurrency-control-mvcc}

Idea: Readers don't block writers, and writers don't block readers. Each
write creates a new version of data with a timestamp.

Transactions read from a consistent snapshot based on their start time.

\subsubsection{Snapshot Isolation}\label{snapshot-isolation}

\begin{itemize}
\item
  Readers see the latest committed version at transaction start.-
  Writers produce new versions; conflicts detected at commit time. Each
  record stores:
\item
  \texttt{value}- \texttt{created\_at}- \texttt{deleted\_at} (if
  applicable)
\end{itemize}

Tiny Code (Version Chain)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ Version }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ value}\OperatorTok{;}
\NormalTok{    Timestamp created}\OperatorTok{;}
\NormalTok{    Timestamp deleted}\OperatorTok{;}
\NormalTok{    Version }\OperatorTok{*}\NormalTok{next}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

Read finds version with
\texttt{created\ \textless{}=\ tx.start\ \&\&\ deleted\ \textgreater{}\ tx.start}.

\subsubsection{Pros \& Cons}\label{pros-cons-5}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
No read locks & Higher memory (multiple versions) \\
Readers never block & Write conflicts at commit \\
Great for OLTP systems & GC of old versions needed \\
\end{longtable}

\subsubsection{Used In}\label{used-in}

\begin{itemize}
\tightlist
\item
  PostgreSQL- Oracle- MySQL (InnoDB)- Spanner
\end{itemize}

\subsubsection{4. Optimistic Concurrency Control
(OCC)}\label{optimistic-concurrency-control-occ}

Idea: Assume conflicts are rare. Let transactions run without locks. At
commit time, validate, if conflicts exist, rollback.

\subsubsection{Phases}\label{phases}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Read phase - execute, read data, buffer writes.
\item
  Validation phase - check if conflicts occurred.
\item
  Write phase - apply changes if valid, else abort.
\end{enumerate}

Tiny Code (OCC Validation)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ validate}\OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{T}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Transaction }\OperatorTok{*}\NormalTok{U in committed\_since}\OperatorTok{(}\NormalTok{T}\OperatorTok{.}\NormalTok{start}\OperatorTok{))}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{conflict}\OperatorTok{(}\NormalTok{T}\OperatorTok{,}\NormalTok{ U}\OperatorTok{))}
            \ControlFlowTok{return} \KeywordTok{false}\OperatorTok{;}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros \& Cons}\label{pros-cons-6}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pros & Cons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
No locks → no deadlocks & High abort rate under contention \\
Great for low-conflict workloads & Wasted work on abort \\
\end{longtable}

\subsubsection{Used In}\label{used-in-1}

\begin{itemize}
\tightlist
\item
  In-memory DBs- Distributed systems- STM (Software Transactional
  Memory)
\end{itemize}

\subsubsection{5. Choosing a Strategy}\label{choosing-a-strategy}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
System Type & Preferred Control \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
OLTP (many reads/writes) & MVCC \\
OLAP (read-heavy) & MVCC or OCC \\
Real-time systems & 2PL (predictable) \\
Low contention & OCC \\
High contention & 2PL / MVCC \\
\end{longtable}

\subsubsection{6. Why It Matters}\label{why-it-matters-80}

Concurrency control is the backbone of consistency in databases,
distributed systems, and even multi-threaded programs. It enforces
correctness amid chaos, ensuring your data isn't silently corrupted.

\begin{quote}
``Without order, parallelism is noise. Concurrency control is its
conductor.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-80}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate 2PL with two transactions updating shared data.
\item
  Implement a toy MVCC table with version chains.
\item
  Write an OCC validator for three concurrent transactions.
\item
  Experiment: under high conflict, which model performs best?
\end{enumerate}

\subsection{82. Logging, Recovery, and Commit
Protocols}\label{logging-recovery-and-commit-protocols}

No matter how elegant your algorithms or how fast your storage, failures
happen. Power cuts, crashes, and network splits are inevitable. What
matters is recovery, restoring the system to a consistent state without
losing committed work.

Logging, recovery, and commit protocols form the backbone of reliable
transactional systems, ensuring durability and correctness in the face
of crashes.

\subsubsection{1. The Problem}\label{the-problem-2}

We need to guarantee the ACID properties:

\begin{itemize}
\tightlist
\item
  Atomicity - all or nothing- Consistency - valid before and after-
  Isolation - no interference- Durability - once committed, always safe
  If a crash occurs mid-transaction, how do we roll back or redo
  correctly?
\end{itemize}

The answer: Log everything, then replay or undo after failure.

\subsubsection{2. Write-Ahead Logging
(WAL)}\label{write-ahead-logging-wal}

The golden rule:

\begin{quote}
``Write log entries before modifying the database.''
\end{quote}

Every action is recorded in a sequential log on disk, ensuring the
system can reconstruct the state.

\subsubsection{Log Record Format}\label{log-record-format}

Each log entry typically includes:

\begin{itemize}
\tightlist
\item
  \texttt{LSN} (Log Sequence Number)- \texttt{Transaction\ ID}-
  \texttt{Operation} (update, insert, delete)- \texttt{Before\ image}
  (old value)- \texttt{After\ image} (new value)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct}\NormalTok{ LogEntry }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ lsn}\OperatorTok{;}
    \DataTypeTok{int}\NormalTok{ tx\_id}\OperatorTok{;}
    \DataTypeTok{char}\NormalTok{ op}\OperatorTok{[}\DecValTok{10}\OperatorTok{];}
\NormalTok{    Value before}\OperatorTok{,}\NormalTok{ after}\OperatorTok{;}
\OperatorTok{\};}
\end{Highlighting}
\end{Shaded}

When a transaction commits, the system first flushes logs to disk
(\texttt{fsync}). Only then is the commit acknowledged.

\subsubsection{3. Recovery Actions}\label{recovery-actions}

When the system restarts, it reads logs and applies a recovery
algorithm.

\subsubsection{Three Phases (ARIES
Model)}\label{three-phases-aries-model}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Analysis - determine state at crash (active vs committed)
\item
  Redo - repeat all actions from last checkpoint
\item
  Undo - rollback incomplete transactions
\end{enumerate}

ARIES (Algorithm for Recovery and Isolation Exploiting Semantics) is the
most widely used approach (IBM DB2, PostgreSQL, SQL Server).

\subsubsection{Redo Rule}\label{redo-rule}

If the system committed before crash → redo all updates so data is
preserved.

\subsubsection{Undo Rule}\label{undo-rule}

If the system didn't commit → undo to maintain atomicity.

Tiny Code (Simplified Recovery Sketch)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ recover}\OperatorTok{(}\NormalTok{Log log}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{Entry e }\OperatorTok{:}\NormalTok{ log}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{committed}\OperatorTok{)}
\NormalTok{            apply}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{after}\OperatorTok{);}
        \ControlFlowTok{else}
\NormalTok{            apply}\OperatorTok{(}\NormalTok{e}\OperatorTok{.}\NormalTok{before}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Checkpointing}\label{checkpointing}

Instead of replaying the entire log, systems take checkpoints, periodic
snapshots marking a safe state.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2985}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7015}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sharp checkpoint & Stop all transactions briefly, flush data + log \\
Fuzzy checkpoint & Mark consistent LSN; continue running \\
\end{longtable}

Checkpoints reduce recovery time: only replay after the last checkpoint.

\subsubsection{5. Commit Protocols}\label{commit-protocols}

In distributed systems, multiple nodes must agree to commit or abort
together. This is handled by atomic commit protocols.

\subsubsection{Two-Phase Commit (2PC)}\label{two-phase-commit-2pc}

Goal: All participants either commit or abort in unison.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Prepare phase (voting):

  \begin{itemize}
  \item
    Coordinator asks all participants to ``prepare'' - Each replies
    yes/no2. Commit phase (decision):
  \item
    If all say yes → commit - Else → abort
  \end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Coordinator: PREPARE  }
\NormalTok{Participants: VOTE YES / NO  }
\NormalTok{Coordinator: COMMIT / ABORT}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

If the coordinator crashes after prepare, participants must wait →
blocking protocol.

Tiny Code (2PC Pseudocode)

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{bool}\NormalTok{ two\_phase\_commit}\OperatorTok{(}\NormalTok{Participants P}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for}\NormalTok{ each p in P}\OperatorTok{:}
        \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{p}\OperatorTok{.}\NormalTok{prepare}\OperatorTok{())} \ControlFlowTok{return}\NormalTok{ abort\_all}\OperatorTok{();}
    \ControlFlowTok{for}\NormalTok{ each p in P}\OperatorTok{:}
\NormalTok{        p}\OperatorTok{.}\NormalTok{commit}\OperatorTok{();}
    \ControlFlowTok{return} \KeywordTok{true}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Three-Phase Commit (3PC)}\label{three-phase-commit-3pc}

Improves on 2PC by adding an intermediate phase to avoid indefinite
blocking. More complex, used in systems with reliable failure detection.

\subsubsection{6. Logging in Distributed
Systems}\label{logging-in-distributed-systems}

Each participant maintains its own WAL. To recover globally:

\begin{itemize}
\tightlist
\item
  Use coordinated checkpoints- Maintain global commit logs-
  Consensus-based protocols (Paxos Commit, Raft) can replace 2PC for
  high availability
\end{itemize}

\subsubsection{7. Example Timeline}\label{example-timeline}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Action \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
T1 updates record A & WAL entry written \\
T1 updates record B & WAL entry written \\
T1 commits & WAL flush, commit record \\
Crash! & Disk may be inconsistent \\
Restart & Recovery scans log, redoes T1 \\
\end{longtable}

\subsubsection{8. Pros and Cons}\label{pros-and-cons}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Approach & Strength & Weakness \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
WAL & Simple, durable & Write overhead \\
Checkpointing & Faster recovery & I/O spikes \\
2PC & Global atomicity & Blocking \\
3PC / Consensus & Non-blocking & Complex, slower \\
\end{longtable}

\subsubsection{9. Real Systems}\label{real-systems}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
System & Strategy \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
PostgreSQL & WAL + ARIES + Checkpoint \\
MySQL (InnoDB) & WAL + Fuzzy checkpoint \\
Spanner & WAL + 2PC + TrueTime \\
Kafka & WAL for durability \\
RocksDB & WAL + LSM checkpoints \\
\end{longtable}

\subsubsection{10. Why It Matters}\label{why-it-matters-81}

Logging and commit protocols make data survive crashes and stay
consistent across machines. Without them, every failure risks
corruption.

\begin{quote}
``Persistence is not about never failing, it's about remembering how to
stand back up.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-81}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a toy WAL system that logs before writes.
\item
  Simulate a crash mid-transaction and replay the log.
\item
  Implement a simple 2PC coordinator with two participants.
\item
  Compare recovery time with vs without checkpoints.
\end{enumerate}

\subsection{83. Scheduling (Round Robin, EDF,
Rate-Monotonic)}\label{scheduling-round-robin-edf-rate-monotonic}

In operating systems and real-time systems, scheduling determines the
order in which tasks or processes run. Since resources like CPU time are
limited, a good scheduler aims to balance fairness, efficiency, and
responsiveness.

\subsubsection{1. The Goal of Scheduling}\label{the-goal-of-scheduling}

Every system has tasks competing for the CPU. Scheduling decides:

\begin{itemize}
\tightlist
\item
  Which task runs next- How long it runs- When it yields or preempts
  Different goals apply in different domains:
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Domain & Objective \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
General-purpose OS & Fairness, responsiveness \\
Real-time systems & Meeting deadlines \\
Embedded systems & Predictability \\
High-performance servers & Throughput, latency balance \\
\end{longtable}

A scheduler's policy can be preemptive (interrupts tasks) or
non-preemptive (waits for voluntary yield).

\subsubsection{2. Round Robin Scheduling}\label{round-robin-scheduling}

Round Robin (RR) is one of the simplest preemptive schedulers. Each
process gets a fixed time slice (quantum) and runs in a circular queue.

If a process doesn't finish, it's put back at the end of the queue.

\subsubsection{Tiny Code: Round Robin
(Pseudocode)}\label{tiny-code-round-robin-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{queue processes}\OperatorTok{;}
\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{empty}\OperatorTok{(}\NormalTok{processes}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{    process }\OperatorTok{=}\NormalTok{ dequeue}\OperatorTok{(}\NormalTok{processes}\OperatorTok{);}
\NormalTok{    run\_for\_quantum}\OperatorTok{(}\NormalTok{process}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{process}\OperatorTok{.}\NormalTok{finished}\OperatorTok{)}
\NormalTok{        enqueue}\OperatorTok{(}\NormalTok{processes}\OperatorTok{,}\NormalTok{ process}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Characteristics}\label{characteristics}

\begin{itemize}
\tightlist
\item
  Fair: Every process gets CPU time.- Responsive: Short tasks don't
  starve.- Downside: Context switching overhead if quantum is too small.
  \#\#\#\# Example
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Process & Burst Time & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
P1 & 4 & \\
P2 & 3 & \\
P3 & 2 & \\
\end{longtable}

Quantum = 1 Order: P1, P2, P3, P1, P2, P3, P1, P2 → all finish fairly.

\subsubsection{3. Priority Scheduling}\label{priority-scheduling}

Each task has a priority. The scheduler always picks the
highest-priority ready task.

\begin{itemize}
\item
  Preemptive: A higher-priority task can interrupt a lower one.-
  Non-preemptive: The CPU is released voluntarily. \#\#\#\# Problems
\item
  Starvation: Low-priority tasks may never run.- Solution: Aging -
  gradually increase waiting task priority.
\end{itemize}

\subsubsection{4. Earliest Deadline First
(EDF)}\label{earliest-deadline-first-edf}

EDF is a dynamic priority scheduler for real-time systems. Each task has
a deadline, and the task with the earliest deadline runs first.

\subsubsection{Rule}\label{rule}

At any time, run the ready task with the closest deadline.

\subsubsection{Example}\label{example-15}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Task & Execution Time & Deadline \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
T1 & 1 & 3 \\
T2 & 2 & 5 \\
T3 & 1 & 2 \\
\end{longtable}

Order: T3 → T1 → T2

EDF is optimal for preemptive scheduling of independent tasks on a
single processor.

\subsubsection{5. Rate-Monotonic Scheduling
(RMS)}\label{rate-monotonic-scheduling-rms}

In periodic real-time systems, tasks repeat at fixed intervals. RMS
assigns higher priority to tasks with shorter periods.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Task & Period & Priority \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
T1 & 2 ms & High \\
T2 & 5 ms & Medium \\
T3 & 10 ms & Low \\
\end{longtable}

It's static (priorities don't change) and optimal among fixed-priority
schedulers.

\subsubsection{Utilization Bound}\label{utilization-bound}

For n tasks, RMS is guaranteed schedulable if:

\[
U = \sum_{i=1}^{n} \frac{C_i}{T_i} \le n(2^{1/n} - 1)
\]

For example, for 3 tasks, \(U \le 0.78\).

\subsubsection{6. Shortest Job First
(SJF)}\label{shortest-job-first-sjf}

Run the task with the shortest burst time first.

\begin{itemize}
\tightlist
\item
  Non-preemptive SJF: Once started, runs to completion.- Preemptive SJF
  (Shortest Remaining Time First): Preempts if a shorter job arrives.
  Advantage: Minimizes average waiting time. Disadvantage: Needs
  knowledge of future job lengths.
\end{itemize}

\subsubsection{7. Multilevel Queue
Scheduling}\label{multilevel-queue-scheduling}

Divide processes into classes (interactive, batch, system). Each class
has its own queue with own policy, e.g.:

\begin{itemize}
\tightlist
\item
  Queue 1: System → RR (quantum = 10ms)- Queue 2: Interactive → RR
  (quantum = 50ms)- Queue 3: Batch → FCFS (First-Come-First-Serve) CPU
  is assigned based on queue priority.
\end{itemize}

\subsubsection{8. Multilevel Feedback Queue
(MLFQ)}\label{multilevel-feedback-queue-mlfq}

Processes move between queues based on behavior.

\begin{itemize}
\tightlist
\item
  CPU-bound → move down (lower priority)- I/O-bound → move up (higher
  priority) Goal: Adaptive scheduling that rewards interactive tasks.
\end{itemize}

Used in modern OS kernels (Linux, Windows).

\subsubsection{9. Scheduling Metrics}\label{scheduling-metrics}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Metric & Meaning \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Turnaround Time & Completion − Arrival \\
Waiting Time & Time spent in ready queue \\
Response Time & Time from arrival to first execution \\
Throughput & Completed tasks per unit time \\
CPU Utilization & \% of time CPU is busy \\
\end{longtable}

Schedulers balance these based on design goals.

\subsubsection{10. Why It Matters}\label{why-it-matters-82}

Schedulers shape how responsive, efficient, and fair a system feels. In
operating systems, they govern multitasking. In real-time systems, they
ensure deadlines are met. In servers, they keep latency low and
throughput high.

\begin{quote}
``Scheduling is not just about time. It's about fairness, foresight, and
flow.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-82}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate Round Robin with quantum = 2, compare average waiting time.
\item
  Implement EDF for a set of periodic tasks with deadlines.
\item
  Check schedulability under RMS for 3 periodic tasks.
\item
  Explore Linux CFS (Completely Fair Scheduler) source code.
\item
  Compare SJF and RR for CPU-bound vs I/O-bound workloads.
\end{enumerate}

\subsection{84. Caching and Replacement (LRU, LFU,
CLOCK)}\label{caching-and-replacement-lru-lfu-clock}

Caching is the art of remembering the past to speed up the future. In
computing, caches store recently used or frequently accessed data to
reduce latency and load on slower storage (like disks or networks). The
challenge: caches have limited capacity, so when full, we must decide
what to evict. That's where replacement policies come in.

\subsubsection{1. The Need for Caching}\label{the-need-for-caching}

Caches appear everywhere:

\begin{itemize}
\item
  CPU: L1, L2, L3 caches speed up memory access- Databases: query
  results or index pages- Web browsers / CDNs: recently fetched pages-
  Operating systems: page cache for disk blocks The principle guiding
  all caches is locality:
\item
  Temporal locality: recently used items are likely used again soon-
  Spatial locality: nearby items are likely needed next
\end{itemize}

\subsubsection{2. Cache Replacement
Problem}\label{cache-replacement-problem}

When the cache is full, which item should we remove?

We want to minimize cache misses (requests not found in cache).

Formally:

\begin{quote}
Given a sequence of accesses, find a replacement policy that minimizes
misses.
\end{quote}

Theoretical optimal policy (OPT): always evict the item used farthest in
the future. But OPT requires future knowledge, so we rely on heuristics
like LRU, LFU, CLOCK.

\subsubsection{3. Least Recently Used
(LRU)}\label{least-recently-used-lru}

LRU evicts the least recently accessed item. It assumes recently used =
likely to be used again.

\subsubsection{Implementation
Approaches}\label{implementation-approaches}

\begin{itemize}
\tightlist
\item
  Stack (list): move item to top on access- Hash map + doubly linked
  list: \texttt{O(1)} insert, delete, lookup \#\#\#\# Tiny Code: LRU
  (Simplified)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{typedef} \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ key}\OperatorTok{;}
    \KeywordTok{struct}\NormalTok{ Node }\OperatorTok{*}\NormalTok{prev}\OperatorTok{,} \OperatorTok{*}\NormalTok{next}\OperatorTok{;}
\OperatorTok{\}}\NormalTok{ Node}\OperatorTok{;}

\NormalTok{HashMap cache}\OperatorTok{;}
\NormalTok{List lru\_list}\OperatorTok{;}

\DataTypeTok{void}\NormalTok{ access}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ key}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{in\_cache}\OperatorTok{(}\NormalTok{key}\OperatorTok{))}\NormalTok{ move\_to\_front}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \ControlFlowTok{else} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cache\_full}\OperatorTok{())}\NormalTok{ remove\_lru}\OperatorTok{();}
\NormalTok{        insert\_front}\OperatorTok{(}\NormalTok{key}\OperatorTok{);}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros}\label{pros}

\begin{itemize}
\item
  Good for workloads with strong temporal locality \#\#\#\# Cons
\item
  Costly in hardware or massive caches (metadata overhead)
\end{itemize}

\subsubsection{4. Least Frequently Used
(LFU)}\label{least-frequently-used-lfu}

LFU evicts the least frequently accessed item.

Tracks usage count for each item:

\begin{itemize}
\tightlist
\item
  Increment on each access- Evict lowest-count item \#\#\#\# Example
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Item & Accesses & Frequency \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 3 & 3 \\
B & 1 & 1 \\
C & 2 & 2 \\
\end{longtable}

Evict B.

\subsubsection{Variants}\label{variants-5}

\begin{itemize}
\item
  LFU with aging: gradually reduce counts to adapt to new trends-
  Approximate LFU: counters in ranges (for memory efficiency) \#\#\#\#
  Pros
\item
  Great for stable, repetitive workloads \#\#\#\# Cons
\item
  Poor for workloads with shifting popularity (slow adaptation)
\end{itemize}

\subsubsection{5. FIFO (First In First
Out)}\label{fifo-first-in-first-out}

Simple but naive:

\begin{itemize}
\tightlist
\item
  Evict the oldest item, ignoring usage Used in simple hardware caches.
  Good when access pattern is cyclic, bad otherwise.
\end{itemize}

\subsubsection{6. Random Replacement (RR)}\label{random-replacement-rr}

Evict a random entry.

Surprisingly competitive in some high-concurrency systems, and trivial
to implement. Used in memcached (as an option).

\subsubsection{7. CLOCK Algorithm}\label{clock-algorithm}

A practical approximation of LRU, widely used in OS page replacement.

Each page has a reference bit (R). Pages form a circular list.

Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clock hand sweeps over pages.
\item
  If \texttt{R\ =\ 0}, evict page.
\item
  If \texttt{R\ =\ 1}, set \texttt{R\ =\ 0} and skip.
\end{enumerate}

This mimics LRU with O(1) cost and low overhead.

\subsubsection{8. Second-Chance and Enhanced
CLOCK}\label{second-chance-and-enhanced-clock}

Second-Chance: give recently used pages a ``second chance'' before
eviction. Enhanced CLOCK: also uses modify bit (M) to prefer clean
pages.

Used in Linux's page replacement (with Active/Inactive lists).

\subsubsection{9. Adaptive Algorithms}\label{adaptive-algorithms}

Modern systems use hybrid or adaptive policies:

\begin{itemize}
\tightlist
\item
  ARC (Adaptive Replacement Cache) - balances recency and frequency- CAR
  (Clock with Adaptive Replacement) - CLOCK-style adaptation- TinyLFU -
  frequency sketch + admission policy- Hyperbolic caching - popularity
  decay for large-scale systems These adapt dynamically to changing
  workloads.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-83}

Caching is the backbone of system speed:

\begin{itemize}
\tightlist
\item
  OS uses it for paging- Databases for buffer pools- CPUs for memory
  hierarchies- CDNs for global acceleration Choosing the right eviction
  policy can mean orders of magnitude improvement in latency and
  throughput.
\end{itemize}

\begin{quote}
``A good cache remembers what matters, and forgets what no longer
does.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-83}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate a cache of size 3 with sequence: A B C A B D A B C D Compare
  LRU, LFU, and FIFO miss counts.
\item
  Implement LRU with a doubly-linked list and hash map in C.
\item
  Try CLOCK with reference bits, simulate a sweep.
\item
  Experiment with ARC and TinyLFU for dynamic workloads.
\item
  Measure hit ratios for different access patterns (sequential, random,
  looping).
\end{enumerate}

\subsection{85. Networking (Routing, Congestion
Control)}\label{networking-routing-congestion-control}

Networking algorithms make sure data finds its way through vast,
connected systems, efficiently, reliably, and fairly. Two core pillars
of network algorithms are routing (deciding \emph{where} packets go) and
congestion control (deciding \emph{how fast} to send them).

Together, they ensure the internet functions under heavy load, dynamic
topology, and unpredictable demand.

\subsubsection{1. The Goals of Networking
Algorithms}\label{the-goals-of-networking-algorithms}

\begin{itemize}
\tightlist
\item
  Correctness: all destinations are reachable if paths exist-
  Efficiency: use minimal resources (bandwidth, latency, hops)-
  Scalability: support large, dynamic networks- Robustness: recover from
  failures- Fairness: avoid starving flows
\end{itemize}

\subsubsection{2. Types of Routing}\label{types-of-routing}

Routing decides paths packets should follow through a graph-like
network.

\subsubsection{Static vs Dynamic
Routing}\label{static-vs-dynamic-routing}

\begin{itemize}
\item
  Static: fixed routes, manual configuration (good for small networks)-
  Dynamic: routes adjust automatically as topology changes
  (internet-scale) \#\#\#\# Unicast, Multicast, Broadcast
\item
  Unicast: one-to-one (most traffic)- Multicast: one-to-many (video
  streaming, gaming)- Broadcast: one-to-all (local networks)
\end{itemize}

\subsubsection{3. Shortest Path Routing}\label{shortest-path-routing}

Most routing relies on shortest path algorithms:

\subsubsection{Dijkstra's Algorithm}\label{dijkstras-algorithm-1}

\begin{itemize}
\item
  Builds shortest paths from one source- Complexity:
  \texttt{O(E\ log\ V)} with priority queue Used in:
\item
  OSPF (Open Shortest Path First)- IS-IS (Intermediate System to
  Intermediate System) \#\#\#\# Bellman-Ford Algorithm
\item
  Handles negative edges- Basis for Distance-Vector routing (RIP)
  \#\#\#\# Tiny Code: Dijkstra for Routing
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#define INF }\FloatTok{1e9}
\DataTypeTok{int}\NormalTok{ dist}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{],}\NormalTok{ visited}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}
\NormalTok{vector}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ adj}\OperatorTok{[}\NormalTok{MAX}\OperatorTok{];}

\DataTypeTok{void}\NormalTok{ dijkstra}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ s}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}\NormalTok{ dist}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ INF}\OperatorTok{;}
\NormalTok{    dist}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{    priority\_queue}\OperatorTok{\textless{}}\NormalTok{pair}\OperatorTok{\textless{}}\DataTypeTok{int}\OperatorTok{,}\DataTypeTok{int}\OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ pq}\OperatorTok{;}
\NormalTok{    pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\DecValTok{0}\OperatorTok{,}\NormalTok{ s}\OperatorTok{\});}
    \ControlFlowTok{while} \OperatorTok{(!}\NormalTok{pq}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
        \DataTypeTok{int}\NormalTok{ u }\OperatorTok{=}\NormalTok{ pq}\OperatorTok{.}\NormalTok{top}\OperatorTok{().}\NormalTok{second}\OperatorTok{;}\NormalTok{ pq}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \ControlFlowTok{continue}\OperatorTok{;}
\NormalTok{        visited}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{=} \DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\KeywordTok{auto} \OperatorTok{[}\NormalTok{v}\OperatorTok{,}\NormalTok{ w}\OperatorTok{]:}\NormalTok{ adj}\OperatorTok{[}\NormalTok{u}\OperatorTok{])} \OperatorTok{\{}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{\textgreater{}}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{                dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{]} \OperatorTok{=}\NormalTok{ dist}\OperatorTok{[}\NormalTok{u}\OperatorTok{]} \OperatorTok{+}\NormalTok{ w}\OperatorTok{;}
\NormalTok{                pq}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{{-}}\NormalTok{dist}\OperatorTok{[}\NormalTok{v}\OperatorTok{],}\NormalTok{ v}\OperatorTok{\});}
            \OperatorTok{\}}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Distance-Vector vs
Link-State}\label{distance-vector-vs-link-state}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Distance-Vector (RIP) & Link-State (OSPF) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Info Shared & Distance to neighbors & Full topology map \\
Convergence & Slower (loops possible) & Fast (SPF computation) \\
Complexity & Lower & Higher \\
Examples & RIP, BGP (conceptually) & OSPF, IS-IS \\
\end{longtable}

RIP uses Bellman-Ford. OSPF floods link-state updates, runs Dijkstra at
each node.

\subsubsection{5. Hierarchical Routing}\label{hierarchical-routing}

Large-scale networks (like the Internet) use hierarchical routing:

\begin{itemize}
\tightlist
\item
  Routers grouped into Autonomous Systems (AS)- Intra-AS routing: OSPF,
  IS-IS- Inter-AS routing: BGP (Border Gateway Protocol) BGP exchanges
  reachability info, not shortest paths, and prefers policy-based
  routing (e.g., cost, contracts, peering).
\end{itemize}

\subsubsection{6. Congestion Control}\label{congestion-control}

Even with good routes, we can't flood links. Congestion control ensures
fair and efficient use of bandwidth.

Implemented primarily at the transport layer (TCP).

\subsubsection{TCP Congestion Control}\label{tcp-congestion-control}

Key components:

\begin{itemize}
\item
  Additive Increase, Multiplicative Decrease (AIMD)- Slow Start: probe
  capacity- Congestion Avoidance: grow cautiously- Fast Retransmit /
  Recovery Modern variants:
\item
  TCP Reno: classic AIMD- TCP Cubic: non-linear growth for high-speed
  networks- BBR (Bottleneck Bandwidth + RTT): model-based control
  \#\#\#\# Algorithm Sketch (AIMD)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{On ACK: cwnd += 1/cwnd  // increase slowly}
\NormalTok{On loss: cwnd /= 2      // halve window}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Queue Management}\label{queue-management}

Routers maintain queues. Too full? =\textgreater{} Packet loss, latency
spikes, tail drop.

Solutions:

\begin{itemize}
\tightlist
\item
  RED (Random Early Detection) - drop packets early- CoDel (Controlled
  Delay) - monitor queue delay, drop adaptively These prevent
  bufferbloat, improving latency for real-time traffic.
\end{itemize}

\subsubsection{8. Flow Control vs Congestion
Control}\label{flow-control-vs-congestion-control}

\begin{itemize}
\tightlist
\item
  Flow Control: prevent sender from overwhelming receiver- Congestion
  Control: prevent sender from overwhelming network TCP uses both:
  receive window (rwnd) and congestion window (cwnd). Actual sending
  rate = \texttt{min(rwnd,\ cwnd)}.
\end{itemize}

\subsubsection{9. Data Plane vs Control
Plane}\label{data-plane-vs-control-plane}

\begin{itemize}
\item
  Control Plane: decides routes (OSPF, BGP)- Data Plane: forwards
  packets (fast path) Modern networking (e.g.~SDN, Software Defined
  Networking) separates these:
\item
  Controller computes routes- Switches act on flow rules
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-84}

Routing and congestion control shape the performance of:

\begin{itemize}
\tightlist
\item
  The Internet backbone- Data center networks (with load balancing)-
  Cloud services and microservice meshes- Content delivery networks
  (CDNs) Every packet's journey, from your laptop to a global data
  center, relies on these ideas.
\end{itemize}

\begin{quote}
``Networking is not magic. It's algorithms moving data through time and
space.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-84}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Dijkstra's algorithm for a small network graph.
\item
  Simulate RIP (Distance Vector): each node updates from neighbors.
\item
  Model TCP AIMD window growth; visualize with Python.
\item
  Try RED: drop packets when queue length \textgreater{} threshold.
\item
  Compare TCP Reno, Cubic, BBR throughput in simulation.
\end{enumerate}

\subsection{86. Distributed Consensus (Paxos, Raft,
PBFT)}\label{distributed-consensus-paxos-raft-pbft}

In a distributed system, multiple nodes must agree on a single value,
for example, the state of a log, a database entry, or a blockchain
block. This agreement process is called consensus.

Consensus algorithms let distributed systems act as one reliable system,
even when some nodes fail, crash, or lie (Byzantine faults).

\subsubsection{1. Why Consensus?}\label{why-consensus}

Imagine a cluster managing a shared log (like in databases or Raft).
Each node might:

\begin{itemize}
\tightlist
\item
  See different requests,- Fail and recover,- Communicate over
  unreliable links. We need all non-faulty nodes to agree on the same
  order of operations.
\end{itemize}

A valid consensus algorithm must satisfy:

\begin{itemize}
\tightlist
\item
  Agreement: all correct nodes choose the same value- Validity: the
  chosen value was proposed by a node- Termination: every correct node
  eventually decides- Fault Tolerance: works despite failures
\end{itemize}

\subsubsection{2. The FLP Impossibility}\label{the-flp-impossibility}

The FLP theorem (Fischer, Lynch, Paterson, 1985) says:

\begin{quote}
In an asynchronous system with even one faulty process, no deterministic
algorithm can guarantee consensus.
\end{quote}

So practical algorithms use:

\begin{itemize}
\tightlist
\item
  Randomization, or- Partial synchrony (timeouts, retries)
\end{itemize}

\subsubsection{3. Paxos: The Classical
Algorithm}\label{paxos-the-classical-algorithm}

Paxos, by Leslie Lamport, is the theoretical foundation for distributed
consensus.

It revolves around three roles:

\begin{itemize}
\tightlist
\item
  Proposers: suggest values- Acceptors: vote on proposals- Learners:
  learn the final decision Consensus proceeds in two phases.
\end{itemize}

\subsubsection{Phase 1 (Prepare)}\label{phase-1-prepare}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Proposer picks a proposal number \texttt{n} and sends
  \texttt{(Prepare,\ n)} to acceptors.
\item
  Acceptors respond with their highest accepted proposal (if any).
\end{enumerate}

\subsubsection{Phase 2 (Accept)}\label{phase-2-accept}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If proposer receives a majority of responses, it sends
  \texttt{(Accept,\ n,\ v)} with value \texttt{v} (highest seen or new).
\item
  Acceptors accept if they haven't promised higher \texttt{n}.
\end{enumerate}

When a majority accept, value \texttt{v} is chosen.

\subsubsection{Guarantees}\label{guarantees}

\begin{itemize}
\item
  Safety: no two different values chosen- Liveness: possible under
  stable leadership \#\#\#\# Drawbacks
\item
  Complex to implement correctly- High messaging overhead \textgreater{}
  ``Paxos is for theorists; Raft is for engineers.''
\end{itemize}

\subsubsection{4. Raft: Understandable
Consensus}\label{raft-understandable-consensus}

Raft was designed to be simpler and more practical than Paxos, focusing
on replicated logs.

\subsubsection{Roles}\label{roles}

\begin{itemize}
\tightlist
\item
  Leader: coordinates all changes- Followers: replicate leader's log-
  Candidates: during elections \#\#\#\# Workflow
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Leader Election

  \begin{itemize}
  \item
    Timeout triggers candidate election. - Each follower votes; majority
    wins.2. Log Replication
  \item
    Leader appends entries, sends \texttt{AppendEntries} RPCs. -
    Followers acknowledge; leader commits when majority ack.3. Safety
  \item
    Logs are consistent across majority. - Followers accept only valid
    prefixes. Raft ensures:
  \end{itemize}
\end{enumerate}

\begin{itemize}
\tightlist
\item
  At most one leader per term- Committed entries never lost- Logs stay
  consistent \#\#\#\# Pseudocode Sketch
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{on timeout }\OperatorTok{{-}\textgreater{}}\NormalTok{ become\_candidate}\OperatorTok{()}
\NormalTok{send RequestVote}\OperatorTok{(}\NormalTok{term}\OperatorTok{,}\NormalTok{ id}\OperatorTok{)}
\ControlFlowTok{if}\NormalTok{ majority\_votes }\OperatorTok{{-}\textgreater{}}\NormalTok{ become\_leader}\OperatorTok{()}

\NormalTok{on AppendEntries}\OperatorTok{(}\NormalTok{term}\OperatorTok{,}\NormalTok{ entries}\OperatorTok{):}
    \ControlFlowTok{if}\NormalTok{ term }\OperatorTok{\textgreater{}=}\NormalTok{ current\_term}\OperatorTok{:}
\NormalTok{        append}\OperatorTok{(}\NormalTok{entries}\OperatorTok{)}
\NormalTok{        reply success}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. PBFT: Byzantine Fault
Tolerance}\label{pbft-byzantine-fault-tolerance}

Paxos and Raft assume crash faults (nodes stop, not lie). For Byzantine
faults (arbitrary behavior), we use PBFT (Practical Byzantine Fault
Tolerance).

Tolerates up to \texttt{f} faulty nodes out of \texttt{3f\ +\ 1} total.

\subsubsection{Phases}\label{phases-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pre-Prepare: Leader proposes value
\item
  Prepare: Nodes broadcast proposal hashes
\item
  Commit: Nodes confirm receipt by 2f+1 votes
\end{enumerate}

Used in blockchains and critical systems (space, finance).

\subsubsection{6. Quorum Concept}\label{quorum-concept}

Consensus often relies on quorums (majorities):

\begin{itemize}
\item
  Two quorums always intersect, ensuring consistency.- Write quorum +
  read quorum ≥ total nodes. In Raft/Paxos:
\item
  Majority = \texttt{N/2\ +\ 1}- Guarantees overlap even if some nodes
  fail.
\end{itemize}

\subsubsection{7. Log Replication and State
Machines}\label{log-replication-and-state-machines}

Consensus underlies Replicated State Machines (RSM):

\begin{itemize}
\item
  Every node applies the same commands in the same order.- Guarantees
  deterministic, identical states. This model powers:
\item
  Databases (etcd, Spanner, TiKV)- Coordination systems (ZooKeeper,
  Consul)- Kubernetes control planes
\end{itemize}

\subsubsection{8. Leader Election}\label{leader-election}

All practical consensus systems need leaders:

\begin{itemize}
\item
  Simplifies coordination- Reduces conflicts- Heartbeats detect
  failures- New elections restore progress Algorithms:
\item
  Raft Election (random timeouts)- Bully Algorithm- Chang-Roberts Ring
  Election
\end{itemize}

\subsubsection{9. Performance and
Optimization}\label{performance-and-optimization}

\begin{itemize}
\item
  Batching: amortize RPC overhead- Pipeline: parallelize appends-
  Read-only optimizations: serve from followers (stale reads)- Witness
  nodes: participate in quorum without full data Advanced:
\item
  Multi-Paxos: reuse leader, fewer rounds- Fast Paxos: shortcut some
  phases- Viewstamped Replication: Paxos-like log replication
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-85}

Consensus is the backbone of reliability in modern distributed systems.
Every consistent database, service registry, or blockchain depends on
it.

Systems using consensus:

\begin{itemize}
\tightlist
\item
  etcd, Consul, ZooKeeper - cluster coordination- Raft in Kubernetes -
  leader election- PBFT in blockchains - fault-tolerant ledgers-
  Spanner, TiDB - consistent databases \textgreater{} ``Consensus is how
  machines learn to agree, and trust.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-85}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Raft leader election in C or Python.
\item
  Simulate Paxos on 5 nodes with message drops.
\item
  Explore PBFT: try failing nodes and Byzantine behavior.
\item
  Compare performance of Raft vs Paxos under load.
\item
  Build a replicated key-value store with Raft.
\end{enumerate}

\subsection{87. Load Balancing and Rate
Limiting}\label{load-balancing-and-rate-limiting}

When systems scale, no single server can handle all requests alone. Load
balancing distributes incoming traffic across multiple servers to
improve throughput, reduce latency, and prevent overload. Meanwhile,
rate limiting protects systems by controlling how often requests are
allowed, ensuring fairness, stability, and security.

These two ideas, spreading the load and controlling the flow, are
cornerstones of modern distributed systems and APIs.

\subsubsection{1. Why Load Balancing
Matters}\label{why-load-balancing-matters}

Imagine a web service receiving thousands of requests per second. If
every request went to one machine, it would crash. A load balancer (LB)
acts as a traffic director, spreading requests across many backends.

Goals:

\begin{itemize}
\tightlist
\item
  Efficiency - fully utilize servers- Reliability - no single point of
  failure- Scalability - handle growing workloads- Flexibility -
  add/remove servers dynamically
\end{itemize}

\subsubsection{2. Types of Load
Balancers}\label{types-of-load-balancers}

\subsubsection{1. Layer 4 (Transport
Layer)}\label{layer-4-transport-layer}

Balances based on IP and port. Fast and protocol-agnostic (works for
TCP/UDP).

Example: Linux IPVS, Envoy, HAProxy

\subsubsection{2. Layer 7 (Application
Layer)}\label{layer-7-application-layer}

Understands protocols like HTTP. Can route by URL path, headers,
cookies.

Example: Nginx, Envoy, AWS ALB

\subsubsection{3. Load Balancing
Algorithms}\label{load-balancing-algorithms}

\subsubsection{Round Robin}\label{round-robin}

Cycles through backends in order.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Req1 → ServerA  }
\NormalTok{Req2 → ServerB  }
\NormalTok{Req3 → ServerC}
\end{Highlighting}
\end{Shaded}

Simple, fair (if all nodes equal).

\subsubsection{Weighted Round Robin}\label{weighted-round-robin}

Assigns weights to reflect capacity. Example: ServerA(2x), ServerB(1x)

\subsubsection{Least Connections}\label{least-connections}

Send request to server with fewest active connections.

\subsubsection{Least Response Time}\label{least-response-time}

Select backend with lowest latency (monitored dynamically).

\subsubsection{Hash-Based (Consistent
Hashing)}\label{hash-based-consistent-hashing}

Deterministically route based on request key (like user ID).

\begin{itemize}
\tightlist
\item
  Keeps cache locality- Used in CDNs, distributed caches
  (e.g.~memcached) \#\#\#\# Random
\end{itemize}

Pick a random backend, surprisingly effective under uniform load.

\subsubsection{4. Consistent Hashing (In
Depth)}\label{consistent-hashing-in-depth}

Used for sharding and sticky sessions.

Key idea:

\begin{itemize}
\tightlist
\item
  Map servers to a hash ring- A request's key is hashed onto the ring-
  Assigned to next clockwise server When servers join/leave, only small
  fraction of keys move.
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  CDNs- Distributed caches (Redis Cluster, DynamoDB)- Load-aware systems
\end{itemize}

\subsubsection{5. Health Checks and
Failover}\label{health-checks-and-failover}

A smart LB monitors health of each server:

\begin{itemize}
\tightlist
\item
  Heartbeat pings (HTTP/TCP)- Auto-remove unhealthy servers- Rebalance
  traffic instantly Example: If ServerB fails, remove from rotation:
\end{itemize}

\begin{verbatim}
Healthy: [ServerA, ServerC]
\end{verbatim}

Also supports active-passive failover: hot standby servers take over
when active fails.

\subsubsection{6. Global Load Balancing}\label{global-load-balancing}

Across regions or data centers:

\begin{itemize}
\tightlist
\item
  GeoDNS: route to nearest region- Anycast: advertise same IP globally;
  routing picks nearest- Latency-based routing: measure and pick lowest
  RTT Used by CDNs, cloud services, multi-region apps
\end{itemize}

\subsubsection{7. Rate Limiting: The Other
Side}\label{rate-limiting-the-other-side}

If load balancing spreads the work, rate limiting keeps total work
reasonable.

It prevents:

\begin{itemize}
\item
  Abuse (bots, DDoS)- Overload (too many requests)- Fairness issues (no
  user dominates resources) Policies:
\item
  Per-user, per-IP, per-API-key- Global or per-endpoint
\end{itemize}

\subsubsection{8. Rate Limiting
Algorithms}\label{rate-limiting-algorithms}

\subsubsection{Token Bucket}\label{token-bucket}

\begin{itemize}
\tightlist
\item
  Bucket holds tokens (capacity = burst limit)- Each request consumes 1
  token- Tokens refill at constant rate (rate limit)- If empty → reject
  or delay Good for bursty traffic.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{tokens }\OperatorTok{\textgreater{}} \DecValTok{0}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    tokens}\OperatorTok{{-}{-};}
\NormalTok{    allow}\OperatorTok{();}
\OperatorTok{\}} \ControlFlowTok{else}\NormalTok{ reject}\OperatorTok{();}
\end{Highlighting}
\end{Shaded}

\subsubsection{Leaky Bucket}\label{leaky-bucket}

\begin{itemize}
\tightlist
\item
  Requests flow into a bucket, drain at fixed rate- Excess = overflow =
  dropped Smooths bursts; used for shaping.
\end{itemize}

\subsubsection{Fixed Window Counter}\label{fixed-window-counter}

\begin{itemize}
\item
  Count requests in fixed interval (e.g.~1s)- Reset every window- Simple
  but unfair around boundaries \#\#\#\# Sliding Window Log / Sliding
  Window Counter
\item
  Maintain timestamps of requests- Remove old ones beyond time window-
  More accurate and fair
\end{itemize}

\subsubsection{9. Combining Both}\label{combining-both}

A full system might:

\begin{itemize}
\tightlist
\item
  Use rate limiting per user or service- Use load balancing across
  nodes- Apply circuit breakers when overload persists Together, they
  form resilient architectures that stay online even under spikes.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-86}

These techniques make large-scale systems:

\begin{itemize}
\item
  Scalable - handle millions of users- Stable - prevent cascading
  failures- Fair - each client gets a fair share- Resilient - recover
  gracefully from spikes or node loss Used in:
\item
  API Gateways (Kong, Envoy, Nginx)- Cloud Load Balancers (AWS ALB, GCP
  LB)- Kubernetes Ingress and Service Meshes- Distributed Caches and
  Databases \textgreater{} ``Balance keeps systems alive. Limits keep
  them sane.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-86}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate Round Robin and Least Connections balancing across 3 servers.
\item
  Implement a Token Bucket rate limiter in C or Python.
\item
  Test burst traffic, observe drops or delays.
\item
  Combine Consistent Hashing with Token Bucket for user-level control.
\item
  Visualize how load balancing + rate limiting keep system latency low.
\end{enumerate}

\subsection{88. Search and Indexing (Inverted, BM25,
WAND)}\label{search-and-indexing-inverted-bm25-wand}

Search engines, whether web-scale like Google or local like SQLite's
FTS, rely on efficient indexing and ranking to answer queries fast.
Instead of scanning all documents, they use indexes (structured lookup
tables) to quickly find relevant matches.

This section explores inverted indexes, ranking algorithms (TF-IDF,
BM25), and efficient retrieval techniques like WAND.

\subsubsection{1. The Search Problem}\label{the-search-problem}

Given:

\begin{itemize}
\item
  A corpus of documents- A query (e.g., ``machine learning algorithms'')
  We want to return:
\item
  Relevant documents- Ranked by importance and similarity Naive search →
  O(N × M) comparisons Inverted indexes → O(K log N), where K = terms in
  query
\end{itemize}

\subsubsection{2. Inverted Index: The Heart of
Search}\label{inverted-index-the-heart-of-search}

An inverted index maps terms → documents containing them.

\subsubsection{Example}\label{example-16}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Term & Postings List \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``data'' & {[}1, 4, 5{]} \\
``algorithm'' & {[}2, 3, 5{]} \\
``machine'' & {[}1, 2{]} \\
\end{longtable}

Each posting may include:

\begin{itemize}
\tightlist
\item
  docID- term frequency (tf)- positions (for phrase search) \#\#\#\#
  Construction Steps
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Tokenize documents → words
\item
  Normalize (lowercase, stemming, stopword removal)
\item
  Build postings: term → {[}docIDs, tf, positions{]}
\item
  Sort \& compress for storage efficiency
\end{enumerate}

Used by:

\begin{itemize}
\tightlist
\item
  Elasticsearch, Lucene, Whoosh, Solr
\end{itemize}

\subsubsection{3. Boolean Retrieval}\label{boolean-retrieval}

Simplest model:

\begin{itemize}
\tightlist
\item
  Query = Boolean expression
  e.g.~\texttt{(machine\ AND\ learning)\ OR\ AI}
\end{itemize}

Use set operations on postings:

\begin{itemize}
\tightlist
\item
  AND → intersection- OR → union- NOT → difference Fast intersection
  uses merge algorithm on sorted lists.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{void}\NormalTok{ intersect}\OperatorTok{(}\DataTypeTok{int}\NormalTok{ A}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ B}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ n}\OperatorTok{,} \DataTypeTok{int}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{,}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{while} \OperatorTok{(}\NormalTok{i }\OperatorTok{\textless{}}\NormalTok{ n }\OperatorTok{\&\&}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ m}\OperatorTok{)} \OperatorTok{\{}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{==}\NormalTok{ B}\OperatorTok{[}\NormalTok{j}\OperatorTok{])} \OperatorTok{\{}\NormalTok{ print}\OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}\NormalTok{ i}\OperatorTok{++;}\NormalTok{ j}\OperatorTok{++;} \OperatorTok{\}}
        \ControlFlowTok{else} \ControlFlowTok{if} \OperatorTok{(}\NormalTok{A}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{\textless{}}\NormalTok{ B}\OperatorTok{[}\NormalTok{j}\OperatorTok{])}\NormalTok{ i}\OperatorTok{++;}
        \ControlFlowTok{else}\NormalTok{ j}\OperatorTok{++;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

But Boolean search doesn't rank results, so we need scoring models.

\subsubsection{4. Vector Space Model}\label{vector-space-model}

Represent documents and queries as term vectors. Each dimension = term
weight (tf-idf).

\begin{itemize}
\tightlist
\item
  tf: term frequency in document- idf: inverse document frequency
  \(idf = \log\frac{N}{df_t}\)
\end{itemize}

Cosine similarity measures relevance: \[
\text{score}(q, d) = \frac{q \cdot d}{|q| |d|}
\]

Simple, interpretable, forms basis of BM25 and modern embeddings.

\subsubsection{5. BM25: The Classic Ranking
Function}\label{bm25-the-classic-ranking-function}

BM25 (Best Match 25) is the de facto standard in information retrieval.

\[
\text{score}(q, d) = \sum_{t \in q} IDF(t) \cdot \frac{f(t, d) \cdot (k_1 + 1)}{f(t, d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}
\]

Where:

\begin{itemize}
\item
  ( f(t, d) ): term frequency- ( \textbar d\textbar{} ): doc length- (
  avgdl ): average doc length- \(k_1, b\): tunable params (typ. 1.2-2.0,
  0.75) \#\#\#\# Advantages
\item
  Balances term frequency, document length, and rarity- Fast and
  effective baseline- Still used in Elasticsearch, Lucene, OpenSearch
\end{itemize}

\subsubsection{6. Efficiency Tricks: WAND, Block-Max
WAND}\label{efficiency-tricks-wand-block-max-wand}

Ranking involves merging multiple postings. We can skip irrelevant
documents early with WAND (Weak AND).

\subsubsection{WAND Principle}\label{wand-principle}

\begin{itemize}
\tightlist
\item
  Each term has upper-bound score- Maintain pointers in each posting-
  Compute potential max score- If max \textless{} current threshold,
  skip doc Improves latency for top-k retrieval.
\end{itemize}

Variants:

\begin{itemize}
\tightlist
\item
  BMW (Block-Max WAND) - uses block-level score bounds- MaxScore -
  simpler thresholding- Dynamic pruning - skip unpromising candidates
\end{itemize}

\subsubsection{7. Index Compression}\label{index-compression}

Postings lists are long, compression is crucial.

Common schemes:

\begin{itemize}
\tightlist
\item
  Delta encoding: store gaps between docIDs- Variable-byte (VB) or Gamma
  coding- Frame of Reference (FOR) and SIMD-BP128 for vectorized
  decoding Goal: smaller storage + faster decompression
\end{itemize}

\subsubsection{8. Advanced Retrieval}\label{advanced-retrieval}

\subsubsection{Proximity Search}\label{proximity-search}

Require words appear near each other. Use positional indexes.

\subsubsection{Phrase Search}\label{phrase-search}

Match exact sequences using positions: ``machine learning'' ≠ ``learning
machine''

\subsubsection{Fuzzy / Approximate
Search}\label{fuzzy-approximate-search}

Allow typos: Use Levenshtein automata, n-grams, or k-approximate
matching

\subsubsection{Fielded Search}\label{fielded-search}

Score per field (title, body, tags) Weighted combination

\subsubsection{9. Learning-to-Rank and Semantic
Search}\label{learning-to-rank-and-semantic-search}

Modern search adds ML-based re-ranking:

\begin{itemize}
\tightlist
\item
  Learning to Rank (LTR): use features (tf, idf, BM25, clicks)- Neural
  re-ranking: BERT-style embeddings for semantic similarity- Hybrid
  retrieval: combine BM25 + dense vectors (e.g.~ColBERT, RRF) Also: ANN
  (Approximate Nearest Neighbor) for vector-based search.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-87}

Efficient search powers:

\begin{itemize}
\tightlist
\item
  Web search engines- IDE symbol lookup- Log search, code search-
  Database full-text search- AI retrieval pipelines (RAG) It's where
  algorithms meet language and scale.
\end{itemize}

\begin{quote}
``Search is how we connect meaning to memory.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-87}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a tiny inverted index in C or Python.
\item
  Implement Boolean AND and OR queries.
\item
  Compute TF-IDF and BM25 scores for a toy dataset.
\item
  Add WAND pruning for top-k retrieval.
\item
  Compare BM25 vs semantic embeddings for relevance.
\end{enumerate}

\subsection{89. Compression and Encoding in
Systems}\label{compression-and-encoding-in-systems}

Compression and encoding algorithms are the quiet workhorses of
computing, shrinking data to save space, bandwidth, and time. They allow
systems to store more, transmit faster, and process efficiently. From
files and databases to networks and logs, compression shapes nearly
every layer of system design.

\subsubsection{1. Why Compression
Matters}\label{why-compression-matters}

Compression is everywhere:

\begin{itemize}
\item
  Databases - column stores, indexes, logs- Networks - HTTP, TCP, QUIC
  payloads- File systems - ZFS, NTFS, btrfs compression- Streaming -
  video/audio codecs- Logs \& telemetry - reduce I/O and storage cost
  Benefits:
\item
  Smaller data = faster I/O- Less storage = lower cost- Less transfer =
  higher throughput Trade-offs:
\item
  CPU overhead (compression/decompression)- Latency (especially for
  small data)- Suitability (depends on entropy and structure)
\end{itemize}

\subsubsection{2. Key Concepts}\label{key-concepts}

\subsubsection{Entropy}\label{entropy}

Minimum bits needed to represent data (Shannon). High entropy → less
compressible.

\subsubsection{Redundancy}\label{redundancy}

Compression exploits repetition and patterns.

\subsubsection{Lossless vs Lossy}\label{lossless-vs-lossy}

\begin{itemize}
\tightlist
\item
  Lossless: reversible (ZIP, PNG, LZ4)- Lossy: approximate (JPEG, MP3,
  H.264) In system contexts, lossless dominates.
\end{itemize}

\subsubsection{3. Common Lossless Compression
Families}\label{common-lossless-compression-families}

\subsubsection{Huffman Coding}\label{huffman-coding-1}

\begin{itemize}
\tightlist
\item
  Prefix-free variable-length codes- Frequent symbols = short codes-
  Optimal under symbol-level model Used in: DEFLATE, JPEG, MP3
\end{itemize}

\subsubsection{Arithmetic Coding}\label{arithmetic-coding-1}

\begin{itemize}
\item
  Encodes sequence as fractional interval- More efficient than Huffman
  for skewed distributions- Used in: H.264, bzip2, AV1 \#\#\#\#
  Dictionary-Based (LZ77, LZ78)
\item
  Replace repeated substrings with references- Core of ZIP, gzip, zlib,
  LZMA, Snappy \#\#\#\# LZ77 Sketch
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{not EOF}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    find longest match in sliding window}\OperatorTok{;}
\NormalTok{    output }\OperatorTok{(}\NormalTok{offset}\OperatorTok{,}\NormalTok{ length}\OperatorTok{,}\NormalTok{ next\_char}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Variants:

\begin{itemize}
\item
  LZ4 - fast, lower ratio- Snappy - optimized for speed- Zstandard
  (Zstd) - tunable speed/ratio, dictionary support \#\#\#\#
  Burrows-Wheeler Transform (BWT)
\item
  Reorders data to group similar symbols- Followed by Move-To-Front +
  Huffman- Used in bzip2, BWT-based compressors \#\#\#\# Run-Length
  Encoding (RLE)
\item
  Replace consecutive repeats with (symbol, count)- Great for structured
  or sparse data Example: \texttt{AAAAABBBCC} → \texttt{(A,5)(B,3)(C,2)}
\end{itemize}

\subsubsection{4. Specialized Compression in
Systems}\label{specialized-compression-in-systems}

\subsubsection{Columnar Databases}\label{columnar-databases}

Compress per column:

\begin{itemize}
\tightlist
\item
  Dictionary encoding - map strings → ints- Run-length encoding - good
  for sorted columns- Delta encoding - store differences (time series)-
  Bit-packing - fixed-width integers in minimal bits Combine multiple
  for optimal ratio.
\end{itemize}

Example (time deltas):

\begin{verbatim}
[100, 102, 103, 107] → [100, +2, +1, +4]
\end{verbatim}

\subsubsection{Log and Telemetry
Compression}\label{log-and-telemetry-compression}

\begin{itemize}
\item
  Structured formats → fieldwise encoding- Often Snappy or LZ4 for fast
  decode- Aggregators (Fluentd, Loki, Kafka) rely heavily on them
  \#\#\#\# Data Lakes and Files
\item
  Parquet, ORC, Arrow → columnar + compressed- Choose codec per column:
  LZ4 for speed, Zstd for ratio
\end{itemize}

\subsubsection{5. Streaming and Chunked
Compression}\label{streaming-and-chunked-compression}

Large data often processed in chunks:

\begin{itemize}
\tightlist
\item
  Enables random access and parallelism- Needed for network streams,
  distributed files Example: \texttt{zlib} block, \texttt{Zstd} frame,
  \texttt{gzip} chunk
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  HTTP chunked encoding- Kafka log segments- MapReduce shuffle
\end{itemize}

\subsubsection{6. Encoding Schemes}\label{encoding-schemes}

Compression ≠ encoding. Encoding ensures safe transport.

\subsubsection{Base64}\label{base64}

\begin{itemize}
\item
  Maps 3 bytes → 4 chars- 33\% overhead- Used for binary → text (emails,
  JSON APIs) \#\#\#\# URL Encoding
\item
  Escape unsafe chars with \texttt{\%xx} \#\#\#\# Delta Encoding
\item
  Store differences, not full values \#\#\#\# Varint / Zigzag Encoding
\item
  Compact integers (e.g.~protobufs)- Smaller numbers → fewer bytes
  Example:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{x }\OperatorTok{\textgreater{}=} \BaseNTok{0x80}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ emit}\OperatorTok{((}\NormalTok{x }\OperatorTok{\&} \BaseNTok{0x7F}\OperatorTok{)} \OperatorTok{|} \BaseNTok{0x80}\OperatorTok{);}\NormalTok{ x }\OperatorTok{\textgreater{}\textgreater{}=} \DecValTok{7}\OperatorTok{;} \OperatorTok{\}}
\NormalTok{emit}\OperatorTok{(}\NormalTok{x}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Adaptive and Context
Models}\label{adaptive-and-context-models}

Modern compressors adapt to local patterns:

\begin{itemize}
\tightlist
\item
  PPM (Prediction by Partial Matching)- Context mixing (PAQ)- Zstd uses
  FSE (Finite State Entropy) coding Balance between speed, memory, and
  compression ratio.
\end{itemize}

\subsubsection{8. Hardware Acceleration}\label{hardware-acceleration}

Compression can be offloaded to:

\begin{itemize}
\tightlist
\item
  CPUs with SIMD (AVX2, SSE4.2)- GPUs (parallel encode/decode)- NICs /
  SmartNICs- ASICs (e.g., Intel QAT) Critical for high-throughput
  databases, network appliances, storage systems.
\end{itemize}

\subsubsection{9. Design Trade-offs}\label{design-trade-offs}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Goal & Best Choice \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Max speed & LZ4, Snappy \\
Max ratio & Zstd, LZMA \\
Balance & Zstd (tunable) \\
Column store & RLE, Delta, Dict \\
Logs / telemetry & Snappy, LZ4 \\
Archival & bzip2, xz \\
Real-time & LZ4, Brotli (fast mode) \\
\end{longtable}

Choose based on CPU budget, I/O cost, latency tolerance.

\subsubsection{10. Why It Matters}\label{why-it-matters-88}

Compression is a first-class optimization:

\begin{itemize}
\tightlist
\item
  Saves petabytes in data centers- Boosts throughput across networks-
  Powers cloud storage (S3, BigQuery, Snowflake)- Enables efficient
  analytics and ML pipelines \textgreater{} ``Every byte saved is time
  earned.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-88}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compress text using Huffman coding (build frequency table).
\item
  Compare gzip, Snappy, and Zstd on a 1GB dataset.
\item
  Implement delta encoding and RLE for numeric data.
\item
  Try dictionary encoding on repetitive strings.
\item
  Measure compression ratio, speed, and CPU usage trade-offs.
\end{enumerate}

\subsection{90. Fault Tolerance and
Replication}\label{fault-tolerance-and-replication}

Modern systems must survive hardware crashes, network partitions, or
data loss without stopping. Fault tolerance ensures that a system
continues to function, even when parts fail. Replication underpins this
resilience, duplicating data or computation across multiple nodes for
redundancy, performance, and consistency.

Together, they form the backbone of reliability in distributed systems.

\subsubsection{1. Why Fault Tolerance?}\label{why-fault-tolerance}

No system is perfect:

\begin{itemize}
\tightlist
\item
  Servers crash- Disks fail- Networks partition- Power goes out The
  question isn't \emph{if} failure happens, but \emph{when}.
  Fault-tolerant systems detect, contain, and recover from failure
  automatically.
\end{itemize}

Goals:

\begin{itemize}
\tightlist
\item
  Availability - keep serving requests- Durability - never lose data-
  Consistency - stay correct across replicas
\end{itemize}

\subsubsection{2. Failure Models}\label{failure-models}

\subsubsection{Crash Faults}\label{crash-faults}

Node stops responding but doesn't misbehave. Handled by restarts or
replication (Raft, Paxos).

\subsubsection{Omission Faults}\label{omission-faults}

Lost messages or dropped updates. Handled with retries and
acknowledgments.

\subsubsection{Byzantine Faults}\label{byzantine-faults}

Arbitrary/malicious behavior. Handled by Byzantine Fault Tolerance
(PBFT), expensive but robust.

\subsubsection{3. Redundancy: The Core
Strategy}\label{redundancy-the-core-strategy}

Fault tolerance = redundancy + detection + recovery

Redundancy types:

\begin{itemize}
\tightlist
\item
  Hardware: multiple power supplies, disks (RAID)- Software: replicated
  services, retries- Data: multiple copies, erasure codes- Temporal:
  retry or checkpoint and replay
\end{itemize}

\subsubsection{4. Replication Models}\label{replication-models}

\subsubsection{1. Active Replication}\label{active-replication}

All replicas process requests in parallel (lockstep). Results must
match. Used in real-time and Byzantine systems.

\subsubsection{2. Passive
(Primary-Backup)}\label{passive-primary-backup}

One leader (primary) handles requests. Backups replicate log, take over
on failure. Used in Raft, ZooKeeper, PostgreSQL streaming.

\subsubsection{3. Quorum Replication}\label{quorum-replication}

Writes and reads contact majority of replicas. Ensures overlap →
consistency. Used in Cassandra, DynamoDB, Etcd.

\subsubsection{5. Consistency Models}\label{consistency-models}

Replication introduces a trade-off between consistency and availability
(CAP theorem).

\subsubsection{Strong Consistency}\label{strong-consistency}

All clients see the same value immediately. Example: Raft, Etcd,
Spanner.

\subsubsection{Eventual Consistency}\label{eventual-consistency}

Replicas converge over time. Example: DynamoDB, Cassandra.

\subsubsection{Causal Consistency}\label{causal-consistency}

Preserves causal order of events. Example: Vector clocks, CRDTs.

Choice depends on workload:

\begin{itemize}
\tightlist
\item
  Banking → strong- Social feeds → eventual- Collaborative editing →
  causal
\end{itemize}

\subsubsection{6. Checkpointing and
Recovery}\label{checkpointing-and-recovery}

To recover after crash:

\begin{itemize}
\tightlist
\item
  Periodically checkpoint state- On restart, replay log of missed events
  Example: Databases → Write-Ahead Log (WAL) Stream systems → Kafka
  checkpoints
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{1. Save state to disk}
\NormalTok{2. Record latest log position}
\NormalTok{3. On restart → reload + replay}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Erasure Coding}\label{erasure-coding}

Instead of full copies, store encoded fragments. With ( k ) data blocks,
( m ) parity blocks → tolerate ( m ) failures.

Example: Reed-Solomon (used in HDFS, Ceph)

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
k & m & Total & Fault Tolerance \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
4 & 2 & 6 & 2 failures \\
\end{longtable}

Better storage efficiency than 3× replication.

\subsubsection{8. Failure Detection}\label{failure-detection}

Detecting failure is tricky in distributed systems (because of latency).
Common techniques:

\begin{itemize}
\tightlist
\item
  Heartbeats - periodic ``I'm alive'' messages- Timeouts - suspect node
  if no heartbeat- Gossip protocols - share failure info among peers
  Used in Consul, Cassandra, Kubernetes health checks.
\end{itemize}

\subsubsection{9. Self-Healing Systems}\label{self-healing-systems}

After failure:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Detect it
\item
  Isolate faulty component
\item
  Replace or restart
\item
  Rebalance load or re-replicate data
\end{enumerate}

Patterns:

\begin{itemize}
\tightlist
\item
  Supervisor trees (Erlang/Elixir)- Self-healing clusters (Kubernetes)-
  Rebalancing (Cassandra ring repair) ``Never trust a single machine,
  trust the system.''
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-89}

Fault tolerance turns fragile infrastructure into reliable services.

Used in:

\begin{itemize}
\tightlist
\item
  Databases (replication + WAL)- Distributed storage (HDFS, Ceph, S3)-
  Orchestration (Kubernetes controllers)- Streaming systems (Kafka,
  Flink) Without replication and fault tolerance, large-scale systems
  would collapse under failure.
\end{itemize}

\begin{quote}
``Resilience is built, not assumed.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-89}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a primary-backup key-value store: leader writes, follower
  replicates.
\item
  Add heartbeat + timeout detection to trigger failover.
\item
  Simulate partition: explore behavior under strong vs eventual
  consistency.
\item
  Implement checkpoint + replay recovery for a small app.
\item
  Compare 3× replication vs Reed-Solomon (4+2) for space and
  reliability.
\end{enumerate}

\section{Chapter 10. AI, ML and
Optimization}\label{chapter-10.-ai-ml-and-optimization-1}

\subsection{91. Classical ML (k-means, Naive Bayes, SVM, Decision
Trees)}\label{classical-ml-k-means-naive-bayes-svm-decision-trees}

Classical machine learning is built on interpretable mathematics and
solid optimization foundations. Long before deep learning, these
algorithms powered search engines, spam filters, and recommendation
systems. They're still used today, fast, explainable, and easy to
deploy.

This section covers the four pillars of classical ML:

\begin{itemize}
\tightlist
\item
  k-means - unsupervised clustering- Naive Bayes - probabilistic
  classification- SVM - margin-based classification- Decision Trees -
  rule-based learning
\end{itemize}

\subsubsection{1. The Essence of Classical
ML}\label{the-essence-of-classical-ml}

Classical ML is about learning from data using statistical principles,
often without huge compute. Given dataset ( D = \{\(x_i, y_i\)\} ), the
task is to:

\begin{itemize}
\tightlist
\item
  Predict ( y ) from ( x )- Generalize beyond seen data- Balance bias
  and variance
\end{itemize}

\subsubsection{2. k-means Clustering}\label{k-means-clustering}

Goal: partition data into ( k ) groups (clusters) such that
intra-cluster distance is minimized.

\subsubsection{Objective}\label{objective}

\[
\min_{C} \sum_{i=1}^k \sum_{x \in C_i} |x - \mu_i|^2
\] Where \(\mu_i\) = centroid of cluster ( i ).

\subsubsection{Algorithm}\label{algorithm}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose ( k ) random centroids
\item
  Assign each point to nearest centroid
\item
  Recompute centroids
\item
  Repeat until stable
\end{enumerate}

\subsubsection{Tiny Code (C-style)}\label{tiny-code-c-style}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{iter }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ iter }\OperatorTok{\textless{}}\NormalTok{ max\_iter}\OperatorTok{;}\NormalTok{ iter}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    assign\_points\_to\_clusters}\OperatorTok{();}
\NormalTok{    recompute\_centroids}\OperatorTok{();}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros}\label{pros-1}

\begin{itemize}
\item
  Simple, fast (( O(nkd) ))- Works well for spherical clusters \#\#\#\#
  Cons
\item
  Requires ( k )- Sensitive to initialization, outliers Variants:
\item
  k-means++ (better initialization)- Mini-batch k-means (scalable)
\end{itemize}

\subsubsection{3. Naive Bayes Classifier}\label{naive-bayes-classifier}

A probabilistic model using Bayes' theorem under independence
assumptions.

\[
P(y|x) \propto P(y) \prod_{i=1}^n P(x_i | y)
\]

\subsubsection{Algorithm}\label{algorithm-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute prior ( P(y) )
\item
  Compute likelihood ( P\(x_i | y\) )
\item
  Predict class with max posterior
\end{enumerate}

\subsubsection{Types}\label{types}

\begin{itemize}
\tightlist
\item
  Multinomial NB - text (bag of words)- Gaussian NB - continuous
  features- Bernoulli NB - binary features \#\#\#\# Example (Spam
  Detection)
\end{itemize}

\begin{verbatim}
P(spam | "win money") ∝ P(spam) * P("win"|spam) * P("money"|spam)
\end{verbatim}

\subsubsection{Pros}\label{pros-2}

\begin{itemize}
\item
  Fast, works well for text- Needs little data- Probabilistic
  interpretation \#\#\#\# Cons
\item
  Assumes feature independence- Poor for correlated features
\end{itemize}

\subsubsection{4. Support Vector Machines
(SVM)}\label{support-vector-machines-svm-1}

SVM finds the max-margin hyperplane separating classes.

\subsubsection{Objective}\label{objective-1}

Maximize margin = distance between boundary and nearest points.

\[
\min_{w, b} \frac{1}{2} |w|^2 \quad \text{s.t.} \quad y_i(w \cdot x_i + b) \ge 1
\]

Can be solved via Quadratic Programming.

\subsubsection{Intuition}\label{intuition}

\begin{itemize}
\tightlist
\item
  Each data point → vector- Hyperplane: \(w \cdot x + b = 0\)- Support
  vectors = boundary points \#\#\#\# Kernel Trick
\end{itemize}

Transform input via kernel ( K\(x_i, x_j\) = \phi\(x_i\)
\cdot \phi\(x_j\) ):

\begin{itemize}
\item
  Linear: dot product- Polynomial: ( \(x_i \cdot x_j + c\)\^{}d )- RBF:
  \(e^{-\gamma |x_i - x_j|^2}\) \#\#\#\# Pros
\item
  Effective in high dimensions- Can model nonlinear boundaries- Few
  hyperparameters \#\#\#\# Cons
\item
  Slow on large data- Harder to tune kernel parameters
\end{itemize}

\subsubsection{5. Decision Trees}\label{decision-trees}

If-else structure for classification/regression.

At each node:

\begin{itemize}
\item
  Pick feature ( f ) and threshold ( t )- Split to maximize information
  gain \#\#\#\# Metrics
\item
  Entropy: \(H = -\sum p_i \log p_i\)- Gini: \(G = 1 - \sum p_i^2\)
  \#\#\#\# Pseudocode
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \OperatorTok{(}\NormalTok{feature }\OperatorTok{\textless{}}\NormalTok{ threshold}\OperatorTok{)}
\NormalTok{    go left}\OperatorTok{;}
\ControlFlowTok{else}
\NormalTok{    go right}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Build recursively until:

\begin{itemize}
\item
  Max depth- Min samples per leaf- Pure nodes \#\#\#\# Pros
\item
  Interpretable- Handles mixed data- No scaling needed \#\#\#\# Cons
\item
  Prone to overfitting- Unstable (small data changes) Fixes:
\item
  Pruning (reduce depth)- Ensembles: Random Forests, Gradient Boosting
\end{itemize}

\subsubsection{6. Bias-Variance Tradeoff}\label{bias-variance-tradeoff}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Bias & Variance \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
k-means & High & Low \\
Naive Bayes & High & Low \\
SVM & Low & Medium \\
Decision Tree & Low & High \\
\end{longtable}

Balancing both = good generalization.

\subsubsection{7. Evaluation Metrics}\label{evaluation-metrics-1}

For classification:

\begin{itemize}
\item
  Accuracy, Precision, Recall, F1-score- ROC-AUC, Confusion Matrix For
  clustering:
\item
  Inertia, Silhouette Score Always use train/test split or
  cross-validation.
\end{itemize}

\subsubsection{8. Scaling to Large Data}\label{scaling-to-large-data}

Techniques:

\begin{itemize}
\item
  Mini-batch training- Online updates (SGD)- Dimensionality reduction
  (PCA)- Approximation (Random Projections) Libraries:
\item
  scikit-learn (Python)- liblinear, libsvm (C/C++)- MLlib (Spark)
\end{itemize}

\subsubsection{9. When to Use What}\label{when-to-use-what}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Task & Recommended Algorithm \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Text classification & Naive Bayes \\
Clustering & k-means \\
Nonlinear classification & SVM (RBF) \\
Tabular data & Decision Tree \\
Quick baseline & Logistic Regression / NB \\
\end{longtable}

\subsubsection{10. Why It Matters}\label{why-it-matters-90}

These algorithms are fast, interpretable, and theoretical foundations of
modern ML. They remain the go-to choice for:

\begin{itemize}
\tightlist
\item
  Small to medium datasets- Real-time classification- Explainable AI
  \textgreater{} ``Classical ML is the art of solving problems with math
  you can still write on a whiteboard.''
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-90}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cluster 2D points with k-means, plot centroids.
\item
  Train Naive Bayes on a spam/ham dataset.
\item
  Classify linearly separable data with SVM.
\item
  Build a Decision Tree from scratch (entropy, Gini).
\item
  Compare models' accuracy and interpretability.
\end{enumerate}

\subsection{92. Ensemble Methods (Bagging, Boosting, Random
Forests)}\label{ensemble-methods-bagging-boosting-random-forests}

Ensemble methods combine multiple weak learners to build a strong
predictor. Instead of relying on one model, ensembles vote, average, or
boost multiple models, improving stability and accuracy.

They are the bridge between classical and modern ML , simple models,
combined smartly, become powerful.

\subsubsection{1. The Core Idea}\label{the-core-idea-4}

\begin{quote}
``Many weak learners, when combined, can outperform a single strong
one.''
\end{quote}

Mathematically, if \(f_1, f_2, \ldots, f_k\) are weak learners, an
ensemble predictor is:

\[
F(x) = \frac{1}{k}\sum_{i=1}^k f_i(x)
\]

For classification, combine via majority vote. For regression, combine
via average.

\subsubsection{2. Bagging (Bootstrap
Aggregating)}\label{bagging-bootstrap-aggregating}

Bagging reduces variance by training models on different samples.

\subsubsection{Steps}\label{steps-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw ( B ) bootstrap samples from dataset ( D ).
\item
  Train one model per sample.
\item
  Aggregate predictions by averaging or voting.
\end{enumerate}

\[
\hat{f}*{bag}(x) = \frac{1}{B} \sum*{b=1}^B f_b(x)
\]

Each \(f_b\) is trained on a random subset (with replacement).

\subsubsection{Example}\label{example-17}

\begin{itemize}
\tightlist
\item
  Base learner: Decision Tree- Ensemble: Bagged Trees- Famous instance:
  Random Forest \#\#\#\# Tiny Code (C-style Pseudocode)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ b }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ b }\OperatorTok{\textless{}}\NormalTok{ B}\OperatorTok{;}\NormalTok{ b}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    D\_b }\OperatorTok{=}\NormalTok{ bootstrap\_sample}\OperatorTok{(}\NormalTok{D}\OperatorTok{);}
\NormalTok{    model}\OperatorTok{[}\NormalTok{b}\OperatorTok{]} \OperatorTok{=}\NormalTok{ train\_tree}\OperatorTok{(}\NormalTok{D\_b}\OperatorTok{);}
\OperatorTok{\}}
\NormalTok{prediction }\OperatorTok{=}\NormalTok{ average\_predictions}\OperatorTok{(}\NormalTok{model}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{Pros}\label{pros-3}

\begin{itemize}
\item
  Reduces variance- Works well with high-variance learners-
  Parallelizable \#\#\#\# Cons
\item
  Increases computation- Doesn't reduce bias
\end{itemize}

\subsubsection{3. Random Forest}\label{random-forest}

A bagging-based ensemble of decision trees with feature randomness.

\subsubsection{Key Ideas}\label{key-ideas}

\begin{itemize}
\tightlist
\item
  Each tree trained on bootstrap sample.- At each split, consider random
  subset of features.- Final prediction = majority vote or average. This
  decorrelates trees, improving generalization.
\end{itemize}

\[
F(x) = \frac{1}{B} \sum_{b=1}^{B} T_b(x)
\]

\subsubsection{Pros}\label{pros-4}

\begin{itemize}
\item
  Handles large feature sets- Low overfitting- Good default for tabular
  data \#\#\#\# Cons
\item
  Less interpretable- Slower on huge datasets OOB (Out-of-Bag) error =
  internal validation from unused samples.
\end{itemize}

\subsubsection{4. Boosting}\label{boosting}

Boosting focuses on reducing bias by sequentially training models , each
one corrects errors from the previous.

\subsubsection{Steps}\label{steps-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with weak learner ( f\_1(x) )
\item
  Train next learner ( f\_2(x) ) on residuals/errors
\item
  Combine with weighted sum
\end{enumerate}

\[
F_m(x) = F_{m-1}(x) + \alpha_m f_m(x)
\]

Weights \(\alpha_m\) focus on difficult examples.

\subsubsection{Tiny Code (Conceptual)}\label{tiny-code-conceptual-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{F }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ m }\OperatorTok{\textless{}}\NormalTok{ M}\OperatorTok{;}\NormalTok{ m}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    residual }\OperatorTok{=}\NormalTok{ y }\OperatorTok{{-}}\NormalTok{ predict}\OperatorTok{(}\NormalTok{F}\OperatorTok{,}\NormalTok{ x}\OperatorTok{);}
\NormalTok{    f\_m }\OperatorTok{=}\NormalTok{ train\_weak\_learner}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ residual}\OperatorTok{);}
\NormalTok{    F }\OperatorTok{+=}\NormalTok{ alpha}\OperatorTok{[}\NormalTok{m}\OperatorTok{]} \OperatorTok{*}\NormalTok{ f\_m}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. AdaBoost (Adaptive
Boosting)}\label{adaboost-adaptive-boosting}

AdaBoost adapts weights on samples after each iteration.

\subsubsection{Algorithm}\label{algorithm-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize weights: \(w_i = \frac{1}{n}\)
\item
  Train weak classifier \(f_t\)
\item
  Compute error: \(\epsilon_t\)
\item
  Update weights: \[
  w_i \leftarrow w_i \cdot e^{\alpha_t \cdot I(y_i \ne f_t(x_i))}
  \] where
  \(\alpha_t = \frac{1}{2} \ln\left(\frac{1 - \epsilon_t}{\epsilon_t}\right)\)
\item
  Normalize weights
\end{enumerate}

Final classifier: \[
F(x) = \text{sign}\left( \sum_t \alpha_t f_t(x) \right)
\]

\subsubsection{Pros}\label{pros-5}

\begin{itemize}
\item
  High accuracy on clean data- Simple and interpretable weights \#\#\#\#
  Cons
\item
  Sensitive to outliers- Sequential → not easily parallelizable
\end{itemize}

\subsubsection{6. Gradient Boosting}\label{gradient-boosting}

A modern version of boosting using gradient descent on loss.

At each step, fit new model to negative gradient of loss function.

\subsubsection{Objective}\label{objective-2}

\[
F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)
\]

where \(h_m(x) \approx -\frac{\partial L(y, F(x))}{\partial F(x)}\)

\subsubsection{Common Libraries}\label{common-libraries}

\begin{itemize}
\item
  XGBoost
\item
  LightGBM
\item
  CatBoost \#\#\#\# Pros
\item
  High performance on tabular data- Flexible (custom loss)- Handles
  mixed feature types \#\#\#\# Cons
\item
  Slower to train- Sensitive to hyperparameters
\end{itemize}

\subsubsection{7. Stacking (Stacked
Generalization)}\label{stacking-stacked-generalization}

Combine multiple models (base learners) via a meta-model.

\subsubsection{Steps}\label{steps-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train base models (SVM, Tree, NB, etc.)
\item
  Collect their predictions
\item
  Train meta-model (e.g.~Logistic Regression) on outputs
\end{enumerate}

\[
\hat{y} = f_{meta}(f_1(x), f_2(x), \ldots, f_k(x))
\]

\subsubsection{8. Bagging vs Boosting}\label{bagging-vs-boosting}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Feature & Bagging & Boosting \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Strategy & Parallel & Sequential \\
Goal & Reduce variance & Reduce bias \\
Weighting & Uniform & Adaptive \\
Example & Random Forest & AdaBoost, XGBoost \\
\end{longtable}

\subsubsection{9. Bias-Variance Behavior}\label{bias-variance-behavior}

\begin{itemize}
\tightlist
\item
  Bagging: ↓ variance- Boosting: ↓ bias- Random Forest: balanced-
  Stacking: flexible but complex
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-91}

Ensemble methods are the workhorses of classical ML competitions and
real-world tabular problems. They blend interpretability, flexibility,
and predictive power.

\begin{quote}
``One tree may fall, but a forest stands strong.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-91}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train a Random Forest on the Iris dataset.
\item
  Implement AdaBoost from scratch using decision stumps.
\item
  Compare Bagging vs Boosting accuracy.
\item
  Try XGBoost with different learning rates.
\item
  Visualize feature importance across models.
\end{enumerate}

\subsection{93. Gradient Methods (SGD, Adam,
RMSProp)}\label{gradient-methods-sgd-adam-rmsprop}

Gradient-based optimization is the heartbeat of machine learning. These
methods update parameters iteratively by following the negative gradient
of the loss function. They power everything from linear regression to
deep neural networks.

\subsubsection{1. The Core Idea}\label{the-core-idea-5}

We want to minimize a loss function ( L\(\theta\) ). Starting from some
initial parameters \(\theta_0\), we move in the opposite direction of
the gradient:

\[
\theta_{t+1} = \theta_t - \eta \cdot \nabla_\theta L(\theta_t)
\]

where \(\eta\) is the learning rate (step size).

The gradient tells us which way the function increases fastest , we move
the other way.

\subsubsection{2. Batch Gradient Descent}\label{batch-gradient-descent}

Uses the entire dataset to compute the gradient.

\[
\nabla_\theta L(\theta) = \frac{1}{N} \sum_{i=1}^N \nabla_\theta \ell_i(\theta)
\]

\begin{itemize}
\tightlist
\item
  Accurate but slow for large ( N )- Each update is expensive Tiny Code
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    grad }\OperatorTok{=}\NormalTok{ compute\_full\_gradient}\OperatorTok{(}\NormalTok{data}\OperatorTok{,}\NormalTok{ theta}\OperatorTok{);}
\NormalTok{    theta }\OperatorTok{=}\NormalTok{ theta }\OperatorTok{{-}}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ grad}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Good for: small datasets or convex problems

\subsubsection{3. Stochastic Gradient Descent
(SGD)}\label{stochastic-gradient-descent-sgd}

Instead of full data, use one random sample per step.

\[
\theta_{t+1} = \theta_t - \eta \cdot \nabla_\theta \ell_i(\theta_t)
\]

\begin{itemize}
\tightlist
\item
  Noisy but faster updates- Can escape local minima- Great for online
  learning Tiny Code
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each sample }\OperatorTok{(}\NormalTok{x\_i}\OperatorTok{,}\NormalTok{ y\_i}\OperatorTok{):}
\NormalTok{    grad }\OperatorTok{=}\NormalTok{ grad\_loss}\OperatorTok{(}\NormalTok{theta}\OperatorTok{,}\NormalTok{ x\_i}\OperatorTok{,}\NormalTok{ y\_i}\OperatorTok{);}
\NormalTok{    theta }\OperatorTok{{-}=}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ grad}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Pros

\begin{itemize}
\item
  Fast convergence- Works on large datasets Cons
\item
  Noisy updates- Requires learning rate tuning
\end{itemize}

\subsubsection{4. Mini-Batch Gradient
Descent}\label{mini-batch-gradient-descent}

Compromise between batch and stochastic.

Use small subset (mini-batch) of samples:

\[
\theta_{t+1} = \theta_t - \eta \cdot \frac{1}{m} \sum_{i=1}^m \nabla_\theta \ell_i(\theta_t)
\]

Usually batch size = 32 or 64. Faster, more stable updates.

\subsubsection{5. Momentum}\label{momentum}

Adds velocity to smooth oscillations.

\[
v_t = \beta v_{t-1} + (1 - \beta) \nabla_\theta L(\theta_t)
\]

\[
\theta_{t+1} = \theta_t - \eta v_t
\]

This accumulates past gradients to speed movement in consistent
directions.

Think of it like a heavy ball rolling down a hill.

\subsubsection{6. Nesterov Accelerated Gradient
(NAG)}\label{nesterov-accelerated-gradient-nag}

Improves momentum by looking ahead:

\[
v_t = \beta v_{t-1} + \eta \nabla_\theta L(\theta_t - \beta v_{t-1})
\]

It anticipates the future position before computing the gradient.

Faster convergence in convex settings.

\subsubsection{7. RMSProp}\label{rmsprop}

Adjusts learning rate per parameter using exponential average of squared
gradients:

\[
E[g^2]*t = \rho E[g^2]*{t-1} + (1 - \rho) g_t^2
\]

\[
\theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t
\]

This helps when gradients vary in magnitude.

Good for: non-stationary objectives, deep networks

\subsubsection{8. Adam (Adaptive Moment
Estimation)}\label{adam-adaptive-moment-estimation}

Combines momentum + RMSProp:

\[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
\]

\[
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
\]

Bias-corrected estimates:

\[
\hat{m}_t = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v}_t = \frac{v_t}{1 - \beta_2^t}
\]

Update rule:

\[
\theta_{t+1} = \theta_t - \frac{\eta \cdot \hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
\]

Tiny Code (Conceptual)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ v }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ t }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}=}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ grad}\OperatorTok{(}\NormalTok{theta}\OperatorTok{);}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ beta1 }\OperatorTok{*}\NormalTok{ m }\OperatorTok{+} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ beta1}\OperatorTok{)} \OperatorTok{*}\NormalTok{ g}\OperatorTok{;}
\NormalTok{    v }\OperatorTok{=}\NormalTok{ beta2 }\OperatorTok{*}\NormalTok{ v }\OperatorTok{+} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ beta2}\OperatorTok{)} \OperatorTok{*}\NormalTok{ g }\OperatorTok{*}\NormalTok{ g}\OperatorTok{;}
\NormalTok{    m\_hat }\OperatorTok{=}\NormalTok{ m }\OperatorTok{/} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ pow}\OperatorTok{(}\NormalTok{beta1}\OperatorTok{,}\NormalTok{ t}\OperatorTok{));}
\NormalTok{    v\_hat }\OperatorTok{=}\NormalTok{ v }\OperatorTok{/} \OperatorTok{(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ pow}\OperatorTok{(}\NormalTok{beta2}\OperatorTok{,}\NormalTok{ t}\OperatorTok{));}
\NormalTok{    theta }\OperatorTok{{-}=}\NormalTok{ eta }\OperatorTok{*}\NormalTok{ m\_hat }\OperatorTok{/} \OperatorTok{(}\NormalTok{sqrt}\OperatorTok{(}\NormalTok{v\_hat}\OperatorTok{)} \OperatorTok{+}\NormalTok{ eps}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Pros

\begin{itemize}
\item
  Works well out of the box- Adapts learning rate- Great for deep
  learning Cons
\item
  May not converge exactly- Needs decay schedule for stability
\end{itemize}

\subsubsection{9. Learning Rate
Schedules}\label{learning-rate-schedules}

Control \(\eta\) over time:

\begin{itemize}
\tightlist
\item
  Step decay: \(\eta_t = \eta_0 \cdot \gamma^{\lfloor t/s \rfloor}\)-
  Exponential decay: \(\eta_t = \eta_0 e^{-\lambda t}\)- Cosine
  annealing: smooth periodic decay- Warm restarts: reset learning rate
  periodically
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-92}

All modern deep learning is built on gradients. Choosing the right
optimizer can mean faster training and better accuracy.

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Optimizer & Adaptive & Momentum & Common Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
SGD & No & Optional & Simple tasks \\
SGD + Momentum & No & Yes & ConvNets \\
RMSProp & Yes & No & RNNs \\
Adam & Yes & Yes & Transformers, DNNs \\
\end{longtable}

\begin{quote}
``Optimization is the art of taking small steps in the right direction ,
many times over.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-92}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement SGD and Adam on a linear regression task.
\item
  Compare training curves for SGD, Momentum, RMSProp, and Adam.
\item
  Experiment with learning rate schedules.
\item
  Visualize optimization paths on a 2D contour plot.
\end{enumerate}

\subsection{94. Deep Learning (Backpropagation, Dropout,
Normalization)}\label{deep-learning-backpropagation-dropout-normalization}

Deep learning is about stacking layers of computation so that the
network can learn hierarchical representations. From raw pixels to
abstract features, deep nets build meaning through composition of
functions.

At the core of this process are three ideas: backpropagation,
regularization (dropout), and normalization.

\subsubsection{1. The Essence of Deep
Learning}\label{the-essence-of-deep-learning}

A neural network is a chain of functions:

\[
f(x; \theta) = f_L(f_{L-1}(\cdots f_1(x)))
\]

Each layer transforms its input and passes it on.

Training involves finding parameters \(\theta\) that minimize a loss (
L(f\(x; \theta\), y) ).

\subsubsection{2. Backpropagation}\label{backpropagation}

Backpropagation is the algorithm that teaches neural networks.

It uses the chain rule of calculus to efficiently compute gradients
layer by layer.

For each layer ( i ):

\[
\frac{\partial L}{\partial \theta_i} = \frac{\partial L}{\partial a_i} \cdot \frac{\partial a_i}{\partial \theta_i}
\]

and propagate backward:

\[
\frac{\partial L}{\partial a_{i-1}} = \frac{\partial L}{\partial a_i} \cdot \frac{\partial a_i}{\partial a_{i-1}}
\]

So every neuron learns how much it contributed to the error.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Pseudocode for 2{-}layer network}
\NormalTok{forward}\OperatorTok{:}
\NormalTok{    z1 }\OperatorTok{=}\NormalTok{ W1}\OperatorTok{*}\NormalTok{x }\OperatorTok{+}\NormalTok{ b1}\OperatorTok{;}
\NormalTok{    a1 }\OperatorTok{=}\NormalTok{ relu}\OperatorTok{(}\NormalTok{z1}\OperatorTok{);}
\NormalTok{    z2 }\OperatorTok{=}\NormalTok{ W2}\OperatorTok{*}\NormalTok{a1 }\OperatorTok{+}\NormalTok{ b2}\OperatorTok{;}
\NormalTok{    y\_hat }\OperatorTok{=}\NormalTok{ softmax}\OperatorTok{(}\NormalTok{z2}\OperatorTok{);}
\NormalTok{    loss }\OperatorTok{=}\NormalTok{ cross\_entropy}\OperatorTok{(}\NormalTok{y\_hat}\OperatorTok{,}\NormalTok{ y}\OperatorTok{);}

\NormalTok{backward}\OperatorTok{:}
\NormalTok{    dz2 }\OperatorTok{=}\NormalTok{ y\_hat }\OperatorTok{{-}}\NormalTok{ y}\OperatorTok{;}
\NormalTok{    dW2 }\OperatorTok{=}\NormalTok{ dz2 }\OperatorTok{*}\NormalTok{ a1}\OperatorTok{.}\NormalTok{T}\OperatorTok{;}
\NormalTok{    db2 }\OperatorTok{=}\NormalTok{ sum}\OperatorTok{(}\NormalTok{dz2}\OperatorTok{);}
\NormalTok{    da1 }\OperatorTok{=}\NormalTok{ W2}\OperatorTok{.}\NormalTok{T }\OperatorTok{*}\NormalTok{ dz2}\OperatorTok{;}
\NormalTok{    dz1 }\OperatorTok{=}\NormalTok{ da1 }\OperatorTok{*}\NormalTok{ relu\_grad}\OperatorTok{(}\NormalTok{z1}\OperatorTok{);}
\NormalTok{    dW1 }\OperatorTok{=}\NormalTok{ dz1 }\OperatorTok{*}\NormalTok{ x}\OperatorTok{.}\NormalTok{T}\OperatorTok{;}
\NormalTok{    db1 }\OperatorTok{=}\NormalTok{ sum}\OperatorTok{(}\NormalTok{dz1}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Each gradient is computed by local differentiation and multiplied back.

\subsubsection{3. Activation Functions}\label{activation-functions}

Nonlinear activations let networks approximate nonlinear functions.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Function & Formula & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
ReLU & \(\max(0, x)\) & Default, fast \\
Sigmoid & \(\frac{1}{1 + e^{-x}}\) & Probabilities \\
Tanh & \(\tanh(x)\) & Centered activations \\
GELU & \(x \, \Phi(x)\) & Modern transformers \\
\end{longtable}

Without nonlinearity, stacking layers is just one big linear
transformation.

\subsubsection{4. Dropout}\label{dropout}

Dropout is a regularization technique that prevents overfitting. During
training, randomly turn off neurons:

\[
\tilde{a}_i = a_i \cdot m_i, \quad m_i \sim \text{Bernoulli}(p)
\]

At inference, scale activations by ( p ) (keep probability).

It forces the network to not rely on any single path.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\DataTypeTok{int}\NormalTok{ i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{rand\_uniform}\OperatorTok{()} \OperatorTok{\textless{}}\NormalTok{ p}\OperatorTok{)}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
    \ControlFlowTok{else}\NormalTok{ a}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{/=}\NormalTok{ p}\OperatorTok{;} \CommentTok{// scaling}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{5. Normalization}\label{normalization}

Normalization stabilizes and speeds up training by reducing internal
covariate shift.

\subsubsection{Batch Normalization}\label{batch-normalization}

Normalize activations per batch:

\[
\hat{x} = \frac{x - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}
\]

\[
y = \gamma \hat{x} + \beta
\]

Learnable parameters \(\gamma, \beta\) restore flexibility.

Benefits:

\begin{itemize}
\tightlist
\item
  Smooth gradients- Allows higher learning rates- Acts as regularizer
  \#\#\#\# Layer Normalization
\end{itemize}

Used in transformers (normalizes across features, not batch).

\subsubsection{6. Initialization}\label{initialization}

Proper initialization helps gradients flow.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Scheme & Formula & Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Xavier & \(\text{Var}(W) = \frac{1}{n_{in}}\) & Tanh \\
He & \(\text{Var}(W) = \frac{2}{n_{in}}\) & ReLU \\
\end{longtable}

Poor initialization can lead to vanishing or exploding gradients.

\subsubsection{7. Training Pipeline}\label{training-pipeline}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize weights
\item
  Forward pass
\item
  Compute loss
\item
  Backward pass (backprop)
\item
  Update weights (e.g.~with Adam)
\end{enumerate}

Repeat until convergence.

\subsubsection{8. Deep Architectures}\label{deep-architectures}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Model & Key Idea & Typical Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
MLP & Fully connected & Tabular data \\
CNN & Convolutions & Images \\
RNN & Sequential recurrence & Time series, text \\
Transformer & Self-attention & Language, vision \\
\end{longtable}

Each architecture stacks linear operations and nonlinearities in
different ways.

\subsubsection{9. Overfitting and
Regularization}\label{overfitting-and-regularization}

Common fixes:

\begin{itemize}
\tightlist
\item
  Dropout- Weight decay (\(L_2\) regularization)- Data augmentation-
  Early stopping The key is to improve generalization, not just minimize
  training loss.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-93}

Backpropagation turned neural networks from theory to practice.
Normalization made them train faster. Dropout made them generalize
better.

Together, they unlocked the deep learning revolution.

\begin{quote}
``Depth gives power, but gradients give life.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-93}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement a 2-layer network with ReLU and softmax.
\item
  Add dropout and batch normalization.
\item
  Visualize training with and without dropout.
\item
  Compare performance on MNIST with and without normalization.
\end{enumerate}

\subsection{95. Sequence Models (Viterbi, Beam Search,
CTC)}\label{sequence-models-viterbi-beam-search-ctc}

Sequence models process data where order matters, text, speech, DNA,
time series. They capture dependencies across positions, predicting the
next step from context.

This section explores three fundamental tools: Viterbi, Beam Search, and
CTC (Connectionist Temporal Classification).

\subsubsection{1. The Nature of Sequential
Data}\label{the-nature-of-sequential-data}

Sequential data has temporal or structural order. Each element \(x_t\)
depends on past inputs \(x_{1:t-1}\).

Common sequence tasks:

\begin{itemize}
\tightlist
\item
  Tagging (POS tagging, named entity recognition)- Transcription (speech
  → text)- Decoding (translation, path reconstruction) To handle such
  problems, we need models that remember.
\end{itemize}

\subsubsection{2. Hidden Markov Models
(HMMs)}\label{hidden-markov-models-hmms}

A Hidden Markov Model assumes:

\begin{itemize}
\tightlist
\item
  A sequence of hidden states \(z_1, z_2, \ldots, z_T\)- Each state
  emits an observation \(x_t\)- Transition and emission probabilities
  govern the process \[
  P(z_t | z_{t-1}) = A_{z_{t-1}, z_t}, \quad P(x_t | z_t) = B_{z_t}(x_t)
  \]
\end{itemize}

Goal: find the most likely sequence of hidden states given observations.

\subsubsection{3. The Viterbi Algorithm}\label{the-viterbi-algorithm}

Viterbi is a dynamic programming algorithm to decode the most probable
path:

\[
\delta_t(i) = \max_{z_{1:t-1}} P(z_{1:t-1}, z_t = i, x_{1:t})
\]

Recurrence:

\[
\delta_t(i) = \max_j \big( \delta_{t-1}(j) \cdot A_{j,i} \big) \cdot B_i(x_t)
\]

Track backpointers to reconstruct the best sequence.

Time complexity: \(O(T \cdot N^2)\),\\
where \(N\) = number of states, \(T\) = sequence length.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{t }\OperatorTok{=} \DecValTok{1}\OperatorTok{;}\NormalTok{ t }\OperatorTok{\textless{}}\NormalTok{ T}\OperatorTok{;}\NormalTok{ t}\OperatorTok{++)} \OperatorTok{\{}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)} \OperatorTok{\{}
        \DataTypeTok{double}\NormalTok{ best }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{INF}\OperatorTok{;}
        \DataTypeTok{int}\NormalTok{ argmax }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{j }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ j }\OperatorTok{\textless{}}\NormalTok{ N}\OperatorTok{;}\NormalTok{ j}\OperatorTok{++)} \OperatorTok{\{}
            \DataTypeTok{double}\NormalTok{ score }\OperatorTok{=}\NormalTok{ delta}\OperatorTok{[}\NormalTok{t}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{][}\NormalTok{j}\OperatorTok{]} \OperatorTok{*}\NormalTok{ A}\OperatorTok{[}\NormalTok{j}\OperatorTok{][}\NormalTok{i}\OperatorTok{];}
            \ControlFlowTok{if} \OperatorTok{(}\NormalTok{score }\OperatorTok{\textgreater{}}\NormalTok{ best}\OperatorTok{)} \OperatorTok{\{}\NormalTok{ best }\OperatorTok{=}\NormalTok{ score}\OperatorTok{;}\NormalTok{ argmax }\OperatorTok{=}\NormalTok{ j}\OperatorTok{;} \OperatorTok{\}}
        \OperatorTok{\}}
\NormalTok{        delta}\OperatorTok{[}\NormalTok{t}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ best }\OperatorTok{*}\NormalTok{ B}\OperatorTok{[}\NormalTok{i}\OperatorTok{][}\NormalTok{x}\OperatorTok{[}\NormalTok{t}\OperatorTok{]];}
\NormalTok{        backptr}\OperatorTok{[}\NormalTok{t}\OperatorTok{][}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ argmax}\OperatorTok{;}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use \texttt{backptr} to trace back the optimal path.

\subsubsection{4. Beam Search}\label{beam-search}

For many sequence models (e.g.~neural machine translation), exhaustive
search is impossible. Beam search keeps only the top-k best hypotheses
at each step.

Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with an empty sequence and score 0
\item
  At each step, expand each candidate with all possible next tokens
\item
  Keep only k best sequences (beam size)
\item
  Stop when all sequences end or reach max length
\end{enumerate}

Beam size controls trade-off:

\begin{itemize}
\tightlist
\item
  Larger beam → better accuracy, slower- Smaller beam → faster, riskier
\end{itemize}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{step }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ step }\OperatorTok{\textless{}}\NormalTok{ max\_len}\OperatorTok{;}\NormalTok{ step}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    vector}\OperatorTok{\textless{}}\NormalTok{Candidate}\OperatorTok{\textgreater{}}\NormalTok{ new\_beam}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{c in beam}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{        probs }\OperatorTok{=}\NormalTok{ model\_next}\OperatorTok{(}\NormalTok{c}\OperatorTok{.}\NormalTok{seq}\OperatorTok{);}
        \ControlFlowTok{for} \OperatorTok{(}\NormalTok{token}\OperatorTok{,}\NormalTok{ p in probs}\OperatorTok{)}
\NormalTok{            new\_beam}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{c}\OperatorTok{.}\NormalTok{seq }\OperatorTok{+}\NormalTok{ token}\OperatorTok{,}\NormalTok{ c}\OperatorTok{.}\NormalTok{score }\OperatorTok{+}\NormalTok{ log}\OperatorTok{(}\NormalTok{p}\OperatorTok{)\});}
    \OperatorTok{\}}
\NormalTok{    beam }\OperatorTok{=}\NormalTok{ top\_k}\OperatorTok{(}\NormalTok{new\_beam}\OperatorTok{,}\NormalTok{ k}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Use log probabilities to avoid underflow.

\subsubsection{5. Connectionist Temporal Classification
(CTC)}\label{connectionist-temporal-classification-ctc}

Used in speech recognition and handwriting recognition where input and
output lengths differ.

CTC learns to align input frames with output symbols without explicit
alignment.

Add a special blank symbol (∅) to allow flexible alignment.

Example (CTC decoding):

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Frame & Output & After Collapse \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A ∅ A A & A ∅ A & A A \\
H ∅ ∅ H & H H & H \\
\end{longtable}

Loss: \[
P(y | x) = \sum_{\pi \in \text{Align}(x, y)} P(\pi | x)
\] where \(\pi\) are all alignments that reduce to ( y ).

CTC uses dynamic programming to compute forward-backward probabilities.

\subsubsection{6. Comparing Methods}\label{comparing-methods}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1594}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2319}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2609}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Used In
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Handles Alignment?
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Viterbi & HMMs & Most probable state path & Yes \\
Beam Search & Neural decoders & Approximate search & Implicit \\
CTC & Speech / seq2seq & Sum over alignments & Yes \\
\end{longtable}

\subsubsection{7. Use Cases}\label{use-cases}

\begin{itemize}
\tightlist
\item
  Viterbi: POS tagging, speech decoding- Beam Search: translation, text
  generation- CTC: ASR, OCR, gesture recognition
\end{itemize}

\subsubsection{8. Implementation Tips}\label{implementation-tips}

\begin{itemize}
\tightlist
\item
  Use log-space for probabilities- In beam search, apply length
  normalization- In CTC, use dynamic programming tables- Combine CTC +
  beam search for speech decoding
\end{itemize}

\subsubsection{9. Common Pitfalls}\label{common-pitfalls-1}

\begin{itemize}
\tightlist
\item
  Viterbi assumes Markov property (limited memory)- Beam Search can miss
  global optimum- CTC can confuse repeated characters without blanks
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-94}

Sequence models are the bridge between structure and time. They show how
to decode hidden meaning in ordered data.

From decoding Morse code to transcribing speech, these algorithms give
machines the gift of sequence understanding.

\subsubsection{Try It Yourself}\label{try-it-yourself-94}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Viterbi for a 3-state HMM.
\item
  Compare greedy decoding vs beam search on a toy language model.
\item
  Build a CTC loss table for a short sequence (like ``HELLO'').
\end{enumerate}

\subsection{96. Metaheuristics (GA, SA, PSO,
ACO)}\label{metaheuristics-ga-sa-pso-aco}

Metaheuristics are general-purpose optimization strategies that search
through vast, complex spaces when exact methods are too slow or
infeasible. They don't guarantee the perfect answer but often find
good-enough solutions fast.

This section covers four classics:

\begin{itemize}
\tightlist
\item
  GA (Genetic Algorithm)- SA (Simulated Annealing)- PSO (Particle Swarm
  Optimization)- ACO (Ant Colony Optimization)
\end{itemize}

\subsubsection{1. The Metaheuristic
Philosophy}\label{the-metaheuristic-philosophy}

Metaheuristics draw inspiration from nature and physics. They combine
exploration (searching widely) and exploitation (refining promising
spots).

They're ideal for:

\begin{itemize}
\tightlist
\item
  NP-hard problems (TSP, scheduling)- Continuous optimization (parameter
  tuning)- Black-box functions (no gradients) They trade mathematical
  guarantees for practical power.
\end{itemize}

\subsubsection{2. Genetic Algorithm (GA)}\label{genetic-algorithm-ga}

Inspired by natural selection, GAs evolve a population of solutions.

\subsubsection{Core Steps}\label{core-steps}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize population randomly
\item
  Evaluate fitness of each
\item
  Select parents
\item
  Crossover to produce offspring
\item
  Mutate to add variation
\item
  Replace worst with new candidates
\end{enumerate}

Repeat until convergence.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{gen }\OperatorTok{=} \DecValTok{0}\OperatorTok{;}\NormalTok{ gen }\OperatorTok{\textless{}}\NormalTok{ max\_gen}\OperatorTok{;}\NormalTok{ gen}\OperatorTok{++)} \OperatorTok{\{}
\NormalTok{    evaluate}\OperatorTok{(}\NormalTok{pop}\OperatorTok{);}
\NormalTok{    parents }\OperatorTok{=}\NormalTok{ select\_best}\OperatorTok{(}\NormalTok{pop}\OperatorTok{);}
\NormalTok{    offspring }\OperatorTok{=}\NormalTok{ crossover}\OperatorTok{(}\NormalTok{parents}\OperatorTok{);}
\NormalTok{    mutate}\OperatorTok{(}\NormalTok{offspring}\OperatorTok{);}
\NormalTok{    pop }\OperatorTok{=}\NormalTok{ select\_survivors}\OperatorTok{(}\NormalTok{pop}\OperatorTok{,}\NormalTok{ offspring}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Operators

\begin{itemize}
\tightlist
\item
  Selection: tournament, roulette-wheel- Crossover: one-point, uniform-
  Mutation: bit-flip, Gaussian Strengths: global search, diverse
  exploration Weakness: may converge slowly
\end{itemize}

\subsubsection{3. Simulated Annealing
(SA)}\label{simulated-annealing-sa}

Mimics cooling of metals, start hot (high randomness), slowly cool.

At each step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Propose random neighbor
\item
  Accept if better
\item
  If worse, accept with probability \[
  P = e^{-\frac{\Delta E}{T}}
  \]
\item
  Gradually lower ( T )
\end{enumerate}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OperatorTok{=}\NormalTok{ T\_init}\OperatorTok{;}
\NormalTok{state }\OperatorTok{=}\NormalTok{ random\_state}\OperatorTok{();}
\ControlFlowTok{while} \OperatorTok{(}\NormalTok{T }\OperatorTok{\textgreater{}}\NormalTok{ T\_min}\OperatorTok{)} \OperatorTok{\{}
\NormalTok{    next }\OperatorTok{=}\NormalTok{ neighbor}\OperatorTok{(}\NormalTok{state}\OperatorTok{);}
\NormalTok{    dE }\OperatorTok{=}\NormalTok{ cost}\OperatorTok{(}\NormalTok{next}\OperatorTok{)} \OperatorTok{{-}}\NormalTok{ cost}\OperatorTok{(}\NormalTok{state}\OperatorTok{);}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{dE }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{||}\NormalTok{ exp}\OperatorTok{({-}}\NormalTok{dE}\OperatorTok{/}\NormalTok{T}\OperatorTok{)} \OperatorTok{\textgreater{}}\NormalTok{ rand\_uniform}\OperatorTok{())}
\NormalTok{        state }\OperatorTok{=}\NormalTok{ next}\OperatorTok{;}
\NormalTok{    T }\OperatorTok{*=}\NormalTok{ alpha}\OperatorTok{;} \CommentTok{// cooling rate}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

Strengths: escapes local minima Weakness: sensitive to cooling schedule

\subsubsection{4. Particle Swarm Optimization
(PSO)}\label{particle-swarm-optimization-pso}

Inspired by bird flocking. Each particle adjusts velocity based on:

\begin{itemize}
\tightlist
\item
  Its own best position- The global best found \[
  v_i \leftarrow w v_i + c_1 r_1 (p_i - x_i) + c_2 r_2 (g - x_i)
  \]
\end{itemize}

\[
x_i \leftarrow x_i + v_i
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each particle i}\OperatorTok{:}
\NormalTok{    v}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{=}\NormalTok{ w}\OperatorTok{*}\NormalTok{v}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+}\NormalTok{ c1}\OperatorTok{*}\NormalTok{r1}\OperatorTok{*(}\NormalTok{pbest}\OperatorTok{[}\NormalTok{i}\OperatorTok{]{-}}\NormalTok{x}\OperatorTok{[}\NormalTok{i}\OperatorTok{])} \OperatorTok{+}\NormalTok{ c2}\OperatorTok{*}\NormalTok{r2}\OperatorTok{*(}\NormalTok{gbest}\OperatorTok{{-}}\NormalTok{x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]);}
\NormalTok{    x}\OperatorTok{[}\NormalTok{i}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ v}\OperatorTok{[}\NormalTok{i}\OperatorTok{];}
\NormalTok{    update\_best}\OperatorTok{(}\NormalTok{i}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Strengths: continuous domains, easy Weakness: premature convergence

\subsubsection{5. Ant Colony Optimization
(ACO)}\label{ant-colony-optimization-aco}

Inspired by ant foraging, ants deposit pheromones on paths. The stronger
the trail, the more likely others follow.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize pheromone on all edges
\item
  Each ant builds a solution (prob. ∝ pheromone)
\item
  Evaluate paths
\item
  Evaporate pheromone
\item
  Reinforce good paths
\end{enumerate}

\[
\tau_{ij} \leftarrow (1 - \rho)\tau_{ij} + \sum_k \Delta\tau_{ij}^k
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ each iteration}\OperatorTok{:}
    \ControlFlowTok{for}\NormalTok{ each ant}\OperatorTok{:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ build\_solution}\OperatorTok{(}\NormalTok{pheromone}\OperatorTok{);}
\NormalTok{        score }\OperatorTok{=}\NormalTok{ evaluate}\OperatorTok{(}\NormalTok{path}\OperatorTok{);}
\NormalTok{    evaporate}\OperatorTok{(}\NormalTok{pheromone}\OperatorTok{);}
\NormalTok{    deposit}\OperatorTok{(}\NormalTok{pheromone}\OperatorTok{,}\NormalTok{ best\_paths}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

Strengths: combinatorial problems (TSP) Weakness: parameter tuning,
slower convergence

\subsubsection{6. Comparing the Four}\label{comparing-the-four}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0870}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2029}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2754}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4348}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Inspiration
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best For
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key Idea
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GA & Evolution & Discrete search & Selection, crossover, mutation \\
SA & Thermodynamics & Local optima escape & Cooling + randomness \\
PSO & Swarm behavior & Continuous search & Local + global attraction \\
ACO & Ant foraging & Graph paths & Pheromone reinforcement \\
\end{longtable}

\subsubsection{7. Design Patterns}\label{design-patterns}

Common metaheuristic pattern:

\begin{itemize}
\tightlist
\item
  Represent solution- Define fitness / cost function- Define neighbor /
  mutation operators- Balance randomness and greediness Tuning
  parameters often matters more than equations.
\end{itemize}

\subsubsection{8. Hybrid Metaheuristics}\label{hybrid-metaheuristics}

Combine strengths:

\begin{itemize}
\tightlist
\item
  GA + SA: evolve population, fine-tune locally- PSO + DE: use swarm +
  differential evolution- ACO + Local Search: reinforce with
  hill-climbing These hybrids often outperform single methods.
\end{itemize}

\subsubsection{9. Common Pitfalls}\label{common-pitfalls-2}

\begin{itemize}
\tightlist
\item
  Poor representation → weak search- Over-exploitation → stuck in local
  optima- Bad parameters → chaotic or stagnant behavior Always visualize
  progress (fitness over time).
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-95}

Metaheuristics give us adaptive intelligence, searching without
gradients, equations, or complete knowledge. They reflect nature's way
of solving complex puzzles: iterate, adapt, survive.

\begin{quote}
``Optimization is not about perfection. It's about progress guided by
curiosity.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-95}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Simulated Annealing for the Traveling Salesman Problem.
\item
  Create a Genetic Algorithm for knapsack optimization.
\item
  Tune PSO parameters to fit a function \(f(x) = x^2 + 10\sin x\).
\item
  Compare ACO paths for TSP at different evaporation rates.
\end{enumerate}

\subsection{97. Reinforcement Learning (Q-learning, Policy
Gradients)}\label{reinforcement-learning-q-learning-policy-gradients}

Reinforcement Learning (RL) is about learning through interaction , an
agent explores an environment, takes actions, and learns from rewards.
Unlike supervised learning (where correct labels are given), RL learns
what to do by trial and error.

This section introduces two core approaches:

\begin{itemize}
\tightlist
\item
  Q-learning (value-based)- Policy Gradient (policy-based)
\end{itemize}

\subsubsection{1. The Reinforcement Learning
Setting}\label{the-reinforcement-learning-setting}

An RL problem is modeled as a Markov Decision Process (MDP):

\begin{itemize}
\tightlist
\item
  States \(S\)
\item
  Actions \(A\)
\item
  Transition \(P(s' \mid s, a)\)
\item
  Reward \(R(s, a)\)
\item
  Discount factor \(\gamma\)
\end{itemize}

The agent's goal is to find a policy \(\pi(a \mid s)\) that maximizes
expected return:

\[
G_t = \sum_{k=0}^\infty \gamma^k R_{t+k+1}
\]

\subsubsection{2. Value Functions}\label{value-functions}

The value function measures how good a state (or state-action pair) is.

\begin{itemize}
\item
  State-value: \[
  V^\pi(s) = \mathbb{E}_\pi[G_t | S_t = s]
  \]
\item
  Action-value (Q-function): \[
  Q^\pi(s, a) = \mathbb{E}_\pi[G_t | S_t = s, A_t = a]
  \]
\end{itemize}

\subsubsection{3. Bellman Equation}\label{bellman-equation}

The Bellman equation relates a state's value to its neighbors:

\[
Q^*(s,a) = R(s,a) + \gamma \max_{a'} Q^*(s',a')
\]

This recursive definition drives value iteration and Q-learning.

\subsubsection{4. Q-Learning}\label{q-learning}

Q-learning learns the optimal action-value function off-policy
(independent of behavior policy):

Update Rule: \[
Q(s,a) \leftarrow Q(s,a) + \alpha \big[ r + \gamma \max_{a'} Q(s',a') - Q(s,a) \big]
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Q}\OperatorTok{[}\NormalTok{s}\OperatorTok{][}\NormalTok{a}\OperatorTok{]} \OperatorTok{+=}\NormalTok{ alpha }\OperatorTok{*} \OperatorTok{(}\NormalTok{r }\OperatorTok{+}\NormalTok{ gamma }\OperatorTok{*}\NormalTok{ max}\OperatorTok{(}\NormalTok{Q}\OperatorTok{[}\NormalTok{s\_next}\OperatorTok{])} \OperatorTok{{-}}\NormalTok{ Q}\OperatorTok{[}\NormalTok{s}\OperatorTok{][}\NormalTok{a}\OperatorTok{]);}
\NormalTok{s }\OperatorTok{=}\NormalTok{ s\_next}\OperatorTok{;}
\end{Highlighting}
\end{Shaded}

Repeat while exploring (e.g., \(\varepsilon\)-greedy):

\begin{itemize}
\tightlist
\item
  With probability \(\varepsilon\), choose a random action
\item
  With probability \(1 - \varepsilon\), choose the best action
\end{itemize}

Over time, \(Q\) converges to \(Q^*\).

\subsubsection{5. Exploration vs
Exploitation}\label{exploration-vs-exploitation}

RL is a balancing act:

\begin{itemize}
\item
  Exploration: try new actions to gather knowledge- Exploitation: use
  current best knowledge to maximize reward Strategies:
\item
  ε-greedy- Softmax action selection- Upper Confidence Bound (UCB)
\end{itemize}

\subsubsection{6. Policy Gradient
Methods}\label{policy-gradient-methods}

Instead of learning Q-values, learn the policy directly. Represent
policy with parameters \(\theta\):

\[
\pi_\theta(a|s) = P(a | s; \theta)
\]

Goal: maximize expected return \[
J(\theta) = \mathbb{E}*{\pi*\theta}[G_t]
\]

Gradient ascent update: \[
\theta \leftarrow \theta + \alpha \nabla_\theta J(\theta)
\]

REINFORCE Algorithm: \[
\nabla_\theta J(\theta) = \mathbb{E}\big[ G_t \nabla_\theta \log \pi_\theta(a_t|s_t) \big]
\]

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OperatorTok{+=}\NormalTok{ alpha }\OperatorTok{*}\NormalTok{ G\_t }\OperatorTok{*}\NormalTok{ grad\_logpi}\OperatorTok{(}\NormalTok{a\_t}\OperatorTok{,}\NormalTok{ s\_t}\OperatorTok{);}
\end{Highlighting}
\end{Shaded}

\subsubsection{7. Actor-Critic
Architecture}\label{actor-critic-architecture}

Combines policy gradient (actor) + value estimation (critic).

\begin{itemize}
\tightlist
\item
  Actor: updates policy- Critic: estimates value (baseline) Update: \[
  \theta \leftarrow \theta + \alpha_\theta \delta_t \nabla_\theta \log \pi_\theta(a_t|s_t)
  \]
\end{itemize}

\[
w \leftarrow w + \alpha_w \delta_t \nabla_w V_w(s_t)
\]

with TD error: \[
\delta_t = r + \gamma V(s') - V(s)
\]

\subsubsection{8. Comparing Methods}\label{comparing-methods-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1967}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1148}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2131}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1803}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0492}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Learns
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
On/Off Policy
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Continuous?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Q-learning & Value-based & Q(s, a) & Off-policy & No & \\
Policy Gradient & Policy-based & π(a & s) & On-policy & Yes \\
Actor-Critic & Hybrid & Both & On-policy & Yes & \\
\end{longtable}

\subsubsection{9. Extensions}\label{extensions}

\begin{itemize}
\tightlist
\item
  Deep Q-Networks (DQN): use neural nets for Q(s, a)- PPO / A3C:
  advanced actor-critic methods- TD(λ): tradeoff between MC and TD
  learning- Double Q-learning: reduce overestimation- Entropy
  regularization: encourage exploration
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-96}

Reinforcement learning powers autonomous agents, game AIs, and control
systems. It's the foundation of AlphaGo, robotics control, and adaptive
decision systems.

\begin{quote}
``An agent learns not from instruction but from experience.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-96}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Q-learning for a grid-world maze.
\item
  Add ε-greedy exploration.
\item
  Visualize the learned policy.
\item
  Try REINFORCE with a simple policy (e.g.~softmax over actions).
\item
  Compare convergence of Q-learning vs Policy Gradient.
\end{enumerate}

\subsection{98. Approximation and Online
Algorithms}\label{approximation-and-online-algorithms}

In the real world, we often can't wait for a perfect solution , data
arrives on the fly, or the problem is too hard to solve exactly. That's
where approximation and online algorithms shine. They aim for
good-enough results, fast and adaptively, under uncertainty.

\subsubsection{1. The Big Picture}\label{the-big-picture-1}

\begin{itemize}
\tightlist
\item
  Approximation algorithms: Solve NP-hard problems with provable
  bounds.- Online algorithms: Make immediate decisions without knowing
  the future. Both trade optimality for efficiency or adaptability.
\end{itemize}

\subsubsection{2. Approximation
Algorithms}\label{approximation-algorithms}

An approximation algorithm finds a solution within a factor \(\rho\) of
the optimal.

If ( C ) is cost of the algorithm, and \(C^*\) is optimal cost:

\[
\rho = \max\left(\frac{C}{C^*}, \frac{C^*}{C}\right)
\]

Example: \(\rho = 2\) → solution at most twice worse than optimal.

\subsubsection{3. Example: Vertex Cover}\label{example-vertex-cover}

Problem: Given graph ( G(V,E) ), choose smallest set of vertices
covering all edges.

Algorithm (2-approximation):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize cover = ∅
\item
  While edges remain:

  \begin{itemize}
  \tightlist
  \item
    Pick any edge (u, v) - Add both u, v to cover - Remove all edges
    incident on u or v Guarantee: At most 2× optimal size.
  \end{itemize}
\end{enumerate}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cover }\OperatorTok{=} \OperatorTok{\{\};}
\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{edges}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
    \OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{)} \OperatorTok{=}\NormalTok{ edges}\OperatorTok{.}\NormalTok{pop}\OperatorTok{();}
\NormalTok{    cover}\OperatorTok{.}\NormalTok{add}\OperatorTok{(}\NormalTok{u}\OperatorTok{);}
\NormalTok{    cover}\OperatorTok{.}\NormalTok{add}\OperatorTok{(}\NormalTok{v}\OperatorTok{);}
\NormalTok{    remove\_incident\_edges}\OperatorTok{(}\NormalTok{u}\OperatorTok{,}\NormalTok{ v}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{4. Example: Metric TSP (Triangle
Inequality)}\label{example-metric-tsp-triangle-inequality}

Algorithm (Christofides):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Find MST
\item
  Find odd-degree vertices
\item
  Find min perfect matching
\item
  Combine + shortcut to get tour
\end{enumerate}

Guarantee: ≤ 1.5 × optimal.

\subsubsection{5. Greedy Approximation: Set
Cover}\label{greedy-approximation-set-cover}

Goal: Cover universe ( U ) with minimum sets \(S_i\).

Greedy Algorithm: Pick set covering most uncovered elements each time.
Guarantee: \(H_n \approx \ln n\) factor approximation.

\subsubsection{6. Online Algorithms}\label{online-algorithms}

Online algorithms must decide now, before future input is known.

Goal: Minimize competitive ratio:

\[
\text{CR} = \max_{\text{input}} \frac{\text{Cost}*{\text{online}}}{\text{Cost}*{\text{optimal offline}}}
\]

Lower CR → better adaptability.

\subsubsection{7. Classic Example: Online
Paging}\label{classic-example-online-paging}

You have k pages in cache, sequence of page requests.

\begin{itemize}
\item
  If page in cache → hit- Else → miss, must evict one page Strategies:
\item
  LRU (Least Recently Used): evict oldest- FIFO: evict first loaded-
  Random: pick randomly Competitive Ratio:
\item
  LRU: ≤ ( k )- Random: ≤ ( 2k-1 )
\end{itemize}

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cache }\OperatorTok{=}\NormalTok{ LRUCache}\OperatorTok{(}\NormalTok{k}\OperatorTok{);}
\ControlFlowTok{for} \OperatorTok{(}\NormalTok{page in requests}\OperatorTok{)} \OperatorTok{\{}
    \ControlFlowTok{if} \OperatorTok{(!}\NormalTok{cache}\OperatorTok{.}\NormalTok{contains}\OperatorTok{(}\NormalTok{page}\OperatorTok{))}
\NormalTok{        cache}\OperatorTok{.}\NormalTok{evict\_oldest}\OperatorTok{();}
\NormalTok{    cache}\OperatorTok{.}\NormalTok{add}\OperatorTok{(}\NormalTok{page}\OperatorTok{);}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{8. Online Bipartite Matching
(Karp-Vazirani-Vazirani)}\label{online-bipartite-matching-karp-vazirani-vazirani}

Given offline set U and online set V (arrives one by one), match
greedily. Competitive ratio: \(1 - \frac{1}{e}\)

Used in ad allocation and resource assignment.

\subsubsection{9. Approximation + Online
Together}\label{approximation-online-together}

Modern algorithms blend both:

\begin{itemize}
\tightlist
\item
  Streaming algorithms: One pass, small memory (Count-Min, reservoir
  sampling)- Online learning: Update models incrementally (SGD,
  perceptron)- Approximate dynamic programming: RL and heuristic search
  These are approximate online solvers , both quick and adaptive.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-97}

Approximation algorithms give us provable near-optimal answers. Online
algorithms give us real-time adaptivity. Together, they model
intelligence under limits , when time and information are scarce.

\begin{quote}
``Sometimes, good and on time beats perfect and late.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-97}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement 2-approx vertex cover on a small graph.
\item
  Simulate online paging with LRU vs Random.
\item
  Build a greedy set cover solver.
\item
  Measure competitive ratio on test sequences.
\item
  Combine ideas: streaming + approximation for big data filtering.
\end{enumerate}

\subsection{99. Fairness, Causal Inference, and Robust
Optimization}\label{fairness-causal-inference-and-robust-optimization}

As algorithms increasingly shape decisions , from hiring to lending to
healthcare , we must ensure they're fair, causally sound, and robust to
uncertainty. This section blends ideas from ethics, statistics, and
optimization to make algorithms not just efficient, but responsible and
reliable.

\subsubsection{1. Why Fairness Matters}\label{why-fairness-matters}

Machine learning systems often inherit biases from data. Without
intervention, they can amplify inequality or discrimination.

Fairness-aware algorithms explicitly measure and correct these effects.

Common sources of bias:

\begin{itemize}
\tightlist
\item
  Historical bias (biased data)- Measurement bias (imprecise features)-
  Selection bias (skewed samples) The goal: equitable treatment across
  sensitive groups (gender, race, region, etc.)
\end{itemize}

\subsubsection{2. Formal Fairness
Criteria}\label{formal-fairness-criteria}

Several fairness notions exist, often conflicting:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1705}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2636}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3721}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0465}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1473}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Criterion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Demographic Parity & ( P\(\hat{Y}=1                      | A=a\) =
P\(\hat{Y}=1                               | A=b\) ) & Equal positive
rate & & \\
Equal Opportunity & Equal true positive rates & Same recall for all
groups & & \\
Equalized Odds & Equal TPR \& FPR & Balanced errors & & \\
Calibration & Same predicted probability meaning & If model says 70\%,
all groups should achieve 70\% & & \\
\end{longtable}

No single measure fits all , fairness depends on context and trade-offs.

\subsubsection{3. Algorithmic Fairness
Techniques}\label{algorithmic-fairness-techniques}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Pre-processing Rebalance or reweight data before training. Example:
  reweighing, sampling.
\item
  In-processing Add fairness constraints to loss function. Example:
  adversarial debiasing.
\item
  Post-processing Adjust predictions after training. Example: threshold
  shifting.
\end{enumerate}

Tiny Code (Adversarial Debiasing Skeleton)

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ x, a, y }\KeywordTok{in}\NormalTok{ data:}
\NormalTok{    y\_pred }\OperatorTok{=}\NormalTok{ model(x)}
\NormalTok{    loss\_main }\OperatorTok{=}\NormalTok{ loss\_fn(y\_pred, y)}
\NormalTok{    loss\_adv }\OperatorTok{=}\NormalTok{ adv\_fn(y\_pred, a)}
\NormalTok{    loss\_total }\OperatorTok{=}\NormalTok{ loss\_main }\OperatorTok{{-}}\NormalTok{ λ }\OperatorTok{*}\NormalTok{ loss\_adv}
\NormalTok{    update(loss\_total)}
\end{Highlighting}
\end{Shaded}

Here, the adversary tries to predict sensitive attribute, encouraging
invariance.

\subsubsection{4. Causal Inference
Basics}\label{causal-inference-basics}

Correlation ≠ causation. To reason about fairness and robustness, we
need causal understanding , what \emph{would} happen if we changed
something.

Causal inference models relationships via Directed Acyclic Graphs
(DAGs):

\begin{itemize}
\tightlist
\item
  Nodes: variables- Edges: causal influence
\end{itemize}

\subsubsection{5. Counterfactual
Reasoning}\label{counterfactual-reasoning}

A counterfactual asks:

\begin{quote}
``What would the outcome be if we intervened differently?''
\end{quote}

Formally: \[
P(Y_{do(X=x)})
\]

Used in:

\begin{itemize}
\tightlist
\item
  Fairness (counterfactual fairness)- Policy evaluation- Robust decision
  making
\end{itemize}

\subsubsection{6. Counterfactual
Fairness}\label{counterfactual-fairness}

An algorithm is counterfactually fair if prediction stays the same under
hypothetical changes to sensitive attributes.

\[
\hat{Y}*{A \leftarrow a}(U) = \hat{Y}*{A \leftarrow a'}(U)
\]

This requires causal models , not just data.

\subsubsection{7. Robust Optimization}\label{robust-optimization}

In uncertain environments, we want solutions that hold up under
worst-case conditions.

Formulation: \[
\min_x \max_{\xi \in \Xi} f(x, \xi)
\]

where \(\Xi\) is the uncertainty set.

Example: Design a portfolio that performs well under varying market
conditions.

Tiny Code

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{double}\NormalTok{ robust\_objective}\OperatorTok{(}\DataTypeTok{double}\NormalTok{ x}\OperatorTok{[],}\NormalTok{ Scenario Xi}\OperatorTok{[],} \DataTypeTok{int}\NormalTok{ N}\OperatorTok{)} \OperatorTok{\{}
    \DataTypeTok{double}\NormalTok{ worst }\OperatorTok{=} \OperatorTok{{-}}\NormalTok{INF}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{i}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ i}\OperatorTok{\textless{}}\NormalTok{N}\OperatorTok{;}\NormalTok{ i}\OperatorTok{++)}
\NormalTok{        worst }\OperatorTok{=}\NormalTok{ max}\OperatorTok{(}\NormalTok{worst}\OperatorTok{,}\NormalTok{ f}\OperatorTok{(}\NormalTok{x}\OperatorTok{,}\NormalTok{ Xi}\OperatorTok{[}\NormalTok{i}\OperatorTok{]));}
    \ControlFlowTok{return}\NormalTok{ worst}\OperatorTok{;}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

This searches for a solution minimizing worst-case loss.

\subsubsection{8. Distributional
Robustness}\label{distributional-robustness}

Instead of worst-case instances, protect against worst-case
distributions:

\[
\min_\theta \sup_{Q \in \mathcal{B}(P)} \mathbb{E}_{x \sim Q}[L(\theta, x)]
\]

Used in adversarial training and domain adaptation.

Example: Add noise or perturbations to improve resilience:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_adv }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+}\NormalTok{ ε }\OperatorTok{*}\NormalTok{ sign(grad(loss, x))}
\end{Highlighting}
\end{Shaded}

\subsubsection{9. Balancing Fairness, Causality, and
Robustness}\label{balancing-fairness-causality-and-robustness}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1408}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4930}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3662}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Goal
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Challenge
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fairness & Parity, Adversarial, Counterfactual & Competing
definitions \\
Causality & DAGs, do-calculus, SCMs & Identifying true structure \\
Robustness & Min-max, DRO, Adversarial Training & Trade-off with
accuracy \\
\end{longtable}

Real-world design involves balancing trade-offs.

Sometimes improving fairness reduces accuracy, or robustness increases
conservatism.

\subsubsection{10. Why It Matters}\label{why-it-matters-98}

Algorithms don't exist in isolation , they affect people. Embedding
fairness, causality, and robustness ensures systems are trustworthy,
interpretable, and just.

\begin{quote}
``The goal is not just intelligent algorithms , but responsible ones.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-98}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train a simple classifier on biased data.
\item
  Apply reweighing or adversarial debiasing.
\item
  Draw a causal DAG of your data features.
\item
  Compute counterfactual fairness for a sample.
\item
  Implement a robust loss using adversarial perturbations.
\end{enumerate}

\subsection{100. AI Planning, Search, and Learning
Systems}\label{ai-planning-search-and-learning-systems}

AI systems are not just pattern recognizers , they are decision makers.
They plan, search, and learn in structured environments, choosing
actions that lead to long-term goals. This section explores how modern
AI combines planning, search, and learning to solve complex tasks.

\subsubsection{1. What Is AI Planning?}\label{what-is-ai-planning}

AI planning is about finding a sequence of actions that transforms an
initial state into a goal state.

Formally, a planning problem consists of:

\begin{itemize}
\tightlist
\item
  States ( S )- Actions ( A )- Transition function ( T(s, a) \to s' )-
  Goal condition \(G \subseteq S\)- Cost function ( c(a) ) The
  objective: Find a plan \(\pi = [a_1, a_2, \ldots, a_n]\) minimizing
  total cost or maximizing reward.
\end{itemize}

\subsubsection{2. Search-Based Planning}\label{search-based-planning}

At the heart of planning lies search. Search explores possible action
sequences, guided by heuristics.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Type & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS & Uninformed & Deep exploration, no guarantee \\
BFS & Uninformed & Finds shortest path \\
Dijkstra & Weighted & Optimal if costs ≥ 0 \\
A* & Heuristic & Combines cost + heuristic \\
\end{longtable}

A* Search Formula: \[
f(n) = g(n) + h(n)
\] where:

\begin{itemize}
\tightlist
\item
  ( g(n) ): cost so far- ( h(n) ): heuristic estimate to goal If ( h )
  is admissible, A* is optimal.
\end{itemize}

Tiny Code (A* Skeleton)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{priority\_queue}\OperatorTok{\textless{}}\NormalTok{Node}\OperatorTok{\textgreater{}}\NormalTok{ open}\OperatorTok{;}
\NormalTok{g}\OperatorTok{[}\NormalTok{start}\OperatorTok{]} \OperatorTok{=} \DecValTok{0}\OperatorTok{;}
\NormalTok{open}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{start}\OperatorTok{,}\NormalTok{ h}\OperatorTok{(}\NormalTok{start}\OperatorTok{)\});}

\ControlFlowTok{while} \OperatorTok{(!}\NormalTok{open}\OperatorTok{.}\NormalTok{empty}\OperatorTok{())} \OperatorTok{\{}
\NormalTok{    n }\OperatorTok{=}\NormalTok{ open}\OperatorTok{.}\NormalTok{pop\_min}\OperatorTok{();}
    \ControlFlowTok{if} \OperatorTok{(}\NormalTok{goal}\OperatorTok{(}\NormalTok{n}\OperatorTok{))} \ControlFlowTok{break}\OperatorTok{;}
    \ControlFlowTok{for} \OperatorTok{(}\NormalTok{a in actions}\OperatorTok{(}\NormalTok{n}\OperatorTok{))} \OperatorTok{\{}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ step}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ a}\OperatorTok{);}
\NormalTok{        cost }\OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{n}\OperatorTok{]} \OperatorTok{+}\NormalTok{ c}\OperatorTok{(}\NormalTok{n}\OperatorTok{,}\NormalTok{ a}\OperatorTok{);}
        \ControlFlowTok{if} \OperatorTok{(}\NormalTok{cost }\OperatorTok{\textless{}}\NormalTok{ g}\OperatorTok{[}\NormalTok{s}\OperatorTok{])} \OperatorTok{\{}
\NormalTok{            g}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=}\NormalTok{ cost}\OperatorTok{;}
\NormalTok{            f}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{=}\NormalTok{ g}\OperatorTok{[}\NormalTok{s}\OperatorTok{]} \OperatorTok{+}\NormalTok{ h}\OperatorTok{(}\NormalTok{s}\OperatorTok{);}
\NormalTok{            open}\OperatorTok{.}\NormalTok{push}\OperatorTok{(\{}\NormalTok{s}\OperatorTok{,}\NormalTok{ f}\OperatorTok{[}\NormalTok{s}\OperatorTok{]\});}
        \OperatorTok{\}}
    \OperatorTok{\}}
\OperatorTok{\}}
\end{Highlighting}
\end{Shaded}

\subsubsection{3. Heuristics and
Admissibility}\label{heuristics-and-admissibility}

A heuristic ( h(s) ) estimates distance to the goal.

\begin{itemize}
\item
  Admissible: never overestimates- Consistent: satisfies triangle
  inequality Examples:
\item
  Manhattan distance (grids)- Euclidean distance (geometry)- Pattern
  databases (puzzles) Good heuristics = faster convergence.
\end{itemize}

\subsubsection{4. Classical Planning
(STRIPS)}\label{classical-planning-strips}

In symbolic AI, states are represented by facts (predicates), and
actions have preconditions and effects.

Example:

\begin{verbatim}
Action: Move(x, y)
Precondition: At(x), Clear(y)
Effect: ¬At(x), At(y)
\end{verbatim}

Search happens in logical state space.

Planners:

\begin{itemize}
\tightlist
\item
  Forward search (progression)- Backward search (regression)- Heuristic
  planners (FF, HSP)
\end{itemize}

\subsubsection{5. Hierarchical Planning}\label{hierarchical-planning}

Break complex goals into subgoals.

\begin{itemize}
\tightlist
\item
  HTN (Hierarchical Task Networks): Define high-level tasks broken into
  subtasks.
\end{itemize}

Example: ``Make dinner'' → {[}Cook rice, Stir-fry vegetables, Set
table{]}

Hierarchy makes planning modular and interpretable.

\subsubsection{6. Probabilistic Planning}\label{probabilistic-planning}

When actions are uncertain:

\begin{itemize}
\tightlist
\item
  MDPs: full observability, stochastic transitions- POMDPs: partial
  observability Use value iteration, policy iteration, or Monte Carlo
  planning.
\end{itemize}

\subsubsection{7. Learning to Plan}\label{learning-to-plan}

Combine learning with search:

\begin{itemize}
\tightlist
\item
  Learned heuristics: neural networks approximate ( h(s) )-
  AlphaZero-style planning: learn value + policy, guide tree search-
  Imitation learning: mimic expert demonstrations This bridges classical
  AI and modern ML.
\end{itemize}

Tiny Code (Learning-Guided A*)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f }\OperatorTok{=}\NormalTok{ g }\OperatorTok{+}\NormalTok{ alpha }\OperatorTok{*}\NormalTok{ learned\_heuristic(s)}
\end{Highlighting}
\end{Shaded}

Neural net learns ( h\_\theta(s) ) from solved examples.

\subsubsection{8. Integrated Systems}\label{integrated-systems}

Modern AI stacks combine:

\begin{itemize}
\item
  Search (planning backbone)- Learning (policy, heuristic, model)-
  Simulation (data generation) Examples:
\item
  AlphaZero: self-play + MCTS + neural nets- MuZero: learns model +
  value + policy jointly- Large Language Agents: use reasoning + memory
  + search
\end{itemize}

\subsubsection{9. Real-World
Applications}\label{real-world-applications}

\begin{itemize}
\tightlist
\item
  Robotics: motion planning, pathfinding- Games: Go, Chess, strategy
  games- Logistics: route optimization- Autonomy: drones, vehicles, AI
  assistants- Synthesis: program and query generation Each blends
  symbolic reasoning and statistical learning.
\end{itemize}

\subsubsection{10. Why It Matters}\label{why-it-matters-99}

Planning, search, and learning form the triad of intelligence:

\begin{itemize}
\tightlist
\item
  Search explores possibilities- Planning sequences actions toward
  goals- Learning adapts heuristics from experience Together, they power
  systems that think, adapt, and act.
\end{itemize}

\begin{quote}
``Intelligence is not just knowing , it is choosing wisely under
constraints.''
\end{quote}

\subsubsection{Try It Yourself}\label{try-it-yourself-99}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement A* search on a grid maze.
\item
  Add a Manhattan heuristic.
\item
  Extend to probabilistic transitions (simulate noise).
\item
  Build a simple planner with preconditions and effects.
\item
  Train a neural heuristic to guide search on puzzles.
\end{enumerate}

\bookmarksetup{startatroot}

\chapter{The Plan}\label{the-plan}

\subsection{Chapter 1. Foundations of
Algorithms}\label{chapter-1.-foundations-of-algorithms-2}

\subsubsection{1. What Is an Algorithm?}\label{what-is-an-algorithm-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0256}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.6410}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Euclid's GCD & Oldest known algorithm for greatest common divisor \\
2 & Sieve of Eratosthenes & Generate primes efficiently \\
3 & Binary Search & Divide and conquer search \\
4 & Exponentiation by Squaring & Fast power computation \\
5 & Long Division & Classic step-by-step arithmetic \\
6 & Modular Addition Algorithm & Wrap-around arithmetic \\
7 & Base Conversion Algorithm & Convert between number systems \\
8 & Factorial Computation & Recursive and iterative approaches \\
9 & Fibonacci Sequence & Recursive vs.~dynamic computation \\
10 & Tower of Hanoi & Recursive problem-solving pattern \\
\end{longtable}

\subsubsection{2. Measuring Time and
Space}\label{measuring-time-and-space-2}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0317}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4127}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5556}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
11 & Counting Operations & Manual step-counting for complexity \\
12 & Loop Analysis & Evaluate time cost of loops \\
13 & Recurrence Expansion & Analyze recursive costs \\
14 & Amortized Analysis & Average per-operation cost \\
15 & Space Counting & Stack and heap tracking \\
16 & Memory Footprint Estimator & Track per-variable usage \\
17 & Time Complexity Table & Map O(1)\ldots O(n²)\ldots O(2ⁿ) \\
18 & Space-Time Tradeoff & Cache vs.~recomputation \\
19 & Profiling Algorithm & Empirical time measurement \\
20 & Benchmarking Framework & Compare algorithm performance \\
\end{longtable}

\subsubsection{3. Big-O, Big-Theta,
Big-Omega}\label{big-o-big-theta-big-omega-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0290}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4348}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5362}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
21 & Growth Rate Comparator & Compare asymptotic behaviors \\
22 & Dominant Term Extractor & Simplify runtime expressions \\
23 & Limit-Based Complexity Test & Using limits for asymptotics \\
24 & Summation Simplifier & Sum of arithmetic/geometric sequences \\
25 & Recurrence Tree Method & Visualize recursive costs \\
26 & Master Theorem Evaluator & Solve T(n) recurrences \\
27 & Big-Theta Proof Builder & Bounding upper and lower limits \\
28 & Big-Omega Case Finder & Best-case scenario analysis \\
29 & Empirical Complexity Estimator & Measure via doubling
experiments \\
30 & Complexity Class Identifier & Match runtime to known class \\
\end{longtable}

\subsubsection{4. Algorithmic Paradigms (Greedy, Divide and Conquer,
DP)}\label{algorithmic-paradigms-greedy-divide-and-conquer-dp-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
31 & Greedy Coin Change & Local optimal step-by-step \\
32 & Huffman Coding & Greedy compression tree \\
33 & Merge Sort & Divide and conquer sort \\
34 & Binary Search & Divide and conquer search \\
35 & Karatsuba Multiplication & Recursive divide \& conquer \\
36 & Matrix Chain Multiplication & DP with substructure \\
37 & Longest Common Subsequence & Classic DP problem \\
38 & Rod Cutting & DP optimization \\
39 & Activity Selection & Greedy scheduling \\
40 & Optimal Merge Patterns & Greedy file merging \\
\end{longtable}

\subsubsection{5. Recurrence Relations}\label{recurrence-relations-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
41 & Linear Recurrence Solver & Closed-form for linear recurrences \\
42 & Master Theorem & Divide-and-conquer complexity \\
43 & Substitution Method & Inductive proof approach \\
44 & Iteration Method & Expand recurrence step-by-step \\
45 & Generating Functions & Transform recurrences \\
46 & Matrix Exponentiation & Solve linear recurrences fast \\
47 & Recurrence to DP Table & Tabulation approach \\
48 & Divide \& Combine Template & Convert recurrence into algorithm \\
49 & Memoized Recursive Solver & Store overlapping results \\
50 & Characteristic Polynomial & Solve homogeneous recurrence \\
\end{longtable}

\subsubsection{6. Searching Basics}\label{searching-basics-2}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
51 & Linear Search & Sequential element scan \\
52 & Binary Search & Midpoint halving \\
53 & Jump Search & Block skip linear \\
54 & Exponential Search & Doubling step size \\
55 & Interpolation Search & Estimate position by value \\
56 & Ternary Search & Divide into thirds \\
57 & Fibonacci Search & Golden ratio search \\
58 & Sentinel Search & Early termination optimization \\
59 & Bidirectional Search & Meet-in-the-middle \\
60 & Search in Rotated Array & Adapted binary search \\
\end{longtable}

\subsubsection{7. Sorting Basics}\label{sorting-basics-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
61 & Bubble Sort & Adjacent swap sort \\
62 & Selection Sort & Find minimum each pass \\
63 & Insertion Sort & Incremental build sort \\
64 & Shell Sort & Gap-based insertion \\
65 & Merge Sort & Divide-and-conquer \\
66 & Quick Sort & Partition-based \\
67 & Heap Sort & Binary heap order \\
68 & Counting Sort & Integer key distribution \\
69 & Radix Sort & Digit-by-digit \\
70 & Bucket Sort & Group into ranges \\
\end{longtable}

\subsubsection{8. Data Structures
Overview}\label{data-structures-overview-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
71 & Stack Push/Pop & LIFO operations \\
72 & Queue Enqueue/Dequeue & FIFO operations \\
73 & Singly Linked List & Linear node chain \\
74 & Doubly Linked List & Bidirectional traversal \\
75 & Hash Table Insertion & Key-value indexing \\
76 & Binary Search Tree Insert & Ordered node placement \\
77 & Heapify & Build heap in-place \\
78 & Union-Find Operations & Disjoint-set management \\
79 & Graph Adjacency List Build & Sparse representation \\
80 & Trie Insertion/Search & Prefix tree for strings \\
\end{longtable}

\subsubsection{9. Graphs and Trees
Overview}\label{graphs-and-trees-overview-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
81 & DFS Traversal & Depth-first exploration \\
82 & BFS Traversal & Level-order exploration \\
83 & Topological Sort & DAG ordering \\
84 & Minimum Spanning Tree & Kruskal/Prim overview \\
85 & Dijkstra's Shortest Path & Weighted graph shortest route \\
86 & Bellman-Ford & Handle negative edges \\
87 & Floyd-Warshall & All-pairs shortest path \\
88 & Union-Find for MST & Edge grouping \\
89 & Tree Traversals & Inorder, Preorder, Postorder \\
90 & LCA (Lowest Common Ancestor) & Common node in tree \\
\end{longtable}

\subsubsection{10. Algorithm Design
Patterns}\label{algorithm-design-patterns-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
91 & Brute Force & Try all possibilities \\
92 & Greedy Choice & Local optimum per step \\
93 & Divide and Conquer & Break and merge \\
94 & Dynamic Programming & Reuse subproblems \\
95 & Backtracking & Explore with undo \\
96 & Branch and Bound & Prune search space \\
97 & Randomized Algorithm & Inject randomness \\
98 & Approximation Algorithm & Near-optimal solution \\
99 & Online Algorithm & Step-by-step decision \\
100 & Hybrid Strategy & Combine paradigms \\
\end{longtable}

\subsection{Chapter 2. Sorting and
Searching}\label{chapter-2.-sorting-and-searching-2}

\subsubsection{11. Elementary Sorting (Bubble, Insertion,
Selection)}\label{elementary-sorting-bubble-insertion-selection-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
101 & Bubble Sort & Swap adjacent out-of-order elements \\
102 & Improved Bubble Sort & Stop early if already sorted \\
103 & Cocktail Shaker Sort & Bidirectional bubble pass \\
104 & Selection Sort & Select smallest element each pass \\
105 & Double Selection Sort & Find both min and max each pass \\
106 & Insertion Sort & Insert each element into correct spot \\
107 & Binary Insertion Sort & Use binary search for position \\
108 & Gnome Sort & Simple insertion-like with swaps \\
109 & Odd-Even Sort & Parallel-friendly comparison sort \\
110 & Stooge Sort & Recursive quirky educational sort \\
\end{longtable}

\subsubsection{12. Divide-and-Conquer Sorting (Merge, Quick,
Heap)}\label{divide-and-conquer-sorting-merge-quick-heap-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
111 & Merge Sort & Recursive divide and merge \\
112 & Iterative Merge Sort & Bottom-up non-recursive version \\
113 & Quick Sort & Partition-based recursive sort \\
114 & Hoare Partition Scheme & Classic quicksort partition \\
115 & Lomuto Partition Scheme & Simpler but less efficient \\
116 & Randomized Quick Sort & Avoid worst-case pivot \\
117 & Heap Sort & Heapify + extract max repeatedly \\
118 & 3-Way Quick Sort & Handle duplicates efficiently \\
119 & External Merge Sort & Disk-based merge for large data \\
120 & Parallel Merge Sort & Divide work among threads \\
\end{longtable}

\subsubsection{13. Counting and Distribution Sorts (Counting, Radix,
Bucket)}\label{counting-and-distribution-sorts-counting-radix-bucket-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5781}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
121 & Counting Sort & Count key occurrences \\
122 & Stable Counting Sort & Preserve order of equals \\
123 & Radix Sort (LSD) & Least significant digit first \\
124 & Radix Sort (MSD) & Most significant digit first \\
125 & Bucket Sort & Distribute into buckets \\
126 & Pigeonhole Sort & Simple bucket variant \\
127 & Flash Sort & Distribution with in-place correction \\
128 & Postman Sort & Stable multi-key sort \\
129 & Address Calculation Sort & Hash-like distribution \\
130 & Spread Sort & Hybrid radix/quick strategy \\
\end{longtable}

\subsubsection{14. Hybrid Sorts (IntroSort,
Timsort)}\label{hybrid-sorts-introsort-timsort-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
131 & IntroSort & Quick + Heap fallback \\
132 & TimSort & Merge + Insertion + Runs \\
133 & Dual-Pivot QuickSort & Modern quicksort optimization \\
134 & SmoothSort & Heap-like adaptive sort \\
135 & Block Merge Sort & Cache-efficient merge variant \\
136 & Adaptive Merge Sort & Adjusts to partially sorted data \\
137 & PDQSort & Pattern-defeating quicksort \\
138 & WikiSort & Stable in-place merge \\
139 & GrailSort & In-place stable mergesort \\
140 & Adaptive Hybrid Sort & Dynamically selects strategy \\
\end{longtable}

\subsubsection{15. Special Sorts (Cycle, Gnome, Comb,
Pancake)}\label{special-sorts-cycle-gnome-comb-pancake-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
141 & Cycle Sort & Minimal writes \\
142 & Comb Sort & Shrinking gap bubble \\
143 & Gnome Sort & Insertion-like with swaps \\
144 & Cocktail Sort & Two-way bubble \\
145 & Pancake Sort & Flip-based sorting \\
146 & Bitonic Sort & Parallel network sorting \\
147 & Odd-Even Merge Sort & Sorting network design \\
148 & Sleep Sort & Uses timing as order key \\
149 & Bead Sort & Simulates gravity \\
150 & Bogo Sort & Randomly permute until sorted \\
\end{longtable}

\subsubsection{16. Linear and Binary
Search}\label{linear-and-binary-search-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
151 & Linear Search & Scan sequentially \\
152 & Linear Search (Sentinel) & Guard element at end \\
153 & Binary Search (Iterative) & Halve interval each loop \\
154 & Binary Search (Recursive) & Halve interval via recursion \\
155 & Binary Search (Lower Bound) & First \textgreater= target \\
156 & Binary Search (Upper Bound) & First \textgreater{} target \\
157 & Exponential Search & Double step size \\
158 & Jump Search & Jump fixed steps then linear \\
159 & Fibonacci Search & Golden-ratio style jumps \\
160 & Uniform Binary Search & Avoid recomputing midpoints \\
\end{longtable}

\subsubsection{17. Interpolation and Exponential
Search}\label{interpolation-and-exponential-search-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
161 & Interpolation Search & Estimate index by value \\
162 & Recursive Interpolation Search & Divide by estimated midpoint \\
163 & Exponential Search & Double and binary refine \\
164 & Doubling Search & Generic exponential pattern \\
165 & Galloping Search & Used in TimSort merges \\
166 & Unbounded Binary Search & Find bounds dynamically \\
167 & Root-Finding Bisection & Search zero-crossing \\
168 & Golden Section Search & Optimize unimodal function \\
169 & Fibonacci Search (Optimum) & Similar to golden search \\
170 & Jump + Binary Hybrid & Combined probing strategy \\
\end{longtable}

\subsubsection{18. Selection Algorithms (Quickselect, Median of
Medians)}\label{selection-algorithms-quickselect-median-of-medians-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
171 & Quickselect & Partition-based selection \\
172 & Median of Medians & Deterministic pivot \\
173 & Randomized Select & Random pivot version \\
174 & Binary Search on Answer & Range-based selection \\
175 & Order Statistics Tree & BST with rank queries \\
176 & Tournament Tree Selection & Hierarchical comparison \\
177 & Heap Select (Min-Heap) & Maintain top-k elements \\
178 & Partial QuickSort & Sort partial prefix \\
179 & BFPRT Algorithm & Linear-time selection \\
180 & Kth Largest Stream & Streaming selection \\
\end{longtable}

\subsubsection{19. Range Searching and Nearest
Neighbor}\label{range-searching-and-nearest-neighbor-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
181 & Binary Search Range & Find lower and upper bounds \\
182 & Segment Tree Query & Sum/min/max over interval \\
183 & Fenwick Tree Query & Efficient prefix sums \\
184 & Interval Tree Search & Overlap queries \\
185 & KD-Tree Search & Spatial nearest neighbor \\
186 & R-Tree Query & Range search in geometry \\
187 & Range Minimum Query (RMQ) & Sparse table approach \\
188 & Mo's Algorithm & Offline query reordering \\
189 & Sweep Line Range Search & Sort + scan technique \\
190 & Ball Tree Nearest Neighbor & Metric-space search \\
\end{longtable}

\subsubsection{20. Search Optimizations and
Variants}\label{search-optimizations-and-variants-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
191 & Binary Search with Tolerance & For floating values \\
192 & Ternary Search & Unimodal optimization \\
193 & Hash-Based Search & O(1) expected lookup \\
194 & Bloom Filter Lookup & Probabilistic membership \\
195 & Cuckoo Hash Search & Dual-hash relocation \\
196 & Robin Hood Hashing & Equalize probe lengths \\
197 & Jump Consistent Hashing & Stable hash assignment \\
198 & Prefix Search in Trie & Auto-completion lookup \\
199 & Pattern Search in Suffix Array & Fast substring lookup \\
200 & Search in Infinite Array & Dynamic bound finding \\
\end{longtable}

\subsection{Chapter 3. Data Structures in
Action}\label{chapter-3.-data-structures-in-action-1}

\subsubsection{21. Arrays, Linked Lists, Stacks,
Queues}\label{arrays-linked-lists-stacks-queues-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0441}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4706}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4853}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
201 & Dynamic Array Resize & Doubling strategy for capacity \\
202 & Circular Array Implementation & Wrap-around indexing \\
203 & Singly Linked List Insert/Delete & Basic node manipulation \\
204 & Doubly Linked List Insert/Delete & Two-way linkage \\
205 & Stack Push/Pop & LIFO structure \\
206 & Queue Enqueue/Dequeue & FIFO structure \\
207 & Deque Implementation & Double-ended queue \\
208 & Circular Queue & Fixed-size queue with wrap-around \\
209 & Stack via Queue & Implement stack using two queues \\
210 & Queue via Stack & Implement queue using two stacks \\
\end{longtable}

\subsubsection{22. Hash Tables and Variants (Cuckoo, Robin Hood,
Consistent)}\label{hash-tables-and-variants-cuckoo-robin-hood-consistent-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
211 & Hash Table Insertion & Key-value pair with modulo \\
212 & Linear Probing & Resolve collisions sequentially \\
213 & Quadratic Probing & Nonlinear probing sequence \\
214 & Double Hashing & Alternate hash on collision \\
215 & Cuckoo Hashing & Two-table relocation strategy \\
216 & Robin Hood Hashing & Equalize probe length fairness \\
217 & Chained Hash Table & Linked list buckets \\
218 & Perfect Hashing & No-collision mapping \\
219 & Consistent Hashing & Stable distribution across nodes \\
220 & Dynamic Rehashing & Resize on load factor threshold \\
\end{longtable}

\subsubsection{23. Heaps (Binary, Fibonacci,
Pairing)}\label{heaps-binary-fibonacci-pairing-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
221 & Binary Heap Insert & Bubble-up maintenance \\
222 & Binary Heap Delete & Heapify-down maintenance \\
223 & Build Heap (Heapify) & Bottom-up O(n) build \\
224 & Heap Sort & Extract max repeatedly \\
225 & Min Heap Implementation & For smallest element access \\
226 & Max Heap Implementation & For largest element access \\
227 & Fibonacci Heap Insert/Delete & Amortized efficient operations \\
228 & Pairing Heap Merge & Lightweight mergeable heap \\
229 & Binomial Heap Merge & Merge trees of equal order \\
230 & Leftist Heap Merge & Maintain rank-skewed heap \\
\end{longtable}

\subsubsection{24. Balanced Trees (AVL, Red-Black, Splay,
Treap)}\label{balanced-trees-avl-red-black-splay-treap-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
231 & AVL Tree Insert & Rotate to maintain balance \\
232 & AVL Tree Delete & Balance after deletion \\
233 & Red-Black Tree Insert & Color fix and rotations \\
234 & Red-Black Tree Delete & Maintain invariants \\
235 & Splay Tree Access & Move accessed node to root \\
236 & Treap Insert & Priority-based rotation \\
237 & Treap Delete & Randomized balance \\
238 & Weight Balanced Tree & Maintain subtree weights \\
239 & Scapegoat Tree Rebuild & Rebalance on size threshold \\
240 & AA Tree & Simplified red-black variant \\
\end{longtable}

\subsubsection{25. Segment Trees and Fenwick
Trees}\label{segment-trees-and-fenwick-trees-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
241 & Build Segment Tree & Recursive construction \\
242 & Range Sum Query & Recursive or iterative query \\
243 & Range Update & Lazy propagation technique \\
244 & Point Update & Modify single element \\
245 & Fenwick Tree Build & Incremental binary index \\
246 & Fenwick Update & Update cumulative sums \\
247 & Fenwick Query & Prefix sum retrieval \\
248 & Segment Tree Merge & Combine child results \\
249 & Persistent Segment Tree & Maintain history of versions \\
250 & 2D Segment Tree & For matrix range queries \\
\end{longtable}

\subsubsection{26. Disjoint Set Union
(Union-Find)}\label{disjoint-set-union-union-find-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
251 & Make-Set & Initialize each element \\
252 & Find & Locate representative \\
253 & Union & Merge two sets \\
254 & Union by Rank & Attach smaller tree to larger \\
255 & Path Compression & Flatten tree structure \\
256 & DSU with Rollback & Support undo operations \\
257 & DSU on Tree & Track subtree connectivity \\
258 & Kruskal's MST & Edge selection with DSU \\
259 & Connected Components & Group graph nodes \\
260 & Offline Query DSU & Handle dynamic unions \\
\end{longtable}

\subsubsection{27. Probabilistic Data Structures (Bloom, Count-Min,
HyperLogLog)}\label{probabilistic-data-structures-bloom-count-min-hyperloglog-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
261 & Bloom Filter Insert & Hash to bit array \\
262 & Bloom Filter Query & Probabilistic membership check \\
263 & Counting Bloom Filter & Support deletions via counters \\
264 & Cuckoo Filter & Space-efficient alternative \\
265 & Count-Min Sketch & Approximate frequency table \\
266 & HyperLogLog & Cardinality estimation \\
267 & Flajolet-Martin & Early probabilistic counting \\
268 & MinHash & Estimate Jaccard similarity \\
269 & Reservoir Sampling & Random k-sample stream \\
270 & Skip Bloom Filter & Range queries on Bloom \\
\end{longtable}

\subsubsection{28. Skip Lists and
B-Trees}\label{skip-lists-and-b-trees-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
271 & Skip List Insert & Probabilistic layered list \\
272 & Skip List Delete & Adjust pointers \\
273 & Skip List Search & Jump via tower levels \\
274 & B-Tree Insert & Split on overflow \\
275 & B-Tree Delete & Merge on underflow \\
276 & B+ Tree Search & Leaf-based sequential scan \\
277 & B+ Tree Range Query & Efficient ordered access \\
278 & B* Tree & More space-efficient variant \\
279 & Adaptive Radix Tree & Byte-wise branching \\
280 & Trie Compression & Path compression optimization \\
\end{longtable}

\subsubsection{29. Persistent and Functional Data
Structures}\label{persistent-and-functional-data-structures-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
281 & Persistent Stack & Keep all versions \\
282 & Persistent Array & Copy-on-write segments \\
283 & Persistent Segment Tree & Versioned updates \\
284 & Persistent Linked List & Immutable nodes \\
285 & Functional Queue & Amortized reverse lists \\
286 & Finger Tree & Fast concat and split \\
287 & Zipper Structure & Localized mutation \\
288 & Red-Black Persistent Tree & Immutable balanced tree \\
289 & Trie with Versioning & Historical string lookup \\
290 & Persistent Union-Find & Time-travel connectivity \\
\end{longtable}

\subsubsection{30. Advanced Trees and Range
Queries}\label{advanced-trees-and-range-queries-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
291 & Sparse Table Build & Static range min/max \\
292 & Cartesian Tree & RMQ to LCA transformation \\
293 & Segment Tree Beats & Handle complex queries \\
294 & Merge Sort Tree & Range count queries \\
295 & Wavelet Tree & Rank/select by value \\
296 & KD-Tree & Multidimensional queries \\
297 & Range Tree & Orthogonal range queries \\
298 & Fenwick 2D Tree & Matrix prefix sums \\
299 & Treap Split/Merge & Range-based treap ops \\
300 & Mo's Algorithm on Tree & Offline subtree queries \\
\end{longtable}

\subsection{Chapter 4. Graph
Algorithms}\label{chapter-4.-graph-algorithms-2}

\subsubsection{31. Traversals (DFS, BFS, Iterative
Deepening)}\label{traversals-dfs-bfs-iterative-deepening-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4795}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4795}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
301 & Depth-First Search (Recursive) & Explore deeply before
backtracking \\
302 & Depth-First Search (Iterative) & Stack-based exploration \\
303 & Breadth-First Search (Queue) & Level-order traversal \\
304 & Iterative Deepening DFS & Combine depth-limit + completeness \\
305 & Bidirectional BFS & Search from both ends \\
306 & DFS on Grid & Maze solving / connected components \\
307 & BFS on Grid & Shortest path in unweighted graph \\
308 & Multi-Source BFS & Parallel layer expansion \\
309 & Topological Sort (DFS-based) & DAG ordering \\
310 & Topological Sort (Kahn's Algorithm) & In-degree tracking \\
\end{longtable}

\subsubsection{32. Strongly Connected Components (Tarjan,
Kosaraju)}\label{strongly-connected-components-tarjan-kosaraju-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
311 & Kosaraju's Algorithm & Two-pass DFS \\
312 & Tarjan's Algorithm & Low-link discovery \\
313 & Gabow's Algorithm & Stack pair tracking \\
314 & SCC DAG Construction & Condensed component graph \\
315 & SCC Online Merge & Incremental condensation \\
316 & Component Label Propagation & Iterative labeling \\
317 & Path-Based SCC & DFS with path stack \\
318 & Kosaraju Parallel Version & SCC via parallel DFS \\
319 & Dynamic SCC Maintenance & Add/remove edges \\
320 & SCC for Weighted Graph & Combine with edge weights \\
\end{longtable}

\subsubsection{33. Shortest Paths (Dijkstra, Bellman-Ford, A*,
Johnson)}\label{shortest-paths-dijkstra-bellman-ford-a-johnson-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
321 & Dijkstra (Binary Heap) & Greedy edge relaxation \\
322 & Dijkstra (Fibonacci Heap) & Improved priority queue \\
323 & Bellman-Ford & Negative weights support \\
324 & SPFA (Queue Optimization) & Faster average Bellman-Ford \\
325 & A* Search & Heuristic-guided path \\
326 & Floyd--Warshall & All-pairs shortest path \\
327 & Johnson's Algorithm & All-pairs using reweighting \\
328 & 0-1 BFS & Deque-based shortest path \\
329 & Dial's Algorithm & Integer weight buckets \\
330 & Multi-Source Dijkstra & Multiple starting points \\
\end{longtable}

\subsubsection{34. Shortest Path Variants (0--1 BFS, Bidirectional,
Heuristic
A*)}\label{shortest-path-variants-01-bfs-bidirectional-heuristic-a}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4219}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5312}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
331 & 0--1 BFS & For edges with weight 0 or 1 \\
332 & Bidirectional Dijkstra & Meet in the middle \\
333 & A* with Euclidean Heuristic & Spatial shortest path \\
334 & ALT Algorithm & A* landmarks + triangle inequality \\
335 & Contraction Hierarchies & Preprocessing for road networks \\
336 & CH Query Algorithm & Shortcut-based routing \\
337 & Bellman-Ford Queue Variant & Early termination \\
338 & Dijkstra with Early Stop & Halt on target \\
339 & Goal-Directed Search & Restrict expansion direction \\
340 & Yen's K Shortest Paths & Enumerate multiple best paths \\
\end{longtable}

\subsubsection{35. Minimum Spanning Trees (Kruskal, Prim,
Borůvka)}\label{minimum-spanning-trees-kruskal-prim-borux16fvka-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
341 & Kruskal's Algorithm & Sort edges + union-find \\
342 & Prim's Algorithm (Heap) & Grow MST from seed \\
343 & Prim's Algorithm (Adj Matrix) & Dense graph variant \\
344 & Borůvka's Algorithm & Component merging \\
345 & Reverse-Delete MST & Remove heavy edges \\
346 & MST via Dijkstra Trick & For positive weights \\
347 & Dynamic MST Maintenance & Handle edge updates \\
348 & Minimum Bottleneck Spanning Tree & Max edge minimization \\
349 & Manhattan MST & Grid graph optimization \\
350 & Euclidean MST (Kruskal + Geometry) & Use Delaunay graph \\
\end{longtable}

\subsubsection{36. Flows (Ford--Fulkerson, Edmonds--Karp,
Dinic)}\label{flows-fordfulkerson-edmondskarp-dinic}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5079}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
351 & Ford--Fulkerson & Augmenting path method \\
352 & Edmonds--Karp & BFS-based Ford--Fulkerson \\
353 & Dinic's Algorithm & Level graph + blocking flow \\
354 & Push--Relabel & Local preflow push \\
355 & Capacity Scaling & Speed-up with capacity tiers \\
356 & Cost Scaling & Min-cost optimization \\
357 & Min-Cost Max-Flow (Bellman-Ford) & Costed augmenting paths \\
358 & Min-Cost Max-Flow (SPFA) & Faster average \\
359 & Circulation with Demands & Generalized flow formulation \\
360 & Successive Shortest Path & Incremental min-cost updates \\
\end{longtable}

\subsubsection{37. Cuts (Stoer--Wagner, Karger,
Gomory--Hu)}\label{cuts-stoerwagner-karger-gomoryhu}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
361 & Stoer--Wagner Minimum Cut & Global min cut \\
362 & Karger's Randomized Cut & Contract edges randomly \\
363 & Karger--Stein & Recursive randomized cut \\
364 & Gomory--Hu Tree & All-pairs min-cut \\
365 & Max-Flow Min-Cut & Duality theorem application \\
366 & Stoer--Wagner Repeated Phase & Multiple passes \\
367 & Dynamic Min Cut & Maintain on edge update \\
368 & Minimum s--t Cut (Edmonds--Karp) & Based on flow \\
369 & Approximate Min Cut & Random sampling \\
370 & Min k-Cut & Partition graph into k parts \\
\end{longtable}

\subsubsection{38. Matchings (Hopcroft--Karp, Hungarian,
Blossom)}\label{matchings-hopcroftkarp-hungarian-blossom}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
371 & Bipartite Matching (DFS) & Simple augmenting path \\
372 & Hopcroft--Karp & O(E√V) bipartite matching \\
373 & Hungarian Algorithm & Weighted assignment \\
374 & Kuhn--Munkres & Max-weight matching \\
375 & Blossom Algorithm & General graph matching \\
376 & Edmonds' Blossom Shrinking & Odd cycle contraction \\
377 & Greedy Matching & Fast approximate \\
378 & Stable Marriage (Gale--Shapley) & Stable pairing \\
379 & Weighted b-Matching & Capacity-constrained \\
380 & Maximal Matching & Local greedy maximal set \\
\end{longtable}

\subsubsection{39. Tree Algorithms (LCA, HLD, Centroid
Decomposition)}\label{tree-algorithms-lca-hld-centroid-decomposition-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
381 & Euler Tour LCA & Flatten tree to array \\
382 & Binary Lifting LCA & Jump powers of two \\
383 & Tarjan's LCA (Offline DSU) & Query via union-find \\
384 & Heavy-Light Decomposition & Decompose paths \\
385 & Centroid Decomposition & Recursive split on centroid \\
386 & Tree Diameter (DFS Twice) & Farthest pair \\
387 & Tree DP & Subtree-based optimization \\
388 & Rerooting DP & Compute all roots' answers \\
389 & Binary Search on Tree & Edge weight constraints \\
390 & Virtual Tree & Build on query subset \\
\end{longtable}

\subsubsection{40. Advanced Graph Algorithms and
Tricks}\label{advanced-graph-algorithms-and-tricks-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5224}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
391 & Topological DP & DP on DAG order \\
392 & SCC Condensed Graph DP & Meta-graph processing \\
393 & Eulerian Path & Trail covering all edges \\
394 & Hamiltonian Path & NP-complete exploration \\
395 & Chinese Postman & Eulerian circuit with repeats \\
396 & Hierholzer's Algorithm & Construct Eulerian circuit \\
397 & Johnson's Cycle Finding & Enumerate all cycles \\
398 & Transitive Closure (Floyd--Warshall) & Reachability matrix \\
399 & Graph Coloring (Backtracking) & Constraint satisfaction \\
400 & Articulation Points \& Bridges & Critical structure detection \\
\end{longtable}

\subsection{Chapter 5. Dynamic
Programming}\label{chapter-5.-dynamic-programming-2}

\subsubsection{41. DP Basics and State
Transitions}\label{dp-basics-and-state-transitions-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0435}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5072}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4493}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
401 & Fibonacci DP & Classic top-down vs bottom-up \\
402 & Climbing Stairs & Count paths with small steps \\
403 & Grid Paths & DP over 2D lattice \\
404 & Min Cost Path & Accumulate minimal sums \\
405 & Coin Change (Count Ways) & Combinatorial sums \\
406 & Coin Change (Min Coins) & Minimize step count \\
407 & Knapsack 0/1 & Select items under weight limit \\
408 & Knapsack Unbounded & Repeatable items \\
409 & Longest Increasing Subsequence (DP) & Subsequence optimization \\
410 & Edit Distance (Levenshtein) & Measure similarity step-by-step \\
\end{longtable}

\subsubsection{42. Classic Problems (Knapsack, Subset Sum, Coin
Change)}\label{classic-problems-knapsack-subset-sum-coin-change-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
411 & 0/1 Knapsack & Value maximization under capacity \\
412 & Subset Sum & Boolean feasibility DP \\
413 & Equal Partition & Divide set into equal halves \\
414 & Count of Subsets with Sum & Counting variant \\
415 & Target Sum & DP with +/- transitions \\
416 & Unbounded Knapsack & Reuse items \\
417 & Fractional Knapsack & Greedy + DP comparison \\
418 & Coin Change (Min Coins) & DP shortest path \\
419 & Coin Change (Count Ways) & Combinatorial counting \\
420 & Multi-Dimensional Knapsack & Capacity in multiple dimensions \\
\end{longtable}

\subsubsection{43. Sequence Problems (LIS, LCS, Edit
Distance)}\label{sequence-problems-lis-lcs-edit-distance-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5224}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
421 & Longest Increasing Subsequence & O(n²) DP \\
422 & LIS (Patience Sorting) & O(n log n) optimized \\
423 & Longest Common Subsequence & Two-sequence DP \\
424 & Edit Distance (Levenshtein) & Transform operations \\
425 & Longest Palindromic Subsequence & Symmetric DP \\
426 & Shortest Common Supersequence & Merge sequences \\
427 & Longest Repeated Subsequence & DP with overlap \\
428 & String Interleaving & Merge with order preservation \\
429 & Sequence Alignment (Bioinformatics) & Gap penalties \\
430 & Diff Algorithm (Myers/DP) & Minimal edit path \\
\end{longtable}

\subsubsection{44. Matrix and Chain
Problems}\label{matrix-and-chain-problems-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
431 & Matrix Chain Multiplication & Parenthesization cost \\
432 & Boolean Parenthesization & Count true outcomes \\
433 & Burst Balloons & Interval DP \\
434 & Optimal BST & Weighted search cost \\
435 & Polygon Triangulation & DP over partitions \\
436 & Matrix Path Sum & DP on 2D grid \\
437 & Largest Square Submatrix & Dynamic growth check \\
438 & Max Rectangle in Binary Matrix & Histogram + DP \\
439 & Submatrix Sum Queries & Prefix sum DP \\
440 & Palindrome Partitioning & DP with cuts \\
\end{longtable}

\subsubsection{45. Bitmask DP and Traveling
Salesman}\label{bitmask-dp-and-traveling-salesman-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
441 & Traveling Salesman (TSP) & Visit all cities \\
442 & Subset DP & Over subsets of states \\
443 & Hamiltonian Path DP & State compression \\
444 & Assignment Problem DP & Mask over tasks \\
445 & Partition into Two Sets & Balanced load \\
446 & Count Hamiltonian Cycles & Bitmask enumeration \\
447 & Steiner Tree DP & Minimal connection of terminals \\
448 & SOS DP (Sum Over Subsets) & Precompute sums \\
449 & Bitmask Knapsack & State compression \\
450 & Bitmask Independent Set & Graph subset optimization \\
\end{longtable}

\subsubsection{46. Digit DP and SOS DP}\label{digit-dp-and-sos-dp-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
451 & Count Numbers with Property & Digit-state transitions \\
452 & Count Without Adjacent Duplicates & Adjacent constraints \\
453 & Sum of Digits in Range & Carry-dependent states \\
454 & Count with Mod Condition & DP over digit sum mod M \\
455 & Count of Increasing Digits & Ordered constraint \\
456 & Count with Forbidden Digits & Exclusion transitions \\
457 & SOS DP Subset Sum & Sum over bitmask subsets \\
458 & SOS DP Superset Sum & Sum over supersets \\
459 & XOR Basis DP & Combine digit and bit DP \\
460 & Digit DP for Palindromes & Symmetric digit state \\
\end{longtable}

\subsubsection{47. DP Optimizations (Divide \& Conquer, Convex Hull
Trick,
Knuth)}\label{dp-optimizations-divide-conquer-convex-hull-trick-knuth-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
461 & Divide \& Conquer DP & Monotone decision property \\
462 & Knuth Optimization & DP with quadrangle inequality \\
463 & Convex Hull Trick & Linear recurrence min queries \\
464 & Li Chao Tree & Segment-based hull maintenance \\
465 & Slope Trick & Piecewise-linear optimization \\
466 & Monotonic Queue Optimization & Sliding DP state \\
467 & Bitset DP & Speed via bit-parallel \\
468 & Offline DP Queries & Preprocessing state \\
469 & DP + Segment Tree & Range-based optimization \\
470 & Divide \& Conquer Knapsack & Split-space DP \\
\end{longtable}

\subsubsection{48. Tree DP and Rerooting}\label{tree-dp-and-rerooting-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
471 & Subtree Sum DP & Aggregate values \\
472 & Diameter DP & Max path via child states \\
473 & Independent Set DP & Choose or skip nodes \\
474 & Vertex Cover DP & Tree constraint problem \\
475 & Path Counting DP & Count root-leaf paths \\
476 & DP on Rooted Tree & Bottom-up aggregation \\
477 & Rerooting Technique & Compute for all roots \\
478 & Distance Sum Rerooting & Efficient recomputation \\
479 & Tree Coloring DP & Combinatorial counting \\
480 & Binary Search on Tree DP & Monotonic transitions \\
\end{longtable}

\subsubsection{49. DP Reconstruction and
Traceback}\label{dp-reconstruction-and-traceback-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
481 & Reconstruct LCS & Backtrack table \\
482 & Reconstruct LIS & Track predecessors \\
483 & Reconstruct Knapsack & Recover selected items \\
484 & Edit Distance Alignment & Trace insert/delete/substitute \\
485 & Matrix Chain Parentheses & Rebuild parenthesization \\
486 & Coin Change Reconstruction & Backtrack last used coin \\
487 & Path Reconstruction DP & Trace minimal route \\
488 & Sequence Reconstruction & Rebuild from states \\
489 & Multi-Choice Reconstruction & Combine best subpaths \\
490 & Traceback Visualization & Visual DP backtrack tool \\
\end{longtable}

\subsubsection{50. Meta-DP and Optimization
Templates}\label{meta-dp-and-optimization-templates-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
491 & State Compression Template & Represent subsets compactly \\
492 & Transition Optimization Template & Precompute transitions \\
493 & Space Optimization Template & Rolling arrays \\
494 & Multi-Dimensional DP Template & Nested loops version \\
495 & Decision Monotonicity & Optimization hint \\
496 & Monge Array Optimization & Matrix property leverage \\
497 & Divide \& Conquer Template & Half-split recursion \\
498 & Rerooting Template & Generalized tree DP \\
499 & Iterative DP Pattern & Bottom-up unrolling \\
500 & Memoization Template & Recursive caching skeleton \\
\end{longtable}

\subsection{Chapter 6. Mathematics for
Algorithms}\label{chapter-6.-mathematics-for-algorithms-1}

\subsubsection{51. Number Theory (GCD, Modular Arithmetic,
CRT)}\label{number-theory-gcd-modular-arithmetic-crt-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
501 & Euclidean Algorithm & Compute gcd(a, b) \\
502 & Extended Euclidean Algorithm & Solve ax + by = gcd(a, b) \\
503 & Modular Addition & Add under modulo M \\
504 & Modular Multiplication & Multiply under modulo M \\
505 & Modular Exponentiation & Fast power mod M \\
506 & Modular Inverse & Compute a⁻¹ mod M \\
507 & Chinese Remainder Theorem & Combine modular systems \\
508 & Binary GCD (Stein's Algorithm) & Bitwise gcd \\
509 & Modular Reduction & Normalize residues \\
510 & Modular Linear Equation Solver & Solve ax ≡ b (mod m) \\
\end{longtable}

\subsubsection{52. Primality and Factorization (Miller--Rabin, Pollard
Rho)}\label{primality-and-factorization-millerrabin-pollard-rho}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
511 & Trial Division & Simple prime test \\
512 & Sieve of Eratosthenes & Generate primes up to n \\
513 & Sieve of Atkin & Faster sieve variant \\
514 & Miller--Rabin Primality Test & Probabilistic primality \\
515 & Fermat Primality Test & Modular power check \\
516 & Pollard's Rho & Randomized factorization \\
517 & Pollard's p−1 Method & Factor using smoothness \\
518 & Wheel Factorization & Skip known composites \\
519 & AKS Primality Test & Deterministic polynomial test \\
520 & Segmented Sieve & Prime generation for large n \\
\end{longtable}

\subsubsection{53. Combinatorics (Permutations, Combinations,
Subsets)}\label{combinatorics-permutations-combinations-subsets-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
521 & Factorial Precomputation & Build n! table \\
522 & nCr Computation & Use Pascal's or factorials \\
523 & Pascal's Triangle & Binomial coefficients \\
524 & Multiset Combination & Repetition allowed \\
525 & Permutation Generation & Lexicographic order \\
526 & Next Permutation & STL-style increment \\
527 & Subset Generation & Bitmask or recursion \\
528 & Gray Code Generation & Single-bit flips \\
529 & Catalan Number DP & Count valid parentheses \\
530 & Stirling Numbers & Partition counting \\
\end{longtable}

\subsubsection{54. Probability and Randomized
Algorithms}\label{probability-and-randomized-algorithms-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
531 & Monte Carlo Simulation & Approximate via randomness \\
532 & Las Vegas Algorithm & Always correct, variable time \\
533 & Reservoir Sampling & Uniform sampling from stream \\
534 & Randomized QuickSort & Expected O(n log n) \\
535 & Randomized QuickSelect & Random pivot \\
536 & Birthday Paradox Simulation & Probability collision \\
537 & Random Hashing & Reduce collision chance \\
538 & Random Walk Simulation & State transitions \\
539 & Coupon Collector Estimation & Expected trials \\
540 & Markov Chain Simulation & Transition matrix sampling \\
\end{longtable}

\subsubsection{55. Sieve Methods and Modular
Math}\label{sieve-methods-and-modular-math-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0455}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4545}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
541 & Sieve of Eratosthenes & Base prime sieve \\
542 & Linear Sieve & O(n) sieve variant \\
543 & Segmented Sieve & Range prime generation \\
544 & SPF (Smallest Prime Factor) Table & Factorization via sieve \\
545 & Möbius Function Sieve & Multiplicative function calc \\
546 & Euler's Totient Sieve & Compute φ(n) for all n \\
547 & Divisor Count Sieve & Count divisors efficiently \\
548 & Modular Precomputation & Store inverses, factorials \\
549 & Fermat Little Theorem & a\^{}(p−1) ≡ 1 mod p \\
550 & Wilson's Theorem & Prime test via factorial mod p \\
\end{longtable}

\subsubsection{56. Linear Algebra (Gaussian Elimination, LU,
SVD)}\label{linear-algebra-gaussian-elimination-lu-svd-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
551 & Gaussian Elimination & Solve Ax = b \\
552 & Gauss-Jordan Elimination & Reduced row echelon \\
553 & LU Decomposition & Factor A into L·U \\
554 & Cholesky Decomposition & A = L·Lᵀ for SPD \\
555 & QR Decomposition & Orthogonal factorization \\
556 & Matrix Inversion (Gauss-Jordan) & Find A⁻¹ \\
557 & Determinant by Elimination & Product of pivots \\
558 & Rank of Matrix & Count non-zero rows \\
559 & Eigenvalue Power Method & Approximate dominant eigenvalue \\
560 & Singular Value Decomposition & A = UΣVᵀ \\
\end{longtable}

\subsubsection{57. FFT and NTT (Fast
Transforms)}\label{fft-and-ntt-fast-transforms-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5079}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4444}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
561 & Discrete Fourier Transform (DFT) & O(n²) baseline \\
562 & Fast Fourier Transform (FFT) & O(n log n) convolution \\
563 & Cooley--Tukey FFT & Recursive divide and conquer \\
564 & Iterative FFT & In-place bit reversal \\
565 & Inverse FFT & Recover time-domain \\
566 & Convolution via FFT & Polynomial multiplication \\
567 & Number Theoretic Transform (NTT) & Modulo prime FFT \\
568 & Inverse NTT & Modular inverse transform \\
569 & Bluestein's Algorithm & FFT of arbitrary size \\
570 & FFT-Based Multiplication & Big integer product \\
\end{longtable}

\subsubsection{58. Numerical Methods (Newton, Simpson,
Runge--Kutta)}\label{numerical-methods-newton-simpson-rungekutta}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
571 & Newton--Raphson & Root finding via tangent \\
572 & Bisection Method & Interval halving \\
573 & Secant Method & Approximate derivative \\
574 & Fixed-Point Iteration & x = f(x) convergence \\
575 & Gaussian Quadrature & Weighted integration \\
576 & Simpson's Rule & Piecewise quadratic integral \\
577 & Trapezoidal Rule & Linear interpolation integral \\
578 & Runge--Kutta (RK4) & ODE solver \\
579 & Euler's Method & Step-by-step ODE \\
580 & Gradient Descent (1D) & Numerical optimization \\
\end{longtable}

\subsubsection{59. Mathematical Optimization (Simplex, Gradient,
Convex)}\label{mathematical-optimization-simplex-gradient-convex-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
581 & Simplex Method & Linear programming solver \\
582 & Dual Simplex Method & Solve dual constraints \\
583 & Interior-Point Method & Convex optimization \\
584 & Gradient Descent & Unconstrained optimization \\
585 & Stochastic Gradient Descent & Sample-based updates \\
586 & Newton's Method (Multivariate) & Quadratic convergence \\
587 & Conjugate Gradient & Solve SPD systems \\
588 & Lagrange Multipliers & Constrained optimization \\
589 & KKT Conditions Solver & Convex constraint handling \\
590 & Coordinate Descent & Sequential variable updates \\
\end{longtable}

\subsubsection{60. Algebraic Tricks and Transform
Techniques}\label{algebraic-tricks-and-transform-techniques-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
591 & Polynomial Multiplication (FFT) & Fast convolution \\
592 & Polynomial Inversion & Newton iteration \\
593 & Polynomial Derivative & Term-wise multiply by index \\
594 & Polynomial Integration & Divide by index+1 \\
595 & Formal Power Series Composition & Substitute series \\
596 & Exponentiation by Squaring & Fast powering \\
597 & Modular Exponentiation & Fast power mod M \\
598 & Fast Walsh--Hadamard Transform & XOR convolution \\
599 & Zeta Transform & Subset summation \\
600 & Möbius Inversion & Recover original from sums \\
\end{longtable}

\subsection{Chapter 7. Strings and Text
Algorithms}\label{chapter-7.-strings-and-text-algorithms-2}

\subsubsection{61. String Matching (KMP, Z, Rabin--Karp,
Boyer--Moore)}\label{string-matching-kmp-z-rabinkarp-boyermoore}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
601 & Naive String Matching & Compare every position \\
602 & Knuth--Morris--Pratt (KMP) & Prefix function skipping \\
603 & Z-Algorithm & Match using Z-values \\
604 & Rabin--Karp & Rolling hash comparison \\
605 & Boyer--Moore & Backward skip based on mismatch \\
606 & Boyer--Moore--Horspool & Simplified shift table \\
607 & Sunday Algorithm & Last-character shift \\
608 & Finite Automaton Matching & DFA-based matching \\
609 & Bitap Algorithm & Bitmask approximate matching \\
610 & Two-Way Algorithm & Optimal linear matching \\
\end{longtable}

\subsubsection{62. Multi-Pattern Search
(Aho--Corasick)}\label{multi-pattern-search-ahocorasick}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
611 & Aho--Corasick Automaton & Trie + failure links \\
612 & Trie Construction & Prefix tree build \\
613 & Failure Link Computation & BFS for transitions \\
614 & Output Link Management & Handle overlapping patterns \\
615 & Multi-Pattern Search & Find all keywords \\
616 & Dictionary Matching & Find multiple substrings \\
617 & Dynamic Aho--Corasick & Add/remove patterns \\
618 & Parallel AC Search & Multi-threaded traversal \\
619 & Compressed AC Automaton & Memory-optimized \\
620 & Extended AC with Wildcards & Flexible matching \\
\end{longtable}

\subsubsection{63. Suffix Structures (Suffix Array, Suffix Tree,
LCP)}\label{suffix-structures-suffix-array-suffix-tree-lcp-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
621 & Suffix Array (Naive) & Sort all suffixes \\
622 & Suffix Array (Doubling) & O(n log n) rank-based \\
623 & Kasai's LCP Algorithm & Longest common prefix \\
624 & Suffix Tree (Ukkonen) & Linear-time online \\
625 & Suffix Automaton & Minimal DFA of substrings \\
626 & SA-IS Algorithm & O(n) suffix array \\
627 & LCP RMQ Query & Range minimum for substring \\
628 & Generalized Suffix Array & Multiple strings \\
629 & Enhanced Suffix Array & Combine SA + LCP \\
630 & Sparse Suffix Tree & Space-efficient variant \\
\end{longtable}

\subsubsection{64. Palindromes and Periodicity
(Manacher)}\label{palindromes-and-periodicity-manacher-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4932}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4658}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
631 & Naive Palindrome Check & Expand around center \\
632 & Manacher's Algorithm & O(n) longest palindrome \\
633 & Longest Palindromic Substring & Center expansion \\
634 & Palindrome DP Table & Substring boolean matrix \\
635 & Palindromic Tree (Eertree) & Track distinct palindromes \\
636 & Prefix Function Periodicity & Detect repetition patterns \\
637 & Z-Function Periodicity & Identify periodic suffix \\
638 & KMP Prefix Period Check & Shortest repeating unit \\
639 & Lyndon Factorization & Decompose string into Lyndon words \\
640 & Minimal Rotation (Booth's Algorithm) & Lexicographically minimal
shift \\
\end{longtable}

\subsubsection{65. Edit Distance and
Alignment}\label{edit-distance-and-alignment-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
641 & Levenshtein Distance & Insert/delete/replace cost \\
642 & Damerau--Levenshtein & Swap included \\
643 & Hamming Distance & Count differing bits \\
644 & Needleman--Wunsch & Global alignment \\
645 & Smith--Waterman & Local alignment \\
646 & Hirschberg's Algorithm & Memory-optimized alignment \\
647 & Edit Script Reconstruction & Backtrack operations \\
648 & Affine Gap Penalty DP & Varying gap cost \\
649 & Myers Bit-Vector Algorithm & Fast edit distance \\
650 & Longest Common Subsequence & Alignment by inclusion \\
\end{longtable}

\subsubsection{66. Compression (Huffman, Arithmetic, LZ77,
BWT)}\label{compression-huffman-arithmetic-lz77-bwt-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
651 & Huffman Coding & Optimal prefix tree \\
652 & Canonical Huffman & Deterministic ordering \\
653 & Arithmetic Coding & Interval probability coding \\
654 & Shannon--Fano Coding & Early prefix method \\
655 & Run-Length Encoding (RLE) & Repeat compression \\
656 & LZ77 & Sliding-window match \\
657 & LZ78 & Dictionary building \\
658 & LZW & Variant used in GIF \\
659 & Burrows--Wheeler Transform & Block reordering \\
660 & Move-to-Front Encoding & Locality boosting transform \\
\end{longtable}

\subsubsection{67. Cryptographic Hashes and
Checksums}\label{cryptographic-hashes-and-checksums-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
661 & Rolling Hash & Polynomial mod-based \\
662 & CRC32 & Cyclic redundancy check \\
663 & Adler-32 & Lightweight checksum \\
664 & MD5 & Legacy cryptographic hash \\
665 & SHA-1 & Deprecated hash function \\
666 & SHA-256 & Secure hash standard \\
667 & SHA-3 (Keccak) & Sponge construction \\
668 & HMAC & Keyed message authentication \\
669 & Merkle Tree & Hierarchical hashing \\
670 & Hash Collision Detection & Birthday bound simulation \\
\end{longtable}

\subsubsection{68. Approximate and Streaming
Matching}\label{approximate-and-streaming-matching-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
671 & K-Approximate Matching & Allow k mismatches \\
672 & Bitap Algorithm & Bitwise dynamic programming \\
673 & Landau--Vishkin Algorithm & Edit distance ≤ k \\
674 & Filtering Algorithm & Fast approximate search \\
675 & Wu--Manber & Multi-pattern approximate search \\
676 & Streaming KMP & Online prefix updates \\
677 & Rolling Hash Sketch & Sliding window hashing \\
678 & Sketch-based Similarity & MinHash / LSH variants \\
679 & Weighted Edit Distance & Weighted operations \\
680 & Online Levenshtein & Dynamic stream update \\
\end{longtable}

\subsubsection{69. Bioinformatics Alignment (Needleman--Wunsch,
Smith--Waterman)}\label{bioinformatics-alignment-needlemanwunsch-smithwaterman}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
681 & Needleman--Wunsch & Global sequence alignment \\
682 & Smith--Waterman & Local alignment \\
683 & Gotoh Algorithm & Affine gap penalties \\
684 & Hirschberg Alignment & Linear-space alignment \\
685 & Multiple Sequence Alignment (MSA) & Progressive methods \\
686 & Profile Alignment & Align sequence to profile \\
687 & Hidden Markov Model Alignment & Probabilistic alignment \\
688 & BLAST & Heuristic local search \\
689 & FASTA & Word-based alignment \\
690 & Pairwise DP Alignment & General DP framework \\
\end{longtable}

\subsubsection{70. Text Indexing and Search
Structures}\label{text-indexing-and-search-structures-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5397}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4127}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
691 & Inverted Index Build & Word-to-document mapping \\
692 & Positional Index & Store word positions \\
693 & TF-IDF Weighting & Importance scoring \\
694 & BM25 Ranking & Modern ranking formula \\
695 & Trie Index & Prefix search structure \\
696 & Suffix Array Index & Substring search \\
697 & Compressed Suffix Array & Space-optimized \\
698 & FM-Index & BWT-based compressed index \\
699 & DAWG (Directed Acyclic Word Graph) & Shared suffix graph \\
700 & Wavelet Tree for Text & Rank/select on sequences \\
\end{longtable}

\subsection{Chapter 8. Geometry, Graphics, and Spatial
Algorithms}\label{chapter-8.-geometry-graphics-and-spatial-algorithms-2}

\subsubsection{71. Convex Hull (Graham, Andrew,
Chan)}\label{convex-hull-graham-andrew-chan-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3944}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5634}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
701 & Gift Wrapping (Jarvis March) & Wrap hull one point at a time \\
702 & Graham Scan & Sort by angle, maintain stack \\
703 & Andrew's Monotone Chain & Sort by x, upper + lower hull \\
704 & Chan's Algorithm & Output-sensitive O(n log h) \\
705 & QuickHull & Divide-and-conquer hull \\
706 & Incremental Convex Hull & Add points one by one \\
707 & Divide \& Conquer Hull & Merge two partial hulls \\
708 & 3D Convex Hull & Extend to 3D geometry \\
709 & Dynamic Convex Hull & Maintain hull with inserts \\
710 & Rotating Calipers & Compute diameter, width, antipodal pairs \\
\end{longtable}

\subsubsection{72. Closest Pair and Segment
Intersection}\label{closest-pair-and-segment-intersection-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4921}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4603}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
711 & Closest Pair (Divide \& Conquer) & Split, merge minimal
distance \\
712 & Closest Pair (Sweep Line) & Maintain active window \\
713 & Brute Force Closest Pair & Check all O(n²) pairs \\
714 & Bentley--Ottmann & Find all line intersections \\
715 & Segment Intersection Test & Cross product orientation \\
716 & Line Sweep for Segments & Event-based intersection \\
717 & Intersection via Orientation & CCW test \\
718 & Circle Intersection & Geometry of two circles \\
719 & Polygon Intersection & Clip overlapping polygons \\
720 & Nearest Neighbor Pair & Combine KD-tree + search \\
\end{longtable}

\subsubsection{73. Line Sweep and Plane Sweep
Algorithms}\label{line-sweep-and-plane-sweep-algorithms-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5205}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4384}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
721 & Sweep Line for Events & Process sorted events \\
722 & Interval Scheduling & Select non-overlapping intervals \\
723 & Rectangle Union Area & Sweep edges to count area \\
724 & Segment Intersection (Bentley--Ottmann) & Detect all crossings \\
725 & Skyline Problem & Merge height profiles \\
726 & Closest Pair Sweep & Maintain active set \\
727 & Circle Arrangement & Sweep and count regions \\
728 & Sweep for Overlapping Rectangles & Detect collisions \\
729 & Range Counting & Count points in rectangle \\
730 & Plane Sweep for Triangles & Polygon overlay computation \\
\end{longtable}

\subsubsection{74. Delaunay and Voronoi
Diagrams}\label{delaunay-and-voronoi-diagrams-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5070}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4507}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
731 & Delaunay Triangulation (Incremental) & Add points, maintain
Delaunay \\
732 & Delaunay (Divide \& Conquer) & Merge triangulations \\
733 & Delaunay (Fortune's Sweep) & O(n log n) construction \\
734 & Voronoi Diagram (Fortune's) & Sweep line beachline \\
735 & Incremental Voronoi & Update on insertion \\
736 & Bowyer--Watson & Empty circle criterion \\
737 & Duality Transform & Convert between Voronoi/Delaunay \\
738 & Power Diagram & Weighted Voronoi \\
739 & Lloyd's Relaxation & Smooth Voronoi cells \\
740 & Voronoi Nearest Neighbor & Region-based lookup \\
\end{longtable}

\subsubsection{75. Point in Polygon and Polygon
Triangulation}\label{point-in-polygon-and-polygon-triangulation-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5846}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3692}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
741 & Ray Casting & Count edge crossings \\
742 & Winding Number & Angle sum method \\
743 & Convex Polygon Point Test & Orientation checks \\
744 & Ear Clipping Triangulation & Remove ears iteratively \\
745 & Monotone Polygon Triangulation & Sweep line triangulation \\
746 & Delaunay Triangulation & Optimal triangle quality \\
747 & Convex Decomposition & Split into convex parts \\
748 & Polygon Area (Shoelace Formula) & Signed area computation \\
749 & Minkowski Sum & Add shapes geometrically \\
750 & Polygon Intersection (Weiler--Atherton) & Clip overlapping
shapes \\
\end{longtable}

\subsubsection{76. Spatial Data Structures (KD,
R-tree)}\label{spatial-data-structures-kd-r-tree-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
751 & KD-Tree Build & Recursive median split \\
752 & KD-Tree Search & Axis-aligned query \\
753 & Range Search KD-Tree & Orthogonal query \\
754 & Nearest Neighbor KD-Tree & Closest point search \\
755 & R-Tree Build & Bounding box hierarchy \\
756 & R*-Tree & Optimized split strategy \\
757 & Quad Tree & Spatial decomposition \\
758 & Octree & 3D spatial decomposition \\
759 & BSP Tree (Binary Space Partition) & Split by planes \\
760 & Morton Order (Z-Curve) & Spatial locality index \\
\end{longtable}

\subsubsection{77. Rasterization and Scanline
Techniques}\label{rasterization-and-scanline-techniques-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
761 & Bresenham's Line Algorithm & Efficient integer drawing \\
762 & Midpoint Circle Algorithm & Circle rasterization \\
763 & Scanline Fill & Polygon interior fill \\
764 & Edge Table Fill & Sort edges by y \\
765 & Z-Buffer Algorithm & Hidden surface removal \\
766 & Painter's Algorithm & Sort by depth \\
767 & Gouraud Shading & Vertex interpolation shading \\
768 & Phong Shading & Normal interpolation \\
769 & Anti-Aliasing (Supersampling) & Smooth jagged edges \\
770 & Scanline Polygon Clipping & Efficient clipping \\
\end{longtable}

\subsubsection{78. Computer Vision (Canny, Hough,
SIFT)}\label{computer-vision-canny-hough-sift-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5479}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4110}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
771 & Canny Edge Detector & Gradient + hysteresis \\
772 & Sobel Operator & Gradient magnitude filter \\
773 & Hough Transform (Lines) & Accumulator for line detection \\
774 & Hough Transform (Circles) & Radius-based accumulator \\
775 & Harris Corner Detector & Eigenvalue-based corners \\
776 & FAST Corner Detector & Intensity circle test \\
777 & SIFT (Scale-Invariant Feature Transform) & Keypoint detection \\
778 & SURF (Speeded-Up Robust Features) & Faster descriptor \\
779 & ORB (Oriented FAST + BRIEF) & Binary robust feature \\
780 & RANSAC & Robust model fitting \\
\end{longtable}

\subsubsection{79. Pathfinding in Space (A*, RRT,
PRM)}\label{pathfinding-in-space-a-rrt-prm-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5224}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4328}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
781 & A* Search & Heuristic pathfinding \\
782 & Dijkstra for Grid & Weighted shortest path \\
783 & Theta* & Any-angle pathfinding \\
784 & Jump Point Search & Grid acceleration \\
785 & RRT (Rapidly-Exploring Random Tree) & Random sampling tree \\
786 & RRT* & Optimal variant with rewiring \\
787 & PRM (Probabilistic Roadmap) & Graph sampling planner \\
788 & Visibility Graph & Connect visible vertices \\
789 & Potential Field Pathfinding & Gradient-based navigation \\
790 & Bug Algorithms & Simple obstacle avoidance \\
\end{longtable}

\subsubsection{80. Computational Geometry Variants and
Applications}\label{computational-geometry-variants-and-applications-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
791 & Convex Polygon Intersection & Clip convex sets \\
792 & Minkowski Sum & Shape convolution \\
793 & Rotating Calipers & Closest/farthest pair \\
794 & Half-Plane Intersection & Feasible region \\
795 & Line Arrangement & Count regions \\
796 & Point Location (Trapezoidal Map) & Query region lookup \\
797 & Voronoi Nearest Facility & Region query \\
798 & Delaunay Mesh Generation & Triangulation refinement \\
799 & Smallest Enclosing Circle & Welzl's algorithm \\
800 & Collision Detection (SAT) & Separating axis theorem \\
\end{longtable}

\subsection{Chapter 9. Systems, Databases, and Distributed
Algorithms}\label{chapter-9.-systems-databases-and-distributed-algorithms-2}

\subsubsection{81. Concurrency Control (2PL, MVCC,
OCC)}\label{concurrency-control-2pl-mvcc-occ-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5493}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4085}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
801 & Two-Phase Locking (2PL) & Acquire-then-release locks \\
802 & Strict 2PL & Hold locks until commit \\
803 & Conservative 2PL & Prevent deadlocks via prelock \\
804 & Timestamp Ordering & Schedule by timestamps \\
805 & Multiversion Concurrency Control (MVCC) & Snapshot isolation \\
806 & Optimistic Concurrency Control (OCC) & Validate at commit \\
807 & Serializable Snapshot Isolation & Merge read/write sets \\
808 & Lock-Free Algorithm & Atomic CAS updates \\
809 & Wait-Die / Wound-Wait & Deadlock prevention policies \\
810 & Deadlock Detection (Wait-for Graph) & Cycle detection in waits \\
\end{longtable}

\subsubsection{82. Logging, Recovery, and Commit
Protocols}\label{logging-recovery-and-commit-protocols-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
811 & Write-Ahead Logging (WAL) & Log before commit \\
812 & ARIES Recovery & Re-do/undo with LSNs \\
813 & Shadow Paging & Copy-on-write persistence \\
814 & Two-Phase Commit (2PC) & Coordinator-driven commit \\
815 & Three-Phase Commit (3PC) & Non-blocking variant \\
816 & Checkpointing & Save state for recovery \\
817 & Undo Logging & Rollback uncommitted \\
818 & Redo Logging & Reapply committed \\
819 & Quorum Commit & Majority agreement \\
820 & Consensus Commit & Combine 2PC + Paxos \\
\end{longtable}

\subsubsection{83. Scheduling (Round Robin, EDF,
Rate-Monotonic)}\label{scheduling-round-robin-edf-rate-monotonic-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4769}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
821 & First-Come First-Served (FCFS) & Sequential job order \\
822 & Shortest Job First (SJF) & Optimal average wait \\
823 & Round Robin (RR) & Time-slice fairness \\
824 & Priority Scheduling & Weighted selection \\
825 & Multilevel Queue & Tiered priority queues \\
826 & Earliest Deadline First (EDF) & Real-time optimal \\
827 & Rate Monotonic Scheduling (RMS) & Fixed periodic priority \\
828 & Lottery Scheduling & Probabilistic fairness \\
829 & Multilevel Feedback Queue & Adaptive behavior \\
830 & Fair Queuing (FQ) & Flow-based proportional sharing \\
\end{longtable}

\subsubsection{84. Caching and Replacement (LRU, LFU,
CLOCK)}\label{caching-and-replacement-lru-lfu-clock-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0448}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5672}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3881}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
831 & LRU (Least Recently Used) & Evict oldest used \\
832 & LFU (Least Frequently Used) & Evict lowest frequency \\
833 & FIFO Cache & Simple queue eviction \\
834 & CLOCK Algorithm & Approximate LRU \\
835 & ARC (Adaptive Replacement Cache) & Mix of recency + frequency \\
836 & Two-Queue (2Q) & Separate recent/frequent \\
837 & LIRS (Low Inter-reference Recency Set) & Predict reuse distance \\
838 & TinyLFU & Frequency sketch admission \\
839 & Random Replacement & Simple stochastic policy \\
840 & Belady's Optimal & Evict farthest future use \\
\end{longtable}

\subsubsection{85. Networking (Routing, Congestion
Control)}\label{networking-routing-congestion-control-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5938}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3594}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
841 & Dijkstra's Routing & Shortest path routing \\
842 & Bellman--Ford Routing & Distance-vector routing \\
843 & Link-State Routing (OSPF) & Global view routing \\
844 & Distance-Vector Routing (RIP) & Local neighbor updates \\
845 & Path Vector (BGP) & Route advertisement \\
846 & Flooding & Broadcast to all nodes \\
847 & Spanning Tree Protocol & Loop-free topology \\
848 & Congestion Control (AIMD) & TCP window control \\
849 & Random Early Detection (RED) & Queue preemptive drop \\
850 & ECN (Explicit Congestion Notification) & Mark packets early \\
\end{longtable}

\subsubsection{86. Distributed Consensus (Paxos, Raft,
PBFT)}\label{distributed-consensus-paxos-raft-pbft-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0385}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5385}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4231}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
851 & Basic Paxos & Majority consensus \\
852 & Multi-Paxos & Sequence of agreements \\
853 & Raft & Log replication + leader election \\
854 & Viewstamped Replication & Alternative consensus design \\
855 & PBFT (Practical Byzantine Fault Tolerance) & Byzantine safety \\
856 & Zab (Zookeeper Atomic Broadcast) & Broadcast + ordering \\
857 & EPaxos & Leaderless fast path \\
858 & VRR (Virtual Ring Replication) & Log around ring \\
859 & Two-Phase Commit with Consensus & Transactional commit \\
860 & Chain Replication & Ordered state replication \\
\end{longtable}

\subsubsection{87. Load Balancing and Rate
Limiting}\label{load-balancing-and-rate-limiting-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
861 & Round Robin Load Balancing & Sequential distribution \\
862 & Weighted Round Robin & Proportional to weight \\
863 & Least Connections & Pick least loaded node \\
864 & Consistent Hashing & Map requests stably \\
865 & Power of Two Choices & Sample and choose lesser load \\
866 & Random Load Balancing & Simple uniform random \\
867 & Token Bucket & Rate-based limiter \\
868 & Leaky Bucket & Steady flow shaping \\
869 & Sliding Window Counter & Rolling time window \\
870 & Fixed Window Counter & Resettable counter limiter \\
\end{longtable}

\subsubsection{88. Search and Indexing (Inverted, BM25,
WAND)}\label{search-and-indexing-inverted-bm25-wand-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
871 & Inverted Index Construction & Word → document list \\
872 & Positional Index Build & Store term positions \\
873 & TF-IDF Scoring & Term frequency weighting \\
874 & BM25 Ranking & Modern scoring model \\
875 & Boolean Retrieval & Logical AND/OR/NOT \\
876 & WAND Algorithm & Efficient top-k retrieval \\
877 & Block-Max WAND (BMW) & Early skipping optimization \\
878 & Impact-Ordered Indexing & Sort by contribution \\
879 & Tiered Indexing & Prioritize high-score docs \\
880 & DAAT vs SAAT Evaluation & Document vs score-at-a-time \\
\end{longtable}

\subsubsection{89. Compression and Encoding in
Systems}\label{compression-and-encoding-in-systems-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
881 & Run-Length Encoding (RLE) & Simple repetition encoding \\
882 & Huffman Coding & Optimal variable-length code \\
883 & Arithmetic Coding & Fractional interval coding \\
884 & Delta Encoding & Store differences \\
885 & Variable Byte Encoding & Compact integers \\
886 & Elias Gamma Coding & Prefix integer encoding \\
887 & Rice Coding & Unary + remainder scheme \\
888 & Snappy & Fast block compression \\
889 & Zstandard (Zstd) & Modern adaptive codec \\
890 & LZ4 & High-speed dictionary compressor \\
\end{longtable}

\subsubsection{90. Fault Tolerance and
Replication}\label{fault-tolerance-and-replication-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
891 & Primary--Backup Replication & One leader, one standby \\
892 & Quorum Replication & Majority write/read rule \\
893 & Chain Replication & Ordered consistency \\
894 & Gossip Protocol & Epidemic state exchange \\
895 & Anti-Entropy Repair & Periodic reconciliation \\
896 & Erasure Coding & Redundant data blocks \\
897 & Checksum Verification & Detect corruption \\
898 & Heartbeat Monitoring & Liveness detection \\
899 & Leader Election (Bully) & Highest ID wins \\
900 & Leader Election (Ring) & Token-based rotation \\
\end{longtable}

\subsection{Chapter 10. AI, ML, and
Optimization}\label{chapter-10.-ai-ml-and-optimization-2}

\subsubsection{91. Classical ML (k-means, Naive Bayes, SVM, Decision
Trees)}\label{classical-ml-k-means-naive-bayes-svm-decision-trees-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0423}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4789}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4789}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
901 & k-Means Clustering & Partition by centroid iteration \\
902 & k-Medoids (PAM) & Cluster by exemplars \\
903 & Gaussian Mixture Model (EM) & Soft probabilistic clustering \\
904 & Naive Bayes Classifier & Probabilistic feature independence \\
905 & Logistic Regression & Sigmoid linear classifier \\
906 & Perceptron & Online linear separator \\
907 & Decision Tree (CART) & Recursive partition by impurity \\
908 & ID3 Algorithm & Information gain splitting \\
909 & k-Nearest Neighbors (kNN) & Distance-based classification \\
910 & Linear Discriminant Analysis (LDA) & Projection for separation \\
\end{longtable}

\subsubsection{92. Ensemble Methods (Bagging, Boosting, Random
Forests)}\label{ensemble-methods-bagging-boosting-random-forests-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
911 & Bagging & Bootstrap aggregation \\
912 & Random Forest & Ensemble of decision trees \\
913 & AdaBoost & Weighted error correction \\
914 & Gradient Boosting & Sequential residual fitting \\
915 & XGBoost & Optimized gradient boosting \\
916 & LightGBM & Histogram-based leaf growth \\
917 & CatBoost & Ordered boosting for categoricals \\
918 & Stacking & Meta-model ensemble \\
919 & Voting Classifier & Majority aggregation \\
920 & Snapshot Ensemble & Averaged checkpoints \\
\end{longtable}

\subsubsection{93. Gradient Methods (SGD, Adam,
RMSProp)}\label{gradient-methods-sgd-adam-rmsprop-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0476}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5238}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
921 & Gradient Descent & Batch full-gradient step \\
922 & Stochastic Gradient Descent (SGD) & Sample-wise updates \\
923 & Mini-Batch SGD & Tradeoff speed and variance \\
924 & Momentum & Add velocity to descent \\
925 & Nesterov Accelerated Gradient & Lookahead correction \\
926 & AdaGrad & Adaptive per-parameter rate \\
927 & RMSProp & Exponential moving average \\
928 & Adam & Momentum + adaptive rate \\
929 & AdamW & Decoupled weight decay \\
930 & L-BFGS & Limited-memory quasi-Newton \\
\end{longtable}

\subsubsection{94. Deep Learning (Backpropagation, Dropout,
Normalization)}\label{deep-learning-backpropagation-dropout-normalization-1}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\# & Algorithm & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
931 & Backpropagation & Gradient chain rule \\
932 & Xavier/He Initialization & Scaled variance init \\
933 & Dropout & Random neuron deactivation \\
934 & Batch Normalization & Normalize per batch \\
935 & Layer Normalization & Normalize per feature \\
936 & Gradient Clipping & Prevent explosion \\
937 & Early Stopping & Prevent overfitting \\
938 & Weight Decay & Regularization via penalty \\
939 & Learning Rate Scheduling & Dynamic LR adjustment \\
940 & Residual Connections & Skip layer improvement \\
\end{longtable}

\subsubsection{95. Sequence Models (Viterbi, Beam Search,
CTC)}\label{sequence-models-viterbi-beam-search-ctc-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0405}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5811}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3784}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
941 & Hidden Markov Model (Forward--Backward) & Probabilistic sequence
model \\
942 & Viterbi Algorithm & Most probable path \\
943 & Baum--Welch & EM training for HMMs \\
944 & Beam Search & Top-k path exploration \\
945 & Greedy Decoding & Fast approximate decoding \\
946 & Connectionist Temporal Classification (CTC) & Unaligned sequence
training \\
947 & Attention Mechanism & Weighted context aggregation \\
948 & Transformer Decoder & Self-attention stack \\
949 & Seq2Seq with Attention & Encoder-decoder framework \\
950 & Pointer Network & Output index selection \\
\end{longtable}

\subsubsection{96. Metaheuristics (GA, SA, PSO,
ACO)}\label{metaheuristics-ga-sa-pso-aco-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0455}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4545}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
951 & Genetic Algorithm (GA) & Evolutionary optimization \\
952 & Simulated Annealing (SA) & Temperature-controlled search \\
953 & Tabu Search & Memory of forbidden moves \\
954 & Particle Swarm Optimization (PSO) & Velocity-based search \\
955 & Ant Colony Optimization (ACO) & Pheromone-guided path \\
956 & Differential Evolution (DE) & Vector-based mutation \\
957 & Harmony Search & Music-inspired improvisation \\
958 & Firefly Algorithm & Brightness-attraction movement \\
959 & Bee Colony Optimization & Explore-exploit via scouts \\
960 & Hill Climbing & Local incremental improvement \\
\end{longtable}

\subsubsection{97. Reinforcement Learning (Q-learning, Policy
Gradients)}\label{reinforcement-learning-q-learning-policy-gradients-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0469}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5312}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4219}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
961 & Monte Carlo Control & Average returns \\
962 & Temporal Difference (TD) Learning & Bootstrap updates \\
963 & SARSA & On-policy TD learning \\
964 & Q-Learning & Off-policy TD learning \\
965 & Double Q-Learning & Reduce overestimation \\
966 & Deep Q-Network (DQN) & Neural Q approximator \\
967 & REINFORCE & Policy gradient by sampling \\
968 & Actor--Critic & Value-guided policy update \\
969 & PPO (Proximal Policy Optimization) & Clipped surrogate
objective \\
970 & DDPG / SAC & Continuous action RL \\
\end{longtable}

\subsubsection{98. Approximation and Online
Algorithms}\label{approximation-and-online-algorithms-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0411}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4384}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5205}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
971 & Greedy Set Cover & ln(n)-approximation \\
972 & Vertex Cover Approximation & Double-matching heuristic \\
973 & Traveling Salesman Approximation & MST-based 2-approx \\
974 & k-Center Approximation & Farthest-point heuristic \\
975 & Online Paging (LRU) & Competitive analysis \\
976 & Online Matching (Ranking) & Adversarial input resilience \\
977 & Online Knapsack & Ratio-based acceptance \\
978 & Competitive Ratio Evaluation & Bound worst-case performance \\
979 & PTAS / FPTAS Schemes & Polynomial approximation \\
980 & Primal--Dual Method & Approximate combinatorial optimization \\
\end{longtable}

\subsubsection{99. Fairness, Causal Inference, and Robust
Optimization}\label{fairness-causal-inference-and-robust-optimization-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0441}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5294}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4265}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
981 & Reweighting for Fairness & Adjust sample weights \\
982 & Demographic Parity Constraint & Equalize positive rates \\
983 & Equalized Odds & Align error rates \\
984 & Adversarial Debiasing & Learn fair representations \\
985 & Causal DAG Discovery & Graphical causal inference \\
986 & Propensity Score Matching & Estimate treatment effect \\
987 & Instrumental Variable Estimation & Handle confounders \\
988 & Robust Optimization & Worst-case aware optimization \\
989 & Distributionally Robust Optimization & Minimax over uncertainty
sets \\
990 & Counterfactual Fairness & Simulate do-interventions \\
\end{longtable}

\subsubsection{100. AI Planning, Search, and Learning
Systems}\label{ai-planning-search-and-learning-systems-1}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0625}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4844}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4531}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\#
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
991 & Breadth-First Search (BFS) & Uninformed search \\
992 & Depth-First Search (DFS) & Backtracking search \\
993 & A* Search & Heuristic guided \\
994 & Iterative Deepening A* (IDA*) & Memory-bounded heuristic \\
995 & Uniform Cost Search & Expand by path cost \\
996 & Monte Carlo Tree Search (MCTS) & Exploration vs exploitation \\
997 & Minimax & Game tree evaluation \\
998 & Alpha--Beta Pruning & Prune unneeded branches \\
999 & STRIPS Planning & Action-based state transition \\
1000 & Hierarchical Task Network (HTN) & Structured AI planning \\
\end{longtable}

\bookmarksetup{startatroot}

\chapter{Chapter 1. Foundatmemtions of
Algorithms}\label{chapter-1.-foundatmemtions-of-algorithms}

\section{Section 1. What is an
algorithms?}\label{section-1.-what-is-an-algorithms}

\subsection{1 Euclid's GCD}\label{euclids-gcd}

Euclid's algorithm is one of the oldest and most elegant procedures in
mathematics. It computes the greatest common divisor (GCD) of two
integers by repeatedly applying a simple rule: replace the larger number
with its remainder when divided by the smaller. When the remainder
becomes zero, the smaller number at that step is the GCD.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving}

We want the greatest common divisor of two integers \(a\) and \(b\): the
largest number that divides both without a remainder.

A naive way would be to check all numbers from \(\min(a,b)\) down to 1.
That's \(O(\min(a,b))\) steps, which is too slow for large inputs.
Euclid's insight gives a much faster recursive method using division:

\[
\gcd(a, b) =
\begin{cases}
a, & \text{if } b = 0, \\
\gcd(b, a \bmod b), & \text{otherwise.}
\end{cases}
\]

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language}

Imagine two sticks of lengths \(a\) and \(b\). You can keep cutting the
longer stick by the shorter one until one divides evenly. The length of
the last nonzero remainder is the GCD.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take \(a, b\) with \(a \ge b\).
\item
  Replace \(a\) by \(b\), and \(b\) by \(a \bmod b\).
\item
  Repeat until \(b = 0\).
\item
  Return \(a\).
\end{enumerate}

This process always terminates, since \(b\) strictly decreases each
step.

\subsubsection{Example Step by Step}\label{example-step-by-step}

Find \(\gcd(48, 18)\):

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Step & \(a\) & \(b\) & \(a \bmod b\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 48 & 18 & 12 \\
2 & 18 & 12 & 6 \\
3 & 12 & 6 & 0 \\
\end{longtable}

When \(b = 0\), \(a = 6\). So \(\gcd(48, 18) = 6\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ gcd(a, b):}
    \ControlFlowTok{while}\NormalTok{ b }\OperatorTok{!=} \DecValTok{0}\NormalTok{:}
\NormalTok{        a, b }\OperatorTok{=}\NormalTok{ b, a }\OperatorTok{\%}\NormalTok{ b}
    \ControlFlowTok{return}\NormalTok{ a}

\BuiltInTok{print}\NormalTok{(gcd(}\DecValTok{48}\NormalTok{, }\DecValTok{18}\NormalTok{))  }\CommentTok{\# Output: 6}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-100}

\begin{itemize}
\tightlist
\item
  Foundational example of algorithmic thinking
\item
  Core building block in modular arithmetic, number theory, and
  cryptography
\item
  Efficient: runs in \(O(\log \min(a,b))\) steps
\item
  Easy to implement iteratively or recursively
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works}

If \(a = bq + r\), any common divisor of \(a\) and \(b\) also divides
\(r\), since \(r = a - bq\). Thus, the set of common divisors of
\((a, b)\) and \((b, r)\) is the same, and their greatest element (the
GCD) is unchanged.

Repeatedly applying this property leads to \(b = 0\), where
\(\gcd(a, 0) = a\).

\subsubsection{Try It Yourself}\label{try-it-yourself-100}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \(\gcd(270, 192)\) step by step.
\item
  Implement the recursive version:
\end{enumerate}

\[
\gcd(a, b) = \gcd(b,, a \bmod b)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Extend to find \(\gcd(a, b, c)\) using \(\gcd(\gcd(a, b), c)\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Input \((a, b)\) & Expected Output \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
(48, 18) & 6 \\
(270, 192) & 6 \\
(7, 3) & 1 \\
(10, 0) & 10 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-8}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
GCD & \(O(\log \min(a,b))\) & \(O(1)\) \\
\end{longtable}

Euclid's GCD algorithm is where algorithmic elegance begins, a timeless
loop of division that turns mathematics into motion.

\subsection{2 Sieve of Eratosthenes}\label{sieve-of-eratosthenes-1}

The Sieve of Eratosthenes is a classic ancient algorithm for finding all
prime numbers up to a given limit. It works by iteratively marking the
multiples of each prime, starting from 2. The numbers that remain
unmarked at the end are primes.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-1}

We want to find all prime numbers less than or equal to \(n\). A naive
method checks each number \(k\) by testing divisibility from \(2\) to
\(\sqrt{k}\), which is too slow for large \(n\). The sieve improves this
by using elimination instead of repeated checking.

We aim for an algorithm with time complexity close to
\(O(n \log \log n)\).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create a list \texttt{is\_prime{[}0..n{]}} and mark all as true.
\item
  Mark 0 and 1 as non-prime.
\item
  Starting from \(p = 2\), if \(p\) is still marked prime:

  \begin{itemize}
  \tightlist
  \item
    Mark all multiples of \(p\) (from \(p^2\) to \(n\)) as non-prime.
  \end{itemize}
\item
  Increment \(p\) and repeat until \(p^2 > n\).
\item
  All indices still marked true are primes.
\end{enumerate}

This process ``filters out'' composite numbers step by step, just like
passing sand through finer and finer sieves.

\subsubsection{Example Step by Step}\label{example-step-by-step-1}

Find all primes up to \(30\):

Start:
\([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\)

\begin{itemize}
\tightlist
\item
  \(p = 2\): cross out multiples of 2
\item
  \(p = 3\): cross out multiples of 3
\item
  \(p = 5\): cross out multiples of 5
\end{itemize}

Remaining numbers: \(2, 3, 5, 7, 11, 13, 17, 19, 23, 29\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-1}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ sieve(n):}
\NormalTok{    is\_prime }\OperatorTok{=}\NormalTok{ [}\VariableTok{True}\NormalTok{] }\OperatorTok{*}\NormalTok{ (n }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    is\_prime[}\DecValTok{0}\NormalTok{] }\OperatorTok{=}\NormalTok{ is\_prime[}\DecValTok{1}\NormalTok{] }\OperatorTok{=} \VariableTok{False}

\NormalTok{    p }\OperatorTok{=} \DecValTok{2}
    \ControlFlowTok{while}\NormalTok{ p }\OperatorTok{*}\NormalTok{ p }\OperatorTok{\textless{}=}\NormalTok{ n:}
        \ControlFlowTok{if}\NormalTok{ is\_prime[p]:}
            \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(p }\OperatorTok{*}\NormalTok{ p, n }\OperatorTok{+} \DecValTok{1}\NormalTok{, p):}
\NormalTok{                is\_prime[i] }\OperatorTok{=} \VariableTok{False}
\NormalTok{        p }\OperatorTok{+=} \DecValTok{1}

    \ControlFlowTok{return}\NormalTok{ [i }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ is\_prime[i]]}

\BuiltInTok{print}\NormalTok{(sieve(}\DecValTok{30}\NormalTok{))  }\CommentTok{\# [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-101}

\begin{itemize}
\tightlist
\item
  One of the earliest and most efficient ways to generate primes
\item
  Forms the basis for number-theoretic algorithms and cryptographic
  systems
\item
  Conceptually simple yet mathematically deep
\item
  Demonstrates elimination instead of brute force
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-1}

Every composite number \(n\) has a smallest prime divisor
\(p \le \sqrt{n}\). Thus, when we mark multiples of primes up to
\(\sqrt{n}\), every composite number is crossed out by its smallest
prime factor. Numbers that remain unmarked are prime by definition.

\subsubsection{Try It Yourself}\label{try-it-yourself-101}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run the sieve for \(n = 50\) and list primes.
\item
  Modify to count primes instead of listing them.
\item
  Compare runtime with naive primality tests for large \(n\).
\item
  Extend to a segmented sieve for \(n > 10^7\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-1}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Input \(n\) & Expected Primes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & {[}2, 3, 5, 7{]} \\
20 & {[}2, 3, 5, 7, 11, 13, 17, 19{]} \\
30 & {[}2, 3, 5, 7, 11, 13, 17, 19, 23, 29{]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-9}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sieve & \(O(n \log \log n)\) & \(O(n)\) \\
\end{longtable}

The Sieve of Eratosthenes turns the search for primes into a graceful
pattern of elimination, simple loops revealing the hidden order of
numbers.

\subsection{3 Linear Step Trace}\label{linear-step-trace}

A Linear Step Trace is a simple yet powerful visualization tool for
understanding how an algorithm progresses line by line. It records each
step of execution, showing how variables change over time, helping
beginners see the \emph{flow} of computation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-2}

When learning algorithms, it's easy to lose track of what's happening
after each instruction. A Linear Step Trace helps us \emph{see}
execution in motion, one step, one update at a time.

Instead of abstract reasoning alone, we follow the exact state changes
that occur during the run, making debugging and reasoning far easier.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write down your pseudocode or code.
\item
  Create a table with columns for step number, current line, and
  variable values.
\item
  Each time a line executes, record the line number and updated
  variables.
\item
  Continue until the program finishes.
\end{enumerate}

This method is algorithm-agnostic, it works for loops, recursion,
conditionals, and all flow patterns.

\subsubsection{Example Step by Step}\label{example-step-by-step-2}

Let's trace a simple loop:

\begin{verbatim}
sum = 0
for i in 1..4:
    sum = sum + i
\end{verbatim}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Step & Line & i & sum & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & - & 0 & Initialize sum \\
2 & 2 & 1 & 0 & Loop start \\
3 & 3 & 1 & 1 & sum = 0 + 1 \\
4 & 2 & 2 & 1 & Next iteration \\
5 & 3 & 2 & 3 & sum = 1 + 2 \\
6 & 2 & 3 & 3 & Next iteration \\
7 & 3 & 3 & 6 & sum = 3 + 3 \\
8 & 2 & 4 & 6 & Next iteration \\
9 & 3 & 4 & 10 & sum = 6 + 4 \\
10 & - & - & 10 & End \\
\end{longtable}

Final result: \(sum = 10\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-2}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{sum} \OperatorTok{=} \DecValTok{0}
\NormalTok{trace }\OperatorTok{=}\NormalTok{ []}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{):}
\NormalTok{    trace.append((i, }\BuiltInTok{sum}\NormalTok{))}
    \BuiltInTok{sum} \OperatorTok{+=}\NormalTok{ i}

\NormalTok{trace.append((}\StringTok{"final"}\NormalTok{, }\BuiltInTok{sum}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(trace)}
\CommentTok{\# [(1, 0), (2, 1), (3, 3), (4, 6), (\textquotesingle{}final\textquotesingle{}, 10)]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-102}

\begin{itemize}
\tightlist
\item
  Builds \emph{step-by-step literacy} in algorithm reading
\item
  Great for teaching loops, conditions, and recursion
\item
  Reveals hidden assumptions and logic errors
\item
  Ideal for debugging and analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-2}

Every algorithm can be expressed as a sequence of state transitions. If
each transition is recorded, we obtain a complete trace of computation.
Thus, correctness can be verified by comparing expected vs.~actual state
sequences. This is equivalent to an inductive proof: each step matches
the specification.

\subsubsection{Try It Yourself}\label{try-it-yourself-102}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Trace a recursive factorial function step by step.
\item
  Add a ``call stack'' column to visualize recursion depth.
\item
  Trace an array-sorting loop and mark swaps.
\item
  Compare traces before and after optimization.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-2}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Program & Expected Final State \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
sum of 1..4 & sum = 10 \\
sum of 1..10 & sum = 55 \\
factorial(5) & result = 120 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-10}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Trace Recording & \(O(n)\) & \(O(n)\) \\
\end{longtable}

A Linear Step Trace transforms invisible logic into a visible path, a
story of each line's journey, one state at a time.

\subsection{4 Algorithm Flow Diagram
Builder}\label{algorithm-flow-diagram-builder}

An Algorithm Flow Diagram Builder turns abstract pseudocode into a
visual map, a diagram of control flow that shows where decisions branch,
where loops repeat, and where computations end. It's the bridge between
code and comprehension.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-3}

When an algorithm becomes complex, it's easy to lose track of its
structure. We may know what each line does, but not \emph{how control
moves} through the program.

A flow diagram lays out that control structure explicitly, revealing
loops, branches, merges, and exits at a glance.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Identify actions and decisions

  \begin{itemize}
  \tightlist
  \item
    Actions: assignments, computations
  \item
    Decisions: if, while, for, switch
  \end{itemize}
\item
  Represent them with symbols

  \begin{itemize}
  \tightlist
  \item
    Rectangle → action
  \item
    Diamond → decision
  \item
    Arrow → flow of control
  \end{itemize}
\item
  Connect nodes based on what happens next
\item
  Loop back arrows for iterations, and mark exit points
\end{enumerate}

This yields a graph of control, a shape you can follow from start to
finish.

\subsubsection{Example Step by Step}\label{example-step-by-step-3}

Let's draw the flow for finding the sum of numbers \(1\) to \(n\):

Pseudocode:

\begin{verbatim}
sum = 0
i = 1
while i ≤ n:
    sum = sum + i
    i = i + 1
print(sum)
\end{verbatim}

Flow Outline:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start
\item
  Initialize \texttt{sum\ =\ 0}, \texttt{i\ =\ 1}
\item
  Decision: \texttt{i\ ≤\ n?}

  \begin{itemize}
  \tightlist
  \item
    Yes → Update \texttt{sum}, Increment \texttt{i} → Loop back
  \item
    No → Print sum → End
  \end{itemize}
\end{enumerate}

Textual Diagram:

\begin{verbatim}
  [Start]
     |
[sum=0, i=1]
     |
  (i ≤ n?) ----No----> [Print sum] -> [End]
     |
    Yes
     |
 [sum = sum + i]
     |
 [i = i + 1]
     |
   (Back to i ≤ n?)
\end{verbatim}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-3}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ sum\_to\_n(n):}
    \BuiltInTok{sum} \OperatorTok{=} \DecValTok{0}
\NormalTok{    i }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n:}
        \BuiltInTok{sum} \OperatorTok{+=}\NormalTok{ i}
\NormalTok{        i }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return} \BuiltInTok{sum}
\end{Highlighting}
\end{Shaded}

Use this code to generate flow diagrams automatically with libraries
like \texttt{graphviz} or \texttt{pyflowchart}.

\subsubsection{Why It Matters}\label{why-it-matters-103}

\begin{itemize}
\tightlist
\item
  Reveals structure at a glance
\item
  Makes debugging easier by visualizing possible paths
\item
  Helps design before coding
\item
  Universal representation (language-agnostic)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-3}

Each algorithm's execution path can be modeled as a directed graph:

\begin{itemize}
\tightlist
\item
  Vertices = program states or actions
\item
  Edges = transitions (next step)
\end{itemize}

A flow diagram is simply this control graph rendered visually. It
preserves correctness since each edge corresponds to a valid jump in
control flow.

\subsubsection{Try It Yourself}\label{try-it-yourself-103}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a flowchart for binary search.
\item
  Mark all possible comparison outcomes.
\item
  Add loopbacks for mid-point updates.
\item
  Compare with recursive version, note structural difference.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-3}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Key Decision Node & Expected Paths \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sum loop & \(i \le n\) & 2 (continue, exit) \\
Binary search & \(key == mid?\) & 3 (left, right, found) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-11}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Diagram Construction & \(O(n)\) nodes & \(O(n)\) edges \\
\end{longtable}

An Algorithm Flow Diagram is a lens, it turns invisible execution paths
into a map you can walk, from ``Start'' to ``End.''

\subsection{5 Long Division}\label{long-division}

Long Division is a step-by-step algorithm for dividing one integer by
another. It's one of the earliest examples of a systematic computational
procedure, showing how large problems can be solved through a sequence
of local, repeatable steps.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-4}

We want to compute the quotient and remainder when dividing two integers
\(a\) (dividend) and \(b\) (divisor).

Naively, repeated subtraction would take \(O(a/b)\) steps, far too many
for large numbers. Long Division improves this by grouping subtractions
by powers of 10, performing digit-wise computation efficiently.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Align digits of \(a\) (the dividend).
\item
  Compare current portion of \(a\) to \(b\).
\item
  Find the largest multiple of \(b\) that fits in the current portion.
\item
  Subtract, write the quotient digit, and bring down the next digit.
\item
  Repeat until all digits have been processed.
\item
  The digits written form the quotient; what's left is the remainder.
\end{enumerate}

This method extends naturally to decimals, just continue bringing down
zeros.

\subsubsection{Example Step by Step}\label{example-step-by-step-4}

Compute \(153 \div 7\):

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0471}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1647}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1059}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.4824}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Step
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Portion
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Quotient Digit
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Remainder
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Action
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 15 & 2 & 1 & \(7 \times 2 = 14\), subtract \(15 - 14 = 1\) \\
2 & Bring down 3 → 13 & 1 & 6 & \(7 \times 1 = 7\), subtract
\(13 - 7 = 6\) \\
3 & No more digits & , & 6 & Done \\
\end{longtable}

Result: Quotient \(= 21\), Remainder \(= 6\) Check:
\(7 \times 21 + 6 = 153\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-4}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ long\_division(a, b):}
\NormalTok{    quotient }\OperatorTok{=} \DecValTok{0}
\NormalTok{    remainder }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ digit }\KeywordTok{in} \BuiltInTok{str}\NormalTok{(a):}
\NormalTok{        remainder }\OperatorTok{=}\NormalTok{ remainder }\OperatorTok{*} \DecValTok{10} \OperatorTok{+} \BuiltInTok{int}\NormalTok{(digit)}
\NormalTok{        q }\OperatorTok{=}\NormalTok{ remainder }\OperatorTok{//}\NormalTok{ b}
\NormalTok{        remainder }\OperatorTok{=}\NormalTok{ remainder }\OperatorTok{\%}\NormalTok{ b}
\NormalTok{        quotient }\OperatorTok{=}\NormalTok{ quotient }\OperatorTok{*} \DecValTok{10} \OperatorTok{+}\NormalTok{ q}
    \ControlFlowTok{return}\NormalTok{ quotient, remainder}

\BuiltInTok{print}\NormalTok{(long\_division(}\DecValTok{153}\NormalTok{, }\DecValTok{7}\NormalTok{))  }\CommentTok{\# (21, 6)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-104}

\begin{itemize}
\tightlist
\item
  Introduces loop invariants and digit-by-digit reasoning
\item
  Foundation for division in arbitrary-precision arithmetic
\item
  Core to implementing division in CPUs and big integer libraries
\item
  Demonstrates decomposing a large task into simple, local operations
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-4}

At each step:

\begin{itemize}
\tightlist
\item
  The current remainder \(r_i\) satisfies \(0 \le r_i < b\).
\item
  The algorithm maintains the invariant: \[
  a = b \times Q_i + r_i
  \] where \(Q_i\) is the partial quotient so far.
\item
  Each step reduces the unprocessed part of \(a\), ensuring termination
  with correct \(Q\) and \(r\).
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-104}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Perform \(2345 \div 13\) by hand.
\item
  Verify with Python's \texttt{divmod(2345,\ 13)}.
\item
  Extend your code to produce decimal expansions.
\item
  Compare digit-wise trace with manual process.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-4}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Dividend \(a\) & Divisor \(b\) & Expected Output \((Q, R)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
153 & 7 & (21, 6) \\
100 & 8 & (12, 4) \\
99 & 9 & (11, 0) \\
23 & 5 & (4, 3) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-12}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Long Division & \(O(d)\) & \(O(1)\) \\
\end{longtable}

where \(d\) is the number of digits in \(a\).

Long Division is more than arithmetic, it's the first encounter with
algorithmic thinking: state, iteration, and correctness unfolding one
digit at a time.

\subsection{6 Modular Addition}\label{modular-addition}

Modular addition is arithmetic on a clock, we add numbers, then wrap
around when reaching a fixed limit. It's the simplest example of modular
arithmetic, a system that underlies cryptography, hashing, and cyclic
data structures.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-5}

We want to add two integers \(a\) and \(b\), but keep the result within
a fixed modulus \(m\). That means we compute the remainder after
dividing the sum by \(m\).

Formally, we want:

\[
(a + b) \bmod m
\]

This ensures results always lie in the range \([0, m - 1]\), regardless
of how large \(a\) or \(b\) become.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the sum \(s = a + b\).
\item
  Divide \(s\) by \(m\) to find the remainder.
\item
  The remainder is the modular sum.
\end{enumerate}

If \(s \ge m\), we ``wrap around'' by subtracting \(m\) until it fits in
the modular range.

This idea is like hours on a clock: \(10 + 5\) hours on a \(12\)-hour
clock → \(3\).

\subsubsection{Example Step by Step}\label{example-step-by-step-5}

Let \(a = 10\), \(b = 7\), \(m = 12\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \(s = 10 + 7 = 17\).
\item
  \(17 \bmod 12 = 5\).
\item
  So \((10 + 7) \bmod 12 = 5\).
\end{enumerate}

Check: \(17 - 12 = 5\), fits in \([0, 11]\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-5}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ mod\_add(a, b, m):}
    \ControlFlowTok{return}\NormalTok{ (a }\OperatorTok{+}\NormalTok{ b) }\OperatorTok{\%}\NormalTok{ m}

\BuiltInTok{print}\NormalTok{(mod\_add(}\DecValTok{10}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{12}\NormalTok{))  }\CommentTok{\# 5}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-105}

\begin{itemize}
\tightlist
\item
  Foundation of modular arithmetic
\item
  Used in hashing, cyclic buffers, and number theory
\item
  Crucial for secure encryption (RSA, ECC)
\item
  Demonstrates wrap-around logic in bounded systems
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-5}

By definition of modulus:

\[
x \bmod m = r \quad \text{such that } x = q \times m + r,\ 0 \le r < m
\]

Thus, for \(a + b = q \times m + r\), we have \((a + b) \bmod m = r\).
All equivalent sums differ by a multiple of \(m\), so modular addition
preserves congruence:

\[
(a + b) \bmod m \equiv (a \bmod m + b \bmod m) \bmod m
\]

\subsubsection{Try It Yourself}\label{try-it-yourself-105}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \((15 + 8) \bmod 10\).
\item
  Verify \((a + b) \bmod m = ((a \bmod m) + (b \bmod m)) \bmod m\).
\item
  Test with negative values: \((−3 + 5) \bmod 7\).
\item
  Apply to time arithmetic: what is \(11 + 5\) on a \(12\)-hour clock?
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-5}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(a\) & \(b\) & \(m\) & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 7 & 12 & 5 \\
5 & 5 & 10 & 0 \\
8 & 15 & 10 & 3 \\
11 & 5 & 12 & 4 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-13}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Modular Addition & \(O(1)\) & \(O(1)\) \\
\end{longtable}

Modular addition teaches the rhythm of modular arithmetic, every sum
wraps back into harmony, always staying within its finite world.

\subsection{7 Base Conversion}\label{base-conversion}

Base conversion is the algorithmic process of expressing a number in a
different numeral system. It's how we translate between decimal, binary,
octal, hexadecimal, or any base, the language of computers and
mathematics alike.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-6}

We want to represent an integer \(n\) in base \(b\). In base 10, digits
go from 0 to 9. In base 2, only 0 and 1. In base 16, digits are
\(0 \ldots 9\) and \(A \ldots F\).

The goal is to find a sequence of digits \(d_k d_{k-1} \ldots d_0\) such
that:

\[
n = \sum_{i=0}^{k} d_i \cdot b^i
\]

where \(0 \le d_i < b\).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-6}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with the integer \(n\).
\item
  Repeatedly divide \(n\) by \(b\).
\item
  Record the remainder each time (these are the digits).
\item
  Stop when \(n = 0\).
\item
  The base-\(b\) representation is the remainders read in reverse order.
\end{enumerate}

This works because division extracts digits starting from the least
significant position.

\subsubsection{Example Step by Step}\label{example-step-by-step-6}

Convert \(45\) to binary (\(b = 2\)):

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Step & \(n\) & \(n \div 2\) & Remainder \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 45 & 22 & 1 \\
2 & 22 & 11 & 0 \\
3 & 11 & 5 & 1 \\
4 & 5 & 2 & 1 \\
5 & 2 & 1 & 0 \\
6 & 1 & 0 & 1 \\
\end{longtable}

Read remainders upward: 101101

So \(45_{10} = 101101_2\).

Check:
\(1 \cdot 2^5 + 0 \cdot 2^4 + 1 \cdot 2^3 + 1 \cdot 2^2 + 0 \cdot 2^1 + 1 \cdot 2^0 = 32 + 0 + 8 + 4 + 0 + 1 = 45\)
✅

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-6}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ to\_base(n, b):}
\NormalTok{    digits }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{while}\NormalTok{ n }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{        digits.append(n }\OperatorTok{\%}\NormalTok{ b)}
\NormalTok{        n }\OperatorTok{//=}\NormalTok{ b}
    \ControlFlowTok{return}\NormalTok{ digits[::}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\KeywordTok{or}\NormalTok{ [}\DecValTok{0}\NormalTok{]}

\BuiltInTok{print}\NormalTok{(to\_base(}\DecValTok{45}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\CommentTok{\# [1, 0, 1, 1, 0, 1]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-106}

\begin{itemize}
\tightlist
\item
  Converts numbers between human and machine representations
\item
  Core in encoding, compression, and cryptography
\item
  Builds intuition for positional number systems
\item
  Used in parsing, serialization, and digital circuits
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-6}

Each division step produces one digit \(r_i = n_i \bmod b\). We have:

\[
n_i = b \cdot n_{i+1} + r_i
\]

Unfolding the recurrence gives:

\[
n = \sum_{i=0}^{k} r_i b^i
\]

So collecting remainders in reverse order reconstructs \(n\) exactly.

\subsubsection{Try It Yourself}\label{try-it-yourself-106}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Convert \(100_{10}\) to base 8.
\item
  Convert \(255_{10}\) to base 16.
\item
  Verify by recombining digits via \(\sum d_i b^i\).
\item
  Write a reverse converter: base-\(b\) to decimal.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-6}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Decimal \(n\) & Base \(b\) & Representation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
45 & 2 & 101101 \\
100 & 8 & 144 \\
255 & 16 & FF \\
31 & 5 & 111 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-14}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Base Conversion & \(O(\log_b n)\) & \(O(\log_b n)\) \\
\end{longtable}

Base conversion is arithmetic storytelling, peeling away remainders
until only digits remain, revealing the same number through a different
lens.

\subsection{8 Factorial Computation}\label{factorial-computation}

Factorial computation is the algorithmic act of multiplying a sequence
of consecutive integers, a simple rule that grows explosively. It lies
at the foundation of combinatorics, probability, and mathematical
analysis.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-7}

We want to compute the factorial of a non-negative integer \(n\),
written \(n!\), defined as:

\[
n! = n \times (n - 1) \times (n - 2) \times \cdots \times 1
\]

with the base case:

\[
0! = 1
\]

Factorial counts the number of ways to arrange \(n\) distinct objects,
the building block of permutations and combinations.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-7}

There are two main ways:

Iterative:

\begin{itemize}
\tightlist
\item
  Start with \texttt{result\ =\ 1}
\item
  Multiply by each \(i\) from 1 to \(n\)
\item
  Return result
\end{itemize}

Recursive:

\begin{itemize}
\tightlist
\item
  \(n! = n \times (n - 1)!\)
\item
  Stop when \(n = 0\)
\end{itemize}

Both methods produce the same result; recursion mirrors the mathematical
definition, iteration avoids call overhead.

\subsubsection{Example Step by Step}\label{example-step-by-step-7}

Compute \(5!\):

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & \(n\) & Product \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & 1 \\
2 & 2 & 2 \\
3 & 3 & 6 \\
4 & 4 & 24 \\
5 & 5 & 120 \\
\end{longtable}

So \(5! = 120\) ✅

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-7}

Iterative Version

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ factorial\_iter(n):}
\NormalTok{    result }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{        result }\OperatorTok{*=}\NormalTok{ i}
    \ControlFlowTok{return}\NormalTok{ result}

\BuiltInTok{print}\NormalTok{(factorial\_iter(}\DecValTok{5}\NormalTok{))  }\CommentTok{\# 120}
\end{Highlighting}
\end{Shaded}

Recursive Version

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ factorial\_rec(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{*}\NormalTok{ factorial\_rec(n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(factorial\_rec(}\DecValTok{5}\NormalTok{))  }\CommentTok{\# 120}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-107}

\begin{itemize}
\tightlist
\item
  Core operation in combinatorics, calculus, and probability
\item
  Demonstrates recursion, iteration, and induction
\item
  Grows rapidly, useful for testing overflow and asymptotics
\item
  Appears in binomial coefficients, Taylor series, and permutations
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-7}

By definition, \(n! = n \times (n - 1)!\). Assume \((n - 1)!\) is
correctly computed. Then multiplying by \(n\) yields \(n!\).

By induction:

\begin{itemize}
\tightlist
\item
  Base case: \(0! = 1\)
\item
  Step: if \((n - 1)!\) is correct, so is \(n!\)
\end{itemize}

Thus, the recursive and iterative definitions are equivalent and
correct.

\subsubsection{Try It Yourself}\label{try-it-yourself-107}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute \(6!\) both iteratively and recursively.
\item
  Print intermediate products to trace the growth.
\item
  Compare runtime for \(n = 1000\) using both methods.
\item
  Explore factorial in floating point (\texttt{math.gamma}) for
  non-integers.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-7}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Input \(n\) & Expected Output \(n!\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 \\
1 & 1 \\
3 & 6 \\
5 & 120 \\
6 & 720 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-15}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Iterative & \(O(n)\) & \(O(1)\) \\
Recursive & \(O(n)\) & \(O(n)\) (stack) \\
\end{longtable}

Factorial computation is where simplicity meets infinity, a single rule
that scales from 1 to astronomical numbers with graceful inevitability.

\subsection{9 Iterative Process Tracer}\label{iterative-process-tracer}

An Iterative Process Tracer is a diagnostic algorithm that follows each
iteration of a loop, recording variable states, conditions, and updates.
It helps visualize the evolution of a program's internal state, turning
looping logic into a clear timeline.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-8}

When writing iterative algorithms, it's easy to lose sight of what
happens at each step. Are variables updating correctly? Are loop
conditions behaving as expected? A tracer captures this process, step by
step, so we can verify correctness, find bugs, and teach iteration with
clarity.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-8}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Identify the loop (for or while).
\item
  Before or after each iteration, record:

  \begin{itemize}
  \tightlist
  \item
    The iteration number
  \item
    Key variable values
  \item
    Condition evaluations
  \end{itemize}
\item
  Store these snapshots in a trace table.
\item
  After execution, review how values evolve over time.
\end{enumerate}

Think of it as an ``execution diary'', every iteration gets a journal
entry.

\subsubsection{Example Step by Step}\label{example-step-by-step-8}

Let's trace a simple accumulation:

\begin{verbatim}
sum = 0
for i in 1..5:
    sum = sum + i
\end{verbatim}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Step & \(i\) & \(sum\) & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & 1 & Add first number \\
2 & 2 & 3 & Add second number \\
3 & 3 & 6 & Add third number \\
4 & 4 & 10 & Add fourth number \\
5 & 5 & 15 & Add fifth number \\
\end{longtable}

Final result: \(sum = 15\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-8}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ trace\_sum(n):}
    \BuiltInTok{sum} \OperatorTok{=} \DecValTok{0}
\NormalTok{    trace }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
        \BuiltInTok{sum} \OperatorTok{+=}\NormalTok{ i}
\NormalTok{        trace.append((i, }\BuiltInTok{sum}\NormalTok{))}
    \ControlFlowTok{return}\NormalTok{ trace}

\BuiltInTok{print}\NormalTok{(trace\_sum(}\DecValTok{5}\NormalTok{))}
\CommentTok{\# [(1, 1), (2, 3), (3, 6), (4, 10), (5, 15)]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-108}

\begin{itemize}
\tightlist
\item
  Turns hidden state changes into visible data
\item
  Ideal for debugging loops and verifying invariants
\item
  Supports algorithm teaching and step-by-step reasoning
\item
  Useful in profiling, logging, and unit testing
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-8}

An iterative algorithm is a sequence of deterministic transitions:

\[
S_{i+1} = f(S_i)
\]

Recording \(S_i\) at each iteration yields the complete trajectory of
execution. The trace table captures all intermediate states, ensuring
reproducibility and clarity, a form of operational proof.

\subsubsection{Try It Yourself}\label{try-it-yourself-108}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Trace variable updates in a multiplication loop.
\item
  Add condition checks (e.g.~early exits).
\item
  Record both pre- and post-update states.
\item
  Compare traces of iterative vs recursive versions.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-8}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Input \(n\) & Expected Trace \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
3 & {[}(1, 1), (2, 3), (3, 6){]} \\
4 & {[}(1, 1), (2, 3), (3, 6), (4, 10){]} \\
5 & {[}(1, 1), (2, 3), (3, 6), (4, 10), (5, 15){]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-16}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Tracing & \(O(n)\) & \(O(n)\) \\
\end{longtable}

An Iterative Process Tracer makes thinking visible, a loop's internal
rhythm laid out, step by step, until the final note resolves.

\subsection{10 Tower of Hanoi}\label{tower-of-hanoi}

The Tower of Hanoi is a legendary recursive puzzle that beautifully
illustrates how complex problems can be solved through simple repeated
structure. It's a timeless example of \emph{divide and conquer} thinking
in its purest form.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-9}

We want to move \(n\) disks from a source peg to a target peg, using one
auxiliary peg. Rules:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Move only one disk at a time.
\item
  Never place a larger disk on top of a smaller one.
\end{enumerate}

The challenge is to find the minimal sequence of moves that achieves
this.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-9}

The key insight: To move \(n\) disks, first move \(n-1\) disks aside,
move the largest one, then bring the smaller ones back.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Move \(n-1\) disks from source → auxiliary
\item
  Move the largest disk from source → target
\item
  Move \(n-1\) disks from auxiliary → target
\end{enumerate}

This recursive structure repeats until the smallest disk moves directly.

\subsubsection{Example Step by Step}\label{example-step-by-step-9}

For \(n = 3\), pegs: A (source), B (auxiliary), C (target)

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Move \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & A → C \\
2 & A → B \\
3 & C → B \\
4 & A → C \\
5 & B → A \\
6 & B → C \\
7 & A → C \\
\end{longtable}

Total moves: \(2^3 - 1 = 7\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-9}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ hanoi(n, source, target, aux):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{source}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\NormalTok{target}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{return}
\NormalTok{    hanoi(n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{, source, aux, target)}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{source}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\NormalTok{target}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    hanoi(n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{, aux, target, source)}

\NormalTok{hanoi(}\DecValTok{3}\NormalTok{, }\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-109}

\begin{itemize}
\tightlist
\item
  Classic recursive pattern: break → solve → combine
\item
  Demonstrates exponential growth (\(2^n - 1\) moves)
\item
  Trains recursive reasoning and stack visualization
\item
  Appears in algorithm analysis, recursion trees, and combinatorics
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-9}

Let \(T(n)\) be the number of moves for \(n\) disks. We must move
\(n-1\) disks twice and one largest disk once:

\[
T(n) = 2T(n-1) + 1, \quad T(1) = 1
\]

Solving the recurrence:

\[
T(n) = 2^n - 1
\]

Each recursive step preserves rules and reduces the problem size,
ensuring correctness by structural induction.

\subsubsection{Try It Yourself}\label{try-it-yourself-109}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Trace \(n = 2\) and \(n = 3\) by hand.
\item
  Count recursive calls.
\item
  Modify code to record moves in a list.
\item
  Extend to display peg states after each move.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-9}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
\(n\) & Expected Moves \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 \\
2 & 3 \\
3 & 7 \\
4 & 15 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-17}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Moves & \(O(2^n)\) & \(O(n)\) (recursion stack) \\
\end{longtable}

The Tower of Hanoi turns recursion into art, every move guided by
symmetry, every step revealing how simplicity builds complexity one disk
at a time.

\section{Section 2. Measuring time and
space}\label{section-2.-measuring-time-and-space}

\subsection{11 Counting Operations}\label{counting-operations}

Counting operations is the first step toward understanding time
complexity. It's the art of translating code into math by measuring how
many \emph{basic steps} an algorithm performs, helping us predict
performance before running it.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-10}

We want to estimate how long an algorithm takes, not by clock time, but
by how many fundamental operations it executes. Instead of relying on
hardware speed, we count abstract steps, comparisons, assignments,
additions, each treated as one unit of work.

This turns algorithms into analyzable formulas.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-10}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the unit step (like one comparison or addition).
\item
  Break the algorithm into lines or loops.
\item
  Count repetitions for each operation.
\item
  Sum all counts to get a total step function \(T(n)\).
\item
  Simplify to dominant terms for asymptotic analysis.
\end{enumerate}

We're not measuring \emph{seconds}, we're measuring \emph{structure}.

\subsubsection{Example Step by Step}\label{example-step-by-step-10}

Count operations for:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{sum} \OperatorTok{=} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
    \BuiltInTok{sum} \OperatorTok{+=}\NormalTok{ i}
\end{Highlighting}
\end{Shaded}

Breakdown:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Line & Operation & Count \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Initialization & 1 \\
2 & Loop comparison & \(n + 1\) \\
3 & Addition + assignment & \(n\) \\
\end{longtable}

Total: \[
T(n) = 1 + (n + 1) + n = 2n + 2
\]

Asymptotically: \[
T(n) = O(n)
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-10}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ count\_sum\_ops(n):}
\NormalTok{    ops }\OperatorTok{=} \DecValTok{0}
\NormalTok{    ops }\OperatorTok{+=} \DecValTok{1}  \CommentTok{\# init sum}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{        ops }\OperatorTok{+=} \DecValTok{1}  \CommentTok{\# loop check}
\NormalTok{        ops }\OperatorTok{+=} \DecValTok{1}  \CommentTok{\# sum += i}
\NormalTok{    ops }\OperatorTok{+=} \DecValTok{1}  \CommentTok{\# final loop check}
    \ControlFlowTok{return}\NormalTok{ ops}
\end{Highlighting}
\end{Shaded}

Test: \texttt{count\_sum\_ops(5)} → \texttt{13}

\subsubsection{Why It Matters}\label{why-it-matters-110}

\begin{itemize}
\tightlist
\item
  Builds intuition for algorithm growth
\item
  Reveals hidden costs (nested loops, recursion)
\item
  Foundation for Big-O and runtime proofs
\item
  Language-agnostic: works for any pseudocode
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-10}

Every program can be modeled as a finite sequence of operations
parameterized by input size \(n\). If \(f(n)\) counts these operations
exactly, then for large \(n\), growth rate \(\Theta(f(n))\) matches
actual performance up to constant factors. Counting operations therefore
predicts asymptotic runtime behavior.

\subsubsection{Try It Yourself}\label{try-it-yourself-110}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Count operations in a nested loop:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
    \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{        x }\OperatorTok{+=} \DecValTok{1}
\end{Highlighting}
\end{Shaded}
\item
  Derive \(T(n) = n^2 + 2n + 1\).
\item
  Simplify to \(O(n^2)\).
\item
  Compare iterative vs recursive counting.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-10}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Step Function & Big-O \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Loop & \(2n + 2\) & \(O(n)\) \\
Nested Loop & \(n^2 + 2n + 1\) & \(O(n^2)\) \\
Constant Work & \(c\) & \(O(1)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-18}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Counting Steps & \(O(1)\) (analysis) & \(O(1)\) \\
\end{longtable}

Counting operations transforms code into mathematics, a microscope for
understanding how loops, branches, and recursion scale with input size.

\subsection{12 Loop Analysis}\label{loop-analysis}

Loop analysis is the key to unlocking how algorithms grow, it tells us
how many times a loop runs and, therefore, how many operations are
performed. Every time you see a loop, you're looking at a formula in
disguise.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-11}

We want to determine how many iterations a loop executes as a function
of input size \(n\). This helps us estimate total runtime before
measuring it empirically.

Whether a loop is linear, nested, logarithmic, or mixed, understanding
its iteration count reveals the algorithm's true complexity.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-11}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the loop variable (like \texttt{i} in
  \texttt{for\ i\ in\ range(...)}).
\item
  Find its update rule, additive (\texttt{i\ +=\ 1}) or multiplicative
  (\texttt{i\ *=\ 2}).
\item
  Solve for how many times the condition holds true.
\item
  Multiply by inner loop work if nested.
\item
  Sum all contributions from independent loops.
\end{enumerate}

This transforms loops into algebraic expressions you can reason about.

\subsubsection{Example Step by Step}\label{example-step-by-step-11}

Example 1: Linear Loop

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{    work()}
\end{Highlighting}
\end{Shaded}

\(i\) runs from \(1\) to \(n\), incrementing by \(1\). Iterations: \(n\)
Work: \(O(n)\)

Example 2: Logarithmic Loop

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i }\OperatorTok{=} \DecValTok{1}
\ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n:}
\NormalTok{    work()}
\NormalTok{    i }\OperatorTok{*=} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\(i\) doubles each step: \(1, 2, 4, 8, \dots, n\) Iterations:
\(\log_2 n + 1\) Work: \(O(\log n)\)

Example 3: Nested Loop

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
    \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{        work()}
\end{Highlighting}
\end{Shaded}

Outer loop: \(n\) Inner loop: \(n\) Total work: \(n \times n = n^2\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-11}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ linear\_loop(n):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{        count }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ count  }\CommentTok{\# n}

\KeywordTok{def}\NormalTok{ log\_loop(n):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
\NormalTok{    i }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}=}\NormalTok{ n:}
\NormalTok{        count }\OperatorTok{+=} \DecValTok{1}
\NormalTok{        i }\OperatorTok{*=} \DecValTok{2}
    \ControlFlowTok{return}\NormalTok{ count  }\CommentTok{\# ≈ log2(n)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-111}

\begin{itemize}
\tightlist
\item
  Reveals complexity hidden inside loops
\item
  Core tool for deriving \(O(n)\), \(O(\log n)\), and \(O(n^2)\)
\item
  Makes asymptotic behavior predictable and measurable
\item
  Works for for-loops, while-loops, and nested structures
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-11}

Each loop iteration corresponds to a true condition in its guard. If the
loop variable \(i\) evolves monotonically (by addition or
multiplication), the total number of iterations is the smallest \(k\)
satisfying the exit condition.

For additive updates: \[
i_0 + k \cdot \Delta \ge n \implies k = \frac{n - i_0}{\Delta}
\]

For multiplicative updates: \[
i_0 \cdot r^k \ge n \implies k = \log_r \frac{n}{i_0}
\]

\subsubsection{Try It Yourself}\label{try-it-yourself-111}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Analyze loop:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i }\OperatorTok{=}\NormalTok{ n}
\ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{    i }\OperatorTok{//=} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

  → \(O(\log n)\)
\item
  Analyze double loop:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
    \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(i):}
\NormalTok{        work()}
\end{Highlighting}
\end{Shaded}

  → \(\frac{n(n-1)}{2} = O(n^2)\)
\item
  Combine additive + multiplicative loops.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-11}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5672}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2687}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1642}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Code Pattern
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Iterations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{for\ i\ in\ range(n)} & \(n\) & \(O(n)\) \\
\texttt{while\ i\ \textless{}\ n:\ i\ *=\ 2} & \(\log_2 n\) &
\(O(\log n)\) \\
\texttt{for\ i\ in\ range(n):\ for\ j\ in\ range(n)} & \(n^2\) &
\(O(n^2)\) \\
\texttt{for\ i\ in\ range(n):\ for\ j\ in\ range(i)} &
\(\frac{n(n-1)}{2}\) & \(O(n^2)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-19}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Loop Analysis & \(O(1)\) (per loop) & \(O(1)\) \\
\end{longtable}

Loop analysis turns repetition into arithmetic, every iteration becomes
a term, every loop a story in the language of growth.

\subsection{13 Recurrence Expansion}\label{recurrence-expansion}

Recurrence expansion is how we \emph{unfold} recursive definitions to
see their true cost. Many recursive algorithms (like Merge Sort or Quick
Sort) define runtime in terms of smaller copies of themselves. By
expanding the recurrence, we reveal the total work step by step.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-12}

Recursive algorithms often express their runtime as:

\[
T(n) = a \cdot T!\left(\frac{n}{b}\right) + f(n)
\]

Here:

\begin{itemize}
\tightlist
\item
  \(a\) = number of recursive calls
\item
  \(b\) = factor by which input size is reduced
\item
  \(f(n)\) = work done outside recursion (splitting, merging, etc.)
\end{itemize}

We want to estimate \(T(n)\) by expanding this relation until the base
case.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-12}

Think of recurrence expansion as peeling an onion. Each recursive layer
contributes some cost, and we add all layers until the base.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the recurrence.
\item
  Expand one level: replace \(T(\cdot)\) with its formula.
\item
  Repeat until the argument becomes the base case.
\item
  Sum the work done at each level.
\item
  Simplify the sum to get asymptotic form.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-12}

Take Merge Sort:

\[
T(n) = 2T!\left(\frac{n}{2}\right) + n
\]

Expand:

\begin{itemize}
\tightlist
\item
  Level 0: \(T(n) = 2T(n/2) + n\)
\item
  Level 1: \(T(n/2) = 2T(n/4) + n/2\) → Substitute
  \(T(n) = 4T(n/4) + 2n\)
\item
  Level 2: \(T(n) = 8T(n/8) + 3n\)
\item
  \ldots{}
\item
  Level \(\log_2 n\): \(T(1) = c\)
\end{itemize}

Sum work across levels:

\[
T(n) = n \log_2 n + n = O(n \log n)
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-12}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ recurrence\_expand(a, b, f, n, base}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{    level }\OperatorTok{=} \DecValTok{0}
\NormalTok{    total }\OperatorTok{=} \DecValTok{0}
\NormalTok{    size }\OperatorTok{=}\NormalTok{ n}
    \ControlFlowTok{while}\NormalTok{ size }\OperatorTok{\textgreater{}=}\NormalTok{ base:}
\NormalTok{        cost }\OperatorTok{=}\NormalTok{ (a  level) }\OperatorTok{*}\NormalTok{ f(size)}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ cost}
\NormalTok{        size }\OperatorTok{//=}\NormalTok{ b}
\NormalTok{        level }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ total}
\end{Highlighting}
\end{Shaded}

Use \texttt{f\ =\ lambda\ x:\ x} for Merge Sort.

\subsubsection{Why It Matters}\label{why-it-matters-112}

\begin{itemize}
\tightlist
\item
  Core tool for analyzing recursive algorithms
\item
  Builds intuition before applying the Master Theorem
\item
  Turns abstract recurrence into tangible pattern
\item
  Helps visualize total work per recursion level
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-12}

At level \(i\):

\begin{itemize}
\tightlist
\item
  There are \(a^i\) subproblems.
\item
  Each subproblem has size \(\frac{n}{b^i}\).
\item
  Work per level: \(a^i \cdot f!\left(\frac{n}{b^i}\right)\)
\end{itemize}

Total cost:

\[
T(n) = \sum_{i=0}^{\log_b n} a^i f!\left(\frac{n}{b^i}\right)
\]

Depending on how \(f(n)\) compares to \(n^{\log_b a}\), either top,
bottom, or middle levels dominate.

\subsubsection{Try It Yourself}\label{try-it-yourself-112}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Expand \(T(n) = 3T(n/2) + n^2\).
\item
  Expand \(T(n) = T(n/2) + 1\).
\item
  Visualize total work per level.
\item
  Check your result with Master Theorem.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-12}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Recurrence & Expansion Result & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n) = 2T(n/2) + n\) & \(n \log n\) & \(O(n \log n)\) \\
\(T(n) = T(n/2) + 1\) & \(\log n\) & \(O(\log n)\) \\
\(T(n) = 4T(n/2) + n\) & \(n^2\) & \(O(n^2)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-20}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expansion & \(O(\log n)\) levels & \(O(\log n)\) tree depth \\
\end{longtable}

Recurrence expansion turns recursion into rhythm, each level adding its
verse, the sum revealing the melody of the algorithm's growth.

\subsection{14 Amortized Analysis}\label{amortized-analysis}

Amortized analysis looks beyond the worst case of individual operations
to capture the \emph{average cost per operation} over a long sequence.
It tells us when ``expensive'' actions even out, revealing algorithms
that are faster than they first appear.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-13}

Some operations occasionally take a long time (like resizing an array),
but most are cheap. A naive worst-case analysis exaggerates total cost.
Amortized analysis finds the true average cost across a sequence.

We're not averaging across \emph{inputs}, but across \emph{operations in
one run}.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-13}

Suppose an operation is usually \(O(1)\), but sometimes \(O(n)\). If
that expensive case happens rarely enough, the \emph{average per
operation} is still small.

Three main methods:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Aggregate method, total cost ÷ number of operations
\item
  Accounting method, charge extra for cheap ops, save credit for costly
  ones
\item
  Potential method, define potential energy (stored work) and track
  change
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-13}

Dynamic Array Resizing

When an array is full, double its size and copy elements.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Cost & Comment \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert \#1--\#1 & 1 & insert directly \\
Insert \#2 & 2 & resize to 2, copy 1 \\
Insert \#3 & 3 & resize to 4, copy 2 \\
Insert \#5 & 5 & resize to 8, copy 4 \\
\ldots{} & \ldots{} & \ldots{} \\
\end{longtable}

Total cost after \(n\) inserts ≈ \(2n\) Average cost = \(2n / n = O(1)\)
So each insert is amortized \(O(1)\), not \(O(n)\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-13}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ dynamic\_array(n):}
\NormalTok{    arr }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    capacity }\OperatorTok{=} \DecValTok{1}
\NormalTok{    cost }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{==}\NormalTok{ capacity:}
\NormalTok{            capacity }\OperatorTok{*=} \DecValTok{2}
\NormalTok{            cost }\OperatorTok{+=} \BuiltInTok{len}\NormalTok{(arr)  }\CommentTok{\# copying cost}
\NormalTok{        arr.append(i)}
\NormalTok{        cost }\OperatorTok{+=} \DecValTok{1}  \CommentTok{\# insert cost}
    \ControlFlowTok{return}\NormalTok{ cost, cost }\OperatorTok{/}\NormalTok{ n  }\CommentTok{\# total, amortized average}
\end{Highlighting}
\end{Shaded}

Try \texttt{dynamic\_array(10)} → roughly total cost ≈ 20, average ≈ 2.

\subsubsection{Why It Matters}\label{why-it-matters-113}

\begin{itemize}
\tightlist
\item
  Shows average efficiency over sequences
\item
  Key to analyzing stacks, queues, hash tables, and dynamic arrays
\item
  Explains why ``occasionally expensive'' operations are still efficient
  overall
\item
  Separates perception (worst-case) from reality (aggregate behavior)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-13}

Let \(C_i\) = cost of \(i\)th operation, and \(n\) = total operations.

Aggregate Method:

\[
\text{Amortized cost} = \frac{\sum_{i=1}^n C_i}{n}
\]

If \(\sum C_i = O(n)\), each operation's average = \(O(1)\).

Potential Method:

Define potential \(\Phi_i\) representing saved work. Amortized cost =
\(C_i + \Phi_i - \Phi_{i-1}\) Summing over all operations telescopes
potential away, leaving total cost bounded by initial + final potential.

\subsubsection{Try It Yourself}\label{try-it-yourself-113}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Analyze amortized cost for stack with occasional full pop.
\item
  Use accounting method to assign ``credits'' to inserts.
\item
  Show \(O(1)\) amortized insert in hash table with resizing.
\item
  Compare amortized vs worst-case time.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-13}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation Type & Worst Case & Amortized \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Array Insert (Doubling) & \(O(n)\) & \(O(1)\) \\
Stack Push & \(O(1)\) & \(O(1)\) \\
Queue Dequeue (2-stack) & \(O(n)\) & \(O(1)\) \\
Union-Find (Path Compression) & \(O(\log n)\) & \(O(\alpha(n))\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-21}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Analysis Type & Formula & Goal \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Aggregate & \(\frac{\text{Total Cost}}{n}\) & Simplicity \\
Accounting & Assign credits & Intuition \\
Potential & \(\Delta \Phi\) & Formal rigor \\
\end{longtable}

Amortized analysis reveals the calm beneath chaos --- a few storms don't
define the weather, and one \(O(n)\) moment doesn't ruin \(O(1)\)
harmony.

\subsection{15 Space Counting}\label{space-counting}

Space counting is the spatial twin of operation counting, instead of
measuring time, we measure how much \emph{memory} an algorithm consumes.
Every variable, array, stack frame, or temporary buffer adds to the
footprint. Understanding it helps us write programs that fit in memory
and scale gracefully.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-14}

We want to estimate the space complexity of an algorithm --- how much
memory it needs as input size \(n\) grows.

This includes:

\begin{itemize}
\tightlist
\item
  Static space (fixed variables)
\item
  Dynamic space (arrays, recursion, data structures)
\item
  Auxiliary space (extra working memory beyond input)
\end{itemize}

Our goal: express total memory as a function \(S(n)\).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-14}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count primitive variables (constants, counters, pointers). → constant
  space \(O(1)\)
\item
  Add data structure sizes (arrays, lists, matrices). → often
  proportional to \(n\), \(n^2\), etc.
\item
  Add recursion stack depth, if applicable.
\item
  Ignore constants for asymptotic space, focus on growth.
\end{enumerate}

In the end, \[
S(n) = S_{\text{static}} + S_{\text{dynamic}} + S_{\text{recursive}}
\]

\subsubsection{Example Step by Step}\label{example-step-by-step-14}

Example 1: Linear Array

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arr }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \(n\) integers → \(O(n)\) space
\end{itemize}

Example 2: 2D Matrix

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{matrix }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ n }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  \(n \times n\) elements → \(O(n^2)\) space
\end{itemize}

Example 3: Recursive Factorial

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fact(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ n }\OperatorTok{*}\NormalTok{ fact(n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Depth = \(n\) → Stack = \(O(n)\)
\item
  No extra data structures → \(S(n) = O(n)\)
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-14}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ space\_counter(n):}
\NormalTok{    const }\OperatorTok{=} \DecValTok{1}             \CommentTok{\# O(1)}
\NormalTok{    arr }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ n         }\CommentTok{\# O(n)}
\NormalTok{    matrix }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\NormalTok{n }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]  }\CommentTok{\# O(n\^{}2)}
    \ControlFlowTok{return}\NormalTok{ const }\OperatorTok{+} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{+} \BuiltInTok{len}\NormalTok{(matrix)}
\end{Highlighting}
\end{Shaded}

This simple example illustrates additive contributions.

\subsubsection{Why It Matters}\label{why-it-matters-114}

\begin{itemize}
\tightlist
\item
  Memory is a first-class constraint in large systems
\item
  Critical for embedded, streaming, and real-time algorithms
\item
  Reveals tradeoffs between time and space
\item
  Guides design of in-place vs out-of-place solutions
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-14}

Each algorithm manipulates a finite set of data elements. If \(s_i\) is
the space allocated for structure \(i\), total space is:

\[
S(n) = \sum_i s_i(n)
\]

Asymptotic space is dominated by the largest term, so
\(S(n) = \Theta(\max_i s_i(n))\).

This ensures our analysis scales with data growth.

\subsubsection{Try It Yourself}\label{try-it-yourself-114}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count space for Merge Sort (temporary arrays).
\item
  Compare with Quick Sort (in-place).
\item
  Add recursion cost explicitly.
\item
  Analyze time--space tradeoff for dynamic programming.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-14}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Space & Reason \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & \(O(1)\) & Constant extra memory \\
Merge Sort & \(O(n)\) & Extra array for merging \\
Quick Sort & \(O(\log n)\) & Stack depth \\
DP Table (2D) & \(O(n^2)\) & Full grid of states \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-22}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Component & Example & Cost \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Variables & \(a, b, c\) & \(O(1)\) \\
Arrays & \texttt{arr{[}n{]}} & \(O(n)\) \\
Matrices & \texttt{matrix{[}n{]}{[}n{]}} & \(O(n^2)\) \\
Recursion Stack & Depth \(n\) & \(O(n)\) \\
\end{longtable}

Space counting turns memory into a measurable quantity, every variable a
footprint, every structure a surface, every stack frame a layer in the
architecture of an algorithm.

\subsection{16 Memory Footprint
Estimator}\label{memory-footprint-estimator}

A Memory Footprint Estimator calculates how much memory an algorithm or
data structure truly consumes, not just asymptotically, but in
\emph{real bytes}. It bridges the gap between theoretical space
complexity and practical implementation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-15}

Knowing an algorithm is \(O(n)\) in space isn't enough when working
close to memory limits. We need actual estimates: how many bytes per
element, how much total allocation, and what overheads exist.

A footprint estimator converts theoretical counts into quantitative
estimates for real-world scaling.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-15}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Identify data types used: \texttt{int}, \texttt{float},
  \texttt{pointer}, \texttt{struct}, etc.
\item
  Estimate size per element (language dependent,
  e.g.~\texttt{int\ =\ 4\ bytes}).
\item
  Multiply by count to find total memory usage.
\item
  Include overheads from:

  \begin{itemize}
  \tightlist
  \item
    Object headers or metadata
  \item
    Padding or alignment
  \item
    Pointers or references
  \end{itemize}
\end{enumerate}

Final footprint: \[
\text{Memory} = \sum_i (\text{count}_i \times \text{size}_i) + \text{overhead}
\]

\subsubsection{Example Step by Step}\label{example-step-by-step-15}

Suppose we have a list of \(n = 1{,}000{,}000\) integers in Python.

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Component & Size (Bytes) & Count & Total \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
List object & 64 & 1 & 64 \\
Pointers & 8 & 1,000,000 & 8,000,000 \\
Integer objects & 28 & 1,000,000 & 28,000,000 \\
\end{longtable}

Total ≈ 36 MB (plus interpreter overhead).

If using a fixed \texttt{array(\textquotesingle{}i\textquotesingle{})}
(C-style ints): \(4 \text{ bytes} \times 10^6 = 4\) MB, far more
memory-efficient.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-15}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sys}

\NormalTok{n }\OperatorTok{=} \DecValTok{1\_000\_000}
\NormalTok{arr\_list }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(n))}
\NormalTok{arr\_array }\OperatorTok{=} \BuiltInTok{bytearray}\NormalTok{(n }\OperatorTok{*} \DecValTok{4}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(sys.getsizeof(arr\_list))   }\CommentTok{\# list object}
\BuiltInTok{print}\NormalTok{(sys.getsizeof(arr\_array))  }\CommentTok{\# raw byte array}
\end{Highlighting}
\end{Shaded}

Compare memory cost using \texttt{sys.getsizeof()}.

\subsubsection{Why It Matters}\label{why-it-matters-115}

\begin{itemize}
\tightlist
\item
  Reveals true memory requirements
\item
  Critical for large datasets, embedded systems, and databases
\item
  Explains performance tradeoffs in languages with object overhead
\item
  Supports system design and capacity planning
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-15}

Each variable or element consumes a fixed number of bytes depending on
type. If \(n_i\) elements of type \(t_i\) are allocated, total memory
is:

\[
M(n) = \sum_i n_i \cdot s(t_i)
\]

Since \(s(t_i)\) is constant, growth rate follows counts:
\(M(n) = O(\max_i n_i)\), matching asymptotic analysis while giving
concrete magnitudes.

\subsubsection{Try It Yourself}\label{try-it-yourself-115}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate memory for a matrix of \(1000 \times 1000\) floats (8 bytes
  each).
\item
  Compare Python list of lists vs NumPy array.
\item
  Add overheads for pointers and headers.
\item
  Repeat for custom \texttt{struct} or class with multiple fields.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-15}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4127}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2381}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3492}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Structure
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Approx Memory
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
List of \(n\) ints & \(n \times 28\) B & 28 MB (1M items) \\
Array of \(n\) ints & \(n \times 4\) B & 4 MB \\
Matrix \(n \times n\) floats & \(8n^2\) B & 8 MB for \(n=1000\) \\
Hash Table \(n\) entries & \(O(n)\) & Depends on load factor \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-23}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Metric & Growth & Unit \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Space & \(O(n)\) & Bytes \\
Overhead & \(O(1)\) & Metadata \\
\end{longtable}

A Memory Footprint Estimator turns abstract ``\(O(n)\) space'' into
tangible bytes, letting you \emph{see} how close you are to the edge
before your program runs out of room.

\subsection{17 Time Complexity Table}\label{time-complexity-table}

A Time Complexity Table summarizes how different algorithms grow as
input size increases, it's a map from formula to feeling, showing which
complexities are fast, which are dangerous, and how they compare in
scale.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-16}

We want a quick reference that links mathematical growth rates to
practical performance. Knowing that an algorithm is \(O(n \log n)\) is
good; understanding what that \emph{means} for \(n = 10^6\) is better.

The table helps estimate feasibility: Can this algorithm handle a
million inputs? A billion?

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-16}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  List common complexity classes: constant, logarithmic, linear, etc.
\item
  Write their formulas and interpretations.
\item
  Estimate operations for various \(n\).
\item
  Highlight tipping points, where performance becomes infeasible.
\end{enumerate}

This creates an \emph{intuition grid} for algorithmic growth.

\subsubsection{Example Step by Step}\label{example-step-by-step-16}

Let \(n = 10^6\) (1 million). Estimate operations per complexity class
(approximate scale):

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1733}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1867}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formula
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Operations (n=10⁶)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Intuition
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(O(1)\) & constant & 1 & instant \\
\(O(\log n)\) & \(\log_2 10^6 \approx 20\) & 20 & lightning fast \\
\(O(n)\) & \(10^6\) & 1,000,000 & manageable \\
\(O(n \log n)\) & \(10^6 \cdot 20\) & 20M & still OK \\
\(O(n^2)\) & \((10^6)^2\) & \(10^{12}\) & too slow \\
\(O(2^n)\) & \(2^{20} \approx 10^6\) & impossible beyond \(n=30\) & \\
\(O(n!)\) & factorial & \(10^6!\) & absurdly huge \\
\end{longtable}

The table makes complexity feel \emph{real}.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-16}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ ops\_estimate(n):}
    \ControlFlowTok{return}\NormalTok{ \{}
        \StringTok{"O(1)"}\NormalTok{: }\DecValTok{1}\NormalTok{,}
        \StringTok{"O(log n)"}\NormalTok{: math.log2(n),}
        \StringTok{"O(n)"}\NormalTok{: n,}
        \StringTok{"O(n log n)"}\NormalTok{: n }\OperatorTok{*}\NormalTok{ math.log2(n),}
        \StringTok{"O(n\^{}2)"}\NormalTok{: n2}
\NormalTok{    \}}

\BuiltInTok{print}\NormalTok{(ops\_estimate(}\DecValTok{106}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-116}

\begin{itemize}
\tightlist
\item
  Builds \emph{numerical intuition} for asymptotics
\item
  Helps choose the right algorithm for large \(n\)
\item
  Explains why \(O(n^2)\) might work for \(n=1000\) but not \(n=10^6\)
\item
  Connects abstract math to real-world feasibility
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-16}

Each complexity class describes a function \(f(n)\) bounding operations.
Comparing \(f(n)\) for common \(n\) values illustrates relative growth
rates. Because asymptotic notation suppresses constants, differences in
growth dominate as \(n\) grows.

Thus, numerical examples are faithful approximations of asymptotic
behavior.

\subsubsection{Try It Yourself}\label{try-it-yourself-116}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fill the table for \(n = 10^3, 10^4, 10^6\).
\item
  Plot growth curves for each \(f(n)\).
\item
  Compare runtime if each operation = 1 microsecond.
\item
  Identify feasible vs infeasible complexities for your hardware.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-16}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
\(n\) & \(O(1)\) & \(O(\log n)\) & \(O(n)\) & \(O(n^2)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(10^3\) & 1 & 10 & 1,000 & 1,000,000 \\
\(10^6\) & 1 & 20 & 1,000,000 & \(10^{12}\) \\
\(10^9\) & 1 & 30 & 1,000,000,000 & \(10^{18}\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-24}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Type & Insight \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Table Generation & \(O(1)\) & Static reference \\
Evaluation & \(O(1)\) & Analytical \\
\end{longtable}

A Time Complexity Table turns abstract Big-O notation into a living
chart, where \(O(\log n)\) feels tiny, \(O(n^2)\) feels heavy, and
\(O(2^n)\) feels impossible.

\subsection{18 Space--Time Tradeoff
Explorer}\label{spacetime-tradeoff-explorer}

A Space--Time Tradeoff Explorer helps us understand one of the most
fundamental balances in algorithm design: using more memory to gain
speed, or saving memory at the cost of time. It's the art of finding
equilibrium between storage and computation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-17}

We often face a choice:

\begin{itemize}
\tightlist
\item
  Precompute and store results for instant access (more space, less
  time)
\item
  Compute on demand to save memory (less space, more time)
\end{itemize}

The goal is to analyze both sides and choose the best fit for the
problem's constraints.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-17}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify repeated computations that can be stored.
\item
  Estimate memory cost of storing precomputed data.
\item
  Estimate time saved per query or reuse.
\item
  Compare tradeoffs using total cost models: \[
  \text{Total Cost} = \text{Time Cost} + \lambda \cdot \text{Space Cost}
  \] where \(\lambda\) reflects system priorities.
\item
  Decide whether caching, tabulation, or recomputation is preferable.
\end{enumerate}

You're tuning performance with two dials, one for memory, one for time.

\subsubsection{Example Step by Step}\label{example-step-by-step-17}

Example 1: Fibonacci Numbers

\begin{itemize}
\tightlist
\item
  Recursive (no memory): \(O(2^n)\) time, \(O(1)\) space
\item
  Memoized: \(O(n)\) time, \(O(n)\) space
\item
  Iterative (tabulated): \(O(n)\) time, \(O(1)\) space (store only last
  two)
\end{itemize}

Different tradeoffs for the same problem.

Example 2: Lookup Tables

Suppose you need \(\sin(x)\) for many \(x\) values:

\begin{itemize}
\tightlist
\item
  Compute each time → \(O(n)\) per query
\item
  Store all results → \(O(n)\) memory, \(O(1)\) lookup
\item
  Hybrid: store sampled points, interpolate → balance
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-17}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib\_naive(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ n}
    \ControlFlowTok{return}\NormalTok{ fib\_naive(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ fib\_naive(n}\OperatorTok{{-}}\DecValTok{2}\NormalTok{)}

\KeywordTok{def}\NormalTok{ fib\_memo(n, memo}\OperatorTok{=}\NormalTok{\{\}):}
    \ControlFlowTok{if}\NormalTok{ n }\KeywordTok{in}\NormalTok{ memo: }\ControlFlowTok{return}\NormalTok{ memo[n]}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ n}
\NormalTok{    memo[n] }\OperatorTok{=}\NormalTok{ fib\_memo(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, memo) }\OperatorTok{+}\NormalTok{ fib\_memo(n}\OperatorTok{{-}}\DecValTok{2}\NormalTok{, memo)}
    \ControlFlowTok{return}\NormalTok{ memo[n]}
\end{Highlighting}
\end{Shaded}

Compare time vs memory for each version.

\subsubsection{Why It Matters}\label{why-it-matters-117}

\begin{itemize}
\tightlist
\item
  Helps design algorithms under memory limits or real-time constraints
\item
  Essential in databases, graphics, compilers, and AI caching
\item
  Connects theory (asymptotics) to engineering (resources)
\item
  Promotes thinking in trade curves, not absolutes
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-17}

Let \(T(n)\) = time, \(S(n)\) = space. If we precompute \(k\) results,
\[
T'(n) = T(n) - \Delta T, \quad S'(n) = S(n) + \Delta S
\]

Since \(\Delta T\) and \(\Delta S\) are usually monotonic, minimizing
one increases the other. Thus, the optimal configuration lies where \[
\frac{dT}{dS} = -\lambda
\] reflecting the system's valuation of time vs memory.

\subsubsection{Try It Yourself}\label{try-it-yourself-117}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare naive vs memoized vs iterative Fibonacci.
\item
  Build a lookup table for factorials modulo \(M\).
\item
  Explore DP tabulation (space-heavy) vs rolling array (space-light).
\item
  Evaluate caching in a recursive tree traversal.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-17}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & Space & Time & Strategy \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fibonacci & \(O(1)\) & \(O(2^n)\) & Naive recursion \\
Fibonacci & \(O(n)\) & \(O(n)\) & Memoization \\
Fibonacci & \(O(1)\) & \(O(n)\) & Iterative \\
Lookup Table & \(O(n)\) & \(O(1)\) & Precompute \\
Recompute & \(O(1)\) & \(O(n)\) & On-demand \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-25}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Dimension & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Space--Time Analysis & \(O(1)\) & Conceptual \\
Optimization & \(O(1)\) & Tradeoff curve \\
\end{longtable}

A Space--Time Tradeoff Explorer turns resource limits into creative
levers, helping you choose when to remember, when to recompute, and when
to balance both in harmony.

\subsection{19 Profiling Algorithm}\label{profiling-algorithm}

Profiling an algorithm means measuring how it \emph{actually behaves},
how long it runs, how much memory it uses, how often loops iterate, and
where time is really spent. It turns theoretical complexity into real
performance data.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-18}

Big-O tells us how an algorithm scales, but not how it \emph{performs in
practice}. Constant factors, system load, compiler optimizations, and
cache effects all matter.

Profiling answers:

\begin{itemize}
\tightlist
\item
  Where is the time going?
\item
  Which function dominates?
\item
  Are we bound by CPU, memory, or I/O?
\end{itemize}

It's the microscope for runtime behavior.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-18}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Instrument your code, insert timers, counters, or use built-in
  profilers.
\item
  Run with representative inputs.
\item
  Record runtime, call counts, and memory allocations.
\item
  Analyze hotspots, the 10\% of code causing 90\% of cost.
\item
  Optimize only where it matters.
\end{enumerate}

Profiling doesn't guess, it measures.

\subsubsection{Example Step by Step}\label{example-step-by-step-18}

\subsubsection{Example 1: Timing a
Function}\label{example-1-timing-a-function}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ time}

\NormalTok{start }\OperatorTok{=}\NormalTok{ time.perf\_counter()}
\NormalTok{result }\OperatorTok{=}\NormalTok{ algorithm(n)}
\NormalTok{end }\OperatorTok{=}\NormalTok{ time.perf\_counter()}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Elapsed:"}\NormalTok{, end }\OperatorTok{{-}}\NormalTok{ start)}
\end{Highlighting}
\end{Shaded}

Measure total runtime for a given input size.

\subsubsection{Example 2: Line-Level
Profiling}\label{example-2-line-level-profiling}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ cProfile, pstats}

\NormalTok{cProfile.run(}\StringTok{\textquotesingle{}algorithm(1000)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}stats\textquotesingle{}}\NormalTok{)}
\NormalTok{p }\OperatorTok{=}\NormalTok{ pstats.Stats(}\StringTok{\textquotesingle{}stats\textquotesingle{}}\NormalTok{)}
\NormalTok{p.sort\_stats(}\StringTok{\textquotesingle{}cumtime\textquotesingle{}}\NormalTok{).print\_stats(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Shows the 10 most time-consuming functions.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-18}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ slow\_sum(n):}
\NormalTok{    s }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(i):}
\NormalTok{            s }\OperatorTok{+=}\NormalTok{ j}
    \ControlFlowTok{return}\NormalTok{ s}

\ImportTok{import}\NormalTok{ cProfile}
\NormalTok{cProfile.run(}\StringTok{\textquotesingle{}slow\_sum(500)\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Output lists functions, calls, total time, and cumulative time.

\subsubsection{Why It Matters}\label{why-it-matters-118}

\begin{itemize}
\tightlist
\item
  Bridges theory (Big-O) and practice (runtime)
\item
  Identifies bottlenecks for optimization
\item
  Validates expected scaling across inputs
\item
  Prevents premature optimization, measure first, fix later
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-18}

Every algorithm execution is a trace of operations. Profiling samples or
counts these operations in real time.

If \(t_i\) is time spent in component \(i\), then total runtime
\(T = \sum_i t_i\). Ranking \(t_i\) reveals the dominant terms
empirically, confirming or refuting theoretical assumptions.

\subsubsection{Try It Yourself}\label{try-it-yourself-118}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Profile a recursive function (like Fibonacci).
\item
  Compare iterative vs recursive runtimes.
\item
  Plot \(n\) vs runtime to visualize empirical complexity.
\item
  Use \texttt{memory\_profiler} to capture space usage.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-18}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1648}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4176}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2747}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Expected
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Observed (example)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & \(O(n)\) & runtime ∝ \(n\) & scales linearly \\
Merge Sort & \(O(n \log n)\) & runtime grows slightly faster than \(n\)
& merge overhead \\
Naive Fibonacci & \(O(2^n)\) & explodes at \(n>30\) & confirms
exponential cost \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-26}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Profiling Run & \(O(n)\) (per trial) & \(O(1)\) \\
Report Generation & \(O(f)\) (per function) & \(O(f)\) \\
\end{longtable}

Profiling is where math meets the stopwatch, transforming asymptotic
guesses into concrete numbers and revealing the true heartbeat of your
algorithm.

\subsection{20 Benchmarking Framework}\label{benchmarking-framework}

A Benchmarking Framework provides a structured way to compare algorithms
under identical conditions. It measures performance across input sizes,
multiple trials, and varying hardware, revealing which implementation
truly performs best in practice.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-19}

You've got several algorithms solving the same problem --- which one is
\emph{actually faster}? Which scales better? Which uses less memory?

Benchmarking answers these questions with fair, repeatable experiments
instead of intuition or isolated timing tests.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-19}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define test cases (input sizes, data patterns).
\item
  Run all candidate algorithms under the same conditions.
\item
  Repeat trials to reduce noise.
\item
  Record metrics:

  \begin{itemize}
  \tightlist
  \item
    Runtime
  \item
    Memory usage
  \item
    Throughput or latency
  \end{itemize}
\item
  Aggregate results and visualize trends.
\end{enumerate}

Think of it as a ``tournament'' where each algorithm plays by the same
rules.

\subsubsection{Example Step by Step}\label{example-step-by-step-19}

Suppose we want to benchmark sorting methods:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Inputs: random arrays of sizes \(10^3\), \(10^4\), \(10^5\)
\item
  Algorithms: \texttt{bubble\_sort}, \texttt{merge\_sort},
  \texttt{timsort}
\item
  Metric: average runtime over 5 runs
\item
  Result: table or plot
\end{enumerate}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Size & Bubble Sort & Merge Sort & Timsort \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(10^3\) & 0.05s & 0.001s & 0.0008s \\
\(10^4\) & 5.4s & 0.02s & 0.012s \\
\(10^5\) & -- & 0.25s & 0.15s \\
\end{longtable}

Timsort wins across all sizes, data confirms theory.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-19}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ timeit}
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ bench(func, n, trials}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ [random.randint(}\DecValTok{0}\NormalTok{, n) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}
    \ControlFlowTok{return} \BuiltInTok{min}\NormalTok{(timeit.repeat(}\KeywordTok{lambda}\NormalTok{: func(data.copy()), number}\OperatorTok{=}\DecValTok{1}\NormalTok{, repeat}\OperatorTok{=}\NormalTok{trials))}

\KeywordTok{def}\NormalTok{ bubble\_sort(arr):}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(arr)):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(arr)}\OperatorTok{{-}}\DecValTok{1}\NormalTok{):}
            \ControlFlowTok{if}\NormalTok{ arr[j] }\OperatorTok{\textgreater{}}\NormalTok{ arr[j}\OperatorTok{+}\DecValTok{1}\NormalTok{]:}
\NormalTok{                arr[j], arr[j}\OperatorTok{+}\DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ arr[j}\OperatorTok{+}\DecValTok{1}\NormalTok{], arr[j]}

\KeywordTok{def}\NormalTok{ merge\_sort(arr):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ arr}
\NormalTok{    mid }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}\OperatorTok{//}\DecValTok{2}
    \ControlFlowTok{return}\NormalTok{ merge(merge\_sort(arr[:mid]), merge\_sort(arr[mid:]))}

\KeywordTok{def}\NormalTok{ merge(left, right):}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{while}\NormalTok{ left }\KeywordTok{and}\NormalTok{ right:}
\NormalTok{        result.append(left.pop(}\DecValTok{0}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ left[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ right[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{else}\NormalTok{ right.pop(}\DecValTok{0}\NormalTok{))}
    \ControlFlowTok{return}\NormalTok{ result }\OperatorTok{+}\NormalTok{ left }\OperatorTok{+}\NormalTok{ right}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Bubble:"}\NormalTok{, bench(bubble\_sort, }\DecValTok{1000}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Merge:"}\NormalTok{, bench(merge\_sort, }\DecValTok{1000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-119}

\begin{itemize}
\tightlist
\item
  Converts abstract complexity into empirical performance
\item
  Supports evidence-based optimization
\item
  Detects constant factor effects Big-O hides
\item
  Ensures fair comparisons across algorithms
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-19}

Let \(t_{i,j}\) be time of algorithm \(i\) on trial \(j\). Benchmarking
reports \(\min\), \(\max\), or \(\text{mean}(t_{i,*})\).

By controlling conditions (hardware, input distribution), we treat
\(t_{i,j}\) as samples of the same distribution, allowing valid
comparisons of \(E[t_i]\) (expected runtime). Hence, results reflect
true relative performance.

\subsubsection{Try It Yourself}\label{try-it-yourself-119}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Benchmark linear vs binary search on sorted arrays.
\item
  Test dynamic array insertion vs linked list insertion.
\item
  Run across input sizes \(10^3\), \(10^4\), \(10^5\).
\item
  Plot results: \(n\) (x-axis) vs time (y-axis).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-19}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Comparison & Expectation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble vs Merge & Merge faster after small \(n\) \\
Linear vs Binary Search & Binary faster for \(n > 100\) \\
List vs Dict lookup & Dict \(O(1)\) outperforms List \(O(n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-27}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Run Each Trial & \(O(n)\) & \(O(1)\) \\
Aggregate Results & \(O(k)\) & \(O(k)\) \\
Total Benchmark & \(O(nk)\) & \(O(1)\) \\
\end{longtable}

(\(k\) = number of trials)

A Benchmarking Framework transforms comparison into science, fair tests,
real data, and performance truths grounded in experiment, not hunch.

\section{Section 3. Big-O, Big-Theta,
Big-Omega}\label{section-3.-big-o-big-theta-big-omega}

\subsection{21 Growth Rate Comparator}\label{growth-rate-comparator}

A Growth Rate Comparator helps us \emph{see} how functions grow relative
to each other, the backbone of asymptotic reasoning. It lets us answer
questions like: does \(n^2\) outgrow \(n \log n\)? How fast is \(2^n\)
compared to \(n!\)?

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-20}

We need a clear way to compare how fast two functions increase as \(n\)
becomes large. When analyzing algorithms, runtime functions like \(n\),
\(n \log n\), and \(n^2\) all seem similar at small scales, but their
growth rates diverge quickly.

A comparator gives us a mathematical and visual way to rank them.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-20}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write the two functions \(f(n)\) and \(g(n)\).
\item
  Compute the ratio \(\dfrac{f(n)}{g(n)}\) as \(n \to \infty\).
\item
  Interpret the result:

  \begin{itemize}
  \tightlist
  \item
    If \(\dfrac{f(n)}{g(n)} \to 0\) → \(f(n) = o(g(n))\) (grows slower)
  \item
    If \(\dfrac{f(n)}{g(n)} \to c > 0\) → \(f(n) = \Theta(g(n))\) (same
    growth)
  \item
    If \(\dfrac{f(n)}{g(n)} \to \infty\) → \(f(n) = \omega(g(n))\)
    (grows faster)
  \end{itemize}
\end{enumerate}

This ratio test tells us which function dominates for large \(n\).

\subsubsection{Example Step by Step}\label{example-step-by-step-20}

Example 1: Compare \(n \log n\) vs \(n^2\)

\[
\frac{n \log n}{n^2} = \frac{\log n}{n}
\]

As \(n \to \infty\), \(\frac{\log n}{n} \to 0\) → \(n \log n = o(n^2)\)

Example 2: Compare \(2^n\) vs \(n!\)

\[
\frac{2^n}{n!} \to 0
\]

since \(n!\) grows faster than \(2^n\). → \(2^n = o(n!)\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-20}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ compare\_growth(f, g, ns):}
    \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ ns:}
\NormalTok{        ratio }\OperatorTok{=}\NormalTok{ f(n)}\OperatorTok{/}\NormalTok{g(n)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{:6\}}\SpecialStringTok{, ratio=}\SpecialCharTok{\{}\NormalTok{ratio}\SpecialCharTok{:.6e\}}\SpecialStringTok{"}\NormalTok{)}

\NormalTok{compare\_growth(}\KeywordTok{lambda}\NormalTok{ n: n}\OperatorTok{*}\NormalTok{math.log2(n),}
               \KeywordTok{lambda}\NormalTok{ n: n2,}
\NormalTok{               [}\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{10000}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

Output shows ratio shrinking → confirms slower growth.

\subsubsection{Why It Matters}\label{why-it-matters-120}

\begin{itemize}
\tightlist
\item
  Builds intuition for asymptotic dominance
\item
  Essential for Big-O, Big-Theta, Big-Omega proofs
\item
  Clarifies why some algorithms scale better
\item
  Translates math into visual and numerical comparisons
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-20}

By definition of asymptotic notation:

If \(\displaystyle \lim_{n \to \infty} \frac{f(n)}{g(n)} = 0\), then for
any \(\varepsilon > 0\), \(f(n) < \varepsilon g(n)\) for large \(n\).

Thus, \(f(n)\) grows slower than \(g(n)\).

This formal limit test underlies Big-O reasoning.

\subsubsection{Try It Yourself}\label{try-it-yourself-120}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare \(n^3\) vs \(2^n\)
\item
  Compare \(\sqrt{n}\) vs \(\log n\)
\item
  Compare \(n!\) vs \(n^n\)
\item
  Plot both functions and see where one overtakes the other
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-20}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(f(n)\) & \(g(n)\) & Result & Relation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\log n\) & \(\sqrt{n}\) & \(0\) & \(o(\sqrt{n})\) \\
\(n\) & \(n \log n\) & \(0\) & \(o(n \log n)\) \\
\(n^2\) & \(2^n\) & \(0\) & \(o(2^n)\) \\
\(2^n\) & \(n!\) & \(0\) & \(o(n!)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-28}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Comparison & \(O(1)\) per pair & \(O(1)\) \\
\end{longtable}

A Growth Rate Comparator turns asymptotic theory into a conversation,
showing, with numbers and limits, who really grows faster as \(n\)
climbs toward infinity.

\subsection{22 Dominant Term Extractor}\label{dominant-term-extractor}

A Dominant Term Extractor simplifies complexity expressions by
identifying which term matters most as \(n\) grows large. It's how we
turn messy runtime formulas into clean Big-O notation, by keeping only
what truly drives growth.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-21}

Algorithms often produce composite cost formulas like \[
T(n) = 3n^2 + 10n + 25
\] Not all terms grow equally. The dominant term determines long-run
behavior, so we want to isolate it and discard the rest.

This step bridges detailed operation counting and asymptotic notation.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-21}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the runtime function \(T(n)\) (from counting steps).
\item
  List all terms by their growth type (\(n^3\), \(n^2\), \(n\),
  \(\log n\), constants).
\item
  Find the fastest-growing term as \(n \to \infty\).
\item
  Drop coefficients and lower-order terms.
\item
  The result is the Big-O class.
\end{enumerate}

Think of it as zooming out on a curve, smaller waves vanish at infinity.

\subsubsection{Example Step by Step}\label{example-step-by-step-21}

Example 1: \[
T(n) = 5n^3 + 2n^2 + 7n + 12
\]

For large \(n\), \(n^3\) dominates.

So: \[
T(n) = O(n^3)
\]

Example 2: \[
T(n) = n^2 + n\log n + 10n
\]

Compare term by term: \[
n^2 > n \log n > n
\]

So dominant term is \(n^2\). \(\Rightarrow T(n) = O(n^2)\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-21}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ dominant\_term(terms):}
\NormalTok{    growth\_order }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}1\textquotesingle{}}\NormalTok{: }\DecValTok{0}\NormalTok{, }\StringTok{\textquotesingle{}logn\textquotesingle{}}\NormalTok{: }\DecValTok{1}\NormalTok{, }\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{: }\DecValTok{2}\NormalTok{, }\StringTok{\textquotesingle{}nlogn\textquotesingle{}}\NormalTok{: }\DecValTok{3}\NormalTok{, }\StringTok{\textquotesingle{}n\^{}2\textquotesingle{}}\NormalTok{: }\DecValTok{4}\NormalTok{, }\StringTok{\textquotesingle{}n\^{}3\textquotesingle{}}\NormalTok{: }\DecValTok{5}\NormalTok{, }\StringTok{\textquotesingle{}2\^{}n\textquotesingle{}}\NormalTok{: }\DecValTok{6}\NormalTok{\}}
    \ControlFlowTok{return} \BuiltInTok{max}\NormalTok{(terms, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ t: growth\_order[t])}

\BuiltInTok{print}\NormalTok{(dominant\_term([}\StringTok{\textquotesingle{}n\^{}2\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}nlogn\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{]))  }\CommentTok{\# n\^{}2}
\end{Highlighting}
\end{Shaded}

You can extend this with symbolic simplification using SymPy.

\subsubsection{Why It Matters}\label{why-it-matters-121}

\begin{itemize}
\tightlist
\item
  Simplifies detailed formulas into clean asymptotics
\item
  Focuses attention on scaling behavior, not constants
\item
  Makes performance comparison straightforward
\item
  Core step in deriving Big-O from raw step counts
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-21}

Let \[
T(n) = a_k n^k + a_{k-1} n^{k-1} + \dots + a_0
\]

As \(n \to \infty\), \[
\frac{a_{k-1} n^{k-1}}{a_k n^k} = \frac{a_{k-1}}{a_k n} \to 0
\]

All lower-order terms vanish relative to the largest exponent. So
\(T(n) = \Theta(n^k)\).

This generalizes beyond polynomials to any family of functions with
strict growth ordering.

\subsubsection{Try It Yourself}\label{try-it-yourself-121}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simplify \(T(n) = 4n \log n + 10n + 100\).
\item
  Simplify \(T(n) = 2n^3 + 50n^2 + 1000\).
\item
  Simplify \(T(n) = 5n + 10\log n + 100\).
\item
  Verify using ratio test:
  \(\frac{\text{lower term}}{\text{dominant term}} \to 0\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-21}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Expression & Dominant Term & Big-O \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(3n^2 + 4n + 10\) & \(n^2\) & \(O(n^2)\) \\
\(5n + 8\log n + 7\) & \(n\) & \(O(n)\) \\
\(n \log n + 100n\) & \(n \log n\) & \(O(n \log n)\) \\
\(4n^3 + n^2 + 2n\) & \(n^3\) & \(O(n^3)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-29}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Extraction & \(O(k)\) & \(O(1)\) \\
\end{longtable}

(\(k\) = number of terms)

A Dominant Term Extractor is like a spotlight, it shines on the one term
that decides the pace, letting you see the true asymptotic character of
your algorithm.

\subsection{23 Limit-Based Complexity
Test}\label{limit-based-complexity-test}

The Limit-Based Complexity Test is a precise way to compare how fast two
functions grow by using limits. It's a mathematical tool that turns
intuition (``this one feels faster'') into proof (``this one \emph{is}
faster'').

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-22}

When analyzing algorithms, we often ask: Does \(f(n)\) grow slower,
equal, or faster than \(g(n)\)? Instead of guessing, we use limits to
determine the exact relationship and classify them using Big-O,
\(\Theta\), or \(\Omega\).

This method gives a formal and reliable comparison of growth rates.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-22}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start with two positive functions \(f(n)\) and \(g(n)\).
\item
  Compute the ratio: \[
  L = \lim_{n \to \infty} \frac{f(n)}{g(n)}
  \]
\item
  Interpret the limit:

  \begin{itemize}
  \tightlist
  \item
    If \(L = 0\), then \(f(n) = o(g(n))\) → \(f\) grows slower.
  \item
    If \(0 < L < \infty\), then \(f(n) = \Theta(g(n))\) → same growth
    rate.
  \item
    If \(L = \infty\), then \(f(n) = \omega(g(n))\) → \(f\) grows
    faster.
  \end{itemize}
\end{enumerate}

The ratio tells us how one function ``scales'' relative to another.

\subsubsection{Example Step by Step}\label{example-step-by-step-22}

Example 1:

Compare \(f(n) = n \log n\) and \(g(n) = n^2\).

\[
\frac{f(n)}{g(n)} = \frac{n \log n}{n^2} = \frac{\log n}{n}
\]

As \(n \to \infty\), \(\frac{\log n}{n} \to 0\). So
\(n \log n = o(n^2)\) → grows slower.

Example 2:

Compare \(f(n) = 3n^2 + 4n\) and \(g(n) = n^2\).

\[
\frac{f(n)}{g(n)} = \frac{3n^2 + 4n}{n^2} = 3 + \frac{4}{n}
\]

As \(n \to \infty\), \(\frac{4}{n} \to 0\). So \(\lim = 3\), constant
and positive. Therefore, \(f(n) = \Theta(g(n))\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-22}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\NormalTok{n }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{, positive}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{f }\OperatorTok{=}\NormalTok{ n }\OperatorTok{*}\NormalTok{ sp.log(n)}
\NormalTok{g }\OperatorTok{=}\NormalTok{ n2}
\NormalTok{L }\OperatorTok{=}\NormalTok{ sp.limit(f}\OperatorTok{/}\NormalTok{g, n, sp.oo)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Limit:"}\NormalTok{, L)}
\end{Highlighting}
\end{Shaded}

Outputs \texttt{0}, confirming \(n \log n = o(n^2)\).

\subsubsection{Why It Matters}\label{why-it-matters-122}

\begin{itemize}
\tightlist
\item
  Provides formal proof of asymptotic relationships
\item
  Eliminates guesswork in comparing growth rates
\item
  Core step in Big-O proofs and recurrence analysis
\item
  Helps verify if approximations are valid
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-22}

The definition of asymptotic comparison uses limits:

If \(\displaystyle \lim_{n \to \infty} \frac{f(n)}{g(n)} = 0\), then for
any \(\varepsilon > 0\), \(\exists N\) such that \(\forall n > N\),
\(f(n) \le \varepsilon g(n)\).

This satisfies the formal condition for \(f(n) = o(g(n))\). Similarly,
constant or infinite limits define \(\Theta\) and \(\omega\).

\subsubsection{Try It Yourself}\label{try-it-yourself-122}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare \(n^3\) vs \(2^n\).
\item
  Compare \(\sqrt{n}\) vs \(\log n\).
\item
  Compare \(n!\) vs \(n^n\).
\item
  Check ratio for \(n^2 + n\) vs \(n^2\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-22}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(f(n)\) & \(g(n)\) & Limit & Relationship \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n\) & \(n \log n\) & 0 & \(o(g(n))\) \\
\(n^2 + n\) & \(n^2\) & 1 & \(\Theta(g(n))\) \\
\(2^n\) & \(n^3\) & \(\infty\) & \(\omega(g(n))\) \\
\(\log n\) & \(\sqrt{n}\) & 0 & \(o(g(n))\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-30}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Limit Evaluation & \(O(1)\) symbolic & \(O(1)\) \\
\end{longtable}

The Limit-Based Complexity Test is your mathematical magnifying glass, a
clean, rigorous way to compare algorithmic growth and turn asymptotic
intuition into certainty.

\subsection{24 Summation Simplifier}\label{summation-simplifier}

A Summation Simplifier converts loops and recursive cost expressions
into closed-form formulas using algebra and known summation rules. It
bridges the gap between raw iteration counts and Big-O notation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-23}

When analyzing loops, we often get total work expressed as a sum:

\[
T(n) = \sum_{i=1}^{n} i \quad \text{or} \quad T(n) = \sum_{i=1}^{n} \log i
\]

But Big-O requires us to simplify these sums into familiar functions of
\(n\). Summation simplification transforms iteration patterns into
asymptotic form.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-23}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write down the summation from your loop or recurrence.
\item
  Apply standard formulas or approximations:

  \begin{itemize}
  \tightlist
  \item
    \(\sum_{i=1}^{n} 1 = n\)
  \item
    \(\sum_{i=1}^{n} i = \frac{n(n+1)}{2}\)
  \item
    \(\sum_{i=1}^{n} i^2 = \frac{n(n+1)(2n+1)}{6}\)
  \item
    \(\sum_{i=1}^{n} \log i = O(n \log n)\)
  \end{itemize}
\item
  Drop constants and lower-order terms.
\item
  Return simplified function \(f(n)\) → then apply Big-O.
\end{enumerate}

It's like algebraic compression for iteration counts.

\subsubsection{Example Step by Step}\label{example-step-by-step-23}

Example 1: \[
T(n) = \sum_{i=1}^{n} i
\] Use formula: \[
T(n) = \frac{n(n+1)}{2}
\] Simplify: \[
T(n) = O(n^2)
\]

Example 2: \[
T(n) = \sum_{i=1}^{n} \log i
\] Approximate by integral: \[
\int_1^n \log x , dx = n \log n - n + 1
\] So \(T(n) = O(n \log n)\)

Example 3: \[
T(n) = \sum_{i=1}^{n} \frac{1}{i}
\] ≈ \(\log n\) (Harmonic series)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-23}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\NormalTok{i, n }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}i n\textquotesingle{}}\NormalTok{, positive}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{expr }\OperatorTok{=}\NormalTok{ sp.summation(i, (i, }\DecValTok{1}\NormalTok{, n))}
\BuiltInTok{print}\NormalTok{(sp.simplify(expr))  }\CommentTok{\# n*(n+1)/2}
\end{Highlighting}
\end{Shaded}

Or use \texttt{sp.summation(sp.log(i),\ (i,1,n))} for logarithmic sums.

\subsubsection{Why It Matters}\label{why-it-matters-123}

\begin{itemize}
\tightlist
\item
  Converts nested loops into analyzable formulas
\item
  Core tool in time complexity derivation
\item
  Helps visualize how cumulative work builds up
\item
  Connects discrete steps with continuous approximations
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-23}

If \(f(i)\) is positive and increasing, then by the integral test:

\[
\int_1^n f(x),dx \le \sum_{i=1}^n f(i) \le f(n) + \int_1^n f(x),dx
\]

So for asymptotic purposes, \(\sum f(i)\) and \(\int f(x)\) grow at the
same rate.

This equivalence justifies approximations like
\(\sum \log i = O(n \log n)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-123}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simplify \(\sum_{i=1}^n i^3\).
\item
  Simplify \(\sum_{i=1}^n \sqrt{i}\).
\item
  Simplify \(\sum_{i=1}^n \frac{1}{i^2}\).
\item
  Approximate \(\sum_{i=1}^{n/2} i\) using integrals.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-23}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Summation & Formula & Big-O \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\sum 1\) & \(n\) & \(O(n)\) \\
\(\sum i\) & \(\frac{n(n+1)}{2}\) & \(O(n^2)\) \\
\(\sum i^2\) & \(\frac{n(n+1)(2n+1)}{6}\) & \(O(n^3)\) \\
\(\sum \log i\) & \(n \log n\) & \(O(n \log n)\) \\
\(\sum \frac{1}{i}\) & \(\log n\) & \(O(\log n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-31}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Simplification & \(O(1)\) (formula lookup) & \(O(1)\) \\
\end{longtable}

A Summation Simplifier turns looping arithmetic into elegant formulas,
the difference between counting steps and \emph{seeing} the shape of
growth.

\subsection{25 Recurrence Tree Method}\label{recurrence-tree-method}

The Recurrence Tree Method is a visual technique for solving
divide-and-conquer recurrences. It expands the recursive formula into a
tree of subproblems, sums the work done at each level, and reveals the
total cost.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-24}

Many recursive algorithms (like Merge Sort or Quick Sort) define their
running time as \[
T(n) = a , T!\left(\frac{n}{b}\right) + f(n)
\] where:

\begin{itemize}
\tightlist
\item
  \(a\) = number of subproblems,
\item
  \(b\) = size reduction factor,
\item
  \(f(n)\) = non-recursive work per call.
\end{itemize}

The recurrence tree lets us see the full cost by summing over levels
instead of applying a closed-form theorem immediately.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-24}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Draw the recursion tree

  \begin{itemize}
  \tightlist
  \item
    Root: problem of size \(n\), cost \(f(n)\).
  \item
    Each node: subproblem of size \(\frac{n}{b}\) with cost
    \(f(\frac{n}{b})\).
  \end{itemize}
\item
  Expand levels until base case (\(n=1\)).
\item
  Sum work per level:

  \begin{itemize}
  \tightlist
  \item
    Level \(i\) has \(a^i\) nodes, each size \(\frac{n}{b^i}\).
  \item
    Total work at level \(i\): \[
    W_i = a^i \cdot f!\left(\frac{n}{b^i}\right)
    \]
  \end{itemize}
\item
  Add all levels: \[
  T(n) = \sum_{i=0}^{\log_b n} W_i
  \]
\item
  Identify the dominant level (top, middle, or bottom).
\item
  Simplify to Big-O form.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-24}

Take Merge Sort:

\[
T(n) = 2T!\left(\frac{n}{2}\right) + n
\]

Level 0: \(1 \times n = n\) Level 1: \(2 \times \frac{n}{2} = n\) Level
2: \(4 \times \frac{n}{4} = n\) ⋯ Depth: \(\log_2 n\) levels

Total work: \[
T(n) = n \log_2 n + n = O(n \log n)
\]

Every level costs \(n\), total = \(n \times \log n\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-24}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ recurrence\_tree(a, b, f, n):}
\NormalTok{    total }\OperatorTok{=} \DecValTok{0}
\NormalTok{    level }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ n }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{:}
\NormalTok{        work }\OperatorTok{=}\NormalTok{ (alevel) }\OperatorTok{*}\NormalTok{ f(n}\OperatorTok{/}\NormalTok{(blevel))}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ work}
\NormalTok{        level }\OperatorTok{+=} \DecValTok{1}
\NormalTok{        n }\OperatorTok{/=}\NormalTok{ b}
    \ControlFlowTok{return}\NormalTok{ total}
\end{Highlighting}
\end{Shaded}

Use \texttt{f\ =\ lambda\ x:\ x} for \(f(n) = n\).

\subsubsection{Why It Matters}\label{why-it-matters-124}

\begin{itemize}
\tightlist
\item
  Makes recurrence structure visible and intuitive
\item
  Explains why Master Theorem results hold
\item
  Highlights dominant levels (top-heavy vs bottom-heavy)
\item
  Great teaching and reasoning tool for recursive cost breakdown
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-24}

Each recursive call contributes \(f(n)\) work plus child subcalls.
Because each level's subproblems have equal size, total cost is
additive:

\[
T(n) = \sum_{i=0}^{\log_b n} a^i f!\left(\frac{n}{b^i}\right)
\]

Dominant level dictates asymptotic order:

\begin{itemize}
\tightlist
\item
  Top-heavy: \(f(n)\) dominates → \(O(f(n))\)
\item
  Balanced: all levels equal → \(O(f(n) \log n)\)
\item
  Bottom-heavy: leaves dominate → \(O(n^{\log_b a})\)
\end{itemize}

This reasoning leads directly to the Master Theorem.

\subsubsection{Try It Yourself}\label{try-it-yourself-124}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build tree for \(T(n) = 3T(n/2) + n\).
\item
  Sum each level's work.
\item
  Compare with Master Theorem result.
\item
  Try \(T(n) = T(n/2) + 1\) (logarithmic tree).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-24}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1325}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3976}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1928}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1205}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1566}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Recurrence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Level Work
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Levels
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Total
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Big-O
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(2T(n/2)+n\) & \(n\) & \(\log n\) & \(n \log n\) & \(O(n \log n)\) \\
\(T(n/2)+1\) & \(1\) & \(\log n\) & \(\log n\) & \(O(\log n)\) \\
\(4T(n/2)+n\) & \(a^i = 4^i\), work = \(n \cdot 2^i\) & bottom dominates
& \(O(n^2)\) & \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-32}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Tree Construction & \(O(\log n)\) levels & \(O(\log n)\) \\
\end{longtable}

The Recurrence Tree Method turns abstract formulas into living diagrams,
showing each layer's effort, revealing which level truly drives the
algorithm's cost.

\subsection{26 Master Theorem Evaluator}\label{master-theorem-evaluator}

The Master Theorem Evaluator gives a quick, formula-based way to solve
divide-and-conquer recurrences of the form \[
T(n) = a , T!\left(\frac{n}{b}\right) + f(n)
\] It tells you the asymptotic behavior of \(T(n)\) without full
expansion or summation, a shortcut born from the recurrence tree.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-25}

We want to find the Big-O complexity of divide-and-conquer algorithms
quickly. Manually expanding recursions (via recurrence trees) works, but
is tedious. The Master Theorem classifies solutions by comparing the
recursive work (\(a , T(n/b)\)) and non-recursive work (\(f(n)\)).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-25}

Given \[
T(n) = a , T!\left(\frac{n}{b}\right) + f(n)
\]

\begin{itemize}
\tightlist
\item
  \(a\) = number of subproblems
\item
  \(b\) = shrink factor
\item
  \(f(n)\) = work done outside recursion
\end{itemize}

Compute critical exponent: \[
n^{\log_b a}
\]

Compare \(f(n)\) to \(n^{\log_b a}\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Case 1 (Top-heavy): If \(f(n) = O(n^{\log_b a - \varepsilon})\),
  \[T(n) = \Theta(n^{\log_b a})\] Recursive part dominates.
\item
  Case 2 (Balanced): If \(f(n) = \Theta(n^{\log_b a} \log^k n)\),
  \[T(n) = \Theta(n^{\log_b a} \log^{k+1} n)\] Both contribute equally.
\item
  Case 3 (Bottom-heavy): If
  \(f(n) = \Omega(n^{\log_b a + \varepsilon})\) and regularity condition
  holds: \[a f(n/b) \le c f(n)\] for some \(c<1\), then
  \[T(n) = \Theta(f(n))\] Non-recursive part dominates.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-25}

Example 1: \[
T(n) = 2T(n/2) + n
\]

\begin{itemize}
\tightlist
\item
  \(a = 2\), \(b = 2\), \(f(n) = n\)
\item
  \(n^{\log_2 2} = n\) So \(f(n) = \Theta(n^{\log_2 2})\) → Case 2
\end{itemize}

\[
T(n) = \Theta(n \log n)
\]

Example 2: \[
T(n) = 4T(n/2) + n
\]

\begin{itemize}
\tightlist
\item
  \(a = 4\), \(b = 2\) → \(n^{\log_2 4} = n^2\)
\item
  \(f(n) = n = O(n^{2 - \varepsilon})\) → Case 1
\end{itemize}

\[
T(n) = \Theta(n^2)
\]

Example 3: \[
T(n) = T(n/2) + n
\]

\begin{itemize}
\tightlist
\item
  \(a=1\), \(b=2\), \(n^{\log_2 1}=1\)
\item
  \(f(n)=n = \Omega(n^{0+\varepsilon})\) → Case 3
\end{itemize}

\[
T(n) = \Theta(n)
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-25}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ master\_theorem(a, b, f\_exp):}
\NormalTok{    critical }\OperatorTok{=}\NormalTok{ math.log(a, b)}
    \ControlFlowTok{if}\NormalTok{ f\_exp }\OperatorTok{\textless{}}\NormalTok{ critical:}
        \ControlFlowTok{return} \SpecialStringTok{f"O(n\^{}}\SpecialCharTok{\{}\NormalTok{critical}\SpecialCharTok{:.2f\}}\SpecialStringTok{)"}
    \ControlFlowTok{elif}\NormalTok{ f\_exp }\OperatorTok{==}\NormalTok{ critical:}
        \ControlFlowTok{return} \SpecialStringTok{f"O(n\^{}}\SpecialCharTok{\{}\NormalTok{critical}\SpecialCharTok{:.2f\}}\SpecialStringTok{ log n)"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \SpecialStringTok{f"O(n\^{}}\SpecialCharTok{\{}\NormalTok{f\_exp}\SpecialCharTok{\}}\SpecialStringTok{)"}
\end{Highlighting}
\end{Shaded}

For \(T(n) = 2T(n/2) + n\), call \texttt{master\_theorem(2,2,1)} →
\texttt{O(n\ log\ n)}

\subsubsection{Why It Matters}\label{why-it-matters-125}

\begin{itemize}
\tightlist
\item
  Solves recurrences in seconds
\item
  Foundation for analyzing divide-and-conquer algorithms
\item
  Validates intuition from recurrence trees
\item
  Used widely in sorting, searching, matrix multiplication, FFT
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-25}

Each recursion level costs: \[a^i , f!\left(\frac{n}{b^i}\right)\]

Total cost:
\[T(n) = \sum_{i=0}^{\log_b n} a^i f!\left(\frac{n}{b^i}\right)\]

The relative growth of \(f(n)\) to \(n^{\log_b a}\) determines which
level dominates, top, middle, or bottom, yielding the three canonical
cases.

\subsubsection{Try It Yourself}\label{try-it-yourself-125}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(T(n) = 3T(n/2) + n\)
\item
  \(T(n) = 2T(n/2) + n^2\)
\item
  \(T(n) = 8T(n/2) + n^3\)
\item
  Identify \(a, b, f(n)\) and apply theorem.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-25}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Recurrence & Case & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(2T(n/2)+n\) & 2 & \(O(n \log n)\) \\
\(4T(n/2)+n\) & 1 & \(O(n^2)\) \\
\(T(n/2)+n\) & 3 & \(O(n)\) \\
\(3T(n/3)+n\log n\) & 2 & \(O(n\log^2 n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-33}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Evaluation & \(O(1)\) & \(O(1)\) \\
\end{longtable}

The Master Theorem Evaluator is your formulaic compass, it points
instantly to the asymptotic truth hidden in recursive equations, no
tree-drawing required.

\subsection{27 Big-Theta Proof Builder}\label{big-theta-proof-builder}

A Big-Theta Proof Builder helps you formally prove that a function grows
at the same rate as another. It's the precise way to show that \(f(n)\)
and \(g(n)\) are asymptotically equivalent, growing neither faster nor
slower beyond constant factors.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-26}

We often say an algorithm is \(T(n) = \Theta(n \log n)\), but how do we
prove it? A Big-Theta proof uses inequalities to pin \(T(n)\) between
two scaled versions of a simpler function \(g(n)\), confirming tight
asymptotic bounds.

This transforms intuition into rigorous evidence.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-26}

We say \[
f(n) = \Theta(g(n))
\] if there exist constants \(c_1, c_2 > 0\) and \(n_0\) such that for
all \(n \ge n_0\): \[
c_1 g(n) \le f(n) \le c_2 g(n)
\]

So \(f(n)\) is sandwiched between two constant multiples of \(g(n)\).

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify \(f(n)\) and candidate \(g(n)\).
\item
  Find constants \(c_1\), \(c_2\), and threshold \(n_0\).
\item
  Verify inequality for all \(n \ge n_0\).
\item
  Conclude \(f(n) = \Theta(g(n))\).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-26}

Example 1: \[
f(n) = 3n^2 + 10n + 5
\] Candidate: \(g(n) = n^2\)

For large \(n\), \(10n + 5\) is small compared to \(3n^2\).

We can show: \[
3n^2 \le 3n^2 + 10n + 5 \le 4n^2, \quad \text{for } n \ge 10
\]

Thus, \(f(n) = \Theta(n^2)\) with \(c_1 = 3\), \(c_2 = 4\),
\(n_0 = 10\).

Example 2: \[
f(n) = n \log n + 100n
\] Candidate: \(g(n) = n \log n\)

For \(n \ge 2\), \(\log n \ge 1\), so \(100n \le 100n \log n\). Hence,
\[
n \log n \le f(n) \le 101n \log n
\] → \(f(n) = \Theta(n \log n)\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-26}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ big\_theta\_proof(f, g, n0, c1, c2):}
    \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n0, n0 }\OperatorTok{+} \DecValTok{5}\NormalTok{):}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ (c1}\OperatorTok{*}\NormalTok{g(n) }\OperatorTok{\textless{}=}\NormalTok{ f(n) }\OperatorTok{\textless{}=}\NormalTok{ c2}\OperatorTok{*}\NormalTok{g(n)):}
            \ControlFlowTok{return} \VariableTok{False}
    \ControlFlowTok{return} \VariableTok{True}

\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ n: }\DecValTok{3}\OperatorTok{*}\NormalTok{n2 }\OperatorTok{+} \DecValTok{10}\OperatorTok{*}\NormalTok{n }\OperatorTok{+} \DecValTok{5}
\NormalTok{g }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ n: n2}
\BuiltInTok{print}\NormalTok{(big\_theta\_proof(f, g, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{))  }\CommentTok{\# True}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-126}

\begin{itemize}
\tightlist
\item
  Converts informal claims (``it's \(n^2\)-ish'') into formal proofs
\item
  Builds rigor in asymptotic reasoning
\item
  Essential for algorithm analysis, recurrence proofs, and coursework
\item
  Reinforces understanding of constants and thresholds
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-26}

By definition, \[
f(n) = \Theta(g(n)) \iff \exists c_1, c_2, n_0 : c_1 g(n) \le f(n) \le c_2 g(n)
\] This mirrors how Big-O and Big-Omega combine:

\begin{itemize}
\tightlist
\item
  \(f(n) = O(g(n))\) gives upper bound,
\item
  \(f(n) = \Omega(g(n))\) gives lower bound. Together, they form a tight
  bound, hence \(\Theta\).
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-126}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prove \(5n^3 + n^2 + 100 = \Theta(n^3)\).
\item
  Prove \(4n + 10 = \Theta(n)\).
\item
  Show \(n \log n + 100n = \Theta(n \log n)\).
\item
  Fail a proof: \(n^2 + 3n = \Theta(n)\) (not true).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-26}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2833}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(f(n)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(g(n)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(c_1, c_2, n_0\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Result
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(3n^2 + 10n + 5\) & \(n^2\) & \(3,4,10\) & \(\Theta(n^2)\) \\
\(n \log n + 100n\) & \(n \log n\) & \(1,101,2\) &
\(\Theta(n \log n)\) \\
\(10n + 50\) & \(n\) & \(10,11,5\) & \(\Theta(n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-34}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Verification & \(O(1)\) (symbolic) & \(O(1)\) \\
\end{longtable}

The Big-Theta Proof Builder is your asymptotic courtroom, you bring
evidence, constants, and inequalities, and the proof delivers a verdict:
\(\Theta(g(n))\), beyond reasonable doubt.

\subsection{28 Big-Omega Case Finder}\label{big-omega-case-finder}

A Big-Omega Case Finder helps you identify lower bounds on an
algorithm's growth, the \emph{guaranteed minimum} cost, even in the
best-case scenario. It's the mirror image of Big-O, showing what an
algorithm must at least do.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-27}

Big-O gives us an upper bound (``it won't be slower than this''), but
sometimes we need to know the floor, a complexity it can never beat.

Big-Omega helps us state:

\begin{itemize}
\tightlist
\item
  The fastest possible asymptotic behavior, or
\item
  The minimal cost inherent to the problem itself.
\end{itemize}

This is key when analyzing best-case performance or complexity limits
(like comparison sorting's \(\Omega(n \log n)\) lower bound).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-27}

We say \[
f(n) = \Omega(g(n))
\] if \(\exists c > 0, n_0\) such that \[
f(n) \ge c \cdot g(n) \quad \text{for all } n \ge n_0
\]

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify candidate lower-bound function \(g(n)\).
\item
  Show \(f(n)\) eventually stays above a constant multiple of \(g(n)\).
\item
  Find constants \(c\) and \(n_0\).
\item
  Conclude \(f(n) = \Omega(g(n))\).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-27}

Example 1: \[
f(n) = 3n^2 + 5n + 10
\] Candidate: \(g(n) = n^2\)

For \(n \ge 1\), \[
f(n) \ge 3n^2 \ge 3 \cdot n^2
\]

So \(f(n) = \Omega(n^2)\) with \(c = 3\), \(n_0 = 1\).

Example 2: \[
f(n) = n \log n + 100n
\] Candidate: \(g(n) = n\)

Since \(\log n \ge 1\) for \(n \ge 2\), \[
f(n) = n \log n + 100n \ge n + 100n = 101n
\] → \(f(n) = \Omega(n)\) with \(c = 101\), \(n_0 = 2\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-27}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ big\_omega\_proof(f, g, n0, c):}
    \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n0, n0 }\OperatorTok{+} \DecValTok{5}\NormalTok{):}
        \ControlFlowTok{if}\NormalTok{ f(n) }\OperatorTok{\textless{}}\NormalTok{ c }\OperatorTok{*}\NormalTok{ g(n):}
            \ControlFlowTok{return} \VariableTok{False}
    \ControlFlowTok{return} \VariableTok{True}

\NormalTok{f }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ n: }\DecValTok{3}\OperatorTok{*}\NormalTok{n2 }\OperatorTok{+} \DecValTok{5}\OperatorTok{*}\NormalTok{n }\OperatorTok{+} \DecValTok{10}
\NormalTok{g }\OperatorTok{=} \KeywordTok{lambda}\NormalTok{ n: n2}
\BuiltInTok{print}\NormalTok{(big\_omega\_proof(f, g, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{))  }\CommentTok{\# True}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-127}

\begin{itemize}
\tightlist
\item
  Defines best-case performance
\item
  Provides theoretical lower limits (impossible to beat)
\item
  Complements Big-O (upper bound) and Theta (tight bound)
\item
  Key in proving problem hardness or optimality
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-27}

If \[
\lim_{n \to \infty} \frac{f(n)}{g(n)} = L > 0,
\] then for any \(c \le L\), \(f(n) \ge c \cdot g(n)\) for large \(n\).
Thus \(f(n) = \Omega(g(n))\). This mirrors the formal definition of
\(\Omega\) and follows directly from asymptotic ratio reasoning.

\subsubsection{Try It Yourself}\label{try-it-yourself-127}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show \(4n^3 + n^2 = \Omega(n^3)\)
\item
  Show \(n \log n + n = \Omega(n)\)
\item
  Show \(2^n + n^5 = \Omega(2^n)\)
\item
  Compare with their Big-O forms for contrast.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-27}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
\(f(n)\) & \(g(n)\) & Constants & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(3n^2 + 10n\) & \(n^2\) & \(c=3\), \(n_0=1\) & \(\Omega(n^2)\) \\
\(n \log n + 100n\) & \(n\) & \(c=101\), \(n_0=2\) & \(\Omega(n)\) \\
\(n^3 + n^2\) & \(n^3\) & \(c=1\), \(n_0=1\) & \(\Omega(n^3)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-35}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Verification & \(O(1)\) & \(O(1)\) \\
\end{longtable}

The Big-Omega Case Finder shows the \emph{floor beneath the curve},
ensuring every algorithm stands on a solid lower bound, no matter how
fast it tries to run.

\subsection{29 Empirical Complexity
Estimator}\label{empirical-complexity-estimator}

An Empirical Complexity Estimator bridges theory and experiment, it
measures actual runtimes for various input sizes and fits them to known
growth models like \(O(n)\), \(O(n \log n)\), or \(O(n^2)\). It's how we
\emph{discover} complexity when the math is unclear or the code is
complex.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-28}

Sometimes the exact formula for \(T(n)\) is too messy, or the
implementation details are opaque. We can still estimate complexity
empirically by observing how runtime changes as \(n\) grows.

This approach is especially useful for:

\begin{itemize}
\tightlist
\item
  Black-box code (unknown implementation)
\item
  Experimental validation of asymptotic claims
\item
  Comparing real-world scaling with theoretical predictions
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-28}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Choose representative input sizes \(n_1, n_2, \dots, n_k\).
\item
  Measure runtime \(T(n_i)\) for each size.
\item
  Normalize or compare ratios:

  \begin{itemize}
  \tightlist
  \item
    \(T(2n)/T(n) \approx 2\) → \(O(n)\)
  \item
    \(T(2n)/T(n) \approx 4\) → \(O(n^2)\)
  \item
    \(T(2n)/T(n) \approx \log 2\) → \(O(\log n)\)
  \end{itemize}
\item
  Fit data to candidate models using regression or ratio tests.
\item
  Visualize trends (e.g., log--log plot) to identify slope = exponent.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-28}

Suppose we test input sizes: \(n = 1000, 2000, 4000, 8000\)

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(n\) & \(T(n)\) (ms) & Ratio \(T(2n)/T(n)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1000 & 5 & -- \\
2000 & 10 & 2.0 \\
4000 & 20 & 2.0 \\
8000 & 40 & 2.0 \\
\end{longtable}

Ratio \(\approx 2\) → linear growth → \(T(n) = O(n)\)

Now suppose:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(n\) & \(T(n)\) & Ratio \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1000 & 5 & -- \\
2000 & 20 & 4 \\
4000 & 80 & 4 \\
8000 & 320 & 4 \\
\end{longtable}

Ratio \(\approx 4\) → quadratic growth → \(O(n^2)\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-28}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ time, math}

\KeywordTok{def}\NormalTok{ empirical\_estimate(f, ns):}
\NormalTok{    times }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ ns:}
\NormalTok{        start }\OperatorTok{=}\NormalTok{ time.perf\_counter()}
\NormalTok{        f(n)}
\NormalTok{        end }\OperatorTok{=}\NormalTok{ time.perf\_counter()}
\NormalTok{        times.append(end }\OperatorTok{{-}}\NormalTok{ start)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(ns)):}
\NormalTok{        ratio }\OperatorTok{=}\NormalTok{ times[i] }\OperatorTok{/}\NormalTok{ times[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{ns[i]}\SpecialCharTok{:6\}}\SpecialStringTok{, ratio=}\SpecialCharTok{\{}\NormalTok{ratio}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Test with different algorithms to see scaling.

\subsubsection{Why It Matters}\label{why-it-matters-128}

\begin{itemize}
\tightlist
\item
  Converts runtime data into Big-O form
\item
  Detects bottlenecks or unexpected scaling
\item
  Useful when theoretical analysis is hard
\item
  Helps validate optimizations or refactors
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-28}

If \(T(n) \approx c \cdot f(n)\), then the ratio test \[
\frac{T(kn)}{T(n)} \approx \frac{f(kn)}{f(n)}
\] reveals the exponent \(p\) if \(f(n) = n^p\): \[
\frac{f(kn)}{f(n)} = k^p \implies p = \log_k \frac{T(kn)}{T(n)}
\]

Repeated over multiple \(n\), this converges to the true growth
exponent.

\subsubsection{Try It Yourself}\label{try-it-yourself-128}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Measure runtime of sorting for increasing \(n\).
\item
  Estimate \(p\) using ratio test.
\item
  Plot \(\log n\) vs \(\log T(n)\), slope ≈ exponent.
\item
  Compare \(p\) to theoretical value.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-28}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Algorithm & Observed Ratio & Estimated Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & 4 & \(O(n^2)\) \\
Merge Sort & 2.2 & \(O(n \log n)\) \\
Linear Search & 2 & \(O(n)\) \\
Binary Search & 1.1 & \(O(\log n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-36}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Measurement & \(O(k \cdot T(n))\) & \(O(k)\) \\
Estimation & \(O(k)\) & \(O(1)\) \\
\end{longtable}

(\(k\) = number of sample points)

An Empirical Complexity Estimator transforms stopwatches into science,
turning performance data into curves, curves into equations, and
equations into Big-O intuition.

\subsection{30 Complexity Class
Identifier}\label{complexity-class-identifier}

A Complexity Class Identifier helps you categorize problems and
algorithms into broad complexity classes like constant, logarithmic,
linear, quadratic, exponential, or polynomial time. It's a way to
understand \emph{where your algorithm lives} in the vast map of
computational growth.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-29}

When analyzing an algorithm, we often want to know how big its time cost
gets as input grows. Instead of exact formulas, we classify algorithms
into families based on their asymptotic growth.

This tells us what is \emph{feasible} (polynomial) and what is
\emph{explosive} (exponential), guiding both design choices and
theoretical limits.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-29}

We map the growth rate of \(T(n)\) to a known complexity class:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2031}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4219}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(O(1)\) & Hash lookup & Constant time, no scaling \\
\(O(\log n)\) & Binary search & Sublinear, halves each step \\
\(O(n)\) & Linear scan & Work grows with input size \\
\(O(n \log n)\) & Merge sort & Near-linear with log factor \\
\(O(n^2)\) & Nested loops & Quadratic growth \\
\(O(n^3)\) & Matrix multiplication & Cubic growth \\
\(O(2^n)\) & Backtracking & Exponential explosion \\
\(O(n!)\) & Brute-force permutations & Factorial blowup \\
\end{longtable}

Steps to Identify:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Analyze loops and recursion structure.
\item
  Count dominant operations.
\item
  Match pattern to table above.
\item
  Verify with recurrence or ratio test.
\item
  Assign class: constant → logarithmic → polynomial → exponential.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-29}

Example 1: Single loop:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{    work()}
\end{Highlighting}
\end{Shaded}

→ \(O(n)\) → Linear

Example 2: Nested loops:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
    \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{        work()}
\end{Highlighting}
\end{Shaded}

→ \(O(n^2)\) → Quadratic

Example 3: Divide and conquer: \[
T(n) = 2T(n/2) + n
\] → \(O(n \log n)\) → Log-linear

Example 4: Brute force subsets: \[
2^n \text{ possibilities}
\] → \(O(2^n)\) → Exponential

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-29}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ classify\_complexity(code\_structure):}
    \ControlFlowTok{if} \StringTok{"nested n"} \KeywordTok{in}\NormalTok{ code\_structure:}
        \ControlFlowTok{return} \StringTok{"O(n\^{}2)"}
    \ControlFlowTok{if} \StringTok{"divide and conquer"} \KeywordTok{in}\NormalTok{ code\_structure:}
        \ControlFlowTok{return} \StringTok{"O(n log n)"}
    \ControlFlowTok{if} \StringTok{"constant"} \KeywordTok{in}\NormalTok{ code\_structure:}
        \ControlFlowTok{return} \StringTok{"O(1)"}
    \ControlFlowTok{return} \StringTok{"O(n)"}
\end{Highlighting}
\end{Shaded}

You can extend this to pattern-match pseudocode shapes.

\subsubsection{Why It Matters}\label{why-it-matters-129}

\begin{itemize}
\tightlist
\item
  Gives instant intuition about scalability
\item
  Guides design trade-offs (speed vs.~simplicity)
\item
  Connects practical code to theoretical limits
\item
  Helps compare algorithms solving the same problem
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-29}

If an algorithm performs \(f(n)\) fundamental operations for input size
\(n\), and \(f(n)\) is asymptotically similar to a known class \(g(n)\):
\[
f(n) = \Theta(g(n))
\] then it belongs to the same class. Classes form equivalence groups
under \(\Theta\) notation, simplifying infinite functions into a finite
taxonomy.

\subsubsection{Try It Yourself}\label{try-it-yourself-129}

Classify each:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(T(n) = 5n + 10\)
\item
  \(T(n) = n \log n + 100\)
\item
  \(T(n) = n^3 + 4n^2\)
\item
  \(T(n) = 2^n\)
\end{enumerate}

Identify their Big-O class and interpret feasibility.

\subsubsection{Test Cases}\label{test-cases-29}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\(T(n)\) & Class & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(7n + 3\) & \(O(n)\) & Linear \\
\(3n^2 + 10n\) & \(O(n^2)\) & Quadratic \\
\(n \log n\) & \(O(n \log n)\) & Log-linear \\
\(2^n\) & \(O(2^n)\) & Exponential \\
\(100\) & \(O(1)\) & Constant \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-37}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classification & \(O(1)\) & \(O(1)\) \\
\end{longtable}

The Complexity Class Identifier is your map of the algorithmic universe,
helping you locate where your code stands, from calm constant time to
the roaring infinity of factorial growth.

\bookmarksetup{startatroot}

\chapter{Section 4. Algorithm
Paradigms}\label{section-4.-algorithm-paradigms}

\subsection{31 Greedy Coin Example}\label{greedy-coin-example}

The Greedy Coin Example introduces the greedy algorithm paradigm,
solving problems by always taking the best immediate option, hoping it
leads to a globally optimal solution. In coin change, we repeatedly pick
the largest denomination not exceeding the remaining amount.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-30}

We want to make change for a target amount using the fewest coins
possible. A greedy algorithm always chooses the locally optimal coin,
the largest denomination ≤ remaining total, and repeats until the target
is reached.

This method works for canonical coin systems (like U.S. currency) but
fails for some arbitrary denominations.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-30}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Sort available coin denominations in descending order.
\item
  For each coin:

  \begin{itemize}
  \tightlist
  \item
    Take as many as possible without exceeding the total.
  \item
    Subtract their value from the remaining amount.
  \end{itemize}
\item
  Continue with smaller coins until the remainder is 0.
\end{enumerate}

Greedy assumes: local optimum → global optimum.

\subsubsection{Example Step by Step}\label{example-step-by-step-30}

Let coins = \{25, 10, 5, 1\}, target = 63

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Step & Coin & Count & Remaining \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 25 & 2 & 13 \\
2 & 10 & 1 & 3 \\
3 & 5 & 0 & 3 \\
4 & 1 & 3 & 0 \\
\end{longtable}

Total = 2×25 + 1×10 + 3×1 = 63 Coins used = 6

Greedy solution = optimal (U.S. system is canonical).

Counterexample:

Coins = \{4, 3, 1\}, target = 6

\begin{itemize}
\tightlist
\item
  Greedy: 4 + 1 + 1 = 3 coins
\item
  Optimal: 3 + 3 = 2 coins
\end{itemize}

So greedy may fail for non-canonical systems.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-30}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ greedy\_change(coins, amount):}
\NormalTok{    coins.sort(reverse}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ coin }\KeywordTok{in}\NormalTok{ coins:}
        \ControlFlowTok{while}\NormalTok{ amount }\OperatorTok{\textgreater{}=}\NormalTok{ coin:}
\NormalTok{            amount }\OperatorTok{{-}=}\NormalTok{ coin}
\NormalTok{            result.append(coin)}
    \ControlFlowTok{return}\NormalTok{ result}

\BuiltInTok{print}\NormalTok{(greedy\_change([}\DecValTok{25}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{], }\DecValTok{63}\NormalTok{))  }\CommentTok{\# [25, 25, 10, 1, 1, 1]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-130}

\begin{itemize}
\tightlist
\item
  Demonstrates local decision-making
\item
  Fast and simple: \(O(n)\) over denominations
\item
  Foundation for greedy design in spanning trees, scheduling,
  compression
\item
  Highlights where greedy works and where it fails
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-30}

For canonical systems, greedy satisfies the optimal substructure and
greedy-choice property:

\begin{itemize}
\tightlist
\item
  Greedy-choice property: Locally best → part of a global optimum.
\item
  Optimal substructure: Remaining subproblem has optimal greedy
  solution.
\end{itemize}

Inductively, greedy yields minimal coin count.

\subsubsection{Try It Yourself}\label{try-it-yourself-130}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Try greedy change with \{25, 10, 5, 1\} for 68.
\item
  Try \{9, 6, 1\} for 11, compare with brute force.
\item
  Identify when greedy fails, test \{4, 3, 1\}.
\item
  Extend algorithm to return both coins and count.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-30}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Coins & Amount & Result & Optimal? \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\{25,10,5,1\} & 63 & {[}25,25,10,1,1,1{]} & ✅ \\
\{9,6,1\} & 11 & {[}9,1,1{]} & ✅ \\
\{4,3,1\} & 6 & {[}4,1,1{]} & ❌ (3+3 better) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-38}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sorting & \(O(k \log k)\) & \(O(1)\) \\
Selection & \(O(k)\) & \(O(k)\) \\
\end{longtable}

(\(k\) = number of denominations)

The Greedy Coin Example is the first mirror of the greedy philosophy,
simple, intuitive, and fast, a lens into problems where choosing
\emph{best now} means \emph{best overall}.

\subsection{32 Greedy Template
Simulator}\label{greedy-template-simulator}

The Greedy Template Simulator shows how every greedy algorithm follows
the same pattern, repeatedly choosing the best local option, updating
the state, and moving toward the goal. It's a reusable mental and coding
framework for designing greedy solutions.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-31}

Many optimization problems can be solved by making local choices without
revisiting earlier decisions. Instead of searching all paths (like
backtracking) or building tables (like DP), greedy algorithms follow a
deterministic path of best-next choices.

We want a general template to simulate this structure, useful for
scheduling, coin change, and spanning tree problems.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-31}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Initialize the problem state (remaining value, capacity, etc.).
\item
  While goal not reached:

  \begin{itemize}
  \tightlist
  \item
    Evaluate all local choices.
  \item
    Pick the best immediate option (by some criterion).
  \item
    Update the state accordingly.
  \end{itemize}
\item
  End when no more valid moves exist.
\end{enumerate}

Greedy depends on a selection rule (which local choice is best) and a
feasibility check (is the choice valid?).

\subsubsection{Example Step by Step}\label{example-step-by-step-31}

Problem: Job Scheduling by Deadline (Maximize Profit)

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Job & Deadline & Profit \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 2 & 60 \\
B & 1 & 100 \\
C & 3 & 20 \\
D & 2 & 40 \\
\end{longtable}

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Sort jobs by profit (desc): B(100), A(60), D(40), C(20)
\item
  Take each job if slot ≤ deadline available
\item
  Fill slots:

  \begin{itemize}
  \tightlist
  \item
    Day 1: B
  \item
    Day 2: A
  \item
    Day 3: C → Total Profit = 180
  \end{itemize}
\end{enumerate}

Greedy rule: ``Pick highest profit first if deadline allows.''

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-31}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ greedy\_template(items, is\_valid, select\_best, update\_state):}
\NormalTok{    state }\OperatorTok{=}\NormalTok{ initialize(items)}
    \ControlFlowTok{while} \KeywordTok{not}\NormalTok{ goal\_reached(state):}
\NormalTok{        best }\OperatorTok{=}\NormalTok{ select\_best(items, state)}
        \ControlFlowTok{if}\NormalTok{ is\_valid(best, state):}
\NormalTok{            update\_state(best, state)}
        \ControlFlowTok{else}\NormalTok{:}
            \ControlFlowTok{break}
    \ControlFlowTok{return}\NormalTok{ state}
\end{Highlighting}
\end{Shaded}

Concrete greedy solutions just plug in:

\begin{itemize}
\tightlist
\item
  \texttt{select\_best}: define local criterion
\item
  \texttt{is\_valid}: define feasibility condition
\item
  \texttt{update\_state}: modify problem state
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-131}

\begin{itemize}
\tightlist
\item
  Reveals shared skeleton behind all greedy algorithms
\item
  Simplifies learning, ``different bodies, same bones''
\item
  Encourages reusable code via template-based design
\item
  Helps debug logic: if it fails, test greedy-choice property
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-31}

If a problem has:

\begin{itemize}
\tightlist
\item
  Greedy-choice property: local best is part of global best
\item
  Optimal substructure: subproblem solutions are optimal
\end{itemize}

Then any algorithm following this template produces a global optimum.
Formally proved via induction on input size.

\subsubsection{Try It Yourself}\label{try-it-yourself-131}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Implement template for:

  \begin{itemize}
  \tightlist
  \item
    Coin change
  \item
    Fractional knapsack
  \item
    Interval scheduling
  \end{itemize}
\item
  Compare with brute-force or DP to confirm optimality.
\item
  Identify when greedy fails (e.g., non-canonical coin sets).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-31}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3478}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0870}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2319}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Local Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Works?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fractional Knapsack & Max value/weight & ✅ & Continuous \\
Interval Scheduling & Earliest finish & ✅ & Non-overlapping \\
Coin Change (25,10,5,1) & Largest coin ≤ remaining & ✅ & Canonical
only \\
Job Scheduling & Highest profit first & ✅ & Sorted by profit \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-39}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Selection & \(O(n \log n)\) (sort) & \(O(n)\) \\
Iteration & \(O(n)\) & \(O(1)\) \\
\end{longtable}

The Greedy Template Simulator is the skeleton key of greedy design, once
you learn its shape, every greedy algorithm looks like a familiar face.

\subsection{33 Divide \& Conquer
Skeleton}\label{divide-conquer-skeleton}

The Divide \& Conquer Skeleton captures the universal structure of
algorithms that solve big problems by splitting them into smaller,
independent pieces, solving each recursively, then combining their
results. It's the framework behind mergesort, quicksort, binary search,
and more.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-32}

Some problems are too large or complex to handle at once. Divide \&
Conquer (D\&C) solves them by splitting into smaller subproblems of the
same type, solving recursively, and combining the results into a whole.

We want a reusable template that reveals this recursive rhythm.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-32}

Every D\&C algorithm follows this triplet:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide: Break the problem into smaller subproblems.
\item
  Conquer: Solve each subproblem (often recursively).
\item
  Combine: Merge or assemble partial solutions.
\end{enumerate}

This recursion continues until a base case (small enough to solve
directly).

General Recurrence: \[
T(n) = aT!\left(\frac{n}{b}\right) + f(n)
\]

\begin{itemize}
\tightlist
\item
  \(a\): number of subproblems
\item
  \(b\): factor by which size is reduced
\item
  \(f(n)\): cost to divide/combine
\end{itemize}

\subsubsection{Example Step by Step}\label{example-step-by-step-32}

Example: Merge Sort

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide: Split array into two halves
\item
  Conquer: Recursively sort each half
\item
  Combine: Merge two sorted halves into one
\end{enumerate}

For \(n = 8\):

\begin{itemize}
\tightlist
\item
  Level 0: size 8
\item
  Level 1: size 4 + 4
\item
  Level 2: size 2 + 2 + 2 + 2
\item
  Level 3: size 1 (base case)
\end{itemize}

Each level costs \(O(n)\) → total \(O(n \log n)\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-32}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ divide\_and\_conquer(problem, base\_case, divide, combine):}
    \ControlFlowTok{if}\NormalTok{ base\_case(problem):}
        \ControlFlowTok{return}\NormalTok{ solve\_directly(problem)}
\NormalTok{    subproblems }\OperatorTok{=}\NormalTok{ divide(problem)}
\NormalTok{    solutions }\OperatorTok{=}\NormalTok{ [divide\_and\_conquer(p, base\_case, divide, combine) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ subproblems]}
    \ControlFlowTok{return}\NormalTok{ combine(solutions)}
\end{Highlighting}
\end{Shaded}

Plug in custom \texttt{divide}, \texttt{combine}, and base-case logic
for different problems.

\subsubsection{Why It Matters}\label{why-it-matters-132}

\begin{itemize}
\tightlist
\item
  Models recursive structure of many core algorithms
\item
  Reveals asymptotic pattern via recurrence
\item
  Enables parallelization (subproblems solved independently)
\item
  Balances simplicity (small subproblems) with power (reduction)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-32}

If each recursive level divides the work evenly and recombines in finite
time, then total cost is sum of all level costs: \[
T(n) = \sum_{i=0}^{\log_b n} a^i \cdot f!\left(\frac{n}{b^i}\right)
\] Master Theorem or tree expansion shows convergence to
\(O(n^{\log_b a})\) or \(O(n \log n)\), depending on \(f(n)\).

Correctness follows by induction: each subproblem solved optimally ⇒
combined result optimal.

\subsubsection{Try It Yourself}\label{try-it-yourself-132}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write a D\&C template for:

  \begin{itemize}
  \tightlist
  \item
    Binary Search
  \item
    Merge Sort
  \item
    Karatsuba Multiplication
  \end{itemize}
\item
  Identify \(a\), \(b\), \(f(n)\) for each.
\item
  Solve their recurrences with Master Theorem.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-32}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Algorithm & \(a\) & \(b\) & \(f(n)\) & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Search & 1 & 2 & 1 & \(O(\log n)\) \\
Merge Sort & 2 & 2 & \(n\) & \(O(n \log n)\) \\
Quick Sort & 2 & 2 & \(n\) (expected) & \(O(n \log n)\) \\
Karatsuba & 3 & 2 & \(n\) & \(O(n^{\log_2 3})\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-40}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Recursive calls & \(O(n)\) to \(O(n \log n)\) & \(O(\log n)\) (stack) \\
Combine & \(O(f(n))\) & depends on merging \\
\end{longtable}

The Divide \& Conquer Skeleton is the heartbeat of recursion, a rhythm
of divide, solve, combine, pulsing through the core of algorithmic
design.

\subsection{34 Backtracking Maze Solver}\label{backtracking-maze-solver}

The Backtracking Maze Solver illustrates the backtracking paradigm,
exploring all possible paths through a search space, stepping forward
when valid, and undoing moves when a dead end is reached. It's the
classic model for recursive search and constraint satisfaction.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-33}

We want to find a path from start to goal in a maze or search space
filled with constraints. Brute force would try every path blindly;
backtracking improves on this by pruning paths as soon as they become
invalid.

This approach powers solvers for mazes, Sudoku, N-Queens, and
combinatorial search problems.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-33}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start at the initial position.
\item
  Try a move (north, south, east, west).
\item
  If move is valid, mark position and recurse from there.
\item
  If stuck, backtrack: undo last move and try a new one.
\item
  Stop when goal is reached or all paths are explored.
\end{enumerate}

The algorithm is depth-first in nature, it explores one branch fully
before returning.

\subsubsection{Example Step by Step}\label{example-step-by-step-33}

Maze (Grid Example)

\begin{verbatim}
S . . #
# . # .
. . . G
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Start at S (0,0), Goal at G (2,3)
\item
  Move right, down, or around obstacles (\#)
\item
  Mark visited cells
\item
  When trapped, step back and try another path
\end{itemize}

Path Found: S → (0,1) → (1,1) → (2,1) → (2,2) → G

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-33}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ solve\_maze(maze, x, y, goal):}
    \ControlFlowTok{if}\NormalTok{ (x, y) }\OperatorTok{==}\NormalTok{ goal:}
        \ControlFlowTok{return} \VariableTok{True}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ valid\_move(maze, x, y):}
        \ControlFlowTok{return} \VariableTok{False}
\NormalTok{    maze[x][y] }\OperatorTok{=} \StringTok{\textquotesingle{}V\textquotesingle{}}  \CommentTok{\# Mark visited}
    \ControlFlowTok{for}\NormalTok{ dx, dy }\KeywordTok{in}\NormalTok{ [(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), (}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), (}\DecValTok{0}\NormalTok{,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{), (}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)]:}
        \ControlFlowTok{if}\NormalTok{ solve\_maze(maze, x}\OperatorTok{+}\NormalTok{dx, y}\OperatorTok{+}\NormalTok{dy, goal):}
            \ControlFlowTok{return} \VariableTok{True}
\NormalTok{    maze[x][y] }\OperatorTok{=} \StringTok{\textquotesingle{}.\textquotesingle{}}  \CommentTok{\# Backtrack}
    \ControlFlowTok{return} \VariableTok{False}
\end{Highlighting}
\end{Shaded}

The recursion explores all paths, marking and unmarking as it goes.

\subsubsection{Why It Matters}\label{why-it-matters-133}

\begin{itemize}
\tightlist
\item
  Demonstrates search with undoing
\item
  Foundational for DFS, constraint satisfaction, puzzle solving
\item
  Illustrates state exploration and recursive pruning
\item
  Framework for N-Queens, Sudoku, graph coloring
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-33}

By exploring all valid moves recursively:

\begin{itemize}
\tightlist
\item
  Every feasible path is eventually checked.
\item
  Infeasible branches terminate early due to validity checks.
\item
  Backtracking guarantees all combinations are explored once.
\end{itemize}

Thus, completeness is ensured, and if a path exists, it will be found.

\subsubsection{Try It Yourself}\label{try-it-yourself-133}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a 4×4 maze with one solution.
\item
  Run backtracking manually, marking path and undoing wrong turns.
\item
  Modify rules (e.g., diagonal moves allowed).
\item
  Compare runtime with BFS (which finds shortest path).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-33}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Maze & Solution Found & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Open grid & Yes & Path straight to goal \\
Maze with block & Yes & Backs up and reroutes \\
No path & No & Exhausts all options \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-41}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Search & O(4ⁿ) worst-case & O(n) recursion stack \\
\end{longtable}

(n = number of cells)

Pruning and constraints reduce practical cost.

The Backtracking Maze Solver is a journey of trial and error, a guided
wanderer exploring paths, retreating gracefully, and finding solutions
hidden in the labyrinth.

\subsection{35 Karatsuba Multiplication}\label{karatsuba-multiplication}

The Karatsuba Multiplication algorithm is a divide-and-conquer technique
that multiplies two large numbers faster than the classical grade-school
method. It reduces the multiplication count from 4 to 3 per recursive
step, improving complexity from O(n²) to approximately O(n¹·⁵⁸⁵).

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-34}

When multiplying large numbers (or polynomials), the standard approach
performs every pairwise digit multiplication, O(n²) work for n-digit
numbers. Karatsuba observed that some of this work is redundant. By
reusing partial results cleverly, we can cut down the number of
multiplications and gain speed.

This is the foundation of many fast arithmetic algorithms and symbolic
computation libraries.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-34}

Given two n-digit numbers:

\[
x = 10^{m} \cdot a + b \
y = 10^{m} \cdot c + d
\]

where ( a, b, c, d ) are roughly n/2-digit halves of x and y.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compute three products:

  \begin{itemize}
  \tightlist
  \item
    ( p\_1 = a \cdot c )
  \item
    ( p\_2 = b \cdot d )
  \item
    ( p\_3 = (a + b)(c + d) )
  \end{itemize}
\item
  Combine results using: \[
  x \cdot y = 10^{2m} \cdot p_1 + 10^{m} \cdot (p_3 - p_1 - p_2) + p_2
  \]
\end{enumerate}

This reduces recursive multiplications from 4 to 3.

\subsubsection{Example Step by Step}\label{example-step-by-step-34}

Multiply 12 × 34.

Split:

\begin{itemize}
\tightlist
\item
  a = 1, b = 2
\item
  c = 3, d = 4
\end{itemize}

Compute:

\begin{itemize}
\tightlist
\item
  ( p\_1 = 1 \times 3 = 3 )
\item
  ( p\_2 = 2 \times 4 = 8 )
\item
  ( p\_3 = (1 + 2)(3 + 4) = 3 \times 7 = 21 )
\end{itemize}

Combine: \[
(10^{2}) \cdot 3 + 10 \cdot (21 - 3 - 8) + 8 = 300 + 100 + 8 = 408
\]

So 12 × 34 = 408 (correct).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-34}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ karatsuba(x, y):}
    \ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}} \DecValTok{10} \KeywordTok{or}\NormalTok{ y }\OperatorTok{\textless{}} \DecValTok{10}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ x }\OperatorTok{*}\NormalTok{ y}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(}\BuiltInTok{len}\NormalTok{(}\BuiltInTok{str}\NormalTok{(x)), }\BuiltInTok{len}\NormalTok{(}\BuiltInTok{str}\NormalTok{(y)))}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ n }\OperatorTok{//} \DecValTok{2}
\NormalTok{    a, b }\OperatorTok{=} \BuiltInTok{divmod}\NormalTok{(x, }\DecValTok{10}\ErrorTok{m}\NormalTok{)}
\NormalTok{    c, d }\OperatorTok{=} \BuiltInTok{divmod}\NormalTok{(y, }\DecValTok{10}\ErrorTok{m}\NormalTok{)}
\NormalTok{    p1 }\OperatorTok{=}\NormalTok{ karatsuba(a, c)}
\NormalTok{    p2 }\OperatorTok{=}\NormalTok{ karatsuba(b, d)}
\NormalTok{    p3 }\OperatorTok{=}\NormalTok{ karatsuba(a }\OperatorTok{+}\NormalTok{ b, c }\OperatorTok{+}\NormalTok{ d)}
    \ControlFlowTok{return}\NormalTok{ p1 }\OperatorTok{*} \DecValTok{10}\NormalTok{(}\DecValTok{2}\OperatorTok{*}\NormalTok{m) }\OperatorTok{+}\NormalTok{ (p3 }\OperatorTok{{-}}\NormalTok{ p1 }\OperatorTok{{-}}\NormalTok{ p2) }\OperatorTok{*} \DecValTok{10}\ErrorTok{m} \OperatorTok{+}\NormalTok{ p2}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-134}

\begin{itemize}
\tightlist
\item
  First sub-quadratic multiplication algorithm
\item
  Basis for advanced methods (Toom--Cook, FFT-based)
\item
  Applies to integers, polynomials, big-number arithmetic
\item
  Showcases power of divide and conquer
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-34}

The product expansion is:

\[
(a \cdot 10^m + b)(c \cdot 10^m + d) = a c \cdot 10^{2m} + (a d + b c)10^m + b d
\]

Observe: \[
(a + b)(c + d) = ac + ad + bc + bd
\]

Thus: \[
ad + bc = (a + b)(c + d) - ac - bd
\]

Karatsuba leverages this identity to compute ( ad + bc ) without a
separate multiplication.

Recurrence: \[
T(n) = 3T(n/2) + O(n)
\] Solution: \(T(n) = O(n^{\log_2 3}) \approx O(n^{1.585})\)

\subsubsection{Try It Yourself}\label{try-it-yourself-134}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiply 1234 × 5678 using Karatsuba steps.
\item
  Compare with grade-school multiplication count.
\item
  Visualize recursive calls as a tree.
\item
  Derive recurrence and verify complexity.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-34}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
x & y & Result & Method \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
12 & 34 & 408 & Works \\
123 & 456 & 56088 & Works \\
9999 & 9999 & 99980001 & Works \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-42}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Multiplication & O(n¹·⁵⁸⁵) & O(n) \\
Base case & O(1) & O(1) \\
\end{longtable}

Karatsuba Multiplication reveals the magic of algebraic rearrangement,
using one clever identity to turn brute-force arithmetic into an
elegant, faster divide-and-conquer dance.

\subsection{36 DP State Diagram Example}\label{dp-state-diagram-example}

The DP State Diagram Example introduces the idea of representing dynamic
programming (DP) problems as graphs of states connected by transitions.
It's a visual and structural way to reason about overlapping
subproblems, dependencies, and recurrence relations.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-35}

Dynamic programming problems often involve a set of subproblems that
depend on one another. Without a clear mental model, it's easy to lose
track of which states rely on which others.

A state diagram helps us:

\begin{itemize}
\tightlist
\item
  Visualize states as nodes
\item
  Show transitions as directed edges
\item
  Understand dependency order for iteration or recursion
\end{itemize}

This builds intuition for state definition, transition logic, and
evaluation order.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-35}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define the state, what parameters represent a subproblem (e.g., index,
  capacity, sum).
\item
  Draw each state as a node.
\item
  Add edges to show transitions between states.
\item
  Assign recurrence along edges: \[
  dp[\text{state}] = \text{combine}(dp[\text{previous states}])
  \]
\item
  Solve by topological order (bottom-up) or memoized recursion
  (top-down).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-35}

Example: Fibonacci Sequence

\[
F(n) = F(n-1) + F(n-2)
\]

State diagram:

\begin{verbatim}
F(5)
↙   ↘
F(4) F(3)
↙↘   ↙↘
F(3)F(2)F(2)F(1)
\end{verbatim}

Each node = state \texttt{F(k)} Edges = dependencies on \texttt{F(k-1)}
and \texttt{F(k-2)}

Observation: Many states repeat, shared subproblems suggest memoization
or bottom-up DP.

Another Example: 0/1 Knapsack

State: \texttt{dp{[}i{]}{[}w{]}} = max value using first i items,
capacity w. Transitions:

\begin{itemize}
\tightlist
\item
  Include item i:
  \texttt{dp{[}i-1{]}{[}w-weight{[}i{]}{]}\ +\ value{[}i{]}}
\item
  Exclude item i: \texttt{dp{[}i-1{]}{[}w{]}}
\end{itemize}

Diagram: a grid of states, each cell connected from previous row and
shifted left.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-35}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib\_dp(n):}
\NormalTok{    dp }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{        dp.append(dp[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ dp[i}\OperatorTok{{-}}\DecValTok{2}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ dp[n]}
\end{Highlighting}
\end{Shaded}

Each entry \texttt{dp{[}i{]}} represents a state, filled based on prior
dependencies.

\subsubsection{Why It Matters}\label{why-it-matters-135}

\begin{itemize}
\tightlist
\item
  Makes DP visual and tangible
\item
  Clarifies dependency direction (acyclic structure)
\item
  Ensures correct order of computation
\item
  Serves as blueprint for bottom-up or memoized implementation
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-35}

If a problem's structure can be represented as a DAG of states, and:

\begin{itemize}
\tightlist
\item
  Every state's value depends only on earlier states
\item
  Base states are known
\end{itemize}

Then by evaluating nodes in topological order, we guarantee correctness,
each subproblem is solved after its dependencies.

This matches mathematical induction over recurrence depth.

\subsubsection{Try It Yourself}\label{try-it-yourself-135}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw state diagram for Fibonacci.
\item
  Draw grid for 0/1 Knapsack (rows = items, cols = capacity).
\item
  Visualize transitions for Coin Change (ways to make sum).
\item
  Trace evaluation order bottom-up.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-35}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & State & Transition & Diagram Shape \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fibonacci & dp{[}i{]} & dp{[}i-1{]}+dp{[}i-2{]} & Chain \\
Knapsack & dp{[}i{]}{[}w{]} & max(include, exclude) & Grid \\
Coin Change & dp{[}i{]}{[}s{]} &
dp{[}i-1{]}{[}s{]}+dp{[}i{]}{[}s-coin{]} & Lattice \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-43}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Diagram construction & O(n²) (visual) & O(n²) \\
DP evaluation & O(n·m) typical & O(n·m) \\
\end{longtable}

The DP State Diagram turns abstract recurrences into maps of reasoning,
every arrow a dependency, every node a solved step, guiding you from
base cases to the final solution.

\subsection{37 DP Table Visualization}\label{dp-table-visualization}

The DP Table Visualization is a way to make dynamic programming
tangible, turning states and transitions into a clear table you can
fill, row by row or column by column. Each cell represents a subproblem,
and the process of filling it shows the algorithm's structure.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-36}

Dynamic programming can feel abstract when written as recurrences. A
table transforms that abstraction into something concrete:

\begin{itemize}
\tightlist
\item
  Rows and columns correspond to subproblem parameters
\item
  Cell values show computed solutions
\item
  Filling order reveals dependencies
\end{itemize}

This approach is especially powerful for tabulation (bottom-up DP).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-36}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define your DP state (e.g., \texttt{dp{[}i{]}{[}j{]}} = best value up
  to item i and capacity j).
\item
  Initialize base cases (first row/column).
\item
  Iterate through the table in dependency order.
\item
  Apply recurrence at each cell: \[
  dp[i][j] = \text{combine}(dp[i-1][j], dp[i-1][j-w_i] + v_i)
  \]
\item
  Final cell gives the answer (often bottom-right).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-36}

Example: 0/1 Knapsack

Items:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Item & Weight & Value \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 1 & 15 \\
2 & 3 & 20 \\
3 & 4 & 30 \\
\end{longtable}

Capacity = 4

State: \texttt{dp{[}i{]}{[}w{]}} = max value with first i items,
capacity w.

Recurrence: \[
dp[i][w] = \max(dp[i-1][w], dp[i-1][w - w_i] + v_i)
\]

DP Table:

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
\(i / w\) & 0 & 1 & 2 & 3 & 4 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 15 & 15 & 15 & 15 \\
2 & 0 & 15 & 15 & 20 & 35 \\
3 & 0 & 15 & 15 & 20 & 35 \\
\end{longtable}

Final answer: 35 (items 1 and 2)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-36}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ knapsack(weights, values, W):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(weights)}
\NormalTok{    dp }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\NormalTok{(W}\OperatorTok{+}\DecValTok{1}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n}\OperatorTok{+}\DecValTok{1}\NormalTok{)]}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
        \ControlFlowTok{for}\NormalTok{ w }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(W}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
            \ControlFlowTok{if}\NormalTok{ weights[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}=}\NormalTok{ w:}
\NormalTok{                dp[i][w] }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(dp[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{][w],}
\NormalTok{                               dp[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{][w}\OperatorTok{{-}}\NormalTok{weights[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]] }\OperatorTok{+}\NormalTok{ values[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{])}
            \ControlFlowTok{else}\NormalTok{:}
\NormalTok{                dp[i][w] }\OperatorTok{=}\NormalTok{ dp[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{][w]}
    \ControlFlowTok{return}\NormalTok{ dp}
\end{Highlighting}
\end{Shaded}

Each \texttt{dp{[}i{]}{[}w{]}} is one table cell, filled in increasing
order of i and w.

\subsubsection{Why It Matters}\label{why-it-matters-136}

\begin{itemize}
\tightlist
\item
  Turns recurrence into geometry
\item
  Makes dependencies visible and traceable
\item
  Clarifies filling order (row-wise, diagonal, etc.)
\item
  Serves as debugging tool and teaching aid
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-36}

The table order ensures every subproblem is solved after its
dependencies. By induction:

\begin{itemize}
\tightlist
\item
  Base row/column initialized correctly
\item
  Each cell built from valid earlier states
\item
  Final cell accumulates optimal solution
\end{itemize}

This is equivalent to a topological sort on the DP dependency graph.

\subsubsection{Try It Yourself}\label{try-it-yourself-136}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw the DP table for Coin Change (number of ways).
\item
  Fill row by row.
\item
  Trace dependencies with arrows.
\item
  Mark the path that contributes to the final answer.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-36}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & State & Fill Order & Output \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Knapsack & dp{[}i{]}{[}w{]} & Row-wise & Max value \\
LCS & dp{[}i{]}{[}j{]} & Diagonal & LCS length \\
Edit Distance & dp{[}i{]}{[}j{]} & Row/col & Min ops \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-44}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Filling table & O(n·m) & O(n·m) \\
Traceback (optional) & O(n+m) & O(1) \\
\end{longtable}

The DP Table Visualization is the grid view of recursion, a landscape of
subproblems, each solved once, all leading toward the final cell that
encodes the complete solution.

\subsection{38 Recursive Subproblem Tree
Demo}\label{recursive-subproblem-tree-demo}

The Recursive Subproblem Tree Demo shows how a dynamic programming
problem expands into a tree of subproblems. It visualizes recursion
structure, repeated calls, and where memoization or tabulation can save
redundant work.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-37}

When writing a recursive solution, the same subproblems are often solved
multiple times. Without visualizing this, we may not realize how much
overlap occurs.

By drawing the recursion as a subproblem tree, we can:

\begin{itemize}
\tightlist
\item
  Identify repeated nodes (duplicate work)
\item
  Understand recursion depth
\item
  Decide between memoization (top-down) or tabulation (bottom-up)
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-37}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start from the root: the full problem (e.g., \texttt{F(n)}).
\item
  Expand recursively into smaller subproblems (children).
\item
  Continue until base cases (leaves).
\item
  Observe repeated nodes (same subproblem appearing multiple times).
\item
  Replace repeated computations with a lookup in a table.
\end{enumerate}

The resulting structure is a tree that becomes a DAG after memoization.

\subsubsection{Example Step by Step}\label{example-step-by-step-37}

Example: Fibonacci (Naive Recursive)

\[
F(n) = F(n-1) + F(n-2)
\]

For \(n = 5\):

\begin{verbatim}
        F(5)
       /    \
    F(4)    F(3)
   /   \    /   \
 F(3) F(2) F(2) F(1)
 / \
F(2) F(1)
\end{verbatim}

Repeated nodes: \texttt{F(3)}, \texttt{F(2)} Memoization would store
these results and reuse them.

With Memoization (Tree Collapsed):

\begin{verbatim}
      F(5)
     /   \
   F(4)  F(3)
\end{verbatim}

Each node computed once, repeated calls replaced by cache lookups.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-37}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib(n, memo}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
    \ControlFlowTok{if}\NormalTok{ memo }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{        memo }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{if}\NormalTok{ n }\KeywordTok{in}\NormalTok{ memo:}
        \ControlFlowTok{return}\NormalTok{ memo[n]}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ n}
\NormalTok{    memo[n] }\OperatorTok{=}\NormalTok{ fib(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, memo) }\OperatorTok{+}\NormalTok{ fib(n}\OperatorTok{{-}}\DecValTok{2}\NormalTok{, memo)}
    \ControlFlowTok{return}\NormalTok{ memo[n]}
\end{Highlighting}
\end{Shaded}

The memo dictionary turns the recursion tree into a DAG.

\subsubsection{Why It Matters}\label{why-it-matters-137}

\begin{itemize}
\tightlist
\item
  Exposes hidden redundancy in recursive algorithms
\item
  Motivates memoization (cache results)
\item
  Shows connection between recursion and iteration
\item
  Visual tool for understanding time complexity
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-37}

Let \(T(n)\) be the recursion tree size.

Naive recursion for Fibonacci: \[
T(n) = T(n-1) + T(n-2) + 1
\] ≈ \(O(2^n)\) calls

With memoization, each subproblem computed once: \[
T(n) = O(n)
\]

Proof by induction:

\begin{itemize}
\tightlist
\item
  Base case \(n=1\): trivial
\item
  Inductive step: if all smaller values memoized, reuse ensures
  constant-time lookups per state
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-137}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw the recursion tree for Fibonacci(6).
\item
  Count repeated nodes.
\item
  Add a memo table and redraw as DAG.
\item
  Apply same technique to factorial or grid path problems.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-37}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Function & Naive Calls & Memoized Calls & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
fib(5) & 15 & 6 & O(2ⁿ) → O(n) \\
fib(10) & 177 & 11 & O(2ⁿ) → O(n) \\
fib(20) & 21891 & 21 & O(2ⁿ) → O(n) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-45}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Naive recursion & O(2ⁿ) & O(n) \\
With memoization & O(n) & O(n) \\
\end{longtable}

The Recursive Subproblem Tree Demo turns hidden recursion into a
picture, every branch a computation, every repeated node a chance to
save time, and every cache entry a step toward efficiency.

\subsection{39 Greedy Choice
Visualization}\label{greedy-choice-visualization}

The Greedy Choice Visualization helps you see how greedy algorithms make
decisions step by step, choosing the locally optimal option at each
point and committing to it. By tracing choices visually, you can verify
whether the greedy strategy truly leads to a global optimum.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-38}

A greedy algorithm always chooses the best immediate option. But not
every problem supports this approach, some require backtracking or DP.
To know when greediness works, we need to see the chain of choices and
their effects.

A greedy choice diagram reveals:

\begin{itemize}
\tightlist
\item
  What each local decision looks like
\item
  How each choice affects remaining subproblems
\item
  Whether local optima accumulate into a global optimum
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-38}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with the full problem (e.g., a set of intervals, coins, or
  items).
\item
  Sort or prioritize by a greedy criterion (e.g., largest value,
  earliest finish).
\item
  Pick the best option currently available.
\item
  Eliminate incompatible elements (conflicts, overlaps).
\item
  Repeat until no valid choices remain.
\item
  Visualize each step as a growing path or sequence.
\end{enumerate}

The resulting picture shows a selection frontier, how choices narrow
possibilities.

\subsubsection{Example Step by Step}\label{example-step-by-step-38}

Example 1: Interval Scheduling

Goal: select max non-overlapping intervals.

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Interval & Start & End \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 1 & 4 \\
B & 3 & 5 \\
C & 0 & 6 \\
D & 5 & 7 \\
E & 8 & 9 \\
\end{longtable}

Greedy Rule: Choose earliest finish time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort by finish → A(1--4), B(3--5), C(0--6), D(5--7), E(8--9)
\item
  Pick A → remove overlaps (B, C)
\item
  Next pick D (5--7)
\item
  Next pick E (8--9)
\end{enumerate}

Visualization:

\begin{verbatim}
Timeline: 0---1---3---4---5---7---8---9
           [A]     [D]      [E]
\end{verbatim}

Total = 3 intervals → optimal.

Example 2: Fractional Knapsack

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Item & Value & Weight & Ratio \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 60 & 10 & 6 \\
2 & 100 & 20 & 5 \\
3 & 120 & 30 & 4 \\
\end{longtable}

Greedy Rule: Max value/weight ratio Visualization: pick items in
decreasing ratio order → 1, 2, part of 3.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-38}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ greedy\_choice(items, key):}
\NormalTok{    items }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(items, key}\OperatorTok{=}\NormalTok{key, reverse}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    chosen }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ it }\KeywordTok{in}\NormalTok{ items:}
        \ControlFlowTok{if}\NormalTok{ valid(it, chosen):}
\NormalTok{            chosen.append(it)}
    \ControlFlowTok{return}\NormalTok{ chosen}
\end{Highlighting}
\end{Shaded}

By logging or plotting at each iteration, you can visualize how the
solution grows.

\subsubsection{Why It Matters}\label{why-it-matters-138}

\begin{itemize}
\tightlist
\item
  Shows local vs global tradeoffs visually
\item
  Confirms greedy-choice property (local best = globally best)
\item
  Helps diagnose greedy failures (where path deviates from optimum)
\item
  Strengthens understanding of problem structure
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-38}

A greedy algorithm works if:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Greedy-choice property: local best can lead to global best.
\item
  Optimal substructure: optimal solution of whole contains optimal
  solutions of parts.
\end{enumerate}

Visualization helps verify these conditions, if each chosen step leaves
a smaller problem that is still optimally solvable by the same rule, the
algorithm is correct.

\subsubsection{Try It Yourself}\label{try-it-yourself-138}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw intervals and apply earliest-finish greedy rule.
\item
  Visualize coin selections for greedy coin change.
\item
  Try a counterexample where greedy fails (e.g., coin set \{4,3,1\}).
\item
  Plot selection order to see divergence from optimum.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-38}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3151}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3288}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0822}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2740}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Greedy Rule
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Works?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Interval Scheduling & Earliest finish & Yes & Optimal \\
Fractional Knapsack & Max ratio & Yes & Continuous fractions \\
Coin Change (25,10,5,1) & Largest coin ≤ remaining & Yes & Canonical \\
Coin Change (4,3,1) & Largest coin ≤ remaining & No & Not canonical \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-46}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sort elements & O(n log n) & O(n) \\
Selection loop & O(n) & O(1) \\
\end{longtable}

The Greedy Choice Visualization transforms abstract decision logic into
a picture, a timeline or path that shows exactly how local choices
unfold into (or away from) the global goal.

\subsection{40 Amortized Merge Demo}\label{amortized-merge-demo}

The Amortized Merge Demo illustrates how expensive operations can appear
cheap when averaged over a long sequence. By analyzing total cost across
all steps, we reveal why some algorithms with occasional heavy work
still run efficiently overall.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-39}

Some data structures or algorithms perform occasional costly operations
(like merging arrays, resizing tables, or rebuilding heaps). If we only
look at worst-case time per step, they seem inefficient, but amortized
analysis shows that, over many operations, the \emph{average} cost per
operation stays low.

This method explains why dynamic arrays, union-find, and incremental
merges remain efficient.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-39}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Perform a sequence of operations ( O\_1, O\_2, \ldots, O\_n ).
\item
  Some are cheap (constant time), some are expensive (linear or log).
\item
  Compute total cost over all ( n ) operations.
\item
  Divide total by ( n ) → amortized cost per operation.
\end{enumerate}

Amortized analysis tells us: \[
\text{Amortized cost} = \frac{\text{Total cost over sequence}}{n}
\]

Even if a few operations are expensive, their cost is ``spread out''
across many cheap ones.

\subsubsection{Example Step by Step}\label{example-step-by-step-39}

Example: Dynamic Array Doubling

Suppose we double the array each time it's full.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1864}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1356}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1864}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2373}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2542}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Capacity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Actual Cost
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Total Elements
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cumulative Cost
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert 1--1 & 1 & 1 & 1 & 1 \\
Insert 2--2 & 2 & 2 & 2 & 3 \\
Insert 3--4 & 4 & 3 & 3 & 6 \\
Insert 4--4 & 4 & 1 & 4 & 7 \\
Insert 5--8 & 8 & 5 & 5 & 12 \\
Insert 6--8 & 8 & 1 & 6 & 13 \\
Insert 7--8 & 8 & 1 & 7 & 14 \\
Insert 8--8 & 8 & 1 & 8 & 15 \\
Insert 9--16 & 16 & 9 & 9 & 24 \\
\end{longtable}

Total cost (for 9 inserts) = 24 Amortized cost = 24 / 9 ≈ 2.67 ≈ O(1)

So although some inserts cost O(n), the average cost per insert = O(1).

Example: Amortized Merge in Union-Find

When combining sets, always attach the smaller tree to the larger one.
Each element's depth increases at most O(log n) times → total cost O(n
log n).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-39}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ dynamic\_array\_append(arr, x, capacity):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{==}\NormalTok{ capacity:}
\NormalTok{        capacity }\OperatorTok{*=} \DecValTok{2}  \CommentTok{\# double size}
\NormalTok{        arr.extend([}\VariableTok{None}\NormalTok{]}\OperatorTok{*}\NormalTok{(capacity }\OperatorTok{{-}} \BuiltInTok{len}\NormalTok{(arr)))  }\CommentTok{\# copy cost = len(arr)}
\NormalTok{    arr[}\BuiltInTok{len}\NormalTok{(arr)}\OperatorTok{//}\DecValTok{2}\NormalTok{] }\OperatorTok{=}\NormalTok{ x}
    \ControlFlowTok{return}\NormalTok{ arr, capacity}
\end{Highlighting}
\end{Shaded}

This simulates doubling capacity, where copy cost = current array size.

\subsubsection{Why It Matters}\label{why-it-matters-139}

\begin{itemize}
\tightlist
\item
  Explains hidden efficiency behind resizing structures
\item
  Shows why occasional spikes don't ruin performance
\item
  Foundation for analyzing stacks, queues, hash tables
\item
  Builds intuition for amortized O(1) operations
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-39}

Consider dynamic array resizing:

\begin{itemize}
\tightlist
\item
  Every element gets moved at most once per doubling.
\item
  Over n insertions, total copies ≤ 2n.
\end{itemize}

Thus, \[
\text{Total cost} = O(n) \implies \text{Amortized cost} = O(1)
\]

This uses the aggregate method of amortized analysis:

\[
\text{Amortized cost per operation} = 
\frac{\text{total work}}{\text{\# operations}}
\]

\subsubsection{Try It Yourself}\label{try-it-yourself-139}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate 10 inserts into a doubling array.
\item
  Track total copy cost.
\item
  Plot actual vs amortized cost.
\item
  Repeat with tripling growth factor, compare average cost.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-39}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2133}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3200}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1867}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2800}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Cost Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Amortized Cost
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Array Doubling & Copy + Insert & O(1) & Spread cost \\
Union-Find Merge & Attach smaller to larger & O(α(n)) & α = inverse
Ackermann \\
Stack Push & Resize occasionally & O(1) & Average constant \\
Queue Enqueue & Circular buffer & O(1) & Rotational reuse \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-47}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Step & Worst Case & Amortized & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Single Insert & O(n) & O(1) & O(n) \\
n Inserts & O(n) & O(n) & O(n) \\
\end{longtable}

The Amortized Merge Demo reveals the calm beneath algorithmic chaos,
even when some steps are costly, the long-run rhythm stays smooth,
predictable, and efficient.

\bookmarksetup{startatroot}

\chapter{Section 5. Recurrence
Relations}\label{section-5.-recurrence-relations}

\subsection{41 Linear Recurrence Solver}\label{linear-recurrence-solver}

A Linear Recurrence Solver finds closed-form or iterative solutions for
sequences defined in terms of previous values. It transforms recursive
definitions like \(T(n) = aT(n-1) + b\) into explicit formulas, helping
us understand algorithmic growth.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-40}

Many algorithms, especially recursive ones, define running time through
a recurrence relation, for example:

\[
T(n) = a , T(n-1) + b
\]

To reason about complexity or compute exact values, we want to solve the
recurrence, converting it from a self-referential definition into a
direct expression in \(n\).

This solver provides a methodical way to do that.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-40}

A linear recurrence has the general form:

\[
T(n) = a_1T(n-1) + a_2T(n-2) + \cdots + a_kT(n-k) + f(n)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify coefficients (\(a_1, a_2, \ldots\)).
\item
  Write the characteristic equation for the homogeneous part.
\item
  Solve for roots (\(r_1, r_2, \ldots\)).
\item
  Form the homogeneous solution using those roots.
\item
  Add a particular solution if \(f(n)\) is non-zero.
\item
  Apply initial conditions to fix constants.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-40}

Example 1: \[
T(n) = 2T(n-1) + 3, \quad T(0) = 1
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Homogeneous part: \(T(n) - 2T(n-1) = 0\) → Characteristic root:
  \(r = 2\) → Homogeneous solution: \(T_h(n) = C \cdot 2^n\)
\item
  Particular solution: constant \(p\) Plug in:
  \(p = 2p + 3 \implies p = -3\)
\item
  General solution: \[
  T(n) = C \cdot 2^n - 3
  \]
\item
  Apply \(T(0)=1\): \(1 = C - 3 \implies C = 4\)
\end{enumerate}

✅ Final: \[
T(n) = 4 \cdot 2^n - 3
\]

Example 2 (Fibonacci):

\[
F(n) = F(n-1) + F(n-2), \quad F(0)=0, F(1)=1
\]

Characteristic equation: \[
r^2 - r - 1 = 0
\]

Roots: \[
r_1 = \frac{1+\sqrt{5}}{2}, \quad r_2 = \frac{1-\sqrt{5}}{2}
\]

General solution: \[
F(n) = A r_1^n + B r_2^n
\]

Solving constants yields Binet's Formula: \[
F(n) = \frac{1}{\sqrt{5}}\left[\left(\frac{1+\sqrt{5}}{2}\right)^n - \left(\frac{1-\sqrt{5}}{2}\right)^n\right]
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-40}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ linear\_recurrence(a, b, n, t0):}
\NormalTok{    T }\OperatorTok{=}\NormalTok{ [t0]}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{        T.append(a }\OperatorTok{*}\NormalTok{ T[i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ b)}
    \ControlFlowTok{return}\NormalTok{ T}
\end{Highlighting}
\end{Shaded}

This simulates a simple first-order recurrence like
\(T(n) = aT(n-1) + b\).

\subsubsection{Why It Matters}\label{why-it-matters-140}

\begin{itemize}
\tightlist
\item
  Converts recursive definitions into explicit formulas
\item
  Helps analyze time complexity for recursive algorithms
\item
  Bridges math and algorithm design
\item
  Used in DP transitions, counting problems, and algorithm analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-40}

Unroll \(T(n) = aT(n-1) + b\):

\[
T(n) = a^nT(0) + b(a^{n-1} + a^{n-2} + \cdots + 1)
\]

Sum is geometric: \[
T(n) = a^nT(0) + b \frac{a^n - 1}{a - 1}
\]

Hence the closed form is: \[
T(n) = a^nT(0) + \frac{b(a^n - 1)}{a - 1}
\]

This matches the method of characteristic equations for constant
coefficients.

\subsubsection{Try It Yourself}\label{try-it-yourself-140}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve \(T(n) = 3T(n-1) + 2, , T(0)=1\)
\item
  Solve \(T(n) = 2T(n-1) - T(n-2)\)
\item
  Compare numeric results with iterative simulation
\item
  Draw recursion tree to confirm growth trend
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-40}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Recurrence & Initial & Solution & Growth \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n)=2T(n-1)+3\) & \(T(0)=1\) & \(4 \cdot 2^n - 3\) & \(O(2^n)\) \\
\(T(n)=T(n-1)+1\) & \(T(0)=0\) & \(n\) & \(O(n)\) \\
\(T(n)=3T(n-1)\) & \(T(0)=1\) & \(3^n\) & \(O(3^n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-48}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Recursive (unrolled) & O(n) & O(n) \\
Closed-form & O(1) & O(1) \\
\end{longtable}

A Linear Recurrence Solver turns repeated dependence into explicit
growth, revealing the hidden pattern behind each recursive step.

\subsection{42 Master Theorem}\label{master-theorem}

The Master Theorem provides a direct method to analyze
divide-and-conquer recurrences, allowing you to find asymptotic bounds
without expanding or guessing. It is a cornerstone tool for
understanding recursive algorithms such as merge sort, binary search,
and Strassen's multiplication.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-41}

Many recursive algorithms can be expressed as:

\[
T(n) = a , T!\left(\frac{n}{b}\right) + f(n)
\]

where:

\begin{itemize}
\tightlist
\item
  \(a\): number of subproblems
\item
  \(b\): shrink factor (problem size per subproblem)
\item
  \(f(n)\): additional work outside recursion (combine, partition, etc.)
\end{itemize}

We want to find an asymptotic expression for \(T(n)\) by comparing
recursive cost (\(n^{\log_b a}\)) with non-recursive cost (\(f(n)\)).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-41}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write the recurrence in standard form: \[
  T(n) = a , T(n/b) + f(n)
  \]
\item
  Compute the critical exponent \(\log_b a\).
\item
  Compare \(f(n)\) with \(n^{\log_b a}\):

  \begin{itemize}
  \tightlist
  \item
    If \(f(n)\) is smaller, recursion dominates.
  \item
    If they are equal, both contribute equally.
  \item
    If \(f(n)\) is larger, the outside work dominates.
  \end{itemize}
\end{enumerate}

The theorem gives three standard cases depending on which term grows
faster.

\subsection{The Three Cases}\label{the-three-cases}

Case 1 (Recursive Work Dominates):

If \[
f(n) = O(n^{\log_b a - \varepsilon})
\] for some \(\varepsilon > 0\), then \[
T(n) = \Theta(n^{\log_b a})
\]

Case 2 (Balanced Work):

If \[
f(n) = \Theta(n^{\log_b a})
\] then \[
T(n) = \Theta(n^{\log_b a} \log n)
\]

Case 3 (Non-Recursive Work Dominates):

If \[
f(n) = \Omega(n^{\log_b a + \varepsilon})
\] and \[
a , f(n/b) \le c , f(n)
\] for some constant \(c < 1\), then \[
T(n) = \Theta(f(n))
\]

\subsubsection{Example Step by Step}\label{example-step-by-step-41}

Example 1: Merge Sort

\[
T(n) = 2T(n/2) + O(n)
\]

\begin{itemize}
\tightlist
\item
  \(a = 2\), \(b = 2\), so \(\log_b a = 1\)
\item
  \(f(n) = O(n)\)
\item
  \(f(n) = \Theta(n^{\log_b a})\) → Case 2
\end{itemize}

Result: \[
T(n) = \Theta(n \log n)
\]

Example 2: Binary Search

\[
T(n) = T(n/2) + O(1)
\]

\begin{itemize}
\tightlist
\item
  \(a = 1\), \(b = 2\), so \(\log_b a = 0\)
\item
  \(f(n) = O(1) = \Theta(n^0)\) → Case 2
\end{itemize}

Result: \[
T(n) = \Theta(\log n)
\]

Example 3: Strassen's Matrix Multiplication

\[
T(n) = 7T(n/2) + O(n^2)
\]

\begin{itemize}
\tightlist
\item
  \(a = 7\), \(b = 2\), so \(\log_2 7 \approx 2.81\)
\item
  \(f(n) = O(n^2) = O(n^{2.81 - \varepsilon})\) → Case 1
\end{itemize}

Result: \[
T(n) = \Theta(n^{\log_2 7})
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-41}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ master\_theorem(a, b, f\_exp):}
\NormalTok{    log\_term }\OperatorTok{=}\NormalTok{ math.log(a, b)}
    \ControlFlowTok{if}\NormalTok{ f\_exp }\OperatorTok{\textless{}}\NormalTok{ log\_term:}
        \ControlFlowTok{return} \SpecialStringTok{f"Theta(n\^{}}\SpecialCharTok{\{}\BuiltInTok{round}\NormalTok{(log\_term, }\DecValTok{2}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{)"}
    \ControlFlowTok{elif} \BuiltInTok{abs}\NormalTok{(f\_exp }\OperatorTok{{-}}\NormalTok{ log\_term) }\OperatorTok{\textless{}} \FloatTok{1e{-}9}\NormalTok{:}
        \ControlFlowTok{return} \SpecialStringTok{f"Theta(n\^{}}\SpecialCharTok{\{}\BuiltInTok{round}\NormalTok{(log\_term, }\DecValTok{2}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{ * log n)"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \SpecialStringTok{f"Theta(n\^{}}\SpecialCharTok{\{}\NormalTok{f\_exp}\SpecialCharTok{\}}\SpecialStringTok{)"}
\end{Highlighting}
\end{Shaded}

This helper approximates the result by comparing exponents.

\subsubsection{Why It Matters}\label{why-it-matters-141}

\begin{itemize}
\tightlist
\item
  Converts recursive definitions into asymptotic forms
\item
  Avoids repeated substitution or tree expansion
\item
  Applies to most divide-and-conquer algorithms
\item
  Clarifies when combining work dominates or not
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-41}

Expand the recurrence:

\[
T(n) = aT(n/b) + f(n)
\]

After \(k\) levels:

\[
T(n) = a^k T(n/b^k) + \sum_{i=0}^{k-1} a^i f(n/b^i)
\]

Recursion depth: \(k = \log_b n\)

Now compare total cost per level to \(n^{\log_b a}\):

\begin{itemize}
\tightlist
\item
  If \(f(n)\) grows slower, top levels dominate → Case 1
\item
  If equal, all levels contribute → Case 2
\item
  If faster, bottom level dominates → Case 3
\end{itemize}

The asymptotic result depends on which component dominates the sum.

\subsubsection{Try It Yourself}\label{try-it-yourself-141}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve \(T(n) = 3T(n/2) + n\)
\item
  Solve \(T(n) = 4T(n/2) + n^2\)
\item
  Sketch recursion trees and check which term dominates
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-41}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Recurrence & Case & Solution \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n)=2T(n/2)+n\) & Case 2 & \(\Theta(n \log n)\) \\
\(T(n)=T(n/2)+1\) & Case 2 & \(\Theta(\log n)\) \\
\(T(n)=7T(n/2)+n^2\) & Case 1 & \(\Theta(n^{\log_2 7})\) \\
\(T(n)=2T(n/2)+n^2\) & Case 3 & \(\Theta(n^2)\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2059}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3824}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4118}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Expression
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Recursive work & \(n^{\log_b a}\) & Work across recursive calls \\
Combine work & \(f(n)\) & Work per level \\
Total cost & \(\max(n^{\log_b a}, f(n))\) & Dominant term decides
growth \\
\end{longtable}

The Master Theorem serves as a blueprint for analyzing recursive
algorithms, once the recurrence is in standard form, its complexity
follows by simple comparison.

\subsection{43 Substitution Method}\label{substitution-method}

The Substitution Method is a systematic way to prove the asymptotic
bound of a recurrence by guessing a solution and then proving it by
induction. It's one of the most flexible techniques for verifying time
complexity.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-42}

Many algorithms are defined recursively, for example:

\[
T(n) = 2T(n/2) + n
\]

We often want to show that \(T(n) = O(n \log n)\) or
\(T(n) = \Theta(n^2)\). But before we can apply a theorem, we must
confirm that our guess fits.

The substitution method provides a proof framework:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Guess the asymptotic bound.
\item
  Prove it by induction.
\item
  Adjust constants if necessary.
\end{enumerate}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-42}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make a guess for \(T(n)\), typically inspired by known patterns. For
  example, for \(T(n) = 2T(n/2) + n\), guess \(T(n) = O(n \log n)\).
\item
  Write the inductive hypothesis: Assume \(T(k) \le c , k \log k\) for
  all \(k < n\).
\item
  Substitute into the recurrence: Replace recursive terms with the
  hypothesis.
\item
  Simplify and verify: Show the inequality holds for \(n\), adjusting
  constants if needed.
\item
  Conclude that the guess is valid.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-42}

Example 1:

\[
T(n) = 2T(n/2) + n
\]

Goal: Show \(T(n) = O(n \log n)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Hypothesis: \(T(k) \le c , k \log k\) for all \(k < n\)
\item
  Substitute: \(T(n) \le 2[c(n/2)\log(n/2)] + n\)
\item
  Simplify: \(= c n \log(n/2) + n\) \(= c n (\log n - 1) + n\)
  \(= c n \log n - c n + n\)
\item
  Adjust constant: If \(c \ge 1\), then \(-cn + n \le 0\), so
  \(T(n) \le c n \log n\)
\end{enumerate}

✅ Therefore, \(T(n) = O(n \log n)\).

Example 2:

\[
T(n) = 3T(n/2) + n
\]

Guess: \(T(n) = O(n^{\log_2 3})\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Hypothesis: \(T(k) \le c , k^{\log_2 3}\)
\item
  Substitute:
  \(T(n) \le 3c(n/2)^{\log_2 3} + n = 3c \cdot n^{\log_2 3} / 3 + n = c n^{\log_2 3} + n\)
\item
  Dominant term: \(n^{\log_2 3}\) ✅ \(T(n) = O(n^{\log_2 3})\)
\end{enumerate}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-42}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ substitution\_check(a, b, f\_exp, guess\_exp):}
    \ImportTok{from}\NormalTok{ math }\ImportTok{import}\NormalTok{ log}
\NormalTok{    lhs }\OperatorTok{=}\NormalTok{ a }\OperatorTok{*}\NormalTok{ (}\DecValTok{1} \OperatorTok{/}\NormalTok{ b)  guess\_exp}
\NormalTok{    rhs }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{if}\NormalTok{ lhs }\OperatorTok{\textless{}} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return} \SpecialStringTok{f"Guess n\^{}}\SpecialCharTok{\{}\NormalTok{guess\_exp}\SpecialCharTok{\}}\SpecialStringTok{ holds (Case 1)"}
    \ControlFlowTok{elif} \BuiltInTok{abs}\NormalTok{(lhs }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) }\OperatorTok{\textless{}} \FloatTok{1e{-}9}\NormalTok{:}
        \ControlFlowTok{return} \SpecialStringTok{f"Guess n\^{}}\SpecialCharTok{\{}\NormalTok{guess\_exp}\SpecialCharTok{\}}\SpecialStringTok{ log n (Case 2)"}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return} \SpecialStringTok{f"Guess n\^{}}\SpecialCharTok{\{}\NormalTok{guess\_exp}\SpecialCharTok{\}}\SpecialStringTok{ fails (try larger exponent)"}
\end{Highlighting}
\end{Shaded}

Helps verify whether a guessed exponent fits the recurrence.

\subsubsection{Why It Matters}\label{why-it-matters-142}

\begin{itemize}
\tightlist
\item
  Builds proof-based understanding of complexity
\item
  Confirms asymptotic bounds from intuition or Master Theorem
\item
  Works even when Master Theorem fails (irregular forms)
\item
  Reinforces connection between recursion and growth rate
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-42}

Let \(T(n) = aT(n/b) + f(n)\) Guess \(T(n) = O(n^{\log_b a})\).

Inductive step: \[
T(n) = aT(n/b) + f(n) \le a(c(n/b)^{\log_b a}) + f(n)
\] \[
= c n^{\log_b a} + f(n)
\]

If \(f(n)\) grows slower, \(T(n)\) remains \(O(n^{\log_b a})\) by
choosing \(c\) large enough.

\subsubsection{Try It Yourself}\label{try-it-yourself-142}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Prove \(T(n) = 2T(n/2) + n^2 = O(n^2)\)
\item
  Prove \(T(n) = T(n-1) + 1 = O(n)\)
\item
  Adjust constants to make the induction hold
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-42}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Recurrence & Guess & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n)=2T(n/2)+n\) & \(O(n\log n)\) & Correct \\
\(T(n)=T(n-1)+1\) & \(O(n)\) & Correct \\
\(T(n)=3T(n/2)+n\) & \(O(n^{\log_2 3})\) & Correct \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-4}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Effort & When to Use \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Master Theorem & Quick & Standard divide-and-conquer \\
Substitution & Moderate & Custom or irregular recurrences \\
Iteration & Detailed & Step-by-step expansion \\
\end{longtable}

The Substitution Method blends intuition with rigor, you make a good
guess, and algebra does the rest.

\subsection{44 Iteration Method}\label{iteration-method}

The Iteration Method (also called the Recursion Expansion Method) solves
recurrences by repeatedly substituting the recursive term until the
pattern becomes clear. It is a constructive way to derive closed-form or
asymptotic solutions.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-43}

Recursive algorithms often define their running time in terms of smaller
instances:

\[
T(n) = a , T(n/b) + f(n)
\]

Instead of guessing or applying a theorem, the iteration method unfolds
the recurrence layer by layer, showing exactly how cost accumulates
across recursion levels.

This method is especially helpful when \(f(n)\) follows a recognizable
pattern, like linear, quadratic, or logarithmic functions.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-43}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write down the recurrence:

  \[
  T(n) = a , T(n/b) + f(n)
  \]
\item
  Expand one level at a time:

  \[
  T(n) = a[a , T(n/b^2) + f(n/b)] + f(n)
  \]

  \[
  = a^2 T(n/b^2) + a f(n/b) + f(n)
  \]
\item
  Continue expanding \(k\) levels until the subproblem size becomes 1:

  \[
  T(n) = a^k T(n/b^k) + \sum_{i=0}^{k-1} a^i f(n/b^i)
  \]
\item
  When \(n/b^k = 1\), we have \(k = \log_b n\).
\item
  Substitute \(k = \log_b n\) to find the closed form or asymptotic
  bound.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-43}

Example 1: Merge Sort

\[
T(n) = 2T(n/2) + n
\]

Step 1: Expand

{[} {]}

Step 2: Base Case

When \(n/2^k = 1 \implies k = \log_2 n\)

So: \[
T(n) = n \cdot T(1) + n \log_2 n = O(n \log n)
\]

✅ \(T(n) = \Theta(n \log n)\)

Example 2: Binary Search

\[
T(n) = T(n/2) + 1
\]

Expand:

{[} {]}

✅ \(T(n) = O(\log n)\)

Example 3: Linear Recurrence

\[
T(n) = T(n-1) + 1
\]

Expand:

\[
T(n) = T(n-1) + 1 = T(n-2) + 2 = \cdots = T(1) + (n-1)
\]

✅ \(T(n) = O(n)\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-43}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ iterate\_recurrence(a, b, f, n):}
\NormalTok{    total }\OperatorTok{=} \DecValTok{0}
\NormalTok{    level }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ n }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{:}
\NormalTok{        total }\OperatorTok{+=}\NormalTok{ (a  level) }\OperatorTok{*}\NormalTok{ f(n }\OperatorTok{/}\NormalTok{ (b  level))}
\NormalTok{        n }\OperatorTok{/=}\NormalTok{ b}
\NormalTok{        level }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ total}
\end{Highlighting}
\end{Shaded}

This illustrates the summation process level by level.

\subsubsection{Why It Matters}\label{why-it-matters-143}

\begin{itemize}
\tightlist
\item
  Makes recursion visually transparent
\item
  Works for irregular \(f(n)\) (when Master Theorem doesn't apply)
\item
  Derives exact sums, not just asymptotic bounds
\item
  Builds intuition for recursion trees and logarithmic depth
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-43}

Each level \(i\) of the recursion contributes:

\[
a^i \cdot f(n/b^i)
\]

Total number of levels: \[
\log_b n
\]

So total cost: \[
T(n) = \sum_{i=0}^{\log_b n - 1} a^i f(n/b^i)
\]

This sum can be approximated or bounded using standard summation
techniques, depending on \(f(n)\)'s growth rate.

\subsubsection{Try It Yourself}\label{try-it-yourself-143}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve \(T(n) = 3T(n/2) + n^2\)
\item
  Solve \(T(n) = 2T(n/2) + n \log n\)
\item
  Solve \(T(n) = T(n/2) + n/2\)
\item
  Compare with Master Theorem results
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-43}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Recurrence & Solution & Growth \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n)=2T(n/2)+n\) & \(n \log n\) & \(O(n \log n)\) \\
\(T(n)=T(n/2)+1\) & \(\log n\) & \(O(\log n)\) \\
\(T(n)=T(n-1)+1\) & \(n\) & \(O(n)\) \\
\(T(n)=3T(n/2)+n^2\) & \(n^2\) & \(O(n^2)\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-5}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Expansion & \(O(\log n)\) levels & Stack depth \(O(\log n)\) \\
Summation & Depends on \(f(n)\) & Often geometric or arithmetic \\
\end{longtable}

The Iteration Method unpacks recursion into layers of work, turning a
recurrence into a concrete sum, and a sum into a clear complexity bound.

\subsection{45 Generating Function
Method}\label{generating-function-method}

The Generating Function Method transforms a recurrence relation into an
algebraic equation by encoding the sequence into a power series. Once
transformed, algebraic manipulation yields a closed-form expression or
asymptotic approximation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-44}

A recurrence defines a sequence \(T(n)\) recursively:

\[
T(n) = a_1 T(n-1) + a_2 T(n-2) + \cdots + f(n)
\]

We want to find a closed-form formula instead of computing step by step.
By representing \(T(n)\) as coefficients in a power series, we can use
algebraic tools to solve recurrences cleanly, especially linear
recurrences with constant coefficients.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-44}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define the generating function Let \[
  G(x) = \sum_{n=0}^{\infty} T(n) x^n
  \]
\item
  Multiply the recurrence by \(x^n\) and sum over all \(n\).
\item
  Use properties of sums (shifting indices, factoring constants) to
  rewrite in terms of \(G(x)\).
\item
  Solve the algebraic equation for \(G(x)\).
\item
  Expand \(G(x)\) back into a series (using partial fractions or known
  expansions).
\item
  Extract \(T(n)\) as the coefficient of \(x^n\).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-44}

Example 1: Fibonacci Sequence

\[
T(n) = T(n-1) + T(n-2), \quad T(0) = 0, ; T(1) = 1
\]

Step 1: Define generating function

\[
G(x) = \sum_{n=0}^{\infty} T(n) x^n
\]

Step 2: Multiply recurrence by \(x^n\) and sum over \(n \ge 2\):

\[
\sum_{n=2}^{\infty} T(n) x^n = \sum_{n=2}^{\infty} T(n-1)x^n + \sum_{n=2}^{\infty} T(n-2)x^n
\]

Step 3: Rewrite using shifts:

\[
G(x) - T(0) - T(1)x = x(G(x) - T(0)) + x^2 G(x)
\]

Plug in initial values \(T(0)=0, T(1)=1\):

\[
G(x) - x = xG(x) + x^2 G(x)
\]

Step 4: Solve for \(G(x)\):

\[
G(x)(1 - x - x^2) = x
\]

So:

\[
G(x) = \frac{x}{1 - x - x^2}
\]

Step 5: Expand using partial fractions to get coefficients:

\[
T(n) = \frac{1}{\sqrt{5}} \left[\left(\frac{1+\sqrt{5}}{2}\right)^n - \left(\frac{1-\sqrt{5}}{2}\right)^n\right]
\]

✅ Binet's Formula derived directly.

Example 2: \(T(n) = 2T(n-1) + 3\), \(T(0)=1\)

Let \(G(x) = \sum_{n=0}^{\infty} T(n)x^n\)

Multiply by \(x^n\) and sum over \(n \ge 1\):

\[
G(x) - T(0) = 2xG(x) + 3x \cdot \frac{1}{1-x}
\]

Simplify:

\[
G(x)(1 - 2x) = 1 + \frac{3x}{1-x}
\]

Solve and expand using partial fractions → recover closed-form:

\[
T(n) = 4 \cdot 2^n - 3
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-44}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sympy }\ImportTok{import}\NormalTok{ symbols, Function, Eq, rsolve}

\NormalTok{n }\OperatorTok{=}\NormalTok{ symbols(}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{, integer}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{T }\OperatorTok{=}\NormalTok{ Function(}\StringTok{\textquotesingle{}T\textquotesingle{}}\NormalTok{)}
\NormalTok{recurrence }\OperatorTok{=}\NormalTok{ Eq(T(n), }\DecValTok{2}\OperatorTok{*}\NormalTok{T(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+} \DecValTok{3}\NormalTok{)}
\NormalTok{solution }\OperatorTok{=}\NormalTok{ rsolve(recurrence, T(n), \{T(}\DecValTok{0}\NormalTok{): }\DecValTok{1}\NormalTok{\})}
\BuiltInTok{print}\NormalTok{(solution)  }\CommentTok{\# 4*2n {-} 3}
\end{Highlighting}
\end{Shaded}

Use \texttt{sympy.rsolve} to compute closed forms symbolically.

\subsubsection{Why It Matters}\label{why-it-matters-144}

\begin{itemize}
\tightlist
\item
  Converts recurrence relations into algebraic equations
\item
  Reveals exact closed forms, not just asymptotics
\item
  Works for non-homogeneous and constant-coefficient recurrences
\item
  Bridges combinatorics, discrete math, and algorithm analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-44}

Given a linear recurrence:

\[
T(n) - a_1T(n-1) - \cdots - a_kT(n-k) = f(n)
\]

Multiply by \(x^n\) and sum from \(n=k\) to \(\infty\):

\[
\sum_{n=k}^{\infty} T(n)x^n = a_1x \sum_{n=k}^{\infty} T(n-1)x^{n-1} + \cdots + f(x)
\]

Using index shifts, each term can be written in terms of \(G(x)\),
leading to:

\[
P(x)G(x) = Q(x)
\]

where \(P(x)\) and \(Q(x)\) are polynomials. Solving for \(G(x)\) gives
the sequence structure.

\subsubsection{Try It Yourself}\label{try-it-yourself-144}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve \(T(n)=3T(n-1)-2T(n-2)\) with \(T(0)=2, T(1)=3\).
\item
  Find \(T(n)\) if \(T(n)=T(n-1)+1\), \(T(0)=0\).
\item
  Compare your generating function with unrolled expansion.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-44}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Recurrence & Closed Form & Growth \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(T(n)=2T(n-1)+3\) & \(4 \cdot 2^n - 3\) & \(O(2^n)\) \\
\(T(n)=T(n-1)+1\) & \(n\) & \(O(n)\) \\
\(T(n)=T(n-1)+T(n-2)\) & \(\text{Binet's Formula}\) & \(O(\phi^n)\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-6}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Type & Complexity \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Transformation & Algebraic & O(k) terms \\
Solution & Symbolic (via roots) & O(k\^{}3) \\
Evaluation & Closed form & O(1) \\
\end{longtable}

The Generating Function Method turns recurrences into algebra,
summations become equations, and equations yield exact formulas.

\subsection{46 Matrix Exponentiation}\label{matrix-exponentiation}

The Matrix Exponentiation Method transforms linear recurrences into
matrix form, allowing efficient computation of terms in \(O(\log n)\)
time using fast exponentiation. It's ideal for sequences like Fibonacci,
Tribonacci, and many dynamic programming transitions.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-45}

Many recurrences follow a linear relation among previous terms, such as:

\[
T(n) = a_1 T(n-1) + a_2 T(n-2) + \cdots + a_k T(n-k)
\]

Naively computing \(T(n)\) takes \(O(n)\) steps. By encoding this
recurrence in a matrix, we can compute \(T(n)\) efficiently via
exponentiation, reducing runtime to \(O(k^3 \log n)\).

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-45}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Express the recurrence as a matrix multiplication.
\item
  Construct the transition matrix \(M\) that moves the state from
  \(n-1\) to \(n\).
\item
  Compute \(M^n\) using fast exponentiation (divide and conquer).
\item
  Multiply \(M^n\) by the initial vector to obtain \(T(n)\).
\end{enumerate}

This approach generalizes well to any linear homogeneous recurrence with
constant coefficients.

\subsubsection{Example Step by Step}\label{example-step-by-step-45}

Example 1: Fibonacci Sequence

\[
F(n) = F(n-1) + F(n-2)
\]

Define state vector:

\[
\begin{bmatrix}
F(n) \\
F(n-1)
\end{bmatrix}
=
\begin{bmatrix}
1 & 1 \\
1 & 0
\end{bmatrix}
\begin{bmatrix}
F(n-1) \\
F(n-2)
\end{bmatrix}
\]

So:

\[
M =
\begin{bmatrix}
1 & 1 [6pt]
1 & 0
\end{bmatrix}
\]

Therefore:

\[
\begin{bmatrix}
F(n) \ F(n-1)
\end{bmatrix}
= M^{n-1}
\begin{bmatrix}
F(1) \ F(0)
\end{bmatrix}
\]

Given \(F(1)=1, F(0)=0\), \[
F(n) = (M^{n-1})_{0,0}
\]

Example 2: Second-Order Recurrence

\[
T(n) = 2T(n-1) + 3T(n-2)
\]

Matrix form:

\[
\begin{bmatrix}
T(n) \\[4pt]
T(n-1)
\end{bmatrix}
=
\begin{bmatrix}
2 & 3 \\[4pt]
1 & 0
\end{bmatrix}
\begin{bmatrix}
T(n-1) \\[4pt]
T(n-2)
\end{bmatrix}
\]

So:

\[
\vec{T}(n) = M^{n-2} \vec{T}(2)
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-45}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ mat\_mult(A, B):}
    \ControlFlowTok{return}\NormalTok{ [[}\BuiltInTok{sum}\NormalTok{(A[i][k] }\OperatorTok{*}\NormalTok{ B[k][j] }\ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(A)))}
             \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(B[}\DecValTok{0}\NormalTok{]))] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(A))]}

\KeywordTok{def}\NormalTok{ mat\_pow(M, n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ M}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\NormalTok{:}
\NormalTok{        half }\OperatorTok{=}\NormalTok{ mat\_pow(M, n }\OperatorTok{//} \DecValTok{2}\NormalTok{)}
        \ControlFlowTok{return}\NormalTok{ mat\_mult(half, half)}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ mat\_mult(M, mat\_pow(M, n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{))}

\KeywordTok{def}\NormalTok{ fib\_matrix(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{0}
\NormalTok{    M }\OperatorTok{=}\NormalTok{ [[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{], [}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{]]}
\NormalTok{    Mn }\OperatorTok{=}\NormalTok{ mat\_pow(M, n }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ Mn[}\DecValTok{0}\NormalTok{][}\DecValTok{0}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\texttt{fib\_matrix(n)} computes \(F(n)\) in \(O(\log n)\).

\subsubsection{Why It Matters}\label{why-it-matters-145}

\begin{itemize}
\tightlist
\item
  Converts recursive computation into linear algebra
\item
  Enables \(O(\log n)\) computation for \(T(n)\)
\item
  Generalizes to higher-order recurrences
\item
  Common in DP transitions, Fibonacci-like sequences, and combinatorial
  counting
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-45}

The recurrence:

\[
T(n) = a_1T(n-1) + a_2T(n-2) + \cdots + a_kT(n-k)
\]

can be expressed as:

\[
\vec{T}(n) = M \cdot \vec{T}(n-1)
\]

where \(M\) is the companion matrix:

\[
M =
\begin{bmatrix}
a_1 & a_2 & \cdots & a_k \\
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & & \ddots & 0
\end{bmatrix}
\]

Repeatedly multiplying gives:

\[
\vec{T}(n) = M^{n-k} \vec{T}(k)
\]

Hence, \(T(n)\) is computed by raising \(M\) to a power, exponential
recursion becomes logarithmic multiplication.

\subsubsection{Try It Yourself}\label{try-it-yourself-145}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write matrix form for \(T(n)=3T(n-1)-2T(n-2)\)
\item
  Compute \(T(10)\) with \(T(0)=2\), \(T(1)=3\)
\item
  Implement matrix exponentiation for \(3\times3\) matrices (Tribonacci)
\item
  Compare with iterative solution runtime
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-45}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2547}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1415}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1038}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Recurrence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Matrix
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(T(n)\) / Symbol
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(F(n)=F(n-1)+F(n-2)\) &
\(\begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}\) & \(F(n)\) &
\(O(\log n)\) \\
\(T(n)=2T(n-1)+3T(n-2)\) &
\(\begin{bmatrix} 2 & 3 \\ 1 & 0 \end{bmatrix}\) & \(T(n)\) &
\(O(\log n)\) \\
\(T(n)=T(n-1)+T(n-2)+T(n-3)\) &
\(\begin{bmatrix} 1 & 1 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix}\) &
Tribonacci & \(O(\log n)\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-7}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Matrix exponentiation & \(O(k^3 \log n)\) & \(O(k^2)\) \\
Iterative recurrence & \(O(n)\) & \(O(k)\) \\
\end{longtable}

Matrix Exponentiation turns recurrence solving into matrix powering, a
bridge between recursion and linear algebra, giving exponential speed-up
with mathematical elegance.

\subsection{47 Recurrence to DP Table}\label{recurrence-to-dp-table}

The Recurrence to DP Table method converts a recursive relation into an
iterative table-based approach, removing redundant computation and
improving efficiency from exponential to polynomial time. It's a
cornerstone of Dynamic Programming.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-46}

Recursive formulas often recompute overlapping subproblems. For example:

\[
T(n) = T(n-1) + T(n-2)
\]

A naive recursive call tree grows exponentially because it recomputes
\(T(k)\) many times. By converting this recurrence into a DP table, we
compute each subproblem once and store results, achieving linear or
polynomial time.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-46}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the recurrence and base cases.
\item
  Create a table (array or matrix) to store subproblem results.
\item
  Iteratively fill the table using the recurrence formula.
\item
  Read off the final answer from the last cell.
\end{enumerate}

This technique is called tabulation, a bottom-up form of dynamic
programming.

\subsubsection{Example Step by Step}\label{example-step-by-step-46}

Example 1: Fibonacci Numbers

Recursive formula:

\[
F(n) = F(n-1) + F(n-2), \quad F(0)=0, , F(1)=1
\]

DP version:

\begin{longtable}[]{@{}lllllll@{}}
\toprule\noalign{}
n & 0 & 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
F(n) & 0 & 1 & 1 & 2 & 3 & 5 \\
\end{longtable}

Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize base cases: \texttt{F{[}0{]}=0}, \texttt{F{[}1{]}=1}
\item
  Loop from 2 to n: \texttt{F{[}i{]}\ =\ F{[}i-1{]}\ +\ F{[}i-2{]}}
\item
  Return \texttt{F{[}n{]}}
\end{enumerate}

Example 2: Coin Change (Count Ways)

Recurrence: \[
\text{ways}(n, c) = \text{ways}(n, c-1) + \text{ways}(n-\text{coin}[c], c)
\]

Convert to 2D DP table indexed by (n, c).

Example 3: Grid Paths

Recurrence: \[
P(i,j) = P(i-1,j) + P(i,j-1)
\]

DP table:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
i\j & 0 & 1 & 2 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 & 1 & 1 \\
1 & 1 & 2 & 3 \\
2 & 1 & 3 & 6 \\
\end{longtable}

Each cell = sum of top and left.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-46}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib\_dp(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return} \DecValTok{0}
\NormalTok{    dp }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ (n }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    dp[}\DecValTok{1}\NormalTok{] }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{, n }\OperatorTok{+} \DecValTok{1}\NormalTok{):}
\NormalTok{        dp[i] }\OperatorTok{=}\NormalTok{ dp[i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ dp[i }\OperatorTok{{-}} \DecValTok{2}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ dp[n]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-146}

\begin{itemize}
\tightlist
\item
  Converts exponential recursion to polynomial iteration
\item
  Avoids repeated subproblem computations
\item
  Enables space and time optimization
\item
  Forms the foundation of bottom-up dynamic programming
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-46}

Given recurrence:

\[
T(n) = a_1 T(n-1) + a_2 T(n-2) + \cdots + a_k T(n-k)
\]

Each term depends only on previously computed subproblems. So by filling
the table in increasing order, we ensure all dependencies are ready.

By induction, if base cases are correct, each computed cell is correct.

\subsubsection{Try It Yourself}\label{try-it-yourself-146}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Convert \(F(n)=F(n-1)+F(n-2)\) to a 1D DP array
\item
  Build a 2D table for grid paths \(P(i,j)=P(i-1,j)+P(i,j-1)\)
\item
  Write a DP table for factorial \(n! = n \times (n-1)!\)
\item
  Optimize space (keep only last k terms)
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-46}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1895}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.7263}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.0842}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Input
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Recurrence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Expected
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(F(5)\) & \(F(n)=F(n-1)+F(n-2)\) & 5 \\
Grid(2,2) & \(P(i,j)=P(i-1,j)+P(i,j-1)\) & 6 \\
\(n=3, coins=[1,2]\) &
\(\text{ways}(n,c)=\text{ways}(n,c-1)+\text{ways}(n-\text{coin}[c],c)\)
& 2 \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-8}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Recursive & \(O(2^n)\) & \(O(n)\) \\
DP Table & \(O(n)\) & \(O(n)\) \\
Space-Optimized DP & \(O(n)\) & \(O(1)\) \\
\end{longtable}

Transforming a recurrence into a DP table captures the essence of
dynamic programming, structure, reuse, and clarity over brute
repetition.

\subsection{48 Divide \& Combine
Template}\label{divide-combine-template}

The Divide \& Combine Template is a structural guide for solving
problems by breaking them into smaller, similar subproblems, solving
each independently, and combining their results. It's the core skeleton
behind divide-and-conquer algorithms like Merge Sort, Quick Sort, and
Karatsuba Multiplication.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-47}

Many complex problems can be decomposed into smaller copies of
themselves. Instead of solving the full instance at once, we divide it
into subproblems, solve each recursively, and combine their results.

This approach reduces complexity, promotes parallelism, and yields
recurrence relations like:

\[
T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-47}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide: Split the problem into \(a\) subproblems, each of size
  \(\frac{n}{b}\).
\item
  Conquer: Recursively solve the subproblems.
\item
  Combine: Merge their results into a full solution.
\item
  Base Case: Stop dividing when the subproblem becomes trivially small.
\end{enumerate}

This recursive structure underpins most efficient algorithms for
sorting, searching, and multiplication.

\subsubsection{Example Step by Step}\label{example-step-by-step-47}

Example 1: Merge Sort

\begin{itemize}
\tightlist
\item
  Divide: Split array into two halves
\item
  Conquer: Recursively sort each half
\item
  Combine: Merge two sorted halves
\end{itemize}

Recurrence: \[
T(n) = 2T\left(\frac{n}{2}\right) + O(n)
\]

Example 2: Karatsuba Multiplication

\begin{itemize}
\tightlist
\item
  Divide numbers into halves
\item
  Conquer with 3 recursive multiplications
\item
  Combine using linear combinations
\end{itemize}

Recurrence: \[
T(n) = 3T\left(\frac{n}{2}\right) + O(n)
\]

Example 3: Binary Search

\begin{itemize}
\tightlist
\item
  Divide the array by midpoint
\item
  Conquer on one half
\item
  Combine trivially (return result)
\end{itemize}

Recurrence: \[
T(n) = T\left(\frac{n}{2}\right) + O(1)
\]

\subsection{Generic Template
(Pseudocode)}\label{generic-template-pseudocode}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ divide\_and\_combine(problem):}
    \ControlFlowTok{if}\NormalTok{ is\_small(problem):}
        \ControlFlowTok{return}\NormalTok{ solve\_directly(problem)}
\NormalTok{    subproblems }\OperatorTok{=}\NormalTok{ divide(problem)}
\NormalTok{    results }\OperatorTok{=}\NormalTok{ [divide\_and\_combine(p) }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ subproblems]}
    \ControlFlowTok{return}\NormalTok{ combine(results)}
\end{Highlighting}
\end{Shaded}

This general template can adapt to many problem domains, arrays, trees,
graphs, geometry, and algebra.

\subsubsection{Why It Matters}\label{why-it-matters-147}

\begin{itemize}
\tightlist
\item
  Clarifies recursion structure and base case reasoning
\item
  Enables asymptotic analysis via recurrence
\item
  Lays foundation for parallel and cache-efficient algorithms
\item
  Promotes clean decomposition and reusability
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-47}

If a problem can be decomposed into independent subproblems whose
results can be merged deterministically, recursive decomposition is
valid. By induction:

\begin{itemize}
\tightlist
\item
  Base case: small input solved directly.
\item
  Inductive step: if each subproblem is solved correctly, and the
  combine step correctly merges, the final solution is correct.
\end{itemize}

Thus correctness follows from structural decomposition.

\subsubsection{Try It Yourself}\label{try-it-yourself-147}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement divide-and-conquer sum over an array.
\item
  Write recursive structure for Maximum Subarray (Kadane's divide form).
\item
  Express recurrence \(T(n)=2T(n/2)+n\) and solve via the Master
  Theorem.
\item
  Modify template for parallel processing (e.g., thread pool).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-47}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2267}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2400}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3467}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1867}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Divide
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Combine
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Complexity
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Merge Sort & Halve array & Merge sorted halves & \(O(n \log n)\) \\
Binary Search & Halve search space & Return result & \(O(\log n)\) \\
Karatsuba & Split numbers & Combine linear parts & \(O(n^{1.585})\) \\
Closest Pair (2D) & Split points & Merge cross-boundary pairs &
\(O(n \log n)\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-9}

Given: \[
T(n) = aT\left(\frac{n}{b}\right) + f(n)
\]

By the Master Theorem:

\begin{itemize}
\tightlist
\item
  If \(f(n) = O(n^{\log_b a - \epsilon})\), then
  \(T(n) = \Theta(n^{\log_b a})\)
\item
  If \(f(n) = \Theta(n^{\log_b a})\), then
  \(T(n) = \Theta(n^{\log_b a} \log n)\)
\item
  If \(f(n) = \Omega(n^{\log_b a + \epsilon})\), then
  \(T(n) = \Theta(f(n))\)
\end{itemize}

The Divide \& Combine Template provides the blueprint for recursive
problem solving, simple, elegant, and foundational across all
algorithmic domains.

\subsection{49 Memoized Recursive
Solver}\label{memoized-recursive-solver}

A Memoized Recursive Solver transforms a plain recursive solution into
an efficient one by caching intermediate results. It's the top-down
version of dynamic programming, retaining recursion's clarity while
avoiding redundant work.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-48}

Recursive algorithms often recompute the same subproblems multiple
times. Example:

\[
F(n) = F(n-1) + F(n-2)
\]

A naive recursive call tree repeats \(F(3)\), \(F(2)\), etc.,
exponentially many times. By memoizing (storing) results after the first
computation, we reuse them in \(O(1)\) time later.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-48}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define the recurrence clearly.
\item
  Add a cache (dictionary or array) to store computed results.
\item
  Before each recursive call, check the cache.
\item
  If present, return cached value.
\item
  Otherwise, compute, store, and return.
\end{enumerate}

This approach preserves recursive elegance while matching iterative DP
performance.

\subsubsection{Example Step by Step}\label{example-step-by-step-48}

Example 1: Fibonacci Numbers

Naive recursion: \[
F(n) = F(n-1) + F(n-2)
\]

Memoized version:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
n & F(n) & Cached? \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0 & Base \\
1 & 1 & Base \\
2 & 1 & Computed \\
3 & 2 & Computed \\
4 & 3 & Cached lookups \\
\end{longtable}

Time drops from \(O(2^n)\) to \(O(n)\).

Example 2: Binomial Coefficient

Recurrence: \[
C(n, k) = C(n-1, k-1) + C(n-1, k)
\]

Without memoization: exponential With memoization: \(O(nk)\)

Example 3: Coin Change

\[
\text{ways}(n) = \text{ways}(n-\text{coin}) + \text{ways}(n, \text{next})
\]

Memoize by \((n, \text{index})\) to avoid recomputing states.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-47}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib\_memo(n, memo}\OperatorTok{=}\NormalTok{\{\}):}
    \ControlFlowTok{if}\NormalTok{ n }\KeywordTok{in}\NormalTok{ memo:}
        \ControlFlowTok{return}\NormalTok{ memo[n]}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ n}
\NormalTok{    memo[n] }\OperatorTok{=}\NormalTok{ fib\_memo(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, memo) }\OperatorTok{+}\NormalTok{ fib\_memo(n}\OperatorTok{{-}}\DecValTok{2}\NormalTok{, memo)}
    \ControlFlowTok{return}\NormalTok{ memo[n]}
\end{Highlighting}
\end{Shaded}

Or explicitly pass cache:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib\_memo(n):}
\NormalTok{    memo }\OperatorTok{=}\NormalTok{ \{\}}
    \KeywordTok{def}\NormalTok{ helper(k):}
        \ControlFlowTok{if}\NormalTok{ k }\KeywordTok{in}\NormalTok{ memo:}
            \ControlFlowTok{return}\NormalTok{ memo[k]}
        \ControlFlowTok{if}\NormalTok{ k }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ k}
\NormalTok{        memo[k] }\OperatorTok{=}\NormalTok{ helper(k}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ helper(k}\OperatorTok{{-}}\DecValTok{2}\NormalTok{)}
        \ControlFlowTok{return}\NormalTok{ memo[k]}
    \ControlFlowTok{return}\NormalTok{ helper(n)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-148}

\begin{itemize}
\tightlist
\item
  Retains intuitive recursive structure
\item
  Cuts time complexity drastically
\item
  Natural stepping stone to tabulation (bottom-up DP)
\item
  Enables solving overlapping subproblem recurrences efficiently
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-48}

Let \(S\) be the set of all distinct subproblems. Without memoization,
each is recomputed exponentially many times. With memoization, each
\(s \in S\) is computed exactly once. Thus, total time = \(O(|S|)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-148}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add memoization to naive Fibonacci.
\item
  Memoize binomial coefficients \(C(n,k)\).
\item
  Apply memoization to knapsack recursion.
\item
  Count total recursive calls with and without memoization.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-48}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Naive Time & Memoized Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fibonacci(40) & \(O(2^{40})\) & \(O(40)\) \\
Binomial(20,10) & \(O(2^{20})\) & \(O(200)\) \\
Coin Change(100) & \(O(2^n)\) & \(O(n \cdot k)\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-10}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Method & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Recursive & Exponential & \(O(n)\) stack \\
Memoized & Polynomial (distinct subproblems) & Cache + stack \\
\end{longtable}

Memoization blends clarity and efficiency, recursion that remembers. It
turns naive exponential algorithms into elegant linear or polynomial
solutions with a single insight: never solve the same problem twice.

\subsection{50 Characteristic Polynomial
Solver}\label{characteristic-polynomial-solver}

The Characteristic Polynomial Solver is a powerful algebraic technique
for solving linear homogeneous recurrence relations with constant
coefficients. It expresses the recurrence in terms of polynomial roots,
giving closed-form solutions.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-49}

When faced with recurrences like:

\[
T(n) = a_1 T(n-1) + a_2 T(n-2) + \cdots + a_k T(n-k)
\]

we want a closed-form expression for \(T(n)\) instead of step-by-step
computation. The characteristic polynomial captures the recurrence's
structure, its roots determine the general form of the solution.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-49}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write the recurrence in standard form: \[
  T(n) - a_1 T(n-1) - a_2 T(n-2) - \cdots - a_k T(n-k) = 0
  \]
\item
  Replace \(T(n-i)\) with \(r^{n-i}\) to form a polynomial equation: \[
  r^k - a_1 r^{k-1} - a_2 r^{k-2} - \cdots - a_k = 0
  \]
\item
  Solve for roots \(r_1, r_2, \ldots, r_k\).
\item
  The general solution is: \[
  T(n) = c_1 r_1^n + c_2 r_2^n + \cdots + c_k r_k^n
  \]
\item
  Use initial conditions to solve for constants \(c_i\).
\end{enumerate}

If there are repeated roots, multiply by \(n^p\) for multiplicity \(p\).

\subsubsection{Example Step by Step}\label{example-step-by-step-49}

Example 1: Fibonacci

Recurrence: \[
F(n) = F(n-1) + F(n-2)
\]

Characteristic polynomial: \[
r^2 - r - 1 = 0
\]

Roots: \[
r_1 = \frac{1+\sqrt{5}}{2}, \quad r_2 = \frac{1-\sqrt{5}}{2}
\]

General solution: \[
F(n) = c_1 r_1^n + c_2 r_2^n
\]

Using \(F(0)=0\), \(F(1)=1\): \[
c_1 = \frac{1}{\sqrt{5}}, \quad c_2 = -\frac{1}{\sqrt{5}}
\]

So: \[
F(n) = \frac{1}{\sqrt{5}}\left(\left(\frac{1+\sqrt{5}}{2}\right)^n - \left(\frac{1-\sqrt{5}}{2}\right)^n\right)
\]

This is Binet's Formula.

Example 2: \(T(n) = 3T(n-1) - 2T(n-2)\)

Characteristic polynomial: \[
r^2 - 3r + 2 = 0 \implies (r-1)(r-2)=0
\]

Roots: \(r_1=1, , r_2=2\)

Solution: \[
T(n) = c_1(1)^n + c_2(2)^n = c_1 + c_2 2^n
\]

Use base cases to find \(c_1, c_2\).

Example 3: Repeated Roots

\[
T(n) = 2T(n-1) - T(n-2)
\]

Characteristic: \[
r^2 - 2r + 1 = 0 \implies (r-1)^2 = 0
\]

Solution: \[
T(n) = (c_1 + c_2 n) \cdot 1^n = c_1 + c_2 n
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-48}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sympy }\ImportTok{as}\NormalTok{ sp}

\KeywordTok{def}\NormalTok{ solve\_recurrence(coeffs, initials):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(coeffs)}
\NormalTok{    r }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{)}
\NormalTok{    poly }\OperatorTok{=}\NormalTok{ rn }\OperatorTok{{-}} \BuiltInTok{sum}\NormalTok{(coeffs[i]}\OperatorTok{*}\NormalTok{r(n}\OperatorTok{{-}}\NormalTok{i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n))}
\NormalTok{    roots }\OperatorTok{=}\NormalTok{ sp.roots(poly, r)}
\NormalTok{    r\_syms }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(roots.keys())}
\NormalTok{    c }\OperatorTok{=}\NormalTok{ sp.symbols(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{.join([}\SpecialStringTok{f\textquotesingle{}c}\SpecialCharTok{\{}\NormalTok{i}\OperatorTok{+}\DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{\textquotesingle{}} \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]))}
\NormalTok{    Tn }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(c[i]}\OperatorTok{*}\NormalTok{r\_syms[i]sp.symbols(}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n))}
\NormalTok{    equations }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ i, val }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(initials):}
\NormalTok{        equations.append(Tn.subs(sp.symbols(}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{), i) }\OperatorTok{{-}}\NormalTok{ val)}
\NormalTok{    sol }\OperatorTok{=}\NormalTok{ sp.solve(equations, c)}
    \ControlFlowTok{return}\NormalTok{ Tn.subs(sol)}
\end{Highlighting}
\end{Shaded}

Call \texttt{solve\_recurrence({[}1,\ 1{]},\ {[}0,\ 1{]})} → Binet's
formula.

\subsubsection{Why It Matters}\label{why-it-matters-149}

\begin{itemize}
\tightlist
\item
  Gives closed-form solutions for linear recurrences
\item
  Eliminates need for iteration or recursion
\item
  Connects algorithm analysis to algebra and eigenvalues
\item
  Used in runtime analysis, combinatorics, and discrete modeling
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-49}

Suppose recurrence: \[
T(n) = a_1 T(n-1) + \cdots + a_k T(n-k)
\]

Assume \(T(n) = r^n\):

\[
r^n = a_1 r^{n-1} + \cdots + a_k r^{n-k}
\]

Divide by \(r^{n-k}\):

\[
r^k = a_1 r^{k-1} + \cdots + a_k
\]

Solve polynomial for roots. Each root corresponds to an independent
solution. By linearity, the sum of independent solutions is also a
solution.

\subsubsection{Try It Yourself}\label{try-it-yourself-149}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve \(T(n)=2T(n-1)+T(n-2)\) with \(T(0)=0, T(1)=1\).
\item
  Solve \(T(n)=T(n-1)+2T(n-2)\) with \(T(0)=2, T(1)=3\).
\item
  Solve with repeated root \(r=1\).
\item
  Verify results numerically for \(n=0\ldots5\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-49}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3099}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1690}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3380}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1831}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Recurrence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Polynomial
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Roots
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Closed Form
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(F(n)=F(n-1)+F(n-2)\) & \(r^2-r-1=0\) & \(\frac{1\pm\sqrt{5}}{2}\) &
Binet \\
\(T(n)=3T(n-1)-2T(n-2)\) & \(r^2-3r+2=0\) & 1, 2 & \(c_1+c_2 2^n\) \\
\(T(n)=2T(n-1)-T(n-2)\) & \((r-1)^2=0\) & 1 (double) & \(c_1+c_2 n\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-11}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Solve polynomial & \(O(k^3)\) & \(O(k)\) \\
Evaluate closed form & \(O(1)\) & \(O(1)\) \\
\end{longtable}

The Characteristic Polynomial Solver is the algebraic heart of
recurrence solving, turning repeated patterns into exact formulas
through the power of roots and symmetry.

\bookmarksetup{startatroot}

\chapter{Section 6. Searching basics}\label{section-6.-searching-basics}

\subsection{51 Search Space Visualizer}\label{search-space-visualizer}

A Search Space Visualizer is a conceptual tool to map and understand the
entire landscape of possibilities an algorithm explores. By modeling the
search process as a tree or graph, you gain intuition about
completeness, optimality, and complexity before diving into code.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-50}

When tackling problems like optimization, constraint satisfaction, or
pathfinding, the solution isn't immediate, we must explore a space of
possibilities. Understanding how large that space is, how it grows, and
how it can be pruned is crucial for algorithmic design.

Visualizing the search space helps answer questions like:

\begin{itemize}
\tightlist
\item
  How many states are reachable?
\item
  How deep or wide is the search?
\item
  What's the branching factor?
\item
  Where does the goal lie?
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-50}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Model states as nodes. Each represents a partial or complete solution.
\item
  Model transitions as edges. Each move or decision takes you to a new
  state.
\item
  Define start and goal nodes. Typically, the root (start) expands
  toward one or more goals.
\item
  Trace the exploration. Breadth-first explores level by level;
  depth-first dives deep.
\item
  Label nodes with cost or heuristic values if applicable (for A*,
  branch-and-bound, etc.).
\end{enumerate}

This structure reveals not just correctness but also efficiency and
complexity.

\subsubsection{Example Step by Step}\label{example-step-by-step-50}

Example 1: Binary Search Tree Traversal

For array \texttt{{[}1,\ 2,\ 3,\ 4,\ 5,\ 6,\ 7{]}} and target = 6:

Search space (comparisons):

\begin{verbatim}
        4
       / \
      2   6
     / \ / \
    1  3 5  7
\end{verbatim}

Path explored: 4 → 6 (found)

Search space depth: \(\log_2 7 \approx 3\)

Example 2: 8-Queens Problem

Each level represents placing a queen in a new row. Branching factor
shrinks as constraints reduce possibilities.

Visualization shows 8! total paths, but pruning cuts most.

Example 3: Maze Solver

States = grid cells; edges = possible moves.

Visualization helps you see BFS's wavefront vs DFS's depth-first path.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-49}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\KeywordTok{def}\NormalTok{ visualize\_bfs(graph, start):}
\NormalTok{    visited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([(start, [start])])}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        node, path }\OperatorTok{=}\NormalTok{ queue.popleft()}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Visiting: }\SpecialCharTok{\{}\NormalTok{node}\SpecialCharTok{\}}\SpecialStringTok{, Path: }\SpecialCharTok{\{}\NormalTok{path}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{        visited.add(node)}
        \ControlFlowTok{for}\NormalTok{ neighbor }\KeywordTok{in}\NormalTok{ graph[node]:}
            \ControlFlowTok{if}\NormalTok{ neighbor }\KeywordTok{not} \KeywordTok{in}\NormalTok{ visited:}
\NormalTok{                queue.append((neighbor, path }\OperatorTok{+}\NormalTok{ [neighbor]))}
\end{Highlighting}
\end{Shaded}

Use on a small adjacency list to see BFS layers unfold.

\subsubsection{Why It Matters}\label{why-it-matters-150}

\begin{itemize}
\tightlist
\item
  Builds intuition about algorithm behavior
\item
  Shows breadth vs depth tradeoffs
\item
  Reveals redundant paths and pruning opportunities
\item
  Useful for teaching, debugging, and complexity estimation
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-50}

Let each state \(s \in S\) be connected by transitions \(E\). Search
algorithms define an ordering of node expansion (DFS, BFS,
heuristic-based). Visualizing \(S\) as a graph preserves:

\begin{itemize}
\tightlist
\item
  Completeness: BFS explores all finite paths
\item
  Optimality: with uniform cost, shortest path = first found
\item
  Complexity: proportional to nodes generated (often \(O(b^d)\))
\end{itemize}

\subsubsection{Try It Yourself}\label{try-it-yourself-150}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw search tree for binary search on 7 elements.
\item
  Visualize DFS vs BFS on a maze.
\item
  Build search space for placing 4 queens on a \(4\times4\) board.
\item
  Compare path counts with and without pruning.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-50}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Search Space Size & Visualization Insight \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Search & \(\log_2 n\) & Narrow, balanced \\
8-Queens & \(8!\) & Heavy pruning needed \\
Maze (10x10) & \(100\) nodes & BFS = wave, DFS = path \\
Sudoku & \(9^{81}\) & Prune with constraints \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-12}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Nodes Explored & Memory & Visualization \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
BFS & \(O(b^d)\) & \(O(b^d)\) & Tree layers \\
DFS & \(O(bd)\) & \(O(d)\) & Deep path \\
A* & \(O(b^d)\) & \(O(b^d)\) & Cost-guided frontier \\
\end{longtable}

A Search Space Visualizer turns abstract computation into geometry,
making invisible exploration visible, and helping you reason about
complexity before coding.

\subsection{52 Decision Tree Depth
Estimator}\label{decision-tree-depth-estimator}

A Decision Tree Depth Estimator helps you reason about how many
questions, comparisons, or branching choices an algorithm must make in
the worst, best, or average case. It models decision-making as a tree,
where each node is a test and each leaf is an outcome.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-51}

Any algorithm that proceeds by comparisons or conditional branches (like
sorting, searching, or classification) can be represented as a decision
tree. Analyzing its depth gives insight into:

\begin{itemize}
\tightlist
\item
  Worst-case time complexity (longest path)
\item
  Best-case time complexity (shortest path)
\item
  Average-case complexity (weighted path length)
\end{itemize}

By studying depth, we understand the minimum information needed to solve
the problem.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-51}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Represent each comparison or condition as a branching node.
\item
  Follow each branch based on true/false or less/greater outcomes.
\item
  Each leaf represents a solved instance (e.g.~sorted array, found key).
\item
  The depth = number of decisions on a path.
\item
  Maximum depth → worst-case cost.
\end{enumerate}

This model abstracts away details and focuses purely on information
flow.

\subsubsection{Example Step by Step}\label{example-step-by-step-51}

Example 1: Binary Search

\begin{itemize}
\tightlist
\item
  Each comparison halves the search space.
\item
  Decision tree has depth \(\log_2 n\).
\item
  Minimum comparisons in worst case: \(\lceil \log_2 n \rceil\).
\end{itemize}

Tree for \(n=8\) elements:

\begin{verbatim}
          [mid=4]
         /       \
     [mid=2]     [mid=6]
     /   \       /   \
   [1]   [3]   [5]   [7]
\end{verbatim}

Depth: \(3 = \log_2 8\)

Example 2: Comparison Sort

Each leaf represents a possible ordering. A valid sorting tree must
distinguish all \(n!\) orderings.

So:

\[
2^h \ge n! \implies h \ge \log_2(n!)
\]

Thus, any comparison sort has lower bound: \[
\Omega(n \log n)
\]

Example 3: Decision-Making Algorithm

If solving a yes/no classification with \(b\) possible outcomes, minimum
number of comparisons required = \(\lceil \log_2 b \rceil\).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-50}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ decision\_tree\_depth(outcomes):}
    \CommentTok{\# Minimum comparisons to distinguish outcomes}
    \ControlFlowTok{return}\NormalTok{ math.ceil(math.log2(outcomes))}

\BuiltInTok{print}\NormalTok{(decision\_tree\_depth(}\DecValTok{8}\NormalTok{))  }\CommentTok{\# 3}
\BuiltInTok{print}\NormalTok{(decision\_tree\_depth(}\DecValTok{120}\NormalTok{))  }\CommentTok{\# \textasciitilde{}7 (for 5!)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-151}

\begin{itemize}
\tightlist
\item
  Reveals theoretical limits (no sort faster than \(O(n \log n)\) by
  comparison)
\item
  Models decision complexity in search and optimization
\item
  Bridges information theory and algorithm design
\item
  Helps compare branching strategies
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-51}

Each comparison splits the search space in two. To distinguish \(N\)
possible outcomes, need at least \(h\) comparisons such that: \[
2^h \ge N
\]

Thus: \[
h \ge \lceil \log_2 N \rceil
\]

For sorting: \[
N = n! \implies h \ge \log_2 (n!) = \Omega(n \log n)
\]

This bound holds independent of implementation, it's a lower bound on
information required.

\subsubsection{Try It Yourself}\label{try-it-yourself-151}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build decision tree for 3-element sorting.
\item
  Count comparisons for binary search on \(n=16\).
\item
  Estimate lower bound for 4-element comparison sort.
\item
  Visualize tree for classification with 8 classes.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-51}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Outcomes & Depth Bound \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Search (n=8) & 8 & 3 \\
Sort 3 elements & \(3! = 6\) & \(\ge 3\) \\
Sort 5 elements & \(5! = 120\) & \(\ge 7\) \\
Classify 8 outcomes & 8 & 3 \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-13}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2381}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1905}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1746}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3968}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Search Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Depth
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Meaning
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Binary Search & \(n\) & \(\log_2 n\) & Worst-case comparisons \\
Comparison Sort & \(n!\) & \(\log_2 n!\) & Info-theoretic limit \\
Classifier & \(b\) & \(\log_2 b\) & Min tests for \(b\) classes \\
\end{longtable}

A Decision Tree Depth Estimator helps uncover the invisible ``question
complexity'' behind every algorithm, how many decisions must be made, no
matter how clever your code is.

\subsection{53 Comparison Counter}\label{comparison-counter}

A Comparison Counter measures how many times an algorithm compares
elements or conditions, a direct way to understand its time complexity,
efficiency, and practical performance. Counting comparisons gives
insight into what really drives runtime, especially in comparison-based
algorithms.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-52}

Many algorithms, sorting, searching, selection, optimization, revolve
around comparisons. Every \texttt{if}, \texttt{\textless{}}, or
\texttt{==} is a decision that costs time.

By counting comparisons, we can:

\begin{itemize}
\tightlist
\item
  Estimate exact step counts for small inputs
\item
  Verify asymptotic bounds (\(O(n^2)\), \(O(n \log n)\), etc.)
\item
  Compare different algorithms empirically
\item
  Identify hot spots in implementation
\end{itemize}

This turns performance from a vague idea into measurable data.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-52}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Instrument the algorithm: wrap every comparison in a counter.
\item
  Increment the counter each time a comparison occurs.
\item
  Run the algorithm with sample inputs.
\item
  Observe patterns as input size grows.
\item
  Fit results to complexity functions (\(n\), \(n \log n\), \(n^2\),
  etc.).
\end{enumerate}

This gives both empirical evidence and analytic insight.

\subsubsection{Example Step by Step}\label{example-step-by-step-52}

Example 1: Linear Search

Search through an array of size \(n\). Each comparison checks one
element.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Case & Comparisons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Best & 1 \\
Worst & n \\
Average & \(\frac{n+1}{2}\) \\
\end{longtable}

So: \[
T(n) = O(n)
\]

Example 2: Binary Search

Each step halves the search space.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Case & Comparisons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Best & 1 \\
Worst & \(\lceil \log_2 n \rceil\) \\
Average & \(\approx \log_2 n - 1\) \\
\end{longtable}

So: \[
T(n) = O(\log n)
\]

Example 3: Bubble Sort

For array of length \(n\), each pass compares adjacent elements.

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Pass & Comparisons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \(n-1\) \\
2 & \(n-2\) \\
\ldots{} & \ldots{} \\
n-1 & 1 \\
\end{longtable}

Total: \[
C(n) = (n-1)+(n-2)+\cdots+1 = \frac{n(n-1)}{2}
\]

So: \[
T(n) = O(n^2)
\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-51}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ Counter:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.count }\OperatorTok{=} \DecValTok{0}
    \KeywordTok{def}\NormalTok{ compare(}\VariableTok{self}\NormalTok{, a, b, op):}
        \VariableTok{self}\NormalTok{.count }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ op }\OperatorTok{==} \StringTok{\textquotesingle{}\textless{}\textquotesingle{}}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textless{}}\NormalTok{ b}
        \ControlFlowTok{if}\NormalTok{ op }\OperatorTok{==} \StringTok{\textquotesingle{}\textgreater{}\textquotesingle{}}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textgreater{}}\NormalTok{ b}
        \ControlFlowTok{if}\NormalTok{ op }\OperatorTok{==} \StringTok{\textquotesingle{}==\textquotesingle{}}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{==}\NormalTok{ b}

\CommentTok{\# Example: Bubble Sort}
\KeywordTok{def}\NormalTok{ bubble\_sort(arr):}
\NormalTok{    c }\OperatorTok{=}\NormalTok{ Counter()}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{):}
            \ControlFlowTok{if}\NormalTok{ c.compare(arr[j], arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{], }\StringTok{\textquotesingle{}\textgreater{}\textquotesingle{}}\NormalTok{):}
\NormalTok{                arr[j], arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{], arr[j]}
    \ControlFlowTok{return}\NormalTok{ arr, c.count}
\end{Highlighting}
\end{Shaded}

Run on small arrays to record exact comparison counts.

\subsubsection{Why It Matters}\label{why-it-matters-152}

\begin{itemize}
\tightlist
\item
  Converts abstract complexity into measurable data
\item
  Reveals hidden constants and practical performance
\item
  Useful for algorithm profiling and pedagogy
\item
  Helps confirm theoretical analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-52}

Each comparison corresponds to one node in the algorithm's decision
tree. The number of comparisons = number of nodes visited. Counting
comparisons thus measures path length, which correlates to runtime for
comparison-based algorithms.

By summing over all paths, we recover the exact cost function \(C(n)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-152}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count comparisons in bubble sort vs insertion sort for \(n=5\).
\item
  Measure binary search comparisons for \(n=16\).
\item
  Compare selection sort and merge sort.
\item
  Fit measured values to theoretical \(O(n^2)\) or \(O(n \log n)\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-52}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Input Size & Comparisons & Pattern \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & 10 & 10 & \(O(n)\) \\
Binary Search & 16 & 4 & \(O(\log n)\) \\
Bubble Sort & 5 & 10 & \(\frac{n(n-1)}{2}\) \\
Merge Sort & 8 & 17 & \(\approx n \log n\) \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-14}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Best Case & Worst Case & Average Case \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Linear Search & 1 & n & \(\frac{n+1}{2}\) \\
Binary Search & 1 & \(\log_2 n\) & \(\log_2 n - 1\) \\
Bubble Sort & \(n-1\) & \(\frac{n(n-1)}{2}\) & \(\frac{n(n-1)}{2}\) \\
\end{longtable}

A Comparison Counter brings complexity theory to life, every \texttt{if}
becomes a data point, and every loop reveals its true cost.

\subsection{54 Early Termination
Heuristic}\label{early-termination-heuristic}

An Early Termination Heuristic is a strategy to stop an algorithm before
full completion when the desired result is already guaranteed or further
work won't change the outcome. It's a simple yet powerful optimization
that saves time in best and average cases.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-53}

Many algorithms perform redundant work after the solution is effectively
found or when additional steps no longer improve results. By detecting
these conditions early, we can cut off unnecessary computation, reducing
runtime without affecting correctness.

Key question: \emph{``Can we stop now without changing the answer?''}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-53}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify a stopping condition beyond the usual loop limit.
\item
  Check at each step if the result is already determined.
\item
  Exit early when the condition is satisfied.
\item
  Return partial result if it's guaranteed to be final.
\end{enumerate}

This optimization is common in search, sorting, simulation, and
iterative convergence algorithms.

\subsubsection{Example Step by Step}\label{example-step-by-step-53}

Example 1: Bubble Sort

Normally runs \(n-1\) passes, even if array sorted early. Add a flag to
track swaps; if none occur, terminate.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ bubble\_sort(arr):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
\NormalTok{        swapped }\OperatorTok{=} \VariableTok{False}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{):}
            \ControlFlowTok{if}\NormalTok{ arr[j] }\OperatorTok{\textgreater{}}\NormalTok{ arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{]:}
\NormalTok{                arr[j], arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{], arr[j]}
\NormalTok{                swapped }\OperatorTok{=} \VariableTok{True}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ swapped:}
            \ControlFlowTok{break}  \CommentTok{\# early termination}
    \ControlFlowTok{return}\NormalTok{ arr}
\end{Highlighting}
\end{Shaded}

Best case: already sorted → 1 pass only \[
T(n) = O(n)
\] Worst case: reversed → still \(O(n^2)\)

Example 2: Linear Search

Searching for key \(k\) in array \texttt{A}:

\begin{itemize}
\tightlist
\item
  Stop when found (don't scan full array).
\item
  Average case improves from \(O(n)\) to \(\frac{n}{2}\) comparisons.
\end{itemize}

Example 3: Convergence Algorithms

In iterative solvers:

\begin{itemize}
\tightlist
\item
  Stop when error \textless{} ε (tolerance threshold).
\item
  Avoids unnecessary extra iterations.
\end{itemize}

Example 4: Constraint Search

In backtracking or branch-and-bound:

\begin{itemize}
\tightlist
\item
  Stop exploring when solution cannot improve current best.
\item
  Reduces search space dramatically.
\end{itemize}

\subsubsection{Why It Matters}\label{why-it-matters-153}

\begin{itemize}
\tightlist
\item
  Improves average-case performance
\item
  Reduces energy and time in real-world systems
\item
  Maintains correctness (never stops too early)
\item
  Enables graceful degradation for approximate algorithms
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-53}

Let \(f(i)\) represent progress measure after \(i\) iterations. If
\(f(i)\) satisfies a stopping invariant \(P\), then continuing further
does not alter the final answer. Thus: \[
\exists i < n ;|; P(f(i)) = \text{True} \implies T(n) = i
\] reducing total operations from \(n\) to \(i\) in favorable cases.

\subsubsection{Try It Yourself}\label{try-it-yourself-153}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add early stop to selection sort (when prefix sorted).
\item
  Apply tolerance check to Newton's method.
\item
  Implement linear search with immediate exit.
\item
  Compare runtime with and without early termination.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-53}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2174}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2319}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1594}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1449}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1594}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0870}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Condition
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & No swaps in pass & \(O(n)\) & \(O(n^2)\) & & \\
Linear Search & Found early & \(O(1)\) & \(O(n)\) & & \\
Newton's Method & \$ & x\_\{i+1\}-x\_i & \textless{}\epsilon\$ &
\(O(\log n)\) & \(O(n)\) \\
DFS & Goal found early & \(O(d)\) & \(O(b^d)\) & & \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-15}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Case & Description & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Best & Early stop triggered & Reduced from \(n\) to \(k\) \\
Average & Depends on data order & Often sublinear \\
Worst & Condition never met & Same as original \\
\end{longtable}

An Early Termination Heuristic adds a simple yet profound optimization,
teaching algorithms when to quit, not just how to run.

\subsection{55 Sentinel Technique}\label{sentinel-technique}

The Sentinel Technique is a simple but elegant optimization that
eliminates redundant boundary checks in loops by placing a \emph{special
marker} (the sentinel) at the end of a data structure. It's a subtle
trick that makes code faster, cleaner, and safer.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-54}

In many algorithms, especially search and scanning loops, we repeatedly
check for two things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Whether the element matches a target
\item
  Whether we've reached the end of the structure
\end{enumerate}

This double condition costs extra comparisons every iteration. By adding
a sentinel value, we can guarantee termination and remove one check.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-54}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Append a sentinel value (e.g.~target or infinity) to the end of the
  array.
\item
  Loop until match found, without checking bounds.
\item
  Stop automatically when you hit the sentinel.
\item
  Check afterward if the match was real or sentinel-triggered.
\end{enumerate}

This replaces:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\KeywordTok{and}\NormalTok{ A[i] }\OperatorTok{!=}\NormalTok{ key:}
\NormalTok{    i }\OperatorTok{+=} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

with a simpler loop:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A[n] }\OperatorTok{=}\NormalTok{ key}
\ControlFlowTok{while}\NormalTok{ A[i] }\OperatorTok{!=}\NormalTok{ key:}
\NormalTok{    i }\OperatorTok{+=} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

No more bound check inside the loop.

\subsubsection{Example Step by Step}\label{example-step-by-step-54}

Example 1: Linear Search with Sentinel

Without sentinel:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ linear\_search(A, key):}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(A)):}
        \ControlFlowTok{if}\NormalTok{ A[i] }\OperatorTok{==}\NormalTok{ key:}
            \ControlFlowTok{return}\NormalTok{ i}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

Every step checks both conditions.

With sentinel:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ linear\_search\_sentinel(A, key):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(A)}
\NormalTok{    A.append(key)  }\CommentTok{\# add sentinel}
\NormalTok{    i }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ A[i] }\OperatorTok{!=}\NormalTok{ key:}
\NormalTok{        i }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ i }\ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n }\ControlFlowTok{else} \OperatorTok{{-}}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Only one condition inside loop
\item
  Works for both found and not-found cases
\end{itemize}

Cost Reduction: from \texttt{2n+1} comparisons to \texttt{n+1}

Example 2: Merging Sorted Lists

Add infinity sentinel at the end of each list:

\begin{itemize}
\tightlist
\item
  Prevents repeated end-of-array checks
\item
  Simplifies inner loop logic
\end{itemize}

E.g. in Merge Sort, use sentinel values to avoid
\texttt{if\ i\ \textless{}\ n} checks.

Example 3: String Parsing

Append \texttt{\textquotesingle{}\textbackslash{}0\textquotesingle{}}
(null terminator) so loops can stop automatically on sentinel. Used
widely in C strings.

\subsubsection{Why It Matters}\label{why-it-matters-154}

\begin{itemize}
\tightlist
\item
  Removes redundant checks
\item
  Simplifies loop logic
\item
  Improves efficiency and readability
\item
  Common in systems programming, parsing, searching
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-54}

Let \(n\) be array length. Normally, each iteration does:

\begin{itemize}
\tightlist
\item
  1 comparison with bound
\item
  1 comparison with key
\end{itemize}

So total \(\approx 2n+1\) comparisons.

With sentinel:

\begin{itemize}
\tightlist
\item
  1 comparison per element
\item
  1 final check after loop
\end{itemize}

So total \(\approx n+1\)

Improvement factor ≈ 2× speedup for long lists.

\subsubsection{Try It Yourself}\label{try-it-yourself-154}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement sentinel linear search and count comparisons.
\item
  Add infinity sentinel in merge routine.
\item
  Write a parser that stops on sentinel
  \texttt{\textquotesingle{}\textbackslash{}0\textquotesingle{}}.
\item
  Compare runtime vs standard implementation.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-54}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input & Key & Output & Comparisons \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}1,2,3,4{]}, 3 & 3 & 2 & 3 \\
{[}1,2,3,4{]}, 5 & -1 & 4 & 5 \\
{[}{]} , 1 & -1 & 0 & 1 \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-16}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1642}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3134}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1642}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3582}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Case
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Best & \(O(1)\) & \(O(1)\) & Found immediately \\
Worst & \(O(n)\) & \(O(1)\) & Found at end / not found \\
Improvement & \textasciitilde2× fewer comparisons & +1 sentinel & Always
safe \\
\end{longtable}

The Sentinel Technique is a quiet masterpiece of algorithmic design,
proving that sometimes, one tiny marker can make a big difference.

\subsection{56 Binary Predicate Tester}\label{binary-predicate-tester}

A Binary Predicate Tester is a simple yet fundamental tool for checking
whether a condition involving two operands holds true, a building block
for comparisons, ordering, filtering, and search logic across
algorithms. It clarifies logic and promotes reuse by abstracting
condition checks.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-55}

Every algorithm depends on decisions, ``Is this element smaller?'',
``Are these two equal?'', ``Does this satisfy the constraint?''. These
yes/no questions are binary predicates: functions that return either
\texttt{True} or \texttt{False}.

By formalizing them as reusable testers, we gain:

\begin{itemize}
\tightlist
\item
  Clarity, separate logic from control flow
\item
  Reusability, pass as arguments to algorithms
\item
  Flexibility, easily switch from \texttt{\textless{}} to
  \texttt{\textgreater{}} or \texttt{==}
\end{itemize}

This underlies sorting, searching, and functional-style algorithms.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-55}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define a predicate function that takes two arguments.
\item
  Returns \texttt{True} if condition satisfied, \texttt{False}
  otherwise.
\item
  Use the predicate inside loops, filters, or algorithmic decisions.
\item
  Swap out predicates to change algorithm behavior dynamically.
\end{enumerate}

Predicates serve as the comparison layer, they don't control flow, but
inform it.

\subsubsection{Example Step by Step}\label{example-step-by-step-55}

Example 1: Sorting by Predicate

Define different predicates:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ less(a, b): }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textless{}}\NormalTok{ b}
\KeywordTok{def}\NormalTok{ greater(a, b): }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textgreater{}}\NormalTok{ b}
\KeywordTok{def}\NormalTok{ equal(a, b): }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{==}\NormalTok{ b}
\end{Highlighting}
\end{Shaded}

Pass to sorting routine:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ compare\_sort(arr, predicate):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{):}
            \ControlFlowTok{if}\NormalTok{ predicate(arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{], arr[j]):}
\NormalTok{                arr[j], arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{], arr[j]}
    \ControlFlowTok{return}\NormalTok{ arr}
\end{Highlighting}
\end{Shaded}

Now you can sort ascending or descending just by changing the predicate.

Example 2: Binary Search Condition

Binary search relies on predicate \texttt{is\_less(mid\_value,\ key)} to
decide direction:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ is\_less(a, b): }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textless{}}\NormalTok{ b}
\end{Highlighting}
\end{Shaded}

So the decision step becomes:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ is\_less(arr[mid], key):}
\NormalTok{    left }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    right }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

This makes the comparison logic explicit, not buried inside control.

Example 3: Filtering or Matching

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ between(a, b): }\ControlFlowTok{return}\NormalTok{ a }\OperatorTok{\textless{}}\NormalTok{ b}
\NormalTok{filtered }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ data }\ControlFlowTok{if}\NormalTok{ between(x, }\DecValTok{10}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

Easily swap predicates for greater-than or equality checks.

\subsubsection{Why It Matters}\label{why-it-matters-155}

\begin{itemize}
\tightlist
\item
  Encapsulates decision logic cleanly
\item
  Enables higher-order algorithms (pass functions as arguments)
\item
  Simplifies testing and customization
\item
  Core to generic programming and templates (C++, Python \texttt{key}
  functions)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-55}

Predicates abstract the notion of ordering or relation. If a predicate
satisfies:

\begin{itemize}
\tightlist
\item
  Reflexivity (\(P(x,x)=\text{False}\) or True, as defined)
\item
  Antisymmetry (\(P(a,b) \Rightarrow \neg P(b,a)\))
\item
  Transitivity (\(P(a,b)\wedge P(b,c) \Rightarrow P(a,c)\))
\end{itemize}

then it defines a strict weak ordering, sufficient for sorting and
searching algorithms.

Thus, correctness of algorithms depends on predicate consistency.

\subsubsection{Try It Yourself}\label{try-it-yourself-155}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write predicates for \texttt{\textless{}}, \texttt{\textgreater{}},
  \texttt{==}, and \texttt{divisible(a,b)}.
\item
  Use them in a selection algorithm.
\item
  Test sorting ascending and descending using same code.
\item
  Verify predicate correctness (antisymmetry, transitivity).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-55}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Predicate & a & b & Result & Meaning \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
less & 3 & 5 & True & 3 \textless{} 5 \\
greater & 7 & 2 & True & 7 \textgreater{} 2 \\
equal & 4 & 4 & True & 4 == 4 \\
divisible & 6 & 3 & True & 6 \% 3 == 0 \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-17}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2714}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Predicate call & \(O(1)\) & \(O(1)\) & Constant per check \\
Algorithm using predicate & Depends on structure & , & e.g.~sort:
\(O(n^2)\) \\
\end{longtable}

A Binary Predicate Tester turns hidden conditions into visible design,
clarifying logic, encouraging reuse, and laying the foundation for
generic algorithms that \emph{think in relationships}, not instructions.

\subsection{57 Range Test Function}\label{range-test-function}

A Range Test Function checks whether a given value lies within specified
bounds, a universal operation in algorithms that handle intervals, array
indices, numeric domains, or search constraints. It's small but
powerful, providing correctness and safety across countless
applications.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-56}

Many algorithms operate on ranges, whether scanning arrays, iterating
loops, searching intervals, or enforcing constraints. Repeatedly
checking \texttt{if\ low\ \textless{}=\ x\ \textless{}=\ high} can
clutter code and lead to subtle off-by-one errors.

By defining a reusable range test, we make such checks:

\begin{itemize}
\tightlist
\item
  Centralized (one definition, consistent semantics)
\item
  Readable (intent clear at call site)
\item
  Safe (avoid inconsistent inequalities)
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-56}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Encapsulate the boundary logic into a single function.
\item
  Input: a value \texttt{x} and bounds \texttt{(low,\ high)}.
\item
  Return: \texttt{True} if \texttt{x} satisfies range condition, else
  \texttt{False}.
\item
  Can handle open, closed, or half-open intervals.
\end{enumerate}

Variants:

\begin{itemize}
\tightlist
\item
  Closed: \texttt{{[}low,\ high{]}} → \texttt{low\ ≤\ x\ ≤\ high}
\item
  Half-open: \texttt{{[}low,\ high)} →
  \texttt{low\ ≤\ x\ \textless{}\ high}
\item
  Open: \texttt{(low,\ high)} →
  \texttt{low\ \textless{}\ x\ \textless{}\ high}
\end{itemize}

\subsubsection{Example Step by Step}\label{example-step-by-step-56}

Example 1: Array Index Bounds

Prevent out-of-bounds access:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ in\_bounds(i, n):}
    \ControlFlowTok{return} \DecValTok{0} \OperatorTok{\textless{}=}\NormalTok{ i }\OperatorTok{\textless{}}\NormalTok{ n}

\ControlFlowTok{if}\NormalTok{ in\_bounds(idx, }\BuiltInTok{len}\NormalTok{(arr)):}
\NormalTok{    value }\OperatorTok{=}\NormalTok{ arr[idx]}
\end{Highlighting}
\end{Shaded}

No more manual range logic.

Example 2: Range Filtering

Filter values inside range \texttt{{[}a,\ b{]}}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ in\_range(x, low, high):}
    \ControlFlowTok{return}\NormalTok{ low }\OperatorTok{\textless{}=}\NormalTok{ x }\OperatorTok{\textless{}=}\NormalTok{ high}

\NormalTok{data }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{]}
\NormalTok{filtered }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ data }\ControlFlowTok{if}\NormalTok{ in\_range(x, }\DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{)]}
\CommentTok{\# → [3, 5, 7]}
\end{Highlighting}
\end{Shaded}

Example 3: Constraint Checking

Used in search or optimization algorithms:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ in\_range(candidate, min\_val, max\_val):}
    \ControlFlowTok{continue}  \CommentTok{\# skip invalid candidate}
\end{Highlighting}
\end{Shaded}

Keeps loops clean and avoids boundary bugs.

Example 4: Geometry / Interval Problems

Check interval overlap:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ overlap(a1, a2, b1, b2):}
    \ControlFlowTok{return}\NormalTok{ in\_range(a1, b1, b2) }\KeywordTok{or}\NormalTok{ in\_range(b1, a1, a2)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-156}

\begin{itemize}
\tightlist
\item
  Prevents off-by-one errors
\item
  Improves code clarity and consistency
\item
  Essential in loop guards, search boundaries, and validity checks
\item
  Enables parameter validation and defensive programming
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-56}

Range test expresses a logical conjunction: \[
P(x) = (x \ge \text{low}) \land (x \le \text{high})
\] For closed intervals, the predicate is reflexive and transitive
within the set \([\text{low}, \text{high}]\). By encoding this predicate
as a function, correctness follows from elementary properties of
inequalities.

Half-open variants preserve well-defined iteration bounds (important for
array indices).

\subsubsection{Try It Yourself}\label{try-it-yourself-156}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement \texttt{in\_open\_range(x,\ low,\ high)} for
  \((low, high)\).
\item
  Write \texttt{in\_half\_open\_range(i,\ 0,\ n)} for loops.
\item
  Use range test in binary search termination condition.
\item
  Check index validity in matrix traversal.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-56}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input & Range & Type & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
5 & {[}1, 10{]} & Closed & True \\
10 & {[}1, 10) & Half-open & False \\
0 & (0, 5) & Open & False \\
3 & {[}0, 3{]} & Closed & True \\
\end{longtable}

\subsubsection{Complexity Summary}\label{complexity-summary-18}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Range check & \(O(1)\) & \(O(1)\) & Constant-time comparison \\
Used per loop & \(O(n)\) & \(O(1)\) & Linear overall \\
\end{longtable}

A Range Test Function is a tiny guardrail with big impact, protecting
correctness at every boundary and making algorithms easier to reason
about.

\subsection{58 Search Invariant Checker}\label{search-invariant-checker}

A Search Invariant Checker ensures that key conditions (invariants) hold
throughout a search algorithm's execution. By maintaining these
invariants, we guarantee correctness, prevent subtle bugs, and provide a
foundation for proofs and reasoning.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-57}

When performing iterative searches (like binary search or interpolation
search), we maintain certain truths that must always hold, such as:

\begin{itemize}
\tightlist
\item
  The target, if it exists, is always within the current bounds.
\item
  The search interval shrinks every step.
\item
  Indices remain valid and ordered.
\end{itemize}

Losing these invariants can lead to infinite loops, incorrect results,
or index errors. By explicitly checking invariants, we make correctness
visible and testable.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-57}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define invariants, conditions that must stay true during every
  iteration.
\item
  After each update step, verify these conditions.
\item
  If an invariant fails, assert or log an error.
\item
  Use invariants both for debugging and proofs.
\end{enumerate}

Common search invariants:

\begin{itemize}
\tightlist
\item
  \$ \text{low} \le \text{high} \$
\item
  \$ \text{target} \in [\text{low}, \text{high}] \$
\item
  Interval size decreases: \$ (\text{high} - \text{low}) \$ shrinks each
  step
\end{itemize}

\subsubsection{Example Step by Step}\label{example-step-by-step-57}

Example: Binary Search Invariants

Goal: Maintain correct search window in \([\text{low}, \text{high}]\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialization: \$ \text{low} = 0 \$, \$ \text{high} = n - 1 \$
\item
  Invariant 1: \$ \text{target} \in [\text{low}, \text{high}] \$
\item
  Invariant 2: \$ \text{low} \le \text{high} \$
\item
  Step: Compute mid, narrow range
\item
  Check: Each iteration, assert these invariants
\end{enumerate}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-52}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ binary\_search(arr, target):}
\NormalTok{    low, high }\OperatorTok{=} \DecValTok{0}\NormalTok{, }\BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{while}\NormalTok{ low }\OperatorTok{\textless{}=}\NormalTok{ high:}
        \ControlFlowTok{assert} \DecValTok{0} \OperatorTok{\textless{}=}\NormalTok{ low }\OperatorTok{\textless{}=}\NormalTok{ high }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(arr), }\StringTok{"Invariant broken!"}
\NormalTok{        mid }\OperatorTok{=}\NormalTok{ (low }\OperatorTok{+}\NormalTok{ high) }\OperatorTok{//} \DecValTok{2}

        \ControlFlowTok{if}\NormalTok{ arr[mid] }\OperatorTok{==}\NormalTok{ target:}
            \ControlFlowTok{return}\NormalTok{ mid}
        \ControlFlowTok{elif}\NormalTok{ arr[mid] }\OperatorTok{\textless{}}\NormalTok{ target:}
\NormalTok{            low }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{+} \DecValTok{1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            high }\OperatorTok{=}\NormalTok{ mid }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{1}
\end{Highlighting}
\end{Shaded}

If the invariant fails, we catch logic errors early.

\subsubsection{Why It Matters}\label{why-it-matters-157}

\begin{itemize}
\tightlist
\item
  Proof of correctness: Each iteration preserves truth
\item
  Debugging aid: Detect logic flaws immediately
\item
  Safety guarantee: Prevent invalid access or infinite loops
\item
  Documentation: Clarifies algorithm intent
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-57}

Suppose invariant \(P\) holds before iteration. The update step
transforms state \((\text{low}, \text{high})\) to
\((\text{low}', \text{high}')\).

We prove:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Base Case: \(P\) holds before first iteration (initialization)
\item
  Inductive Step: If \(P\) holds before iteration, and update rules
  maintain \(P\), then \(P\) holds afterward
\end{enumerate}

Hence, by induction, \(P\) always holds. This ensures algorithm
correctness.

\subsubsection{Try It Yourself}\label{try-it-yourself-157}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add invariants to ternary search
\item
  Prove binary search correctness using invariant preservation
\item
  Test boundary cases (empty array, one element)
\item
  Visualize shrinking interval and check invariant truth at each step
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-57}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input Array & Target & Invariants Hold & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}1, 3, 5, 7, 9{]} & 5 & Yes & Index 2 \\
{[}2, 4, 6{]} & 3 & Yes & Not found \\
{[}1{]} & 1 & Yes & Index 0 \\
{[}{]} & 10 & Yes & Not found \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-49}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Check invariant & \(O(1)\) & \(O(1)\) & Constant-time check \\
Total search & \(O(\log n)\) & \(O(1)\) & Preserves correctness \\
\end{longtable}

The Search Invariant Checker turns implicit assumptions into explicit
guarantees, making your search algorithms not only fast but provably
correct.

\subsection{59 Probe Counter}\label{probe-counter}

A Probe Counter tracks how many probes or lookup attempts a search
algorithm performs. It's a diagnostic tool to understand efficiency and
compare performance between different search strategies or data
structures.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-58}

In searching (especially in hash tables, linear probing, or open
addressing), performance depends not just on complexity but on how many
probes are required to find or miss an element.

By counting probes, we:

\begin{itemize}
\tightlist
\item
  Reveal the cost of each search
\item
  Compare performance under different load factors
\item
  Diagnose clustering or inefficient probing patterns
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-58}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize a counter \texttt{probes\ =\ 0}.
\item
  Each time the algorithm checks a position or node, increment
  \texttt{probes}.
\item
  When the search ends, record or return the probe count.
\item
  Use statistics (mean, max, variance) to measure performance.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-58}

Example: Linear Probing in a Hash Table

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute hash: \(h = \text{key} \bmod m\)
\item
  Start at \(h\), check slot
\item
  If collision, move to next slot
\item
  Increment \texttt{probes} each time
\item
  Stop when slot is empty or key is found
\end{enumerate}

If the table is nearly full, probe count increases, revealing efficiency
loss.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-53}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ linear\_probe\_search(table, key):}
\NormalTok{    m }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(table)}
\NormalTok{    h }\OperatorTok{=}\NormalTok{ key }\OperatorTok{\%}\NormalTok{ m}
\NormalTok{    probes }\OperatorTok{=} \DecValTok{0}
\NormalTok{    i }\OperatorTok{=} \DecValTok{0}

    \ControlFlowTok{while}\NormalTok{ table[(h }\OperatorTok{+}\NormalTok{ i) }\OperatorTok{\%}\NormalTok{ m] }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{        probes }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ table[(h }\OperatorTok{+}\NormalTok{ i) }\OperatorTok{\%}\NormalTok{ m] }\OperatorTok{==}\NormalTok{ key:}
            \ControlFlowTok{return}\NormalTok{ (h }\OperatorTok{+}\NormalTok{ i) }\OperatorTok{\%}\NormalTok{ m, probes}
\NormalTok{        i }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{==}\NormalTok{ m:}
            \ControlFlowTok{break}  \CommentTok{\# table full}
    \ControlFlowTok{return} \VariableTok{None}\NormalTok{, probes}
\end{Highlighting}
\end{Shaded}

Example run:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{table }\OperatorTok{=}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{32}\NormalTok{, }\VariableTok{None}\NormalTok{, }\VariableTok{None}\NormalTok{]}
\NormalTok{index, probes }\OperatorTok{=}\NormalTok{ linear\_probe\_search(table, }\DecValTok{21}\NormalTok{)}
\CommentTok{\# probes = 1}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-158}

\begin{itemize}
\tightlist
\item
  Performance insight: Understand search cost beyond asymptotics
\item
  Clustering detection: Reveal poor distribution or collisions
\item
  Load factor tuning: Find thresholds before degradation
\item
  Algorithm comparison: Evaluate quadratic vs linear probing
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-58}

Let \(L\) be the load factor (fraction of table filled). Expected probes
for a successful search in linear probing:

\[
E[P_{\text{success}}] = \frac{1}{2}\left(1 + \frac{1}{1 - L}\right)
\]

Expected probes for unsuccessful search:

\[
E[P_{\text{fail}}] = \frac{1}{2}\left(1 + \frac{1}{(1 - L)^2}\right)
\]

As \(L \to 1\), probe counts grow rapidly, performance decays.

\subsubsection{Try It Yourself}\label{try-it-yourself-158}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a hash table with linear probing
\item
  Insert keys at different load factors
\item
  Measure probe counts for hits and misses
\item
  Compare linear vs quadratic probing
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-58}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3088}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.0441}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1618}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2206}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2647}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Table (size 7)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Load Factor
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Expected Probes
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}10, 21, 32, None\ldots{]} & 21 & 0.4 & 1 & Direct hit \\
{[}10, 21, 32, 43, 54{]} & 43 & 0.7 & 3 & Clustered region \\
{[}10, 21, 32, 43, 54{]} & 99 & 0.7 & 5 & Miss after probing \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-50}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time (Expected) & Time (Worst) & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Probe count & \(O(1)\) per step & \(O(n)\) & \(O(1)\) \\
Total search & \(O(1)\) average & \(O(n)\) & \(O(1)\) \\
\end{longtable}

By counting probes, we move from theory to measured understanding, a
simple metric that reveals the hidden costs behind collisions, load
factors, and search efficiency.

\subsection{60 Cost Curve Plotter}\label{cost-curve-plotter}

A Cost Curve Plotter visualizes how an algorithm's running cost grows as
the input size increases. It turns abstract complexity into a tangible
curve, helping you compare theoretical and empirical performance side by
side.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-59}

Big-O notation tells us how cost scales, but not how much or where
performance starts to break down. A cost curve lets you:

\begin{itemize}
\tightlist
\item
  See real growth vs theoretical models
\item
  Identify crossover points between algorithms
\item
  Detect anomalies or overhead
\item
  Build intuition about efficiency and scaling
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-59}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Choose an algorithm and a range of input sizes.
\item
  For each \(n\), run the algorithm and record:

  \begin{itemize}
  \tightlist
  \item
    Time cost (runtime)
  \item
    Space cost (memory usage)
  \item
    Operation count
  \end{itemize}
\item
  Plot \((n, \text{cost}(n))\) points
\item
  Overlay theoretical curves (\(O(n)\), \(O(n \log n)\), \(O(n^2)\)) for
  comparison
\end{enumerate}

This creates a visual map of performance over scale.

\subsubsection{Example Step by Step}\label{example-step-by-step-59}

Let's measure sorting cost for different input sizes:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
n & Time (ms) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
100 & 0.3 \\
500 & 2.5 \\
1000 & 5.2 \\
2000 & 11.3 \\
4000 & 23.7 \\
\end{longtable}

Plot these points. The curve shape suggests \(O(n \log n)\) behavior.

\subsection{Tiny Code (Python +
Matplotlib)}\label{tiny-code-python-matplotlib}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ time, random, matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\KeywordTok{def}\NormalTok{ measure\_cost(algorithm, sizes):}
\NormalTok{    results }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ sizes:}
\NormalTok{        arr }\OperatorTok{=}\NormalTok{ [random.randint(}\DecValTok{0}\NormalTok{, }\DecValTok{100000}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}
\NormalTok{        start }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{        algorithm(arr)}
\NormalTok{        end }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{        results.append((n, end }\OperatorTok{{-}}\NormalTok{ start))}
    \ControlFlowTok{return}\NormalTok{ results}

\KeywordTok{def}\NormalTok{ plot\_cost\_curve(results):}
\NormalTok{    xs, ys }\OperatorTok{=} \BuiltInTok{zip}\NormalTok{(}\OperatorTok{*}\NormalTok{results)}
\NormalTok{    plt.plot(xs, ys, marker}\OperatorTok{=}\StringTok{\textquotesingle{}o\textquotesingle{}}\NormalTok{)}
\NormalTok{    plt.xlabel(}\StringTok{"Input size (n)"}\NormalTok{)}
\NormalTok{    plt.ylabel(}\StringTok{"Time (seconds)"}\NormalTok{)}
\NormalTok{    plt.title(}\StringTok{"Algorithm Cost Curve"}\NormalTok{)}
\NormalTok{    plt.grid(}\VariableTok{True}\NormalTok{)}
\NormalTok{    plt.show()}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-159}

\begin{itemize}
\tightlist
\item
  Brings Big-O to life
\item
  Visual debugging, detect unexpected spikes
\item
  Compare algorithms empirically
\item
  Tune thresholds, know when to switch strategies
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-59}

If theoretical cost is \(f(n)\) and empirical cost is \(g(n)\), then we
expect:

\[
\lim_{n \to \infty} \frac{g(n)}{f(n)} = c
\]

where \(c\) is a constant scaling factor.

The plotted curve visually approximates \(g(n)\); comparing its shape to
\(f(n)\) reveals whether the complexity class matches expectations.

\subsubsection{Try It Yourself}\label{try-it-yourself-159}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare bubble sort vs merge sort vs quicksort.
\item
  Overlay \(n\), \(n \log n\), and \(n^2\) reference curves.
\item
  Experiment with different data distributions (sorted, reversed).
\item
  Plot both time and memory cost curves.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-59}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Algorithm & Input Size & Time (ms) & Shape & Match \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bubble Sort & 1000 & 80 & Quadratic & \(O(n^2)\) \\
Merge Sort & 1000 & 5 & Linearithmic & \(O(n \log n)\) \\
Quick Sort & 1000 & 3 & Linearithmic & \(O(n \log n)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-51}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Aspect & Cost & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Measurement & \(O(k \cdot T(n))\) & \(k\) sample sizes measured \\
Plotting & \(O(k)\) & Draw curve from \(k\) points \\
Space & \(O(k)\) & Store measurement data \\
\end{longtable}

The Cost Curve Plotter turns theory into shape, a simple graph that
makes scaling behavior and trade-offs instantly clear.

\bookmarksetup{startatroot}

\chapter{Section 7. Sorting basics}\label{section-7.-sorting-basics}

\subsection{61 Swap Counter}\label{swap-counter}

A Swap Counter tracks the number of element swaps performed during a
sorting process. It helps us understand how much rearrangement an
algorithm performs and serves as a diagnostic for efficiency, stability,
and input sensitivity.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-60}

Many sorting algorithms (like Bubble Sort, Selection Sort, or Quick
Sort) rearrange elements through swaps. Counting swaps shows how
``active'' the algorithm is:

\begin{itemize}
\tightlist
\item
  Bubble Sort → high swap count
\item
  Insertion Sort → fewer swaps on nearly sorted input
\item
  Selection Sort → fixed number of swaps
\end{itemize}

By tracking swaps, we compare algorithms on data movement cost, not just
comparisons.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-60}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize a \texttt{swap\_count\ =\ 0}.
\item
  Each time two elements exchange positions, increment the counter.
\item
  At the end, report \texttt{swap\_count} to measure rearrangement
  effort.
\item
  Use results to compare sorting strategies or analyze input patterns.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-60}

Example: Bubble Sort on {[}3, 2, 1{]}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare 3 and 2 → swap → count = 1 → {[}2, 3, 1{]}
\item
  Compare 3 and 1 → swap → count = 2 → {[}2, 1, 3{]}
\item
  Compare 2 and 1 → swap → count = 3 → {[}1, 2, 3{]}
\end{enumerate}

Total swaps: 3

If input is {[}1, 2, 3{]}, no swaps occur, cost reflects sortedness.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-54}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ bubble\_sort\_with\_swaps(arr):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}
\NormalTok{    swaps }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, n }\OperatorTok{{-}}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{):}
            \ControlFlowTok{if}\NormalTok{ arr[j] }\OperatorTok{\textgreater{}}\NormalTok{ arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{]:}
\NormalTok{                arr[j], arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{], arr[j]}
\NormalTok{                swaps }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ arr, swaps}
\end{Highlighting}
\end{Shaded}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{arr, swaps }\OperatorTok{=}\NormalTok{ bubble\_sort\_with\_swaps([}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{])}
\CommentTok{\# swaps = 3}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-160}

\begin{itemize}
\tightlist
\item
  Quantifies data movement cost
\item
  Measures input disorder (zero swaps → already sorted)
\item
  Compares algorithms on swap efficiency
\item
  Reveals adaptive behavior in real data
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-60}

Every swap reduces the inversion count by one. An inversion is a pair
\((i, j)\) such that \(i < j\) and \(a_i > a_j\).

If initial inversion count = \(I\), and each swap fixes one inversion:

\[
\text{Total Swaps} = I_{\text{initial}}
\]

Thus, swap count directly equals disorder measure, a meaningful cost
metric.

\subsubsection{Try It Yourself}\label{try-it-yourself-160}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count swaps for Bubble Sort, Insertion Sort, and Selection Sort.
\item
  Run on sorted, reversed, and random lists.
\item
  Compare counts, which adapts best to nearly sorted data?
\item
  Plot swap count vs input size.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-60}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input & Algorithm & Swaps & Observation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}3, 2, 1{]} & Bubble Sort & 3 & Full reversal \\
{[}1, 2, 3{]} & Bubble Sort & 0 & Already sorted \\
{[}2, 3, 1{]} & Insertion Sort & 2 & Moves minimal elements \\
{[}3, 1, 2{]} & Selection Sort & 2 & Swaps once per position \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-52}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Metric & Cost & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Time (Tracking) & \(O(1)\) & Increment counter per swap \\
Total Swaps & \(O(n^2)\) & Worst case for Bubble Sort \\
Space & \(O(1)\) & Constant extra memory \\
\end{longtable}

A Swap Counter offers a clear window into sorting dynamics, revealing
how ``hard'' the algorithm works and how far the input is from order.

\subsection{62 Inversion Counter}\label{inversion-counter}

An Inversion Counter measures how far a sequence is from being sorted by
counting all pairs that are out of order. It's a numerical measure of
disorder, zero for a sorted list, maximum for a fully reversed one.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-61}

Sorting algorithms fix \emph{inversions}. Each inversion is a pair
\((i, j)\) such that \(i < j\) and \(a_i > a_j\). Counting inversions
gives us:

\begin{itemize}
\tightlist
\item
  A quantitative measure of unsortedness
\item
  A way to analyze algorithm progress
\item
  Insight into best-case vs worst-case behavior
\end{itemize}

This metric is also used in Kendall tau distance, ranking comparisons,
and adaptive sorting research.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-61}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take an array \(A = [a_1, a_2, \ldots, a_n]\).
\item
  For each pair \((i, j)\) where \(i < j\), check if \(a_i > a_j\).
\item
  Increment count for each inversion found.
\item
  A sorted array has \(0\) inversions; a reversed one has
  \(\frac{n(n-1)}{2}\).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-61}

Array: {[}3, 1, 2{]}

\begin{itemize}
\tightlist
\item
  (3, 1): inversion
\item
  (3, 2): inversion
\item
  (1, 2): no inversion
\end{itemize}

Total inversions: 2

A perfect diagnostic: small count → nearly sorted.

\subsection{Tiny Code (Brute Force)}\label{tiny-code-brute-force}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ count\_inversions\_bruteforce(arr):}
\NormalTok{    count }\OperatorTok{=} \DecValTok{0}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(i }\OperatorTok{+} \DecValTok{1}\NormalTok{, n):}
            \ControlFlowTok{if}\NormalTok{ arr[i] }\OperatorTok{\textgreater{}}\NormalTok{ arr[j]:}
\NormalTok{                count }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ count}
\end{Highlighting}
\end{Shaded}

Output: \texttt{count\_inversions\_bruteforce({[}3,\ 1,\ 2{]})} →
\texttt{2}

\subsection{Optimized Approach (Merge
Sort)}\label{optimized-approach-merge-sort}

Counting inversions can be done in \(O(n \log n)\) by modifying merge
sort.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ count\_inversions\_merge(arr):}
    \KeywordTok{def}\NormalTok{ merge\_count(left, right):}
\NormalTok{        i }\OperatorTok{=}\NormalTok{ j }\OperatorTok{=}\NormalTok{ inv }\OperatorTok{=} \DecValTok{0}
\NormalTok{        merged }\OperatorTok{=}\NormalTok{ []}
        \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(left) }\KeywordTok{and}\NormalTok{ j }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(right):}
            \ControlFlowTok{if}\NormalTok{ left[i] }\OperatorTok{\textless{}=}\NormalTok{ right[j]:}
\NormalTok{                merged.append(left[i])}
\NormalTok{                i }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{else}\NormalTok{:}
\NormalTok{                merged.append(right[j])}
\NormalTok{                inv }\OperatorTok{+=} \BuiltInTok{len}\NormalTok{(left) }\OperatorTok{{-}}\NormalTok{ i}
\NormalTok{                j }\OperatorTok{+=} \DecValTok{1}
\NormalTok{        merged }\OperatorTok{+=}\NormalTok{ left[i:]}
\NormalTok{        merged }\OperatorTok{+=}\NormalTok{ right[j:]}
        \ControlFlowTok{return}\NormalTok{ merged, inv}

    \KeywordTok{def}\NormalTok{ sort\_count(sub):}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(sub) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ sub, }\DecValTok{0}
\NormalTok{        mid }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(sub) }\OperatorTok{//} \DecValTok{2}
\NormalTok{        left, invL }\OperatorTok{=}\NormalTok{ sort\_count(sub[:mid])}
\NormalTok{        right, invR }\OperatorTok{=}\NormalTok{ sort\_count(sub[mid:])}
\NormalTok{        merged, invM }\OperatorTok{=}\NormalTok{ merge\_count(left, right)}
        \ControlFlowTok{return}\NormalTok{ merged, invL }\OperatorTok{+}\NormalTok{ invR }\OperatorTok{+}\NormalTok{ invM}

\NormalTok{    \_, total }\OperatorTok{=}\NormalTok{ sort\_count(arr)}
    \ControlFlowTok{return}\NormalTok{ total}
\end{Highlighting}
\end{Shaded}

Result: \(O(n \log n)\) instead of \(O(n^2)\).

\subsubsection{Why It Matters}\label{why-it-matters-161}

\begin{itemize}
\tightlist
\item
  Quantifies disorder precisely
\item
  Used in sorting network analysis
\item
  Predicts best-case improvements for adaptive sorts
\item
  Connects to ranking correlation metrics
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-61}

Every swap in a stable sort fixes exactly one inversion. If we let \(I\)
denote total inversions:

\[
I_{\text{sorted}} = 0, \quad I_{\text{reverse}} = \frac{n(n-1)}{2}
\]

Hence, inversion count measures \emph{distance to sorted order}, a lower
bound on swaps needed by any comparison sort.

\subsubsection{Try It Yourself}\label{try-it-yourself-161}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count inversions for sorted, reversed, and random arrays.
\item
  Plot inversion count vs swap count.
\item
  Test merge sort counter vs brute force counter.
\item
  Measure how inversion count affects adaptive algorithms.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-61}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Input & Inversions & Interpretation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}1, 2, 3{]} & 0 & Already sorted \\
{[}3, 2, 1{]} & 3 & Fully reversed \\
{[}2, 3, 1{]} & 2 & Two pairs out of order \\
{[}1, 3, 2{]} & 1 & Slightly unsorted \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-53}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2623}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2131}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0984}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4262}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Method
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Brute Force & \(O(n^2)\) & \(O(1)\) & Simple but slow \\
Merge Sort Based & \(O(n \log n)\) & \(O(n)\) & Efficient for large
arrays \\
\end{longtable}

An Inversion Counter transforms ``how sorted is this list?'' into a
precise number, perfect for analysis, comparison, and designing smarter
sorting algorithms.

\subsection{63 Stability Checker}\label{stability-checker}

A Stability Checker verifies whether a sorting algorithm preserves the
relative order of equal elements. Stability is essential when sorting
complex records with multiple keys, ensuring secondary attributes remain
in order after sorting by a primary one.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-62}

When sorting, sometimes values tie, they're equal under the primary key.
A stable sort keeps these tied elements in their original order. For
example, sorting students by grade while preserving the order of names
entered earlier.

Without stability, sorting by multiple keys becomes error-prone, and
chained sorts may lose meaning.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-62}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Label each element with its original position.
\item
  Perform the sort.
\item
  After sorting, for all pairs with equal keys, check if the original
  indices remain in ascending order.
\item
  If yes, the algorithm is stable. Otherwise, it's not.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-62}

Array with labels: \texttt{{[}(A,\ 3),\ (B,\ 1),\ (C,\ 3){]}} Sort by
value → \texttt{{[}\ (B,\ 1),\ (A,\ 3),\ (C,\ 3)\ {]}}

Check ties:

\begin{itemize}
\tightlist
\item
  Elements with value \texttt{3}: A before C, and A's original index
  \textless{} C's original index → stable.
\end{itemize}

If result was \texttt{{[}\ (B,\ 1),\ (C,\ 3),\ (A,\ 3)\ {]}}, order of
equals reversed → unstable.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-55}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ is\_stable\_sort(original, sorted\_arr, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x):}
\NormalTok{    positions }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ idx, val }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(original):}
\NormalTok{        positions.setdefault(key(val), []).append(idx)}
    
\NormalTok{    last\_seen }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ val }\KeywordTok{in}\NormalTok{ sorted\_arr:}
\NormalTok{        k }\OperatorTok{=}\NormalTok{ key(val)}
\NormalTok{        pos }\OperatorTok{=}\NormalTok{ positions[k].pop(}\DecValTok{0}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ k }\KeywordTok{in}\NormalTok{ last\_seen }\KeywordTok{and}\NormalTok{ last\_seen[k] }\OperatorTok{\textgreater{}}\NormalTok{ pos:}
            \ControlFlowTok{return} \VariableTok{False}
\NormalTok{        last\_seen[k] }\OperatorTok{=}\NormalTok{ pos}
    \ControlFlowTok{return} \VariableTok{True}
\end{Highlighting}
\end{Shaded}

Usage:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\DecValTok{3}\NormalTok{), (}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{), (}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{3}\NormalTok{)]}
\NormalTok{sorted\_data }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(data, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{1}\NormalTok{])}
\NormalTok{is\_stable\_sort(data, sorted\_data, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{1}\NormalTok{])  }\CommentTok{\# True}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-162}

\begin{itemize}
\tightlist
\item
  Preserves secondary order: essential for multi-key sorts
\item
  Chaining safety: sort by multiple fields step-by-step
\item
  Predictable results: avoids random reorder of equals
\item
  Common property: Merge Sort, Insertion Sort stable; Quick Sort not (by
  default)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-62}

Let \(a_i\) and \(a_j\) be elements with equal keys \(k\). If \(i < j\)
in the input and positions of \(a_i\) and \(a_j\) after sorting are
\(p_i\) and \(p_j\), then the algorithm is stable if and only if:

\[
i < j \implies p_i < p_j \text{ whenever } k_i = k_j
\]

Checking this property across all tied keys confirms stability.

\subsubsection{Try It Yourself}\label{try-it-yourself-162}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare stable sort (Merge Sort) vs unstable sort (Selection Sort).
\item
  Sort list of tuples by one key, check tie preservation.
\item
  Chain sorts (first by last name, then by first name).
\item
  Run checker to confirm final stability.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-62}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2973}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2973}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0946}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3108}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Input
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sorted Result
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Stable?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Explanation
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}(A,3),(B,1),(C,3){]} & {[}(B,1),(A,3),(C,3){]} & Yes & A before C
preserved \\
{[}(A,3),(B,1),(C,3){]} & {[}(B,1),(C,3),(A,3){]} & No & A and C order
reversed \\
{[}(1,10),(2,10),(3,10){]} & {[}(1,10),(2,10),(3,10){]} & Yes & All
tied, all preserved \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-54}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Checking & \(O(n)\) & \(O(n)\) & One pass over sorted array \\
Sorting & Depends & , & Checker independent of sort \\
\end{longtable}

The Stability Checker ensures your sorts respect order among equals, a
small step that safeguards multi-key sorting correctness and
interpretability.

\subsection{64 Comparison Network
Visualizer}\label{comparison-network-visualizer}

A Comparison Network Visualizer shows how fixed sequences of comparisons
sort elements, revealing the structure of sorting networks. These
diagrams help us see how parallel sorting works, step by step,
independent of input data.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-63}

Sorting networks are data-oblivious, their comparison sequence is fixed,
not driven by data. To understand or design them, we need a clear visual
of which elements compare and when. The visualizer turns an abstract
sequence of comparisons into a layered network diagram.

This is key for:

\begin{itemize}
\tightlist
\item
  Analyzing parallel sorting
\item
  Designing hardware-based sorters
\item
  Studying bitonic or odd-even merges
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-63}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Represent each element as a horizontal wire.
\item
  Draw a vertical comparator line connecting the two wires being
  compared.
\item
  Group comparators into layers that can run in parallel.
\item
  The network executes layer by layer, swapping elements if out of
  order.
\end{enumerate}

Result: a visual map of sorting logic.

\subsubsection{Example Step by Step}\label{example-step-by-step-63}

Sorting 4 elements with Bitonic Sort network:

\begin{verbatim}
Layer 1: Compare (0,1), (2,3)
Layer 2: Compare (0,2), (1,3)
Layer 3: Compare (1,2)
\end{verbatim}

Visual:

\begin{verbatim}
0 ──●────┐─────●───
1 ──●─┐──┼──●──┼───
2 ───┼─●──●─┘──●───
3 ───┼────●────┘───
\end{verbatim}

Each dot pair = comparator. The structure is static, independent of
values.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-56}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ visualize\_network(n, layers):}
\NormalTok{    wires }\OperatorTok{=}\NormalTok{ [[}\StringTok{\textquotesingle{}─\textquotesingle{}}\NormalTok{] }\OperatorTok{*}\NormalTok{ (}\BuiltInTok{len}\NormalTok{(layers) }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}

    \ControlFlowTok{for}\NormalTok{ layer\_idx, layer }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(layers):}
        \ControlFlowTok{for}\NormalTok{ (i, j) }\KeywordTok{in}\NormalTok{ layer:}
\NormalTok{            wires[i][layer\_idx] }\OperatorTok{=} \StringTok{\textquotesingle{}●\textquotesingle{}}
\NormalTok{            wires[j][layer\_idx] }\OperatorTok{=} \StringTok{\textquotesingle{}●\textquotesingle{}}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{\}}\SpecialStringTok{: "} \OperatorTok{+} \StringTok{"─"}\NormalTok{.join(wires[i]))}

\NormalTok{layers }\OperatorTok{=}\NormalTok{ [[(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), (}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)], [(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{), (}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{)], [(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)]]}
\NormalTok{visualize\_network(}\DecValTok{4}\NormalTok{, layers)}
\end{Highlighting}
\end{Shaded}

This prints a symbolic visualization of comparator layers.

\subsubsection{Why It Matters}\label{why-it-matters-163}

\begin{itemize}
\tightlist
\item
  Reveals parallelism in sorting logic
\item
  Helps debug data-oblivious algorithms
\item
  Useful for hardware and GPU design
\item
  Foundation for Bitonic, Odd-Even Merge, and Batcher networks
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-63}

A sorting network guarantees correctness if it sorts all binary
sequences of length \(n\).

By the Zero-One Principle:

\begin{quote}
If a comparison network correctly sorts all sequences of 0s and 1s, it
correctly sorts all sequences of arbitrary numbers.
\end{quote}

So visualizing comparators ensures completeness and layer correctness.

\subsubsection{Try It Yourself}\label{try-it-yourself-163}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a 4-input bitonic sorting network.
\item
  Visualize how comparators ``flow'' through layers.
\item
  Check how many layers can run in parallel.
\item
  Test sorting 0/1 sequences manually through the network.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-63}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Inputs & Network Type & Layers & Sorted Output \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}3,1,4,2{]} & Bitonic Sort & 3 & {[}1,2,3,4{]} \\
{[}1,0,1,0{]} & Odd-Even Merge & 3 & {[}0,0,1,1{]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-55}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Metric & Value & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Comparators & \(O(n \log^2 n)\) & Batcher's network complexity \\
Depth & \(O(\log^2 n)\) & Layers executed in parallel \\
Space & \(O(n)\) & One wire per input \\
\end{longtable}

A Comparison Network Visualizer makes parallel sorting tangible, every
comparator and layer visible, transforming abstract hardware logic into
a clear, educational blueprint.

\subsection{65 Adaptive Sort Detector}\label{adaptive-sort-detector}

An Adaptive Sort Detector measures how ``sorted'' an input sequence
already is and predicts whether an algorithm can take advantage of it.
It's a diagnostic tool that estimates presortedness and guides the
choice of an adaptive sorting algorithm.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-64}

Not all inputs are random, many are partially sorted. Some algorithms
(like Insertion Sort or Timsort) perform much faster on nearly sorted
data. We need a way to detect sortedness before choosing the right
strategy.

An adaptive detector quantifies how close an input is to sorted order.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-64}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define a measure of disorder (e.g., number of inversions, runs, or
  local misplacements).
\item
  Traverse the array, counting indicators of unsortedness.
\item
  Return a metric (e.g., 0 = fully sorted, 1 = fully reversed).
\item
  Use this score to decide whether to apply:

  \begin{itemize}
  \tightlist
  \item
    Simple insertion-like sort (for nearly sorted data)
  \item
    General-purpose sort (for random data)
  \end{itemize}
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-64}

Array: {[}1, 2, 4, 3, 5, 6{]}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Compare adjacent pairs:

  \begin{itemize}
  \tightlist
  \item
    1 ≤ 2 (ok)
  \item
    2 ≤ 4 (ok)
  \item
    4 \textgreater{} 3 (disorder)
  \item
    3 ≤ 5 (ok)
  \item
    5 ≤ 6 (ok)
  \end{itemize}
\item
  Count = 1 local inversion
\end{enumerate}

Sortedness score: \[
s = 1 - \frac{\text{disorder}}{n-1} = 1 - \frac{1}{5} = 0.8
\]

80\% sorted, good candidate for adaptive sort.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-57}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ adaptive\_sort\_detector(arr):}
\NormalTok{    disorder }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{{-}} \DecValTok{1}\NormalTok{):}
        \ControlFlowTok{if}\NormalTok{ arr[i] }\OperatorTok{\textgreater{}}\NormalTok{ arr[i }\OperatorTok{+} \DecValTok{1}\NormalTok{]:}
\NormalTok{            disorder }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{return} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ disorder }\OperatorTok{/} \BuiltInTok{max}\NormalTok{(}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}

\NormalTok{arr }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{]}
\NormalTok{score }\OperatorTok{=}\NormalTok{ adaptive\_sort\_detector(arr)}
\CommentTok{\# score = 0.8}
\end{Highlighting}
\end{Shaded}

You can use this score to select algorithms dynamically.

\subsubsection{Why It Matters}\label{why-it-matters-164}

\begin{itemize}
\tightlist
\item
  Detects near-sorted input efficiently
\item
  Enables algorithm selection at runtime
\item
  Saves time on real-world data (logs, streams, merges)
\item
  Core idea behind Timsort's run detection
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-64}

If an algorithm's time complexity depends on disorder \(d\),
e.g.~\(O(n + d)\), and \(d = O(1)\) for nearly sorted arrays, then the
adaptive algorithm approaches linear time.

The detector approximates \(d\), helping us decide when \(O(n + d)\)
beats \(O(n \log n)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-164}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Test arrays with 0, 10\%, 50\%, and 100\% disorder.
\item
  Compare runtime of Insertion Sort vs Merge Sort.
\item
  Use inversion counting for more precise detection.
\item
  Integrate detector into a hybrid sorting routine.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-64}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input & Disorder & Score & Recommendation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}1,2,3,4,5{]} & 0 & 1.0 & Insertion Sort \\
{[}1,3,2,4,5{]} & 1 & 0.8 & Adaptive Sort \\
{[}3,2,1{]} & 2 & 0.0 & Merge / Quick Sort \\
{[}2,1,3,5,4{]} & 2 & 0.6 & Adaptive Sort \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-56}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Disorder check & \(O(n)\) & \(O(1)\) & Single scan \\
Sorting (chosen) & Adaptive & , & Depends on algorithm selected \\
\end{longtable}

The Adaptive Sort Detector bridges theory and pragmatism, quantifying
how ordered your data is and guiding smarter algorithm choices for
real-world performance.

\subsection{66 Sorting Invariant
Checker}\label{sorting-invariant-checker}

A Sorting Invariant Checker verifies that key ordering conditions hold
throughout a sorting algorithm's execution. It's used to reason about
correctness step by step, ensuring that each iteration preserves
progress toward a fully sorted array.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-65}

When debugging or proving correctness of sorting algorithms, we need to
ensure that certain invariants (conditions that must always hold) remain
true. If any invariant breaks, the algorithm may produce incorrect
output, even if it ``looks'' right at a glance.

A sorting invariant formalizes what ``partial progress'' means.
Examples:

\begin{itemize}
\tightlist
\item
  ``All elements before index \texttt{i} are in sorted order.''
\item
  ``All elements beyond pivot are greater or equal to it.''
\item
  ``Heap property holds at every node.''
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-65}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define one or more invariants that describe correctness.
\item
  After each iteration or recursion step, check that these invariants
  still hold.
\item
  If any fail, stop and debug, the algorithm logic is wrong.
\item
  Once sorting finishes, the global invariant (sorted array) must hold.
\end{enumerate}

This approach is key for formal verification and debuggable code.

\subsubsection{Example Step by Step}\label{example-step-by-step-65}

Insertion Sort invariant:

\begin{quote}
Before processing element \texttt{i}, the subarray \texttt{arr{[}:i{]}}
is sorted.
\end{quote}

\begin{itemize}
\tightlist
\item
  Initially \texttt{i\ =\ 1}: subarray \texttt{{[}arr{[}0{]}{]}} is
  sorted.
\item
  After inserting \texttt{arr{[}1{]}}, subarray
  \texttt{{[}arr{[}0:2{]}{]}} is sorted.
\item
  By induction, full array sorted at end.
\end{itemize}

Check after every insertion:
\texttt{assert\ arr{[}:i{]}\ ==\ sorted(arr{[}:i{]})}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-58}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ insertion\_sort\_with\_invariant(arr):}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(arr)):}
\NormalTok{        key }\OperatorTok{=}\NormalTok{ arr[i]}
\NormalTok{        j }\OperatorTok{=}\NormalTok{ i }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{while}\NormalTok{ j }\OperatorTok{\textgreater{}=} \DecValTok{0} \KeywordTok{and}\NormalTok{ arr[j] }\OperatorTok{\textgreater{}}\NormalTok{ key:}
\NormalTok{            arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ arr[j]}
\NormalTok{            j }\OperatorTok{{-}=} \DecValTok{1}
\NormalTok{        arr[j }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=}\NormalTok{ key}
        \CommentTok{\# Check invariant}
        \ControlFlowTok{assert}\NormalTok{ arr[:i}\OperatorTok{+}\DecValTok{1}\NormalTok{] }\OperatorTok{==} \BuiltInTok{sorted}\NormalTok{(arr[:i}\OperatorTok{+}\DecValTok{1}\NormalTok{]), }\SpecialStringTok{f"Invariant broken at i=}\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{\}}\SpecialStringTok{"}
    \ControlFlowTok{return}\NormalTok{ arr}
\end{Highlighting}
\end{Shaded}

If invariant fails, an assertion error reveals the exact iteration.

\subsubsection{Why It Matters}\label{why-it-matters-165}

\begin{itemize}
\tightlist
\item
  Builds correctness proofs via induction
\item
  Early bug detection, pinpoints iteration errors
\item
  Clarifies algorithm intent
\item
  Teaches structured reasoning about program logic
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Formal proofs (loop invariants)
\item
  Algorithm verification
\item
  Education and analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-65}

Let \(P(i)\) denote the invariant ``prefix of length \(i\) is sorted.''

\begin{itemize}
\tightlist
\item
  Base case: \(P(1)\) holds trivially.
\item
  Inductive step: If \(P(i)\) holds, inserting next element keeps
  \(P(i+1)\) true.
\end{itemize}

By induction, \(P(n)\) holds, full array is sorted.

Thus, the invariant framework guarantees correctness if each step
preserves truth.

\subsubsection{Try It Yourself}\label{try-it-yourself-165}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add invariants to Selection Sort (``min element placed at index i'').
\item
  Add heap property invariant to Heap Sort.
\item
  Run assertions in test suite.
\item
  Use \texttt{try/except} to log rather than stop when invariants fail.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-65}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1556}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4778}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Invariant
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Holds?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insertion Sort & Prefix sorted at each step & Yes & Classic inductive
invariant \\
Selection Sort & Min placed at position i & Yes & Verified
iteratively \\
Quick Sort & Pivot partitions left ≤ pivot ≤ right & Yes & Must hold
after partition \\
Bubble Sort & Largest element bubbles to correct position & Yes & After
each full pass \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-57}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1944}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3750}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2917}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Check Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Assertion & \(O(k)\) & \(O(1)\) & For prefix length \(k\) \\
Total cost & \(O(n^2)\) worst & For nested invariant checks & \\
\end{longtable}

A Sorting Invariant Checker transforms correctness from intuition into
logic, enforcing order, proving validity, and illuminating the structure
of sorting algorithms one invariant at a time.

\subsection{67 Distribution Histogram Sort
Demo}\label{distribution-histogram-sort-demo}

A Distribution Histogram Sort Demo visualizes how elements spread across
buckets or bins during distribution-based sorting. It helps learners see
\emph{why} and \emph{how} counting, radix, or bucket sort achieve
linear-time behavior by organizing values before final ordering.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-66}

Distribution-based sorts (Counting, Bucket, Radix) don't rely on
pairwise comparisons. Instead, they classify elements into bins based on
keys or digits. Understanding these algorithms requires visualizing how
data is distributed across categories, a histogram captures that
process.

The demo shows:

\begin{itemize}
\tightlist
\item
  How counts are collected
\item
  How prefix sums turn counts into positions
\item
  How items are rebuilt in sorted order
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-66}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Initialize buckets, one for each key or range.
\item
  Traverse input and increment count in the right bucket.
\item
  Visualize the resulting histogram of frequencies.
\item
  (Optional) Apply prefix sums to show cumulative positions.
\item
  Reconstruct output by reading bins in order.
\end{enumerate}

This visualization connects counting logic to the final sorted array.

\subsubsection{Example Step by Step}\label{example-step-by-step-66}

Example: Counting sort on \texttt{{[}2,\ 1,\ 2,\ 0,\ 1{]}}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Value & Count \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 \\
1 & 2 \\
2 & 2 \\
\end{longtable}

Prefix sums → \texttt{{[}1,\ 3,\ 5{]}} Rebuild array →
\texttt{{[}0,\ 1,\ 1,\ 2,\ 2{]}}

The histogram clearly shows where each group of values will end up.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-59}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\KeywordTok{def}\NormalTok{ histogram\_sort\_demo(arr, max\_value):}
\NormalTok{    counts }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ (max\_value }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr:}
\NormalTok{        counts[x] }\OperatorTok{+=} \DecValTok{1}
    
\NormalTok{    plt.bar(}\BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(counts)), counts)}
\NormalTok{    plt.xlabel(}\StringTok{"Value"}\NormalTok{)}
\NormalTok{    plt.ylabel(}\StringTok{"Frequency"}\NormalTok{)}
\NormalTok{    plt.title(}\StringTok{"Distribution Histogram for Counting Sort"}\NormalTok{)}
\NormalTok{    plt.show()}
    
    \CommentTok{\# Optional reconstruction}
\NormalTok{    sorted\_arr }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ val, freq }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(counts):}
\NormalTok{        sorted\_arr.extend([val] }\OperatorTok{*}\NormalTok{ freq)}
    \ControlFlowTok{return}\NormalTok{ sorted\_arr}
\end{Highlighting}
\end{Shaded}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{histogram\_sort\_demo([}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{], }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-166}

\begin{itemize}
\tightlist
\item
  Makes non-comparison sorting intuitive
\item
  Shows data frequency patterns
\item
  Bridges between counting and position assignment
\item
  Helps explain \(O(n + k)\) complexity visually
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-66}

Each value's frequency \(f_i\) determines exactly how many times it
appears. By prefix-summing counts:

\[
p_i = \sum_{j < i} f_j
\]

we assign unique output positions for each value, ensuring stable,
correct ordering in linear time.

Thus, sorting becomes position mapping, not comparison.

\subsubsection{Try It Yourself}\label{try-it-yourself-166}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Plot histograms for random, sorted, and uniform arrays.
\item
  Compare bucket sizes in Bucket Sort vs digit positions in Radix Sort.
\item
  Add prefix-sum labels to histogram bars.
\item
  Animate step-by-step rebuild of output.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-66}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input & Max & Histogram & Sorted Output \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}2,1,2,0,1{]} & 2 & {[}1,2,2{]} & {[}0,1,1,2,2{]} \\
{[}3,3,3,3{]} & 3 & {[}0,0,0,4{]} & {[}3,3,3,3{]} \\
{[}0,1,2,3{]} & 3 & {[}1,1,1,1{]} & {[}0,1,2,3{]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-58}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Counting & \(O(n)\) & \(O(k)\) & \(k\) = number of buckets \\
Prefix summation & \(O(k)\) & \(O(k)\) & Single pass over counts \\
Reconstruction & \(O(n + k)\) & \(O(n + k)\) & Build sorted array \\
\end{longtable}

The Distribution Histogram Sort Demo transforms abstract counting logic
into a concrete visual, showing how frequency shapes order and making
linear-time sorting crystal clear.

\subsection{68 Key Extraction Function}\label{key-extraction-function}

A Key Extraction Function isolates the specific feature or attribute
from a data element that determines its position in sorting. It's a
foundational tool for flexible, reusable sorting logic, enabling
algorithms to handle complex records, tuples, or custom objects.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-67}

Sorting real-world data often involves structured elements, tuples,
objects, or dictionaries, not just numbers. We rarely sort entire
elements directly; instead, we sort by a key:

\begin{itemize}
\tightlist
\item
  Name alphabetically
\item
  Age numerically
\item
  Date chronologically
\end{itemize}

A key extractor defines \emph{how to view} each item for comparison,
decoupling \emph{data} from \emph{ordering}.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-67}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define a key function: \texttt{key(x)} → extracts sortable attribute.
\item
  Apply key function during comparisons.
\item
  Algorithm sorts based on these extracted values.
\item
  The original elements remain intact, only their order changes.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-67}

Suppose you have:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{students }\OperatorTok{=}\NormalTok{ [}
\NormalTok{    (}\StringTok{"Alice"}\NormalTok{, }\DecValTok{22}\NormalTok{, }\FloatTok{3.8}\NormalTok{),}
\NormalTok{    (}\StringTok{"Bob"}\NormalTok{, }\DecValTok{20}\NormalTok{, }\FloatTok{3.5}\NormalTok{),}
\NormalTok{    (}\StringTok{"Clara"}\NormalTok{, }\DecValTok{21}\NormalTok{, }\FloatTok{3.9}\NormalTok{)}
\NormalTok{]}
\end{Highlighting}
\end{Shaded}

To sort by age, use \texttt{key=lambda\ x:\ x{[}1{]}}. To sort by GPA
(descending), use \texttt{key=lambda\ x:\ -x{[}2{]}}.

Results:

\begin{itemize}
\tightlist
\item
  By age →
  \texttt{{[}("Bob",\ 20,\ 3.5),\ ("Clara",\ 21,\ 3.9),\ ("Alice",\ 22,\ 3.8){]}}
\item
  By GPA →
  \texttt{{[}("Clara",\ 21,\ 3.9),\ ("Alice",\ 22,\ 3.8),\ ("Bob",\ 20,\ 3.5){]}}
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-60}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ sort\_by\_key(data, key):}
    \ControlFlowTok{return} \BuiltInTok{sorted}\NormalTok{(data, key}\OperatorTok{=}\NormalTok{key)}

\NormalTok{students }\OperatorTok{=}\NormalTok{ [(}\StringTok{"Alice"}\NormalTok{, }\DecValTok{22}\NormalTok{, }\FloatTok{3.8}\NormalTok{), (}\StringTok{"Bob"}\NormalTok{, }\DecValTok{20}\NormalTok{, }\FloatTok{3.5}\NormalTok{), (}\StringTok{"Clara"}\NormalTok{, }\DecValTok{21}\NormalTok{, }\FloatTok{3.9}\NormalTok{)]}

\CommentTok{\# Sort by age}
\NormalTok{result }\OperatorTok{=}\NormalTok{ sort\_by\_key(students, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: x[}\DecValTok{1}\NormalTok{])}
\CommentTok{\# Sort by GPA descending}
\NormalTok{result2 }\OperatorTok{=}\NormalTok{ sort\_by\_key(students, key}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ x: }\OperatorTok{{-}}\NormalTok{x[}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

This abstraction allows clean, reusable sorting.

\subsubsection{Why It Matters}\label{why-it-matters-167}

\begin{itemize}
\tightlist
\item
  Separates logic: comparison mechanism vs data structure
\item
  Reusability: one algorithm, many orderings
\item
  Composability: multi-level sorting by chaining keys
\item
  Stability synergy: stable sorts + key extraction = multi-key sorting
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-67}

Let \(f(x)\) be the key extractor. We sort based on \(f(x)\), not \(x\).
If the comparator satisfies:

\[
f(x_i) \le f(x_j) \implies x_i \text{ precedes } x_j
\]

then the resulting order respects the intended attribute. Because \(f\)
is deterministic, sort correctness follows directly from comparator
correctness.

\subsubsection{Try It Yourself}\label{try-it-yourself-167}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort strings by length: \texttt{key=len}
\item
  Sort dictionary list by field:
  \texttt{key=lambda\ d:\ d{[}\textquotesingle{}score\textquotesingle{}{]}}
\item
  Compose keys: \texttt{key=lambda\ x:\ (x.grade,\ x.name)}
\item
  Combine with stability to simulate SQL ``ORDER BY''
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-67}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3731}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2537}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3731}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Input
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Key
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Result
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}(``A'',3),(``B'',1),(``C'',2){]} & \texttt{lambda\ x:x{[}1{]}} &
{[}(``B'',1),(``C'',2),(``A'',3){]} \\
{[}``cat'',``a'',``bird''{]} & \texttt{len} &
{[}``a'',``cat'',``bird''{]} \\
{[}\{``x'':5\},\{``x'':2\},\{``x'':4\}{]} &
\texttt{lambda\ d:d{[}"x"{]}} &
{[}\{``x'':2\},\{``x'':4\},\{``x'':5\}{]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-59}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Step & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Key extraction & \(O(n)\) & \(O(1)\) & One call per element \\
Sorting & \(O(n \log n)\) & \(O(n)\) & Depends on algorithm used \\
Composition & \(O(k \cdot n)\) & \(O(1)\) & For multi-key chaining \\
\end{longtable}

The Key Extraction Function is the bridge between raw data and custom
order, empowering algorithms to sort not just numbers, but meaning.

\subsection{69 Partially Ordered Set
Builder}\label{partially-ordered-set-builder}

A Partially Ordered Set (Poset) Builder constructs a visual and logical
model of relationships that define \emph{partial orderings} among
elements, where some items can be compared, and others cannot. It's a
conceptual tool for understanding sorting constraints, dependency
graphs, and precedence structures.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-68}

Not all collections have a total order. Sometimes only partial
comparisons make sense, such as:

\begin{itemize}
\tightlist
\item
  Task dependencies (A before B, C independent)
\item
  Version control merges
\item
  Topological ordering in DAGs
\end{itemize}

A poset captures these relationships:

\begin{itemize}
\tightlist
\item
  Reflexive: every element ≤ itself
\item
  Antisymmetric: if A ≤ B and B ≤ A, then A = B
\item
  Transitive: if A ≤ B and B ≤ C, then A ≤ C
\end{itemize}

Building a poset helps us visualize constraints before attempting to
sort or schedule.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-68}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define a relation (≤) among elements.
\item
  Build a graph where an edge A → B means ``A ≤ B.''
\item
  Ensure reflexivity, antisymmetry, and transitivity.
\item
  Visualize the result as a Hasse diagram (omit redundant edges).
\item
  Use this structure to find linear extensions (valid sorted orders).
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-68}

Example: Suppose we have tasks with dependencies:

\begin{verbatim}
A ≤ B, A ≤ C, B ≤ D, C ≤ D
\end{verbatim}

Construct the poset:

\begin{itemize}
\tightlist
\item
  Nodes: A, B, C, D
\item
  Edges: A→B, A→C, B→D, C→D
\end{itemize}

Hasse diagram:

\begin{verbatim}
   D
  / \
 B   C
  \ /
   A
\end{verbatim}

Possible total orders (linear extensions):

\begin{itemize}
\tightlist
\item
  A, B, C, D
\item
  A, C, B, D
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-61}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ defaultdict}

\KeywordTok{def}\NormalTok{ build\_poset(relations):}
\NormalTok{    graph }\OperatorTok{=}\NormalTok{ defaultdict(}\BuiltInTok{list}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ a, b }\KeywordTok{in}\NormalTok{ relations:}
\NormalTok{        graph[a].append(b)}
    \ControlFlowTok{return}\NormalTok{ graph}

\NormalTok{relations }\OperatorTok{=}\NormalTok{ [(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{), (}\StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{)]}
\NormalTok{poset }\OperatorTok{=}\NormalTok{ build\_poset(relations)}
\ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ poset.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
A → ['B', 'C']
B → ['D']
C → ['D']
\end{verbatim}

You can extend this to visualize with tools like \texttt{networkx}.

\subsubsection{Why It Matters}\label{why-it-matters-168}

\begin{itemize}
\tightlist
\item
  Models dependencies and precedence
\item
  Foundation of topological sorting
\item
  Explains why total order isn't always possible
\item
  Clarifies constraint satisfaction in scheduling
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Build systems (make, DAGs)
\item
  Task planning
\item
  Compiler dependency analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-68}

A poset \((P, \le)\) satisfies three axioms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Reflexivity: \(\forall x, x \le x\)
\item
  Antisymmetry: \((x \le y \land y \le x) \implies x = y\)
\item
  Transitivity: \((x \le y \land y \le z) \implies x \le z\)
\end{enumerate}

These properties ensure consistent structure. Sorting a poset means
finding a linear extension consistent with all \(\le\) relations, which
a topological sort guarantees for DAGs.

\subsubsection{Try It Yourself}\label{try-it-yourself-168}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define tasks with prerequisites.
\item
  Draw a Hasse diagram.
\item
  Perform topological sort to list valid total orders.
\item
  Add extra relation, check if antisymmetry breaks.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-68}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2769}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3231}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Relations
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Poset Edges
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Linear Orders
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A ≤ B, A ≤ C, B ≤ D, C ≤ D & A→B, A→C, B→D, C→D & {[}A,B,C,D{]},
{[}A,C,B,D{]} \\
A ≤ B, B ≤ C, A ≤ C & A→B, B→C, A→C & {[}A,B,C{]} \\
A ≤ B, B ≤ A (invalid) & , & Violates antisymmetry \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-60}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3030}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1515}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.0909}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4545}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Build relation graph & \(O(E)\) & \(O(V)\) & \(E\) = number of
relations \\
Check antisymmetry & \(O(E)\) & \(O(V)\) & Detect cycles or
bidirectional \\
Topological sort & \(O(V + E)\) & \(O(V)\) & For linear extensions \\
\end{longtable}

The Partially Ordered Set Builder turns abstract ordering constraints
into structured insight, showing not just \emph{what comes first}, but
\emph{what can coexist}.

\subsection{70 Complexity Comparator}\label{complexity-comparator}

A Complexity Comparator helps us understand how different algorithms
scale by comparing their time or space complexity functions directly.
It's a tool for intuition: how does \(O(n)\) stack up against
\(O(n \log n)\) or \(O(2^n)\) as \(n\) grows large?

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-69}

When faced with multiple algorithms solving the same problem, we must
decide which is more efficient for large inputs. Rather than guess, we
compare growth rates of their complexity functions.

Example: Is \(O(n^2)\) slower than \(O(n \log n)\)? For small \(n\),
maybe not. But as \(n \to \infty\), \(n^2\) grows faster, so the
\(O(n \log n)\) algorithm is asymptotically better.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-69}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Define the two functions \(f(n)\) and \(g(n)\) representing their
  costs.
\item
  Compute the ratio \(\frac{f(n)}{g(n)}\) as \(n \to \infty\).
\item
  Interpret the limit:

  \begin{itemize}
  \tightlist
  \item
    If \(\lim_{n \to \infty} \frac{f(n)}{g(n)} = 0\), then
    \(f(n) = o(g(n))\) (grows slower).
  \item
    If limit is \(\infty\), then \(f(n) = \omega(g(n))\) (grows faster).
  \item
    If limit is constant, then \(f(n) = \Theta(g(n))\) (same growth).
  \end{itemize}
\item
  Visualize using plots or tables for small \(n\) to understand
  crossover points.
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-69}

Compare \(f(n) = n \log n\) and \(g(n) = n^2\):

\begin{itemize}
\tightlist
\item
  Compute ratio:
  \(\frac{f(n)}{g(n)} = \frac{n \log n}{n^2} = \frac{\log n}{n}\).
\item
  As \(n \to \infty\), \(\frac{\log n}{n} \to 0\). Therefore,
  \(f(n) = o(g(n))\).
\end{itemize}

Interpretation: \(O(n \log n)\) grows slower than \(O(n^2)\), so it's
more scalable.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-62}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}

\KeywordTok{def}\NormalTok{ compare\_growth(f, g, n\_values):}
    \ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ n\_values:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"n=}\SpecialCharTok{\{}\NormalTok{n}\SpecialCharTok{:6d\}}\SpecialStringTok{ f(n)=}\SpecialCharTok{\{}\NormalTok{f(n)}\SpecialCharTok{:10.2f\}}\SpecialStringTok{ g(n)=}\SpecialCharTok{\{}\NormalTok{g(n)}\SpecialCharTok{:10.2f\}}\SpecialStringTok{ ratio=}\SpecialCharTok{\{}\NormalTok{f(n)}\OperatorTok{/}\NormalTok{g(n)}\SpecialCharTok{:10.6f\}}\SpecialStringTok{"}\NormalTok{)}

\NormalTok{compare\_growth(}\KeywordTok{lambda}\NormalTok{ n: n }\OperatorTok{*}\NormalTok{ math.log2(n),}
               \KeywordTok{lambda}\NormalTok{ n: n2,}
\NormalTok{               [}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{32}\NormalTok{, }\DecValTok{64}\NormalTok{, }\DecValTok{128}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

Output shows how \(\frac{f(n)}{g(n)}\) decreases with \(n\).

\subsubsection{Why It Matters}\label{why-it-matters-169}

\begin{itemize}
\tightlist
\item
  Makes asymptotic comparison visual and numeric
\item
  Reveals crossover points for real-world input sizes
\item
  Helps choose between multiple implementations
\item
  Deepens intuition about scaling laws
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-69}

We rely on limit comparison:

If \(\lim_{n \to \infty} \frac{f(n)}{g(n)} = c\):

\begin{itemize}
\tightlist
\item
  If \(0 < c < \infty\), then \(f(n) = \Theta(g(n))\)
\item
  If \(c = 0\), then \(f(n) = o(g(n))\)
\item
  If \(c = \infty\), then \(f(n) = \omega(g(n))\)
\end{itemize}

This follows from formal definitions of asymptotic notation, ensuring
consistency across comparisons.

\subsubsection{Try It Yourself}\label{try-it-yourself-169}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare \(O(n^2)\) vs \(O(n^3)\)
\item
  Compare \(O(n \log n)\) vs \(O(n^{1.5})\)
\item
  Compare \(O(2^n)\) vs \(O(n!)\)
\item
  Plot their growth using Python or Excel
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-69}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1613}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3710}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3065}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(f(n)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(g(n)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Ratio as \(n \to \infty\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Relationship
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n\) & \(n \log n\) & \(0\) & \(n = o(n \log n)\) \\
\(n \log n\) & \(n^2\) & \(0\) & \(n \log n = o(n^2)\) \\
\(n^2\) & \(n^2\) & \(1\) & \(\Theta\) \\
\(2^n\) & \(n^3\) & \(\infty\) & \(2^n = \omega(n^3)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-61}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Function ratio & \(O(1)\) & \(O(1)\) & Constant-time comparison \\
Empirical table & \(O(k)\) & \(O(k)\) & For \(k\) sampled points \\
Plot visualization & \(O(k)\) & \(O(k)\) & Helps understand crossover \\
\end{longtable}

The Complexity Comparator is your lens for asymptotic insight, showing
not just which algorithm is faster, but \emph{why} it scales better.

\bookmarksetup{startatroot}

\chapter{Section 8. Data Structure
Overview}\label{section-8.-data-structure-overview}

\subsection{71 Stack Simulation}\label{stack-simulation}

A Stack Simulation lets us watch the push and pop operations unfold step
by step, revealing the LIFO (Last In, First Out) nature of this simple
yet powerful data structure.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-70}

Stacks are everywhere: in recursion, expression evaluation,
backtracking, and function calls. But for beginners, their dynamic
behavior can feel abstract. A simulation makes it concrete, every push
adds a layer, every pop removes one.

Goal: Understand how and when elements enter and leave the stack, and
why order matters.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-70}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with an empty stack.
\item
  Push(x): Add element \texttt{x} to the top.
\item
  Pop(): Remove the top element.
\item
  Peek() (optional): Look at the top without removing it.
\item
  The most recently pushed element is always the first removed.
\end{enumerate}

Think of a stack of plates: you can only take from the top.

\subsubsection{Example Step by Step}\label{example-step-by-step-70}

Operations:

\begin{verbatim}
Push(10)
Push(20)
Push(30)
Pop()
Push(40)
\end{verbatim}

Stack evolution:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Operation & Stack State (Top → Bottom) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Push(10) & 10 \\
2 & Push(20) & 20, 10 \\
3 & Push(30) & 30, 20, 10 \\
4 & Pop() & 20, 10 \\
5 & Push(40) & 40, 20, 10 \\
\end{longtable}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-63}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ Stack:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.data }\OperatorTok{=}\NormalTok{ []}

    \KeywordTok{def}\NormalTok{ push(}\VariableTok{self}\NormalTok{, x):}
        \VariableTok{self}\NormalTok{.data.append(x)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Pushed }\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{data[::}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \KeywordTok{def}\NormalTok{ pop(}\VariableTok{self}\NormalTok{):}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.data:}
\NormalTok{            x }\OperatorTok{=} \VariableTok{self}\NormalTok{.data.pop()}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Popped }\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\VariableTok{self}\SpecialCharTok{.}\NormalTok{data[::}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
            \ControlFlowTok{return}\NormalTok{ x}

\CommentTok{\# Demo}
\NormalTok{s }\OperatorTok{=}\NormalTok{ Stack()}
\NormalTok{s.push(}\DecValTok{10}\NormalTok{)}
\NormalTok{s.push(}\DecValTok{20}\NormalTok{)}
\NormalTok{s.push(}\DecValTok{30}\NormalTok{)}
\NormalTok{s.pop()}
\NormalTok{s.push(}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Each action prints the current state, simulating stack behavior.

\subsubsection{Why It Matters}\label{why-it-matters-170}

\begin{itemize}
\tightlist
\item
  Models function calls and recursion
\item
  Essential for undo operations and backtracking
\item
  Underpins expression parsing and evaluation
\item
  Builds intuition for control flow and memory frames
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-70}

A stack enforces LIFO ordering: If you push elements in order
\(a_1, a_2, \ldots, a_n\), you must pop them in reverse:
\(a_n, \ldots, a_2, a_1\).

Formally, each push increases size by 1, each pop decreases it by 1,
ensuring \(|S| = \text{pushes} - \text{pops}\) and order reverses
naturally.

\subsubsection{Try It Yourself}\label{try-it-yourself-170}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate postfix expression evaluation (\texttt{3\ 4\ +\ 5\ *})
\item
  Trace recursive function calls (factorial or Fibonacci)
\item
  Implement browser backtracking with a stack
\item
  Push strings and pop them to reverse order
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-70}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation Sequence & Final Stack (Top → Bottom) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Push(1), Push(2), Pop() & 1 \\
Push(`A'), Push(`B'), Push(`C') & C, B, A \\
Push(5), Pop(), Pop() & (empty) \\
Push(7), Push(9), Push(11), Pop() & 9, 7 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-62}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Push(x) & O(1) & O(n) & Append to list \\
Pop() & O(1) & O(n) & Remove last item \\
Peek() & O(1) & O(n) & Access last item \\
\end{longtable}

A Stack Simulation makes abstract order tangible, every push and pop
tells a story of control, memory, and flow.

\subsection{72 Queue Simulation}\label{queue-simulation}

A Queue Simulation shows how elements move through a first-in, first-out
structure, perfect for modeling waiting lines, job scheduling, or data
streams.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-71}

Queues capture fairness and order. They're essential in task scheduling,
buffering, and resource management, but their behavior can seem opaque
without visualization.

Simulating operations reveals how enqueue and dequeue actions shape the
system over time.

Goal: Understand FIFO (First-In, First-Out) order and how it ensures
fairness in processing.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-71}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with an empty queue.
\item
  Enqueue(x): Add element \texttt{x} to the rear.
\item
  Dequeue(): Remove the front element.
\item
  Peek() (optional): See the next item to be processed.
\end{enumerate}

Like a line at a ticket counter, first person in is first to leave.

\subsubsection{Example Step by Step}\label{example-step-by-step-71}

Operations:

\begin{verbatim}
Enqueue(10)
Enqueue(20)
Enqueue(30)
Dequeue()
Enqueue(40)
\end{verbatim}

Queue evolution:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Step & Operation & Queue State (Front → Rear) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & Enqueue(10) & 10 \\
2 & Enqueue(20) & 10, 20 \\
3 & Enqueue(30) & 10, 20, 30 \\
4 & Dequeue() & 20, 30 \\
5 & Enqueue(40) & 20, 30, 40 \\
\end{longtable}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-64}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\KeywordTok{class}\NormalTok{ Queue:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.data }\OperatorTok{=}\NormalTok{ deque()}

    \KeywordTok{def}\NormalTok{ enqueue(}\VariableTok{self}\NormalTok{, x):}
        \VariableTok{self}\NormalTok{.data.append(x)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Enqueued }\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\BuiltInTok{list}\NormalTok{(}\VariableTok{self}\NormalTok{.data)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

    \KeywordTok{def}\NormalTok{ dequeue(}\VariableTok{self}\NormalTok{):}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.data:}
\NormalTok{            x }\OperatorTok{=} \VariableTok{self}\NormalTok{.data.popleft()}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Dequeued }\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\BuiltInTok{list}\NormalTok{(}\VariableTok{self}\NormalTok{.data)}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
            \ControlFlowTok{return}\NormalTok{ x}

\CommentTok{\# Demo}
\NormalTok{q }\OperatorTok{=}\NormalTok{ Queue()}
\NormalTok{q.enqueue(}\DecValTok{10}\NormalTok{)}
\NormalTok{q.enqueue(}\DecValTok{20}\NormalTok{)}
\NormalTok{q.enqueue(}\DecValTok{30}\NormalTok{)}
\NormalTok{q.dequeue()}
\NormalTok{q.enqueue(}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Each step prints the queue's current state, helping you trace order
evolution.

\subsubsection{Why It Matters}\label{why-it-matters-171}

\begin{itemize}
\tightlist
\item
  Models real-world waiting lines
\item
  Used in schedulers, network buffers, and BFS traversals
\item
  Ensures fair access to limited resources
\item
  Builds intuition for stream processing
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-71}

A queue preserves arrival order. If elements arrive in order
\(a_1, a_2, \ldots, a_n\), they exit in the same order,
\(a_1, a_2, \ldots, a_n\).

Each enqueue appends to the rear, each dequeue removes from the front.
Thus, insertion and removal sequences match, enforcing FIFO.

\subsubsection{Try It Yourself}\label{try-it-yourself-171}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate a print queue, jobs enter and complete in order.
\item
  Implement BFS on a small graph using a queue.
\item
  Model ticket line arrivals and departures.
\item
  Track packet flow through a network buffer.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-71}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6389}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3611}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Operation Sequence
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Final Queue (Front → Rear)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Enqueue(1), Enqueue(2), Dequeue() & 2 \\
Enqueue(`A'), Enqueue(`B'), Enqueue(`C') & A, B, C \\
Enqueue(5), Dequeue(), Dequeue() & (empty) \\
Enqueue(7), Enqueue(9), Enqueue(11), Dequeue() & 9, 11 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-63}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Enqueue(x) & O(1) & O(n) & Append to rear \\
Dequeue() & O(1) & O(n) & Remove from front \\
Peek() & O(1) & O(n) & Access front item \\
\end{longtable}

A Queue Simulation clarifies the rhythm of fairness, each arrival
patiently waits its turn, no one cutting in line.

\subsection{73 Linked List Builder}\label{linked-list-builder}

A Linked List Builder shows how elements connect through pointers, the
foundation for dynamic memory structures where data grows or shrinks on
demand.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-72}

Arrays have fixed size and require contiguous memory. Linked lists solve
this by linking scattered nodes dynamically, one pointer at a time.

By simulating node creation and linkage, we build intuition for pointer
manipulation and traversal, essential for mastering lists, stacks,
queues, and graphs.

Goal: Understand how nodes link together and how to maintain references
during insertion or deletion.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-72}

A singly linked list is a sequence of nodes, each holding:

\begin{itemize}
\tightlist
\item
  A value
\item
  A pointer to the next node
\end{itemize}

Basic operations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create node(value) → allocate new node.
\item
  Insert after → link new node between existing ones.
\item
  Delete → redirect pointers to skip a node.
\item
  Traverse → follow next pointers until \texttt{None}.
\end{enumerate}

Like a chain, each link knows only the next one.

\subsubsection{Example Step by Step}\label{example-step-by-step-72}

Build a list:

\begin{verbatim}
Insert(10)
Insert(20)
Insert(30)
\end{verbatim}

Process:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create node(10): head → 10 → None
\item
  Create node(20): head → 10 → 20 → None
\item
  Create node(30): head → 10 → 20 → 30 → None
\end{enumerate}

Traversal from \texttt{head} prints: \texttt{10\ →\ 20\ →\ 30\ →\ None}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-65}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ Node:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, value):}
        \VariableTok{self}\NormalTok{.value }\OperatorTok{=}\NormalTok{ value}
        \VariableTok{self}\NormalTok{.}\BuiltInTok{next} \OperatorTok{=} \VariableTok{None}

\KeywordTok{class}\NormalTok{ LinkedList:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=} \VariableTok{None}

    \KeywordTok{def}\NormalTok{ insert(}\VariableTok{self}\NormalTok{, value):}
\NormalTok{        new\_node }\OperatorTok{=}\NormalTok{ Node(value)}
        \ControlFlowTok{if} \KeywordTok{not} \VariableTok{self}\NormalTok{.head:}
            \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ new\_node}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            cur }\OperatorTok{=} \VariableTok{self}\NormalTok{.head}
            \ControlFlowTok{while}\NormalTok{ cur.}\BuiltInTok{next}\NormalTok{:}
\NormalTok{                cur }\OperatorTok{=}\NormalTok{ cur.}\BuiltInTok{next}
\NormalTok{            cur.}\BuiltInTok{next} \OperatorTok{=}\NormalTok{ new\_node}
        \VariableTok{self}\NormalTok{.display()}

    \KeywordTok{def}\NormalTok{ display(}\VariableTok{self}\NormalTok{):}
\NormalTok{        cur }\OperatorTok{=} \VariableTok{self}\NormalTok{.head}
\NormalTok{        elems }\OperatorTok{=}\NormalTok{ []}
        \ControlFlowTok{while}\NormalTok{ cur:}
\NormalTok{            elems.append(}\BuiltInTok{str}\NormalTok{(cur.value))}
\NormalTok{            cur }\OperatorTok{=}\NormalTok{ cur.}\BuiltInTok{next}
        \BuiltInTok{print}\NormalTok{(}\StringTok{" → "}\NormalTok{.join(elems) }\OperatorTok{+} \StringTok{" → None"}\NormalTok{)}

\CommentTok{\# Demo}
\NormalTok{ll }\OperatorTok{=}\NormalTok{ LinkedList()}
\NormalTok{ll.insert(}\DecValTok{10}\NormalTok{)}
\NormalTok{ll.insert(}\DecValTok{20}\NormalTok{)}
\NormalTok{ll.insert(}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-172}

\begin{itemize}
\tightlist
\item
  Enables dynamic memory allocation
\item
  No need for contiguous storage
\item
  Powers stacks, queues, hash chains, adjacency lists
\item
  Builds foundation for advanced pointer-based structures
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-72}

Let \(n\) be the number of nodes. Each node has exactly one outgoing
pointer (to \texttt{next}) or \texttt{None}. Traversing once visits
every node exactly once.

Therefore, insertion or traversal takes \(O(n)\) time, and storage is
\(O(n)\) (one node per element).

\subsubsection{Try It Yourself}\label{try-it-yourself-172}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Insert values \texttt{\{5,\ 15,\ 25,\ 35\}}
\item
  Delete the second node and reconnect links
\item
  Reverse the list manually by reassigning pointers
\item
  Visualize how each \texttt{next} changes during reversal
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-72}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation Sequence & Expected Output \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert(10), Insert(20) & 10 → 20 → None \\
Insert(5), Insert(15), Insert(25) & 5 → 15 → 25 → None \\
Empty List & None \\
Single Node & 42 → None \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-64}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert End & O(n) & O(n) & Traverse to tail \\
Delete Node & O(n) & O(n) & Find predecessor \\
Search & O(n) & O(n) & Sequential traversal \\
Traverse & O(n) & O(n) & Visit each node once \\
\end{longtable}

A Linked List Builder is your first dance with pointers, where structure
emerges from simple connections, and memory becomes fluid, flexible, and
free.

\subsection{74 Array Index Visualizer}\label{array-index-visualizer}

An Array Index Visualizer helps you see how arrays organize data in
contiguous memory and how indexing gives \(O(1)\) access to any element.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-73}

Arrays are the simplest data structure, but beginners often struggle to
grasp how indexing truly works under the hood. By visualizing index
positions and memory offsets, you can see why arrays allow direct access
yet require fixed size and contiguous space.

Goal: Understand the relationship between index, address, and element
access.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-73}

An array stores \(n\) elements consecutively in memory. If the base
address is \(A_0\), and each element takes \(s\) bytes, then:

\[ A_i = A_0 + i \times s \]

So accessing index \(i\) is constant-time:

\begin{itemize}
\tightlist
\item
  Compute address
\item
  Jump directly there
\item
  Retrieve value
\end{itemize}

This visualization ties logical indices (0, 1, 2, \ldots) to physical
locations.

\subsubsection{Example Step by Step}\label{example-step-by-step-73}

Suppose we have an integer array:

\begin{verbatim}
arr = [10, 20, 30, 40]
\end{verbatim}

Base address: \texttt{1000}, element size: \texttt{4\ bytes}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Index & Address & Value \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1000 & 10 \\
1 & 1004 & 20 \\
2 & 1008 & 30 \\
3 & 1012 & 40 \\
\end{longtable}

Access \texttt{arr{[}2{]}}:

\begin{itemize}
\tightlist
\item
  Compute \(A_0 + 2 \times 4 = 1008\)
\item
  Retrieve \texttt{30}
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-66}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ visualize\_array(arr, base}\OperatorTok{=}\DecValTok{1000}\NormalTok{, size}\OperatorTok{=}\DecValTok{4}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\StringTok{\textquotesingle{}Index\textquotesingle{}}\SpecialCharTok{:\textless{}8\}\{}\StringTok{\textquotesingle{}Address\textquotesingle{}}\SpecialCharTok{:\textless{}10\}\{}\StringTok{\textquotesingle{}Value\textquotesingle{}}\SpecialCharTok{:\textless{}8\}}\SpecialStringTok{"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i, val }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(arr):}
\NormalTok{        address }\OperatorTok{=}\NormalTok{ base }\OperatorTok{+}\NormalTok{ i }\OperatorTok{*}\NormalTok{ size}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{:\textless{}8\}\{}\NormalTok{address}\SpecialCharTok{:\textless{}10\}\{}\NormalTok{val}\SpecialCharTok{:\textless{}8\}}\SpecialStringTok{"}\NormalTok{)}

\NormalTok{arr }\OperatorTok{=}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{40}\NormalTok{]}
\NormalTok{visualize\_array(arr)}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
Index   Address   Value
0       1000      10
1       1004      20
2       1008      30
3       1012      40
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-173}

\begin{itemize}
\tightlist
\item
  Instant access via address computation
\item
  Contiguity ensures cache locality
\item
  Fixed size and type consistency
\item
  Core of higher-level structures (strings, matrices, tensors)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-73}

Let \(A_0\) be the base address. Each element occupies \(s\) bytes. To
access element \(i\):

\[ A_i = A_0 + i \times s \]

This is a simple arithmetic operation, so access is \(O(1)\),
independent of \(n\).

\subsubsection{Try It Yourself}\label{try-it-yourself-173}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Visualize array \texttt{{[}5,\ 10,\ 15,\ 20,\ 25{]}} with base
  \texttt{5000} and size \texttt{8}.
\item
  Access \texttt{arr{[}4{]}} manually using formula.
\item
  Compare array vs.~linked list access time.
\item
  Modify size and re-run visualization.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-73}

\begin{longtable}[]{@{}llllll@{}}
\toprule\noalign{}
Array & Base & Size & Access & Expected Address & Value \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}10, 20, 30{]} & 1000 & 4 & arr{[}1{]} & 1004 & 20 \\
{[}7, 14, 21, 28{]} & 500 & 2 & arr{[}3{]} & 506 & 28 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-65}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Access & O(1) & O(n) & Direct via formula \\
Update & O(1) & O(n) & Single write \\
Traverse & O(n) & O(n) & Visit all \\
Insert/Delete & O(n) & O(n) & Requires shifting \\
\end{longtable}

An Array Index Visualizer reveals how logic meets hardware, every index
a direct pointer, every element a predictable step from the base.

\subsection{75 Hash Function Mapper}\label{hash-function-mapper}

A Hash Function Mapper shows how keys are transformed into array
indices, turning arbitrary data into fast-access positions.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-74}

We often need to store and retrieve data by key (like ``Alice'' or
``user123''), not by numeric index. But arrays only understand numbers.
A hash function bridges this gap, mapping keys into integer indices so
we can use array-like speed for key-based lookup.

Goal: Understand how keys become indices and how hash collisions occur.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-74}

A hash function takes a key and computes an index:

\[ \text{index} = h(\text{key}) \bmod m \]

where:

\begin{itemize}
\tightlist
\item
  \(h(\text{key})\) is a numeric hash value,
\item
  \(m\) is the table size.
\end{itemize}

For example:

\begin{verbatim}
key = "cat"
h(key) = 493728
m = 10
index = 493728 % 10 = 8
\end{verbatim}

Now \texttt{"cat"} is mapped to slot 8.

If another key maps to the same index, a collision occurs, handled by
chaining or probing.

\subsubsection{Example Step by Step}\label{example-step-by-step-74}

Suppose a table of size 5.

Keys: \texttt{"red"}, \texttt{"blue"}, \texttt{"green"}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Key & Hash Value & Index (\texttt{\%\ 5}) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
red & 432 & 2 \\
blue & 107 & 2 (collision) \\
green & 205 & 0 \\
\end{longtable}

We see \texttt{"red"} and \texttt{"blue"} collide at index 2.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-67}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ simple\_hash(key):}
    \ControlFlowTok{return} \BuiltInTok{sum}\NormalTok{(}\BuiltInTok{ord}\NormalTok{(c) }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ key)}

\KeywordTok{def}\NormalTok{ map\_keys(keys, size}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    table }\OperatorTok{=}\NormalTok{ [[] }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(size)]}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ keys:}
\NormalTok{        idx }\OperatorTok{=}\NormalTok{ simple\_hash(k) }\OperatorTok{\%}\NormalTok{ size}
\NormalTok{        table[idx].append(k)}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Key: }\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{:6\}}\SpecialStringTok{ {-}\textgreater{} Index: }\SpecialCharTok{\{}\NormalTok{idx}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ table}

\NormalTok{keys }\OperatorTok{=}\NormalTok{ [}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{]}
\NormalTok{table }\OperatorTok{=}\NormalTok{ map\_keys(keys)}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
Key: red    -> Index: 2
Key: blue   -> Index: 2
Key: green  -> Index: 0
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-174}

\begin{itemize}
\tightlist
\item
  Enables constant-time average lookup and insertion
\item
  Forms the backbone of hash tables, dictionaries, caches
\item
  Shows tradeoffs between hash quality and collision handling
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-74}

If a hash function distributes keys uniformly, expected number of keys
per slot is \(\frac{n}{m}\).

Thus, expected lookup time:

\[ E[T] = O(1 + \frac{n}{m}) \]

For well-chosen \(m\) and good \(h\), \(E[T] \approx O(1)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-174}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Map \texttt{{[}"cat",\ "dog",\ "bat",\ "rat"{]}} to a table of size 7.
\item
  Observe collisions and try a larger table.
\item
  Replace \texttt{sum(ord(c))} with a polynomial hash:
  \[ h(\text{key}) = \sum c_i \times 31^i \]
\item
  Compare distribution quality.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-74}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Keys & Table Size & Result (Indices) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}``a'', ``b'', ``c''{]} & 3 & 1, 2, 0 \\
{[}``hi'', ``ih''{]} & 5 & collision (same sum) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-66}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time (Expected) & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(1) & O(n) & Average, good hash \\
Search & O(1) & O(n) & With uniform hashing \\
Delete & O(1) & O(n) & Same cost as lookup \\
\end{longtable}

A Hash Function Mapper makes hashing tangible, you watch strings become
slots, collisions emerge, and order dissolve into probability and math.

\subsection{76 Binary Tree Builder}\label{binary-tree-builder}

A Binary Tree Builder illustrates how hierarchical data structures are
constructed by linking nodes with left and right children.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-75}

Linear structures like arrays and lists can't efficiently represent
hierarchical relationships. When you need ordering, searching, and
hierarchical grouping, a binary tree provides the foundation.

Goal: Understand how nodes are connected to form a tree and how
recursive structure emerges naturally.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-75}

A binary tree is made of nodes. Each node has:

\begin{itemize}
\tightlist
\item
  a value
\item
  a left child
\item
  a right child
\end{itemize}

To build a tree:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start with a root node
\item
  Recursively insert new nodes:

  \begin{itemize}
  \tightlist
  \item
    If value \textless{} current → go left
  \item
    Else → go right
  \end{itemize}
\item
  Repeat until you find a null link
\end{enumerate}

This produces a Binary Search Tree (BST), maintaining order property.

\subsubsection{Example Step by Step}\label{example-step-by-step-75}

Insert values: \texttt{{[}10,\ 5,\ 15,\ 3,\ 7,\ 12,\ 18{]}}

Process:

\begin{verbatim}
10
├── 5
│   ├── 3
│   └── 7
└── 15
    ├── 12
    └── 18
\end{verbatim}

Traversal orders:

\begin{itemize}
\tightlist
\item
  Inorder: 3, 5, 7, 10, 12, 15, 18
\item
  Preorder: 10, 5, 3, 7, 15, 12, 18
\item
  Postorder: 3, 7, 5, 12, 18, 15, 10
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-68}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ Node:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, value):}
        \VariableTok{self}\NormalTok{.value }\OperatorTok{=}\NormalTok{ value}
        \VariableTok{self}\NormalTok{.left }\OperatorTok{=} \VariableTok{None}
        \VariableTok{self}\NormalTok{.right }\OperatorTok{=} \VariableTok{None}

\KeywordTok{class}\NormalTok{ BST:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.root }\OperatorTok{=} \VariableTok{None}

    \KeywordTok{def}\NormalTok{ insert(}\VariableTok{self}\NormalTok{, value):}
        \VariableTok{self}\NormalTok{.root }\OperatorTok{=} \VariableTok{self}\NormalTok{.\_insert(}\VariableTok{self}\NormalTok{.root, value)}

    \KeywordTok{def}\NormalTok{ \_insert(}\VariableTok{self}\NormalTok{, node, value):}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
            \ControlFlowTok{return}\NormalTok{ Node(value)}
        \ControlFlowTok{if}\NormalTok{ value }\OperatorTok{\textless{}}\NormalTok{ node.value:}
\NormalTok{            node.left }\OperatorTok{=} \VariableTok{self}\NormalTok{.\_insert(node.left, value)}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            node.right }\OperatorTok{=} \VariableTok{self}\NormalTok{.\_insert(node.right, value)}
        \ControlFlowTok{return}\NormalTok{ node}

    \KeywordTok{def}\NormalTok{ inorder(}\VariableTok{self}\NormalTok{, node):}
        \ControlFlowTok{if}\NormalTok{ node:}
            \VariableTok{self}\NormalTok{.inorder(node.left)}
            \BuiltInTok{print}\NormalTok{(node.value, end}\OperatorTok{=}\StringTok{" "}\NormalTok{)}
            \VariableTok{self}\NormalTok{.inorder(node.right)}

\CommentTok{\# Demo}
\NormalTok{tree }\OperatorTok{=}\NormalTok{ BST()}
\ControlFlowTok{for}\NormalTok{ val }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{18}\NormalTok{]:}
\NormalTok{    tree.insert(val)}
\NormalTok{tree.inorder(tree.root)}
\end{Highlighting}
\end{Shaded}

Output: \texttt{3\ 5\ 7\ 10\ 12\ 15\ 18}

\subsubsection{Why It Matters}\label{why-it-matters-175}

\begin{itemize}
\tightlist
\item
  Core structure for search trees, heaps, and expression trees
\item
  Forms basis for balanced trees (AVL, Red-Black)
\item
  Enables divide-and-conquer recursion naturally
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-75}

A binary search tree maintains the invariant:

\[ \forall \text{node},\ v:
\begin{cases}
v_{\text{left}} < v_{\text{root}} < v_{\text{right}}
\end{cases} \]

Insertion preserves this by recursive placement. Each insertion follows
a single path of height \(h\), so time is \(O(h)\). For balanced trees,
\(h = O(\log n)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-175}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Insert \texttt{{[}8,\ 3,\ 10,\ 1,\ 6,\ 14,\ 4,\ 7,\ 13{]}}.
\item
  Draw the tree structure.
\item
  Perform inorder traversal (should print sorted order).
\item
  Compare with unbalanced insertion order.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-75}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Input Sequence & Inorder Traversal \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}10, 5, 15, 3, 7{]} & 3, 5, 7, 10, 15 \\
{[}2, 1, 3{]} & 1, 2, 3 \\
{[}5{]} & 5 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-67}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time (Avg) & Time (Worst) & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(log n) & O(n) & O(n) \\
Search & O(log n) & O(n) & O(1) \\
Delete & O(log n) & O(n) & O(1) \\
Traverse & O(n) & O(n) & O(n) \\
\end{longtable}

A Binary Tree Builder reveals order within hierarchy, each node a
decision, each branch a story of lesser and greater.

\subsection{77 Heap Structure Demo}\label{heap-structure-demo}

A Heap Structure Demo helps you visualize how binary heaps organize data
to always keep the smallest or largest element at the top, enabling fast
priority access.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-76}

We often need a structure that quickly retrieves the minimum or maximum
element, like in priority queues or scheduling. Sorting every time is
wasteful. A heap maintains partial order so the root is always extreme,
and rearrangement happens locally.

Goal: Understand how insertion and removal maintain the heap property.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-76}

A binary heap is a complete binary tree stored as an array. Each node
satisfies:

\begin{itemize}
\tightlist
\item
  Min-heap: parent ≤ children
\item
  Max-heap: parent ≥ children
\end{itemize}

Insertion and deletion are handled with \emph{sift up} and \emph{sift
down} operations.

\subsubsection{Insert (Heapify Up)}\label{insert-heapify-up}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add new element at the end
\item
  Compare with parent
\item
  Swap if violates heap property
\item
  Repeat until heap property holds
\end{enumerate}

\subsubsection{Remove Root (Heapify
Down)}\label{remove-root-heapify-down}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Replace root with last element
\item
  Compare with children
\item
  Swap with smaller (min-heap) or larger (max-heap) child
\item
  Repeat until property restored
\end{enumerate}

\subsubsection{Example Step by Step
(Min-Heap)}\label{example-step-by-step-min-heap}

Insert \texttt{{[}10,\ 4,\ 15,\ 2{]}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{{[}10{]}}
\item
  \texttt{{[}10,\ 4{]}} → swap(4, 10) → \texttt{{[}4,\ 10{]}}
\item
  \texttt{{[}4,\ 10,\ 15{]}} (no swap)
\item
  \texttt{{[}4,\ 10,\ 15,\ 2{]}} → swap(2, 10) → swap(2, 4) →
  \texttt{{[}2,\ 4,\ 15,\ 10{]}}
\end{enumerate}

Final heap (array): \texttt{{[}2,\ 4,\ 15,\ 10{]}} Tree view:

\begin{verbatim}
    2
   / \
  4  15
 /
10
\end{verbatim}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-69}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ heapq}

\KeywordTok{def}\NormalTok{ heap\_demo():}
\NormalTok{    heap }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{2}\NormalTok{]:}
\NormalTok{        heapq.heappush(heap, x)}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Insert"}\NormalTok{, x, }\StringTok{"→"}\NormalTok{, heap)}
    \ControlFlowTok{while}\NormalTok{ heap:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Pop:"}\NormalTok{, heapq.heappop(heap), }\StringTok{"→"}\NormalTok{, heap)}

\NormalTok{heap\_demo()}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
Insert 10 → [10]
Insert 4 → [4, 10]
Insert 15 → [4, 10, 15]
Insert 2 → [2, 4, 15, 10]
Pop: 2 → [4, 10, 15]
Pop: 4 → [10, 15]
Pop: 10 → [15]
Pop: 15 → []
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-176}

\begin{itemize}
\tightlist
\item
  Enables priority queues (task schedulers, Dijkstra)
\item
  Supports O(1) access to min/max
\item
  Keeps O(log n) insertion/removal cost
\item
  Basis for Heapsort
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-76}

Let \(h = \lfloor \log_2 n \rfloor\) be heap height. Each insert and
delete moves along one path of height \(h\). Thus:

\[ T_{\text{insert}} = T_{\text{delete}} = O(\log n) \]
\[ T_{\text{find-min}} = O(1) \]

\subsubsection{Try It Yourself}\label{try-it-yourself-176}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Insert \texttt{{[}7,\ 2,\ 9,\ 1,\ 5{]}} into a min-heap
\item
  Trace swaps on paper
\item
  Remove min repeatedly and record order (should be sorted ascending)
\item
  Repeat for max-heap version
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-76}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Input & Output (Heap) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & {[}5, 3, 8{]} & {[}3, 5, 8{]} \\
Pop & {[}3, 5, 8{]} & Pop 3 → {[}5, 8{]} \\
Insert & {[}10, 2, 4{]} & {[}2, 10, 4{]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-68}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(log n) & O(n) & Percolate up \\
Delete & O(log n) & O(n) & Percolate down \\
Find Min/Max & O(1) & O(1) & Root access \\
Build Heap & O(n) & O(n) & Bottom-up heapify \\
\end{longtable}

A Heap Structure Demo shows order through shape, every parent above its
children, every insertion a climb toward balance.

\subsection{78 Union-Find Concept}\label{union-find-concept}

A Union-Find Concept (also called Disjoint Set Union, DSU) demonstrates
how to efficiently manage dynamic grouping, deciding whether elements
belong to the same set and merging sets when needed.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-77}

In many problems, we need to track connected components, e.g.~in graphs,
social networks, or Kruskal's MST. We want to answer two operations
efficiently:

\begin{itemize}
\tightlist
\item
  Find(x): which group is x in?
\item
  Union(x, y): merge the groups of x and y
\end{itemize}

Naive approaches (like scanning arrays) cost too much. Union-Find
structures solve this in \emph{almost constant time} using parent
pointers and path compression.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-77}

Each element points to a parent. The root is the representative of its
set. If two elements share the same root, they're in the same group.

Operations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find(x): Follow parent pointers until reaching a root (node where
  \texttt{parent{[}x{]}\ ==\ x}) Use path compression to flatten paths
  for next time
\item
  Union(x, y): Find roots of x and y If different, attach one root to
  the other (merge sets) Optionally, use union by rank/size to keep tree
  shallow
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-76}

Start with \texttt{\{1\},\ \{2\},\ \{3\},\ \{4\}}

Perform:

\begin{verbatim}
Union(1, 2) → {1,2}, {3}, {4}
Union(3, 4) → {1,2}, {3,4}
Union(2, 3) → {1,2,3,4}
\end{verbatim}

All now connected under one root.

If \texttt{Find(4)} → returns \texttt{1} (root of its set)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-70}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ UnionFind:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, n):}
        \VariableTok{self}\NormalTok{.parent }\OperatorTok{=}\NormalTok{ [i }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}
        \VariableTok{self}\NormalTok{.rank }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ n}

    \KeywordTok{def}\NormalTok{ find(}\VariableTok{self}\NormalTok{, x):}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.parent[x] }\OperatorTok{!=}\NormalTok{ x:}
            \VariableTok{self}\NormalTok{.parent[x] }\OperatorTok{=} \VariableTok{self}\NormalTok{.find(}\VariableTok{self}\NormalTok{.parent[x])  }\CommentTok{\# Path compression}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.parent[x]}

    \KeywordTok{def}\NormalTok{ union(}\VariableTok{self}\NormalTok{, x, y):}
\NormalTok{        rx, ry }\OperatorTok{=} \VariableTok{self}\NormalTok{.find(x), }\VariableTok{self}\NormalTok{.find(y)}
        \ControlFlowTok{if}\NormalTok{ rx }\OperatorTok{==}\NormalTok{ ry:}
            \ControlFlowTok{return}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.rank[rx] }\OperatorTok{\textless{}} \VariableTok{self}\NormalTok{.rank[ry]:}
            \VariableTok{self}\NormalTok{.parent[rx] }\OperatorTok{=}\NormalTok{ ry}
        \ControlFlowTok{elif} \VariableTok{self}\NormalTok{.rank[rx] }\OperatorTok{\textgreater{}} \VariableTok{self}\NormalTok{.rank[ry]:}
            \VariableTok{self}\NormalTok{.parent[ry] }\OperatorTok{=}\NormalTok{ rx}
        \ControlFlowTok{else}\NormalTok{:}
            \VariableTok{self}\NormalTok{.parent[ry] }\OperatorTok{=}\NormalTok{ rx}
            \VariableTok{self}\NormalTok{.rank[rx] }\OperatorTok{+=} \DecValTok{1}

\CommentTok{\# Demo}
\NormalTok{uf }\OperatorTok{=}\NormalTok{ UnionFind(}\DecValTok{5}\NormalTok{)}
\NormalTok{uf.union(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{uf.union(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{uf.union(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{([uf.find(i) }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{5}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

Output: \texttt{{[}0,\ 0,\ 0,\ 0,\ 4{]}}

\subsubsection{Why It Matters}\label{why-it-matters-177}

\begin{itemize}
\tightlist
\item
  Foundation for Kruskal's Minimum Spanning Tree
\item
  Detects cycles in undirected graphs
\item
  Efficient for connectivity queries in dynamic graphs
\item
  Used in percolation, image segmentation, clustering
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-77}

Each operation has amortized cost given by the inverse Ackermann
function \(\alpha(n)\), practically constant.

\[ T_{\text{find}}(n), T_{\text{union}}(n) = O(\alpha(n)) \]

Because path compression ensures every node points closer to root each
time, flattening structure to near-constant depth.

\subsubsection{Try It Yourself}\label{try-it-yourself-177}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with \texttt{\{0\},\ \{1\},\ \{2\},\ \{3\},\ \{4\}}
\item
  Apply: \texttt{Union(0,1),\ Union(2,3),\ Union(1,2)}
\item
  Query \texttt{Find(3)} → should match root of \texttt{0}
\item
  Print parent array after each operation
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-77}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Operation Sequence & Resulting Sets \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Union(1, 2), Union(3, 4) & \{1,2\}, \{3,4\}, \{0\} \\
Union(2, 3) & \{0\}, \{1,2,3,4\} \\
Find(4) & Root = 1 (or 0) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-69}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Amortized Time & Space & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Find & \(O(\alpha(n))\) & \(O(n)\) & Path compression \\
Union & \(O(\alpha(n))\) & \(O(n)\) & With rank heuristic \\
Connected(x, y) & \(O(\alpha(n))\) & \(O(1)\) & Via root comparison \\
\end{longtable}

A Union-Find Concept turns disjoint sets into a living network,
connections formed and flattened, unity discovered through structure.

\subsection{79 Graph Representation
Demo}\label{graph-representation-demo}

A Graph Representation Demo reveals how graphs can be encoded in data
structures, showing the tradeoffs between adjacency lists, matrices, and
edge lists.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-78}

Graphs describe relationships, roads between cities, links between
websites, friendships in a network. But before we can run algorithms
(like BFS, Dijkstra, or DFS), we need a representation that matches the
graph's density, size, and operations.

Goal: Understand how different representations encode edges and how to
choose the right one.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-78}

A graph is defined as: \[ G = (V, E) \] where:

\begin{itemize}
\tightlist
\item
  \(V\) = set of vertices
\item
  \(E\) = set of edges (pairs of vertices)
\end{itemize}

We can represent \(G\) in three main ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Adjacency Matrix

  \begin{itemize}
  \tightlist
  \item
    2D array of size \(|V| \times |V|\)
  \item
    Entry \((i, j) = 1\) if edge \((i, j)\) exists, else 0
  \end{itemize}
\item
  Adjacency List

  \begin{itemize}
  \tightlist
  \item
    For each vertex, a list of its neighbors
  \item
    Compact for sparse graphs
  \end{itemize}
\item
  Edge List

  \begin{itemize}
  \tightlist
  \item
    Simple list of all edges
  \item
    Easy to iterate, hard for quick lookup
  \end{itemize}
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-77}

Consider an undirected graph:

\begin{verbatim}
Vertices: {A, B, C, D}
Edges: {(A, B), (A, C), (B, D)}
\end{verbatim}

Adjacency Matrix

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
& A & B & C & D \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 0 & 1 & 1 & 0 \\
B & 1 & 0 & 0 & 1 \\
C & 1 & 0 & 0 & 0 \\
D & 0 & 1 & 0 & 0 \\
\end{longtable}

Adjacency List

\begin{verbatim}
A: [B, C]
B: [A, D]
C: [A]
D: [B]
\end{verbatim}

Edge List

\begin{verbatim}
[(A, B), (A, C), (B, D)]
\end{verbatim}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-71}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ defaultdict}

\CommentTok{\# Adjacency List}
\NormalTok{graph }\OperatorTok{=}\NormalTok{ defaultdict(}\BuiltInTok{list}\NormalTok{)}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), (}\StringTok{"A"}\NormalTok{, }\StringTok{"C"}\NormalTok{), (}\StringTok{"B"}\NormalTok{, }\StringTok{"D"}\NormalTok{)]}

\ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edges:}
\NormalTok{    graph[u].append(v)}
\NormalTok{    graph[v].append(u)  }\CommentTok{\# undirected}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Adjacency List:"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ node, neighbors }\KeywordTok{in}\NormalTok{ graph.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{node}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{neighbors}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}

\CommentTok{\# Adjacency Matrix}
\NormalTok{vertices }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{]}
\NormalTok{n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vertices)}
\NormalTok{matrix }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\NormalTok{n }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}
\NormalTok{index }\OperatorTok{=}\NormalTok{ \{v: i }\ControlFlowTok{for}\NormalTok{ i, v }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(vertices)\}}

\ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edges:}
\NormalTok{    i, j }\OperatorTok{=}\NormalTok{ index[u], index[v]}
\NormalTok{    matrix[i][j] }\OperatorTok{=}\NormalTok{ matrix[j][i] }\OperatorTok{=} \DecValTok{1}

\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Adjacency Matrix:"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ row }\KeywordTok{in}\NormalTok{ matrix:}
    \BuiltInTok{print}\NormalTok{(row)}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
Adjacency List:
A: ['B', 'C']
B: ['A', 'D']
C: ['A']
D: ['B']

Adjacency Matrix:
[0, 1, 1, 0]
[1, 0, 0, 1]
[1, 0, 0, 0]
[0, 1, 0, 0]
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-178}

\begin{itemize}
\tightlist
\item
  Adjacency matrix → fast lookup (\(O(1)\)), high space (\(O(V^2)\))
\item
  Adjacency list → efficient for sparse graphs (\(O(V+E)\))
\item
  Edge list → simple to iterate, ideal for algorithms like Kruskal
\end{itemize}

Choosing wisely impacts performance of every algorithm on the graph.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-78}

Let \(V\) be number of vertices, \(E\) edges.

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Representation & Storage & Edge Check & Iteration \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Adjacency Matrix & \(O(V^2)\) & \(O(1)\) & \(O(V^2)\) \\
Adjacency List & \(O(V + E)\) & \(O(\deg(v))\) & \(O(V + E)\) \\
Edge List & \(O(E)\) & \(O(E)\) & \(O(E)\) \\
\end{longtable}

Sparse graphs (\(E \ll V^2\)) → adjacency list preferred. Dense graphs
(\(E \approx V^2\)) → adjacency matrix is fine.

\subsubsection{Try It Yourself}\label{try-it-yourself-178}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a graph with 5 nodes, 6 edges
\item
  Write all three representations
\item
  Compute storage cost
\item
  Pick best format for BFS vs Kruskal's MST
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-78}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Graph Type & Representation & Benefit \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sparse & List & Space efficient \\
Dense & Matrix & Constant lookup \\
Weighted & Edge List & Easy sorting \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-70}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Matrix & List & Edge List \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Space & \(O(V^2)\) & \(O(V+E)\) & \(O(E)\) \\
Add Edge & \(O(1)\) & \(O(1)\) & \(O(1)\) \\
Check Edge & \(O(1)\) & \(O(\deg(v))\) & \(O(E)\) \\
Iterate & \(O(V^2)\) & \(O(V+E)\) & \(O(E)\) \\
\end{longtable}

A Graph Representation Demo shows the blueprint of connection, the same
network, three different lenses: matrix, list, or edge table.

\subsection{80 Trie Structure
Visualizer}\label{trie-structure-visualizer}

A Trie Structure Visualizer helps you see how strings and prefixes are
stored efficiently, one character per edge, building shared paths for
common prefixes.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-79}

When you need to store and search many strings, especially by prefix,
linear scans or hash tables aren't ideal. We want something that makes
prefix queries fast and memory use efficient through shared structure.

A trie (prefix tree) does exactly that, storing strings as paths,
reusing common prefixes.

Goal: Understand how each character extends a path and how search and
insert work along edges.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-79}

A trie starts with an empty root node. Each edge represents a character.
Each node may have multiple children, one for each possible next
character.

To insert a word:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start at root
\item
  For each character:

  \begin{itemize}
  \tightlist
  \item
    If it doesn't exist, create a new child
  \item
    Move to that child
  \end{itemize}
\item
  Mark last node as ``end of word''
\end{enumerate}

To search:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start at root
\item
  Follow edges by each character
\item
  If path exists and end is marked, word found
\end{enumerate}

\subsubsection{Example Step by Step}\label{example-step-by-step-78}

Insert \texttt{cat}, \texttt{car}, \texttt{dog}

\begin{verbatim}
(root)
 ├── c
 │    └── a
 │         ├── t*
 │         └── r*
 └── d
      └── o
           └── g*
\end{verbatim}

Asterisk \texttt{*} marks word end. Common prefix \texttt{ca} is shared.

Search \texttt{"car"}:

\begin{itemize}
\tightlist
\item
  \texttt{c} ✓
\item
  \texttt{a} ✓
\item
  \texttt{r} ✓
\item
  End marked → found
\end{itemize}

Search \texttt{"cap"}:

\begin{itemize}
\tightlist
\item
  \texttt{c} ✓
\item
  \texttt{a} ✓
\item
  \texttt{p} ✗ → not found
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-72}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ TrieNode:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.children }\OperatorTok{=}\NormalTok{ \{\}}
        \VariableTok{self}\NormalTok{.is\_end }\OperatorTok{=} \VariableTok{False}

\KeywordTok{class}\NormalTok{ Trie:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{):}
        \VariableTok{self}\NormalTok{.root }\OperatorTok{=}\NormalTok{ TrieNode()}

    \KeywordTok{def}\NormalTok{ insert(}\VariableTok{self}\NormalTok{, word):}
\NormalTok{        node }\OperatorTok{=} \VariableTok{self}\NormalTok{.root}
        \ControlFlowTok{for}\NormalTok{ ch }\KeywordTok{in}\NormalTok{ word:}
            \ControlFlowTok{if}\NormalTok{ ch }\KeywordTok{not} \KeywordTok{in}\NormalTok{ node.children:}
\NormalTok{                node.children[ch] }\OperatorTok{=}\NormalTok{ TrieNode()}
\NormalTok{            node }\OperatorTok{=}\NormalTok{ node.children[ch]}
\NormalTok{        node.is\_end }\OperatorTok{=} \VariableTok{True}

    \KeywordTok{def}\NormalTok{ search(}\VariableTok{self}\NormalTok{, word):}
\NormalTok{        node }\OperatorTok{=} \VariableTok{self}\NormalTok{.root}
        \ControlFlowTok{for}\NormalTok{ ch }\KeywordTok{in}\NormalTok{ word:}
            \ControlFlowTok{if}\NormalTok{ ch }\KeywordTok{not} \KeywordTok{in}\NormalTok{ node.children:}
                \ControlFlowTok{return} \VariableTok{False}
\NormalTok{            node }\OperatorTok{=}\NormalTok{ node.children[ch]}
        \ControlFlowTok{return}\NormalTok{ node.is\_end}

\CommentTok{\# Demo}
\NormalTok{trie }\OperatorTok{=}\NormalTok{ Trie()}
\ControlFlowTok{for}\NormalTok{ w }\KeywordTok{in}\NormalTok{ [}\StringTok{"cat"}\NormalTok{, }\StringTok{"car"}\NormalTok{, }\StringTok{"dog"}\NormalTok{]:}
\NormalTok{    trie.insert(w)}
\BuiltInTok{print}\NormalTok{(trie.search(}\StringTok{"car"}\NormalTok{))  }\CommentTok{\# True}
\BuiltInTok{print}\NormalTok{(trie.search(}\StringTok{"cap"}\NormalTok{))  }\CommentTok{\# False}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-179}

\begin{itemize}
\tightlist
\item
  Enables prefix search, autocomplete, dictionary lookup
\item
  Avoids recomputing prefixes
\item
  Efficient for string-intensive applications
\item
  Foundation for compressed tries, DAWGs, and suffix trees
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-79}

Each character in word \(w\) follows one path in trie. Insert cost =
\(O(|w|)\), Search cost = \(O(|w|)\).

For \(n\) words of average length \(L\), total nodes ≤ \(O(nL)\).

Prefix query cost = \(O(p)\), where \(p\) = prefix length.

\subsubsection{Try It Yourself}\label{try-it-yourself-179}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Insert \texttt{{[}"cat",\ "cap",\ "can",\ "dog"{]}}
\item
  Draw tree paths
\item
  Query prefixes \texttt{"ca"} and \texttt{"do"}
\item
  Count total nodes created
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-79}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Input & Output \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & ``cat'', ``car'' & Shared path ``ca'' \\
Search & ``car'' & True \\
Search & ``cap'' & False \\
Prefix & ``ca'' & Exists \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-71}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Operation & Time & Space & Note \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Insert & O(L) & O(L) & L = length of word \\
Search & O(L) & O(1) & Follow path \\
Prefix Query & O(p) & O(1) & Shared traversal \\
\end{longtable}

A Trie Structure Visualizer shows structure born from language, every
word a path, every prefix a meeting point, every branch a shared memory.

\bookmarksetup{startatroot}

\chapter{Section 9. Graphs and Trees
overview}\label{section-9.-graphs-and-trees-overview}

\subsection{81 Graph Model Constructor}\label{graph-model-constructor}

A Graph Model Constructor is how we formally build graphs, sets of
vertices connected by edges, to represent relationships, networks, or
structures in the world.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-80}

We often face problems where elements are connected, roads between
cities, friendships in a network, dependencies in a project. To reason
about these, we need a way to model entities (vertices) and connections
(edges).

The Graph Model Constructor provides the blueprint for turning
real-world relationships into graph data structures we can analyze.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-80}

A graph is defined as:

\[
G = (V, E)
\]

where

\begin{itemize}
\tightlist
\item
  \(V\) = set of vertices (nodes)
\item
  \(E\) = set of edges (connections) between vertices
\end{itemize}

Each edge can be:

\begin{itemize}
\tightlist
\item
  Undirected: \((u, v)\) means \(u\) and \(v\) are connected both ways
\item
  Directed: \((u, v)\) means a one-way connection from \(u\) to \(v\)
\end{itemize}

You can build graphs in multiple ways:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Edge List -- list of pairs \((u, v)\)
\item
  Adjacency List -- dictionary of node → neighbor list
\item
  Adjacency Matrix -- 2D table of connections (1 = edge, 0 = none)
\end{enumerate}

\subsection{Example}\label{example-18}

Input relationships

\begin{verbatim}
A connected to B  
A connected to C  
B connected to C  
C connected to D
\end{verbatim}

Vertices

\begin{verbatim}
V = {A, B, C, D}
\end{verbatim}

Edges

\begin{verbatim}
E = {(A, B), (A, C), (B, C), (C, D)}
\end{verbatim}

Edge List

\begin{verbatim}
[(A, B), (A, C), (B, C), (C, D)]
\end{verbatim}

Adjacency List

\begin{verbatim}
A: [B, C]
B: [A, C]
C: [A, B, D]
D: [C]
\end{verbatim}

Adjacency Matrix

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
& A & B & C & D \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 0 & 1 & 1 & 0 \\
B & 1 & 0 & 1 & 0 \\
C & 1 & 1 & 0 & 1 \\
D & 0 & 0 & 1 & 0 \\
\end{longtable}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-73}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ build\_graph(edge\_list):}
\NormalTok{    graph }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edge\_list:}
\NormalTok{        graph.setdefault(u, []).append(v)}
\NormalTok{        graph.setdefault(v, []).append(u)  }\CommentTok{\# undirected}
    \ControlFlowTok{return}\NormalTok{ graph}

\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{),(}\StringTok{"A"}\NormalTok{,}\StringTok{"C"}\NormalTok{),(}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{),(}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{)]}
\NormalTok{graph }\OperatorTok{=}\NormalTok{ build\_graph(edges)}
\ControlFlowTok{for}\NormalTok{ node, neighbors }\KeywordTok{in}\NormalTok{ graph.items():}
    \BuiltInTok{print}\NormalTok{(node, }\StringTok{":"}\NormalTok{, neighbors)}
\end{Highlighting}
\end{Shaded}

Output

\begin{verbatim}
A : ['B', 'C']
B : ['A', 'C']
C : ['A', 'B', 'D']
D : ['C']
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-180}

\begin{itemize}
\tightlist
\item
  Graphs let us model relationships in any domain: roads, social
  networks, dependencies, knowledge.
\item
  Once constructed, you can apply graph algorithms, BFS, DFS, shortest
  paths, spanning trees, connectivity, to solve real problems.
\item
  The constructor phase defines how efficiently later algorithms run.
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-80}

Given \(n\) vertices and \(m\) edges, we represent each edge \((u,v)\)
by linking \(u\) and \(v\). Construction time = \(O(n + m)\), since each
vertex and edge is processed once.

Adjacency list size = \(O(n + m)\) Adjacency matrix size = \(O(n^2)\)

Thus, adjacency lists are more space-efficient for sparse graphs, while
matrices offer constant-time edge lookups for dense graphs.

\subsubsection{Try It Yourself}\label{try-it-yourself-180}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a graph of 5 cities and their direct flights.
\item
  Represent it as both edge list and adjacency list.
\item
  Count number of edges and neighbors per vertex.
\item
  Draw the resulting graph on paper.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-80}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Input & Representation & Key Property \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{{[}(1,2),\ (2,3){]}} & Adjacency List & 3 vertices, 2 edges \\
Directed edges & Adjacency List & One-way links only \\
Fully connected 3 nodes & Adjacency Matrix & All 1s except diagonal \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-72}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Representation & Space & Lookup & Iteration \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Edge List & O(m) & O(m) & O(m) \\
Adjacency List & O(n + m) & O(deg(v)) & O(m) \\
Adjacency Matrix & O(n²) & O(1) & O(n²) \\
\end{longtable}

A Graph Model Constructor builds the world of connections, from abstract
relations to concrete data structures, forming the backbone of every
graph algorithm that follows.

\subsection{82 Adjacency Matrix Builder}\label{adjacency-matrix-builder}

An Adjacency Matrix Builder constructs a 2D grid representation of a
graph, showing whether pairs of vertices are connected. It's a simple
and powerful way to capture all edges in a compact mathematical form.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-81}

We need a fast, systematic way to test if two vertices are connected.
While adjacency lists are space-efficient, adjacency matrices make edge
lookup \(O(1)\), perfect when connections are dense or frequent checks
are needed.

The Adjacency Matrix Builder gives us a table-like structure to store
edge information clearly.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-81}

An adjacency matrix is an \(n \times n\) table for a graph with \(n\)
vertices:

\[
A[i][j] =
\begin{cases}
1, & \text{if there is an edge from } i \text{ to } j,\\
0, & \text{otherwise.}
\end{cases}
\]

\begin{itemize}
\tightlist
\item
  For undirected graphs, the matrix is symmetric: \(A[i][j] = A[j][i]\)
\item
  For directed graphs, symmetry may not hold
\item
  For weighted graphs, store weights instead of 1s
\end{itemize}

\subsection{Example}\label{example-19}

Vertices: \(V = {A, B, C, D}\) Edges: \({(A,B), (A,C), (B,C), (C,D)}\)

Adjacency Matrix (Undirected)

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
& A & B & C & D \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 0 & 1 & 1 & 0 \\
B & 1 & 0 & 1 & 0 \\
C & 1 & 1 & 0 & 1 \\
D & 0 & 0 & 1 & 0 \\
\end{longtable}

To check if A and C are connected, test \(A[A][C] = 1\)

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-74}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ adjacency\_matrix(vertices, edges, directed}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vertices)}
\NormalTok{    index }\OperatorTok{=}\NormalTok{ \{v: i }\ControlFlowTok{for}\NormalTok{ i, v }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(vertices)\}}
\NormalTok{    A }\OperatorTok{=}\NormalTok{ [[}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ n }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}

    \ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edges:}
\NormalTok{        i, j }\OperatorTok{=}\NormalTok{ index[u], index[v]}
\NormalTok{        A[i][j] }\OperatorTok{=} \DecValTok{1}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ directed:}
\NormalTok{            A[j][i] }\OperatorTok{=} \DecValTok{1}
    \ControlFlowTok{return}\NormalTok{ A}

\NormalTok{vertices }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{]}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), (}\StringTok{"A"}\NormalTok{, }\StringTok{"C"}\NormalTok{), (}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{), (}\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{)]}
\NormalTok{A }\OperatorTok{=}\NormalTok{ adjacency\_matrix(vertices, edges)}
\ControlFlowTok{for}\NormalTok{ row }\KeywordTok{in}\NormalTok{ A:}
    \BuiltInTok{print}\NormalTok{(row)}
\end{Highlighting}
\end{Shaded}

Output

\begin{verbatim}
[0, 1, 1, 0]
[1, 0, 1, 0]
[1, 1, 0, 1]
[0, 0, 1, 0]
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-181}

\begin{itemize}
\item
  Constant-time check for edge existence
\item
  Simple mathematical representation for graph algorithms and proofs
\item
  Foundation for matrix-based graph algorithms like:

  \begin{itemize}
  \tightlist
  \item
    Floyd--Warshall (all-pairs shortest path)
  \item
    Adjacency matrix powers (reachability)
  \item
    Spectral graph theory (Laplacian, eigenvalues)
  \end{itemize}
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-81}

Each vertex pair \((u, v)\) corresponds to one matrix cell \(A[i][j]\).
We visit each edge once to set two symmetric entries (undirected) or one
(directed). Thus:

\begin{itemize}
\tightlist
\item
  Time complexity: \(O(n^2)\) to initialize, \(O(m)\) to fill
\item
  Space complexity: \(O(n^2)\)
\end{itemize}

This tradeoff is worth it when \(m \approx n^2\) (dense graphs).

\subsubsection{Try It Yourself}\label{try-it-yourself-181}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build an adjacency matrix for a directed triangle (A→B, B→C, C→A)
\item
  Modify it to add a self-loop on B
\item
  Check if \(A[B][B] = 1\)
\item
  Compare the symmetry of directed vs undirected graphs
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-81}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Graph Type & Edges & Symmetry & Value \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & (A,B) & Symmetric & A{[}B{]}{[}A{]} = 1 \\
Directed & (A,B) & Not symmetric & A{[}B{]}{[}A{]} = 0 \\
Weighted & (A,B,w=5) & Value stored & A{[}A{]}{[}B{]} = 5 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-73}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Build Matrix & \(O(n^2)\) & \(O(n^2)\) \\
Edge Check & \(O(1)\) & - \\
Iterate Neighbors & \(O(n)\) & - \\
\end{longtable}

An Adjacency Matrix Builder turns a graph into a table, a universal
structure for analysis, efficient queries, and algorithmic
transformation.

\subsection{83 Adjacency List Builder}\label{adjacency-list-builder}

An Adjacency List Builder constructs a flexible representation of a
graph, storing each vertex's neighbors in a list. It's memory-efficient
for sparse graphs and intuitive for traversal-based algorithms.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-82}

We need a way to represent graphs compactly while still supporting quick
traversal of connected vertices. When graphs are sparse (few edges
compared to \(n^2\)), an adjacency matrix wastes space. An adjacency
list focuses only on existing edges, making it both lean and intuitive.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-82}

Each vertex keeps a list of all vertices it connects to. In a directed
graph, edges point one way; in an undirected graph, each edge appears
twice.

For a graph with vertices \(V\) and edges \(E\), the adjacency list is:

\[
\text{Adj}[u] = {v \mid (u, v) \in E}
\]

You can think of it as a dictionary (or map) where each key is a vertex,
and its value is a list of neighbors.

\subsection{Example}\label{example-20}

Vertices: \(V = {A, B, C, D}\) Edges: \({(A,B), (A,C), (B,C), (C,D)}\)

Adjacency List (Undirected)

\begin{verbatim}
A: [B, C]
B: [A, C]
C: [A, B, D]
D: [C]
\end{verbatim}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-75}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ adjacency\_list(vertices, edges, directed}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
\NormalTok{    adj }\OperatorTok{=}\NormalTok{ \{v: [] }\ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vertices\}}
    \ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edges:}
\NormalTok{        adj[u].append(v)}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ directed:}
\NormalTok{            adj[v].append(u)}
    \ControlFlowTok{return}\NormalTok{ adj}

\NormalTok{vertices }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{]}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), (}\StringTok{"A"}\NormalTok{, }\StringTok{"C"}\NormalTok{), (}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{), (}\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{)]}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ adjacency\_list(vertices, edges)}
\ControlFlowTok{for}\NormalTok{ node, nbrs }\KeywordTok{in}\NormalTok{ graph.items():}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{node}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{nbrs}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Output

\begin{verbatim}
A: ['B', 'C']
B: ['A', 'C']
C: ['A', 'B', 'D']
D: ['C']
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-182}

\begin{itemize}
\tightlist
\item
  Space-efficient for sparse graphs (\(O(n + m)\))
\item
  Natural fit for DFS, BFS, and pathfinding
\item
  Easy to modify and extend (weighted edges, labels)
\item
  Forms the basis for graph traversal algorithms and network models
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-82}

Each edge is stored exactly once (directed) or twice (undirected). If
\(n\) is the number of vertices and \(m\) is the number of edges:

\begin{itemize}
\tightlist
\item
  Initialization: \(O(n)\)
\item
  Insertion: \(O(m)\)
\item
  Total Space: \(O(n + m)\)
\end{itemize}

No wasted space for missing edges, each list grows only with actual
neighbors.

\subsubsection{Try It Yourself}\label{try-it-yourself-182}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build an adjacency list for a directed graph with edges (A→B, A→C,
  C→A)
\item
  Add a new vertex E with no edges; confirm it still appears as
  \texttt{E:\ {[}{]}}
\item
  Count how many total neighbors there are, it should match the edge
  count
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-82}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Graph Type & Input Edges & Representation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & (A,B) & A: {[}B{]}, B: {[}A{]} \\
Directed & (A,B) & A: {[}B{]}, B: {[}{]} \\
Weighted & (A,B,5) & A: {[}(B,5){]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-74}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Build List & \(O(n + m)\) & \(O(n + m)\) \\
Check Neighbors & \(O(\deg(v))\) & - \\
Add Edge & \(O(1)\) & - \\
Remove Edge & \(O(\deg(v))\) & - \\
\end{longtable}

An Adjacency List Builder keeps your graph representation clean and
scalable, perfect for algorithms that walk, explore, and connect the
dots across large networks.

\subsection{84 Degree Counter}\label{degree-counter}

A Degree Counter computes how many edges touch each vertex in a graph.
For undirected graphs, the degree is the number of neighbors. For
directed graphs, we distinguish between in-degree and out-degree.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-83}

We want to know how connected each vertex is. Degree counts help answer
structural questions:

\begin{itemize}
\tightlist
\item
  Is the graph regular (all vertices same degree)?
\item
  Are there sources (zero in-degree) or sinks (zero out-degree)?
\item
  Which node is a hub in a network?
\end{itemize}

These insights are foundational for traversal, centrality, and
optimization.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-83}

For each edge \((u, v)\):

\begin{itemize}
\tightlist
\item
  Undirected: increment \texttt{degree{[}u{]}} and
  \texttt{degree{[}v{]}}
\item
  Directed: increment \texttt{out\_degree{[}u{]}} and
  \texttt{in\_degree{[}v{]}}
\end{itemize}

When done, every vertex has its connection count.

\subsection{Example}\label{example-21}

Undirected graph: \[
V = {A, B, C, D}, \quad E = {(A,B), (A,C), (B,C), (C,D)}
\]

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Vertex & Degree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A & 2 \\
B & 2 \\
C & 3 \\
D & 1 \\
\end{longtable}

Directed version:

\begin{itemize}
\tightlist
\item
  In-degree(A)=1 (from C), Out-degree(A)=2 (to B,C)
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-76}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ degree\_counter(vertices, edges, directed}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \ControlFlowTok{if}\NormalTok{ directed:}
\NormalTok{        indeg }\OperatorTok{=}\NormalTok{ \{v: }\DecValTok{0} \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vertices\}}
\NormalTok{        outdeg }\OperatorTok{=}\NormalTok{ \{v: }\DecValTok{0} \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vertices\}}
        \ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edges:}
\NormalTok{            outdeg[u] }\OperatorTok{+=} \DecValTok{1}
\NormalTok{            indeg[v] }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{return}\NormalTok{ indeg, outdeg}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        deg }\OperatorTok{=}\NormalTok{ \{v: }\DecValTok{0} \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vertices\}}
        \ControlFlowTok{for}\NormalTok{ u, v }\KeywordTok{in}\NormalTok{ edges:}
\NormalTok{            deg[u] }\OperatorTok{+=} \DecValTok{1}
\NormalTok{            deg[v] }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{return}\NormalTok{ deg}

\NormalTok{vertices }\OperatorTok{=}\NormalTok{ [}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{, }\StringTok{"D"}\NormalTok{]}
\NormalTok{edges }\OperatorTok{=}\NormalTok{ [(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{), (}\StringTok{"A"}\NormalTok{,}\StringTok{"C"}\NormalTok{), (}\StringTok{"B"}\NormalTok{,}\StringTok{"C"}\NormalTok{), (}\StringTok{"C"}\NormalTok{,}\StringTok{"D"}\NormalTok{)]}
\BuiltInTok{print}\NormalTok{(degree\_counter(vertices, edges))}
\end{Highlighting}
\end{Shaded}

Output

\begin{verbatim}
{'A': 2, 'B': 2, 'C': 3, 'D': 1}
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-183}

\begin{itemize}
\tightlist
\item
  Reveals connectivity patterns
\item
  Identifies isolated nodes
\item
  Enables graph classification (regular, sparse, dense)
\item
  Essential for graph algorithms (topological sort, PageRank, BFS
  pruning)
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-83}

In any undirected graph, the sum of all degrees equals twice the number
of edges:

\[
\sum_{v \in V} \deg(v) = 2|E|
\]

In directed graphs:

\[
\sum_{v \in V} \text{in}(v) = \sum_{v \in V} \text{out}(v) = |E|
\]

These equalities guarantee correctness, every edge contributes exactly
once (or twice if undirected).

\subsubsection{Try It Yourself}\label{try-it-yourself-183}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Create an undirected graph with edges (A,B), (B,C), (C,A)

  \begin{itemize}
  \tightlist
  \item
    Verify all vertices have degree 2
  \end{itemize}
\item
  Add an isolated vertex D

  \begin{itemize}
  \tightlist
  \item
    Check that its degree is 0
  \end{itemize}
\item
  Convert to directed edges and count in/out separately
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-83}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2462}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5538}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Graph
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Input Edges
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Undirected & (A,B), (A,C) & A:2, B:1, C:1 \\
Directed & (A,B), (B,C) & in(A)=0, out(A)=1; in(C)=1, out(C)=0 \\
Isolated Node & (A,B), V=\{A,B,C\} & C:0 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-75}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Count Degrees & \(O(m)\) & \(O(n)\) \\
Lookup Degree & \(O(1)\) & - \\
\end{longtable}

A Degree Counter exposes the heartbeat of a graph, showing which nodes
are busy, which are lonely, and how the network's structure unfolds.

\subsection{85 Path Existence Tester}\label{path-existence-tester}

A Path Existence Tester checks whether there is a route between two
vertices in a graph, whether you can travel from a source to a
destination by following edges.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-84}

In many scenarios, navigation, dependency resolution, communication, the
essential question is: ``Can we get from A to B?''

This is not about finding the \emph{shortest} path, but simply checking
if a path \emph{exists} at all.

Examples:

\begin{itemize}
\tightlist
\item
  Is a file accessible from the root directory?
\item
  Can data flow between two nodes in a network?
\item
  Does a dependency graph contain a reachable edge?
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-84}

We use graph traversal to explore from the source node. If the
destination is reached, a path exists.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Choose a traversal (DFS or BFS)
\item
  Start from source node \texttt{s}
\item
  Mark visited nodes
\item
  Traverse neighbors recursively (DFS) or level by level (BFS)
\item
  If destination \texttt{t} is visited, a path exists
\end{enumerate}

\subsection{Example}\label{example-22}

Graph: \[
V = {A, B, C, D}, \quad E = {(A, B), (B, C), (C, D)}
\]

Query: Is there a path from A to D?

Traversal (DFS or BFS):

\begin{itemize}
\tightlist
\item
  Start at A → B → C → D
\item
  D is reached → Path exists ✅
\end{itemize}

Query: Is there a path from D to A?

\begin{itemize}
\tightlist
\item
  Start at D → no outgoing edges → No path ❌
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-77}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\KeywordTok{def}\NormalTok{ path\_exists(graph, source, target):}
\NormalTok{    visited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([source])}

    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ queue.popleft()}
        \ControlFlowTok{if}\NormalTok{ node }\OperatorTok{==}\NormalTok{ target:}
            \ControlFlowTok{return} \VariableTok{True}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{in}\NormalTok{ visited:}
            \ControlFlowTok{continue}
\NormalTok{        visited.add(node)}
\NormalTok{        queue.extend(graph.get(node, []))}
    \ControlFlowTok{return} \VariableTok{False}

\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{],}
    \StringTok{"B"}\NormalTok{: [}\StringTok{"C"}\NormalTok{],}
    \StringTok{"C"}\NormalTok{: [}\StringTok{"D"}\NormalTok{],}
    \StringTok{"D"}\NormalTok{: []}
\NormalTok{\}}
\BuiltInTok{print}\NormalTok{(path\_exists(graph, }\StringTok{"A"}\NormalTok{, }\StringTok{"D"}\NormalTok{))  }\CommentTok{\# True}
\BuiltInTok{print}\NormalTok{(path\_exists(graph, }\StringTok{"D"}\NormalTok{, }\StringTok{"A"}\NormalTok{))  }\CommentTok{\# False}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-184}

\begin{itemize}
\tightlist
\item
  Core to graph connectivity
\item
  Used in cycle detection, topological sorting, and reachability queries
\item
  Foundational in AI search, routing, compilers, and network analysis
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-84}

Let the graph be \(G = (V, E)\) and traversal be BFS or DFS. Every edge
\((u, v)\) is explored once. If a path exists, traversal will eventually
reach all nodes in the connected component of \texttt{s}. Thus, if
\texttt{t} lies in that component, it will be discovered.

Traversal completeness ensures correctness.

\subsubsection{Try It Yourself}\label{try-it-yourself-184}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Build a directed graph \(A \to B \to C\), and check \(A \to C\) and
  \(C \to A\).
\item
  Add an extra edge \(C \to A\).

  \begin{itemize}
  \tightlist
  \item
    Now the graph is strongly connected.
  \item
    Every node should reach every other node.
  \end{itemize}
\item
  Visualize traversal using a queue or recursion trace.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-84}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Graph & Source & Target & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A→B→C & A & C & True \\
A→B→C & C & A & False \\
A↔B & A & B & True \\
Disconnected & A & D & False \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-76}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
BFS / DFS & \(O(n + m)\) & \(O(n)\) \\
\end{longtable}

\(n\) = vertices, \(m\) = edges.

A Path Existence Tester is the simplest yet most powerful diagnostic for
graph connectivity, revealing whether two points belong to the same
connected world.

\subsection{86 Tree Validator}\label{tree-validator}

A Tree Validator checks whether a given graph satisfies the defining
properties of a tree: it is connected and acyclic.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-85}

We often encounter structures that \emph{look} like trees, but we must
confirm they truly are. For example:

\begin{itemize}
\tightlist
\item
  Can this dependency graph be represented as a tree?
\item
  Is the given parent--child relation a valid hierarchy?
\item
  Does this undirected graph contain cycles or disconnected parts?
\end{itemize}

A Tree Validator formalizes that check.

A tree must satisfy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Connectivity: every vertex reachable from any other.
\item
  Acyclicity: no cycles exist.
\item
  (Equivalently for undirected graphs) \[ |E| = |V| - 1 \]
\end{enumerate}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-85}

We can validate using traversal and counting:

Method 1: DFS + Parent Check

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start DFS from any node.
\item
  Track visited nodes.
\item
  If a neighbor is visited \emph{and not parent}, a cycle exists.
\item
  After traversal, check all nodes visited (connectedness).
\end{enumerate}

Method 2: Edge--Vertex Property

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check if graph has exactly \(|V| - 1\) edges.
\item
  Run DFS/BFS to ensure graph is connected.
\end{enumerate}

\subsection{Example}\label{example-23}

Graph 1: \[
V = {A, B, C, D}, \quad E = {(A, B), (A, C), (B, D)}
\]

\begin{itemize}
\tightlist
\item
  \(|V| = 4\), \(|E| = 3\)
\item
  Connected, no cycle → ✅ Tree
\end{itemize}

Graph 2: \[
V = {A, B, C}, \quad E = {(A, B), (B, C), (C, A)}
\]

\begin{itemize}
\tightlist
\item
  \(|V| = 3\), \(|E| = 3\)
\item
  Cycle present → ❌ Not a tree
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-78}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ is\_tree(graph):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(graph)}
\NormalTok{    visited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
\NormalTok{    parent }\OperatorTok{=}\NormalTok{ \{\}}

    \KeywordTok{def}\NormalTok{ dfs(node, par):}
\NormalTok{        visited.add(node)}
        \ControlFlowTok{for}\NormalTok{ nbr }\KeywordTok{in}\NormalTok{ graph[node]:}
            \ControlFlowTok{if}\NormalTok{ nbr }\OperatorTok{==}\NormalTok{ par:}
                \ControlFlowTok{continue}
            \ControlFlowTok{if}\NormalTok{ nbr }\KeywordTok{in}\NormalTok{ visited:}
                \ControlFlowTok{return} \VariableTok{False}  \CommentTok{\# cycle detected}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ dfs(nbr, node):}
                \ControlFlowTok{return} \VariableTok{False}
        \ControlFlowTok{return} \VariableTok{True}

    \CommentTok{\# Start from first node}
\NormalTok{    start }\OperatorTok{=} \BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(graph))}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ dfs(start, }\VariableTok{None}\NormalTok{):}
        \ControlFlowTok{return} \VariableTok{False}

    \CommentTok{\# Check connectivity}
    \ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(visited) }\OperatorTok{==}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{],}
    \StringTok{"B"}\NormalTok{: [}\StringTok{"A"}\NormalTok{, }\StringTok{"D"}\NormalTok{],}
    \StringTok{"C"}\NormalTok{: [}\StringTok{"A"}\NormalTok{],}
    \StringTok{"D"}\NormalTok{: [}\StringTok{"B"}\NormalTok{]}
\NormalTok{\}}
\BuiltInTok{print}\NormalTok{(is\_tree(graph))  }\CommentTok{\# True}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-185}

Tree validation ensures:

\begin{itemize}
\tightlist
\item
  Hierarchies are acyclic
\item
  Data structures (like ASTs, tries) are well-formed
\item
  Network topologies avoid redundant links
\item
  Algorithms relying on tree properties (DFS order, LCA, spanning tree)
  are safe
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-85}

A connected graph without cycles is a tree. Inductive reasoning:

\begin{itemize}
\tightlist
\item
  Base: single node, zero edges, trivially a tree.
\item
  Induction: adding one edge that connects a new node preserves
  acyclicity. If a cycle forms, it violates tree property.
\end{itemize}

Also, for undirected graph: \[
\text{Tree} \iff \text{Connected} \land |E| = |V| - 1
\]

\subsubsection{Try It Yourself}\label{try-it-yourself-185}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Draw a small graph with 4 nodes.
\item
  Add edges one by one.

  \begin{itemize}
  \tightlist
  \item
    After each addition, test if graph is still a tree.
  \end{itemize}
\item
  Introduce a cycle and rerun validator.
\item
  Remove an edge and check connectivity failure.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-85}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Graph & Connected & Cycle & Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A--B--C & ✅ & ❌ & ✅ \\
A--B, B--C, C--A & ✅ & ✅ & ❌ \\
A--B, C & ❌ & ❌ & ❌ \\
Single Node & ✅ & ❌ & ✅ \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-77}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS & \(O(n + m)\) & \(O(n)\) \\
\end{longtable}

A Tree Validator ensures structure, order, and simplicity, the quiet
geometry behind every hierarchy.

\subsection{86 Tree Validator}\label{tree-validator-1}

A Tree Validator checks whether a given graph satisfies the defining
properties of a tree: it is connected and acyclic.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-86}

We often encounter structures that \emph{look} like trees, but we must
confirm they truly are. For example:

\begin{itemize}
\tightlist
\item
  Can this dependency graph be represented as a tree?
\item
  Is the given parent--child relation a valid hierarchy?
\item
  Does this undirected graph contain cycles or disconnected parts?
\end{itemize}

A Tree Validator formalizes that check.

A tree must satisfy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Connectivity: every vertex reachable from any other.
\item
  Acyclicity: no cycles exist.
\item
  (Equivalently for undirected graphs) \[|E| = |V| - 1\]
\end{enumerate}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-86}

We can validate using traversal and counting.

Method 1: DFS + Parent Check

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start DFS from any node.
\item
  Track visited nodes.
\item
  If a neighbor is visited \emph{and not parent}, a cycle exists.
\item
  After traversal, check all nodes visited (connectedness).
\end{enumerate}

Method 2: Edge--Vertex Property

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Check if graph has exactly \(|V| - 1\) edges.
\item
  Run DFS or BFS to ensure graph is connected.
\end{enumerate}

\subsection{Example}\label{example-24}

Graph 1: \[
V = {A, B, C, D}, \quad E = {(A, B), (A, C), (B, D)}
\]

\begin{itemize}
\tightlist
\item
  \(|V| = 4\), \(|E| = 3\)
\item
  Connected, no cycle → Tree
\end{itemize}

Graph 2: \[
V = {A, B, C}, \quad E = {(A, B), (B, C), (C, A)}
\]

\begin{itemize}
\tightlist
\item
  \(|V| = 3\), \(|E| = 3\)
\item
  Cycle present → Not a tree
\end{itemize}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-79}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ is\_tree(graph):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(graph)}
\NormalTok{    visited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
\NormalTok{    parent }\OperatorTok{=}\NormalTok{ \{\}}

    \KeywordTok{def}\NormalTok{ dfs(node, par):}
\NormalTok{        visited.add(node)}
        \ControlFlowTok{for}\NormalTok{ nbr }\KeywordTok{in}\NormalTok{ graph[node]:}
            \ControlFlowTok{if}\NormalTok{ nbr }\OperatorTok{==}\NormalTok{ par:}
                \ControlFlowTok{continue}
            \ControlFlowTok{if}\NormalTok{ nbr }\KeywordTok{in}\NormalTok{ visited:}
                \ControlFlowTok{return} \VariableTok{False}  \CommentTok{\# cycle detected}
            \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ dfs(nbr, node):}
                \ControlFlowTok{return} \VariableTok{False}
        \ControlFlowTok{return} \VariableTok{True}

    \CommentTok{\# Start from first node}
\NormalTok{    start }\OperatorTok{=} \BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(graph))}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ dfs(start, }\VariableTok{None}\NormalTok{):}
        \ControlFlowTok{return} \VariableTok{False}

    \CommentTok{\# Check connectivity}
    \ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(visited) }\OperatorTok{==}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"A"}\NormalTok{: [}\StringTok{"B"}\NormalTok{, }\StringTok{"C"}\NormalTok{],}
    \StringTok{"B"}\NormalTok{: [}\StringTok{"A"}\NormalTok{, }\StringTok{"D"}\NormalTok{],}
    \StringTok{"C"}\NormalTok{: [}\StringTok{"A"}\NormalTok{],}
    \StringTok{"D"}\NormalTok{: [}\StringTok{"B"}\NormalTok{]}
\NormalTok{\}}
\BuiltInTok{print}\NormalTok{(is\_tree(graph))  }\CommentTok{\# True}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-186}

Tree validation ensures:

\begin{itemize}
\tightlist
\item
  Hierarchies are acyclic
\item
  Data structures (like ASTs, tries) are well-formed
\item
  Network topologies avoid redundant links
\item
  Algorithms relying on tree properties (DFS order, LCA, spanning tree)
  are safe
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-86}

A connected graph without cycles is a tree. Inductive reasoning:

\begin{itemize}
\tightlist
\item
  Base: single node, zero edges, trivially a tree.
\item
  Induction: adding one edge that connects a new node preserves
  acyclicity. If a cycle forms, it violates the tree property.
\end{itemize}

Also, for an undirected graph: \[
\text{Tree} \iff \text{Connected} \land |E| = |V| - 1
\]

\subsubsection{Try It Yourself}\label{try-it-yourself-186}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Draw a small graph with 4 nodes.
\item
  Add edges one by one.

  \begin{itemize}
  \tightlist
  \item
    After each addition, test if the graph is still a tree.
  \end{itemize}
\item
  Introduce a cycle and rerun the validator.
\item
  Remove an edge and check for connectivity failure.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-86}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Graph & Connected & Cycle & Tree \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
A--B--C & Yes & No & Yes \\
A--B, B--C, C--A & Yes & Yes & No \\
A--B, C & No & No & No \\
Single Node & Yes & No & Yes \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-78}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS & \(O(n + m)\) & \(O(n)\) \\
\end{longtable}

A Tree Validator ensures structure, order, and simplicity, the quiet
geometry behind every hierarchy.

\subsection{87 Rooted Tree Builder}\label{rooted-tree-builder}

A Rooted Tree Builder constructs a tree from a given parent array or
edge list, designating one node as the root and connecting all others
accordingly.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-87}

Often we receive data in \emph{flat} form---like a list of parent
indices, database references, or parent--child pairs---and we need to
reconstruct the actual tree structure.

For example:

\begin{itemize}
\tightlist
\item
  A parent array \texttt{{[}\ -1,\ 0,\ 0,\ 1,\ 1,\ 2\ {]}} represents
  which node is parent of each.
\item
  In file systems, each directory knows its parent; we need to rebuild
  the hierarchy.
\end{itemize}

The Rooted Tree Builder formalizes this reconstruction.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-87}

A parent array encodes each node's parent:

\begin{itemize}
\tightlist
\item
  \texttt{parent{[}i{]}\ =\ j} means node \texttt{j} is the parent of
  \texttt{i}.
\item
  If \texttt{parent{[}i{]}\ =\ -1}, then \texttt{i} is the root.
\end{itemize}

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Find the root (the node with parent \texttt{-1}).
\item
  Initialize an adjacency list \texttt{children} for each node.
\item
  For each node \texttt{i}:

  \begin{itemize}
  \tightlist
  \item
    If \texttt{parent{[}i{]}\ !=\ -1}, append \texttt{i} to
    \texttt{children{[}parent{[}i{]}{]}}.
  \end{itemize}
\item
  Output the adjacency structure.
\end{enumerate}

This gives a tree with parent--child relationships.

\subsection{Example}\label{example-25}

Parent array:

\begin{verbatim}
Index:  0  1  2  3  4  5
Parent: -1  0  0  1  1  2
\end{verbatim}

Interpretation:

\begin{itemize}
\tightlist
\item
  \texttt{0} is root.
\item
  \texttt{1} and \texttt{2} are children of \texttt{0}.
\item
  \texttt{3} and \texttt{4} are children of \texttt{1}.
\item
  \texttt{5} is child of \texttt{2}.
\end{itemize}

Tree:

\begin{verbatim}
0
├── 1
│   ├── 3
│   └── 4
└── 2
    └── 5
\end{verbatim}

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-80}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ build\_tree(parent):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(parent)}
\NormalTok{    children }\OperatorTok{=}\NormalTok{ [[] }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n)]}
\NormalTok{    root }\OperatorTok{=} \VariableTok{None}

    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
        \ControlFlowTok{if}\NormalTok{ parent[i] }\OperatorTok{==} \OperatorTok{{-}}\DecValTok{1}\NormalTok{:}
\NormalTok{            root }\OperatorTok{=}\NormalTok{ i}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            children[parent[i]].append(i)}

    \ControlFlowTok{return}\NormalTok{ root, children}
\end{Highlighting}
\end{Shaded}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{parent }\OperatorTok{=}\NormalTok{ [}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\NormalTok{root, children }\OperatorTok{=}\NormalTok{ build\_tree(parent)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Root:"}\NormalTok{, root)}
\ControlFlowTok{for}\NormalTok{ i, c }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(children):}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{i}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Output:

\begin{verbatim}
Root: 0
0: [1, 2]
1: [3, 4]
2: [5]
3: []
4: []
5: []
\end{verbatim}

\subsubsection{Why It Matters}\label{why-it-matters-187}

Tree reconstruction is foundational in:

\begin{itemize}
\tightlist
\item
  Compilers: abstract syntax tree (AST) reconstruction
\item
  Databases: reconstructing hierarchical relationships
\item
  Operating systems: file directory trees
\item
  Organization charts: building hierarchies from parent--child data
\end{itemize}

It connects linear storage to hierarchical structure.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-87}

If the parent array satisfies:

\begin{itemize}
\tightlist
\item
  Exactly one root: one entry with \texttt{-1}
\item
  All other nodes have exactly one parent
\item
  The resulting structure is connected and acyclic
\end{itemize}

Then the output is a valid rooted tree: \[
|E| = |V| - 1, \text{ and exactly one node has no parent.}
\]

Each child is linked once, forming a tree rooted at the unique node with
\texttt{-1}.

\subsubsection{Try It Yourself}\label{try-it-yourself-187}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write your own parent array (e.g.,
  \texttt{{[}\ -1,\ 0,\ 0,\ 1,\ 2\ {]}}).
\item
  Convert it into a tree.
\item
  Draw the hierarchy manually.
\item
  Verify connectivity and acyclicity.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-87}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Parent Array & Root & Children Structure \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}-1, 0, 0, 1, 1, 2{]} & 0 & 0:{[}1,2{]}, 1:{[}3,4{]}, 2:{[}5{]} \\
{[}-1, 0, 1, 2{]} & 0 & 0:{[}1{]}, 1:{[}2{]}, 2:{[}3{]} \\
{[}-1{]} & 0 & 0:{[}{]} \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-79}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Build & \(O(n)\) & \(O(n)\) \\
\end{longtable}

The Rooted Tree Builder bridges the gap between flat data and
hierarchical form, turning arrays into living structures.

\subsection{88 Traversal Order
Visualizer}\label{traversal-order-visualizer}

A Traversal Order Visualizer shows how different tree traversals
(preorder, inorder, postorder, level order) explore nodes, revealing the
logic behind recursive and iterative visits.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-88}

When working with trees, the order of visiting nodes matters. Different
traversals serve different goals:

\begin{itemize}
\tightlist
\item
  Preorder: process parent before children
\item
  Inorder: process left child, then parent, then right child
\item
  Postorder: process children before parent
\item
  Level order: visit nodes breadth-first
\end{itemize}

Understanding these traversals helps in:

\begin{itemize}
\tightlist
\item
  Expression parsing
\item
  File system navigation
\item
  Tree printing and evaluation
\end{itemize}

A visualizer clarifies \emph{when} and \emph{why} each node is visited.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-88}

Consider a binary tree:

\begin{verbatim}
      A
     / \
    B   C
   / \
  D   E
\end{verbatim}

Each traversal orders nodes differently:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Traversal & Order \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Preorder & A, B, D, E, C \\
Inorder & D, B, E, A, C \\
Postorder & D, E, B, C, A \\
Level order & A, B, C, D, E \\
\end{longtable}

Visualization strategy:

\begin{itemize}
\tightlist
\item
  Start at the root.
\item
  Use recursion (depth-first) or queue (breadth-first).
\item
  Record each visit step.
\item
  Output sequence in order visited.
\end{itemize}

\subsubsection{Example Step by Step}\label{example-step-by-step-79}

Tree:

\begin{verbatim}
A
├── B
│   ├── D
│   └── E
└── C
\end{verbatim}

Preorder

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Visit A
\item
  Visit B
\item
  Visit D
\item
  Visit E
\item
  Visit C
\end{enumerate}

Sequence: A B D E C

Inorder

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Traverse left subtree of A (B)
\item
  Traverse left of B (D) → visit D
\item
  Visit B
\item
  Traverse right of B (E) → visit E
\item
  Visit A
\item
  Visit right subtree (C)
\end{enumerate}

Sequence: D B E A C

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-81}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{ Node:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, val):}
        \VariableTok{self}\NormalTok{.val }\OperatorTok{=}\NormalTok{ val}
        \VariableTok{self}\NormalTok{.left }\OperatorTok{=} \VariableTok{None}
        \VariableTok{self}\NormalTok{.right }\OperatorTok{=} \VariableTok{None}

\KeywordTok{def}\NormalTok{ preorder(root):}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ root:}
        \ControlFlowTok{return}\NormalTok{ []}
    \ControlFlowTok{return}\NormalTok{ [root.val] }\OperatorTok{+}\NormalTok{ preorder(root.left) }\OperatorTok{+}\NormalTok{ preorder(root.right)}

\KeywordTok{def}\NormalTok{ inorder(root):}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ root:}
        \ControlFlowTok{return}\NormalTok{ []}
    \ControlFlowTok{return}\NormalTok{ inorder(root.left) }\OperatorTok{+}\NormalTok{ [root.val] }\OperatorTok{+}\NormalTok{ inorder(root.right)}

\KeywordTok{def}\NormalTok{ postorder(root):}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ root:}
        \ControlFlowTok{return}\NormalTok{ []}
    \ControlFlowTok{return}\NormalTok{ postorder(root.left) }\OperatorTok{+}\NormalTok{ postorder(root.right) }\OperatorTok{+}\NormalTok{ [root.val]}

\KeywordTok{def}\NormalTok{ level\_order(root):}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ root:}
        \ControlFlowTok{return}\NormalTok{ []}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ [root]}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        node }\OperatorTok{=}\NormalTok{ queue.pop(}\DecValTok{0}\NormalTok{)}
\NormalTok{        result.append(node.val)}
        \ControlFlowTok{if}\NormalTok{ node.left:}
\NormalTok{            queue.append(node.left)}
        \ControlFlowTok{if}\NormalTok{ node.right:}
\NormalTok{            queue.append(node.right)}
    \ControlFlowTok{return}\NormalTok{ result}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-188}

Traversal order determines:

\begin{itemize}
\tightlist
\item
  Computation sequence (evaluation, deletion, printing)
\item
  Expression tree evaluation (postorder)
\item
  Serialization/deserialization (preorder + inorder)
\item
  Breadth-first exploration (level order)
\end{itemize}

Understanding traversal = understanding how algorithms move through
structure.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-88}

Each traversal is a systematic walk:

\begin{itemize}
\tightlist
\item
  Preorder ensures root-first visitation.
\item
  Inorder ensures sorted order in binary search trees.
\item
  Postorder ensures children processed before parent.
\item
  Level order ensures minimal depth-first layering.
\end{itemize}

Since each node is visited exactly once, correctness follows from
recursion and induction.

\subsubsection{Try It Yourself}\label{try-it-yourself-188}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Build a binary tree with 5 nodes.
\item
  Write out all four traversals by hand.
\item
  Trace recursive calls step by step.
\item
  Observe how order changes per traversal.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-88}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Traversal & Example Tree & Expected Order \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Preorder & A-B-C & A B C \\
Inorder & A-B-C & B A C \\
Postorder & A-B-C & B C A \\
Level order & A-B-C & A B C \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-80}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS (Pre/In/Post) & \(O(n)\) & \(O(h)\) (stack) \\
BFS (Level) & \(O(n)\) & \(O(n)\) (queue) \\
\end{longtable}

The Traversal Order Visualizer turns abstract definitions into motion,
showing how structure guides computation.

\subsection{89 Edge Classifier}\label{edge-classifier}

An Edge Classifier determines the type of each edge encountered during a
graph traversal, whether it is a tree edge, back edge, forward edge, or
cross edge. This classification helps us understand the structure and
flow of a directed or undirected graph.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-89}

In graph algorithms, not all edges play the same role. When we traverse
using DFS, we can interpret the relationship between vertices based on
discovery times.

Edge classification helps answer questions like:

\begin{itemize}
\tightlist
\item
  Is there a cycle? (Look for back edges)
\item
  How is the graph structured? (Tree vs forward edges)
\item
  Is this DAG (Directed Acyclic Graph)? (No back edges)
\item
  What's the hierarchical relation between nodes?
\end{itemize}

By tagging edges, we gain structural insight into traversal behavior.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-89}

During DFS, we assign each vertex:

\begin{itemize}
\tightlist
\item
  Discovery time when first visited.
\item
  Finish time when exploration completes.
\end{itemize}

Each edge \((u, v)\) is then classified as:

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Type & Condition \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Tree edge & \(v\) is first discovered by \((u, v)\) \\
Back edge & \(v\) is ancestor of \(u\) (cycle indicator) \\
Forward edge & \(v\) is descendant of \(u\), but already visited \\
Cross edge & \(v\) is neither ancestor nor descendant of \(u\) \\
\end{longtable}

In undirected graphs, only tree and back edges occur.

\subsection{Example}\label{example-26}

Graph (directed):

\begin{verbatim}
1 → 2 → 3
↑   ↓
4 ← 5
\end{verbatim}

During DFS starting at 1:

\begin{itemize}
\tightlist
\item
  (1,2): tree edge
\item
  (2,3): tree edge
\item
  (3,4): back edge (cycle 1--2--3--4--1)
\item
  (2,5): tree edge
\item
  (5,4): tree edge
\item
  (4,1): back edge
\end{itemize}

So we detect cycles due to back edges.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-82}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ classify\_edges(graph):}
\NormalTok{    time }\OperatorTok{=} \DecValTok{0}
\NormalTok{    discovered }\OperatorTok{=}\NormalTok{ \{\}}
\NormalTok{    finished }\OperatorTok{=}\NormalTok{ \{\}}
\NormalTok{    classification }\OperatorTok{=}\NormalTok{ []}

    \KeywordTok{def}\NormalTok{ dfs(u):}
        \KeywordTok{nonlocal}\NormalTok{ time}
\NormalTok{        time }\OperatorTok{+=} \DecValTok{1}
\NormalTok{        discovered[u] }\OperatorTok{=}\NormalTok{ time}
        \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ graph[u]:}
            \ControlFlowTok{if}\NormalTok{ v }\KeywordTok{not} \KeywordTok{in}\NormalTok{ discovered:}
\NormalTok{                classification.append(((u, v), }\StringTok{"Tree"}\NormalTok{))}
\NormalTok{                dfs(v)}
            \ControlFlowTok{elif}\NormalTok{ v }\KeywordTok{not} \KeywordTok{in}\NormalTok{ finished:}
\NormalTok{                classification.append(((u, v), }\StringTok{"Back"}\NormalTok{))}
            \ControlFlowTok{elif}\NormalTok{ discovered[u] }\OperatorTok{\textless{}}\NormalTok{ discovered[v]:}
\NormalTok{                classification.append(((u, v), }\StringTok{"Forward"}\NormalTok{))}
            \ControlFlowTok{else}\NormalTok{:}
\NormalTok{                classification.append(((u, v), }\StringTok{"Cross"}\NormalTok{))}
\NormalTok{        time }\OperatorTok{+=} \DecValTok{1}
\NormalTok{        finished[u] }\OperatorTok{=}\NormalTok{ time}

    \ControlFlowTok{for}\NormalTok{ node }\KeywordTok{in}\NormalTok{ graph:}
        \ControlFlowTok{if}\NormalTok{ node }\KeywordTok{not} \KeywordTok{in}\NormalTok{ discovered:}
\NormalTok{            dfs(node)}
    \ControlFlowTok{return}\NormalTok{ classification}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-189}

Edge classification underpins:

\begin{itemize}
\tightlist
\item
  Cycle detection (look for back edges)
\item
  Topological sorting (DAGs have no back edges)
\item
  DFS tree structure analysis
\item
  Strongly connected component detection
\end{itemize}

It converts traversal into structural insight.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-89}

DFS imposes a temporal order on discovery and finish times. An edge
\((u, v)\) can only fall into one of the four categories because:

\[
\text{Each vertex has a distinct discovery and finish time interval.}
\]

By comparing intervals \((d[u], f[u])\) and \((d[v], f[v])\), we deduce
whether \(v\) lies inside, before, or after \(u\)'s traversal window.

\subsubsection{Try It Yourself}\label{try-it-yourself-189}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a small directed graph.
\item
  Assign discovery/finish times using DFS.
\item
  Compare intervals for each edge.
\item
  Label each edge as Tree, Back, Forward, or Cross.
\item
  Verify that DAGs have no back edges.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-89}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Edge & Type \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
(A, B) & Tree \\
(B, C) & Tree \\
(C, A) & Back \\
(B, D) & Tree \\
(D, E) & Tree \\
(E, B) & Back \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-81}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS Traversal & \(O(n + m)\) & \(O(n)\) \\
Classification & \(O(m)\) & \(O(m)\) \\
\end{longtable}

The Edge Classifier transforms traversal into topology, making invisible
structures like cycles, hierarchies, and cross-links explicit.

\subsection{90 Connectivity Checker}\label{connectivity-checker}

A Connectivity Checker determines whether a graph is connected, that is,
whether every vertex can be reached from any other vertex. It's a
fundamental diagnostic tool in graph theory and network analysis.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-90}

Connectivity tells us whether the graph forms a single whole or multiple
isolated parts.

We often ask:

\begin{itemize}
\tightlist
\item
  Can all nodes communicate in this network?
\item
  Is this maze solvable from start to end?
\item
  Does this undirected graph form one component or many?
\item
  For directed graphs: can we reach every vertex from every other
  vertex?
\end{itemize}

The Connectivity Checker gives a yes/no answer, and can also enumerate
connected components.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-90}

Undirected Graph:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pick a starting node.
\item
  Perform DFS or BFS, marking all reachable nodes.
\item
  After traversal, if all nodes are marked, the graph is connected.
\end{enumerate}

Directed Graph:

\begin{itemize}
\item
  Use two traversals:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Run DFS from any node. If not all nodes are visited, not strongly
    connected.
  \item
    Reverse all edges and run DFS again. If still not all nodes are
    visited, not strongly connected.
  \end{enumerate}
\end{itemize}

Alternatively, detect strongly connected components (SCCs) via
Kosaraju's or Tarjan's algorithm.

\subsection{Example (Undirected)}\label{example-undirected}

Graph 1:

\begin{verbatim}
1, 2, 3
|       |
4, 5, 6
\end{verbatim}

All nodes reachable → Connected.

Graph 2:

\begin{verbatim}
1, 2    3, 4
\end{verbatim}

Two separate parts → Not connected.

\subsection{Example (Directed)}\label{example-directed}

Graph:

\begin{verbatim}
1 → 2 → 3
↑       ↓
└───────┘
\end{verbatim}

Every node reachable from every other → Strongly connected

Graph:

\begin{verbatim}
1 → 2 → 3
\end{verbatim}

No path from 3 → 1 → Not strongly connected

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-83}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ collections }\ImportTok{import}\NormalTok{ deque}

\KeywordTok{def}\NormalTok{ is\_connected(graph):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(graph)}
\NormalTok{    visited }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}

    \CommentTok{\# BFS from first node}
\NormalTok{    start }\OperatorTok{=} \BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(graph))}
\NormalTok{    queue }\OperatorTok{=}\NormalTok{ deque([start])}
    \ControlFlowTok{while}\NormalTok{ queue:}
\NormalTok{        u }\OperatorTok{=}\NormalTok{ queue.popleft()}
        \ControlFlowTok{if}\NormalTok{ u }\KeywordTok{in}\NormalTok{ visited:}
            \ControlFlowTok{continue}
\NormalTok{        visited.add(u)}
        \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ graph[u]:}
            \ControlFlowTok{if}\NormalTok{ v }\KeywordTok{not} \KeywordTok{in}\NormalTok{ visited:}
\NormalTok{                queue.append(v)}
    
    \ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(visited) }\OperatorTok{==}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

Example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{graph }\OperatorTok{=}\NormalTok{ \{}
    \DecValTok{1}\NormalTok{: [}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{],}
    \DecValTok{2}\NormalTok{: [}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{],}
    \DecValTok{3}\NormalTok{: [}\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{],}
    \DecValTok{4}\NormalTok{: [}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{],}
    \DecValTok{5}\NormalTok{: [}\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{],}
    \DecValTok{6}\NormalTok{: [}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{]}
\NormalTok{\}}
\BuiltInTok{print}\NormalTok{(is\_connected(graph))  }\CommentTok{\# True}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-190}

Connectivity is central in:

\begin{itemize}
\tightlist
\item
  Network reliability, ensure all nodes communicate
\item
  Graph algorithms, many assume connected graphs
\item
  Clustering, find connected components
\item
  Pathfinding, unreachable nodes signal barriers
\end{itemize}

It's often the \emph{first diagnostic check} before deeper analysis.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-90}

For undirected graphs, connectivity is equivalence relation:

\begin{itemize}
\tightlist
\item
  Reflexive: node connects to itself
\item
  Symmetric: if A connects to B, B connects to A
\item
  Transitive: if A connects to B and B connects to C, A connects to C
\end{itemize}

Therefore, DFS/BFS reachability partitioning defines connected
components uniquely.

\subsubsection{Try It Yourself}\label{try-it-yourself-190}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Draw a graph with 6 nodes.
\item
  Run BFS or DFS from node 1.
\item
  Mark all reachable nodes.
\item
  If some remain unvisited, you've found multiple components.
\item
  For directed graphs, try reversing edges and retesting.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-90}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Graph & Type & Result \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1--2--3 & Undirected & Connected \\
1--2, 3--4 & Undirected & Not Connected \\
1→2→3, 3→1 & Directed & Strongly Connected \\
1→2→3 & Directed & Not Strongly Connected \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-82}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
DFS/BFS & \(O(n + m)\) & \(O(n)\) \\
\end{longtable}

A Connectivity Checker ensures your graph is a single story, not a
collection of isolated tales, a foundation before every journey through
the graph.

\bookmarksetup{startatroot}

\chapter{Section 10. Algorithm Design
Patterns}\label{section-10.-algorithm-design-patterns}

\subsection{91 Brute Force Pattern}\label{brute-force-pattern}

The Brute Force Pattern is the simplest and most universal approach to
problem-solving: try every possible option, evaluate them all, and pick
the best. It trades computational efficiency for conceptual clarity and
correctness.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-91}

Sometimes, before clever optimizations or heuristics, we need a baseline
solution, a way to ensure correctness. The brute force approach
guarantees finding the right answer by exploring all possible
configurations, even if it's slow.

Common use cases:

\begin{itemize}
\tightlist
\item
  Exhaustive search (e.g., generating all permutations or subsets)
\item
  Baseline testing before implementing heuristics
\item
  Proving optimality by comparison
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-91}

A brute force algorithm generally follows this structure:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Enumerate all candidate solutions.
\item
  Evaluate each candidate for validity or cost.
\item
  Select the best (or first valid) solution.
\end{enumerate}

This is conceptually simple, though often expensive in time.

\subsection{Example: Traveling Salesman Problem
(TSP)}\label{example-traveling-salesman-problem-tsp-1}

Given \(n\) cities and distances between them, find the shortest tour
visiting all.

Brute force solution:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Generate all \(n!\) possible tours.
\item
  Compute the total distance for each.
\item
  Return the shortest tour.
\end{enumerate}

This ensures correctness but grows factorially in complexity.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-84}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ itertools }\ImportTok{import}\NormalTok{ permutations}

\KeywordTok{def}\NormalTok{ tsp\_bruteforce(dist):}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(dist)}
\NormalTok{    cities }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(}\BuiltInTok{range}\NormalTok{(n))}
\NormalTok{    best }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(}\StringTok{\textquotesingle{}inf\textquotesingle{}}\NormalTok{)}
\NormalTok{    best\_path }\OperatorTok{=} \VariableTok{None}
    
    \ControlFlowTok{for}\NormalTok{ perm }\KeywordTok{in}\NormalTok{ permutations(cities[}\DecValTok{1}\NormalTok{:]):  }\CommentTok{\# fix city 0 as start}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{+} \BuiltInTok{list}\NormalTok{(perm) }\OperatorTok{+}\NormalTok{ [}\DecValTok{0}\NormalTok{]}
\NormalTok{        cost }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(dist[path[i]][path[i}\OperatorTok{+}\DecValTok{1}\NormalTok{]] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n))}
        \ControlFlowTok{if}\NormalTok{ cost }\OperatorTok{\textless{}}\NormalTok{ best:}
\NormalTok{            best }\OperatorTok{=}\NormalTok{ cost}
\NormalTok{            best\_path }\OperatorTok{=}\NormalTok{ path}
    \ControlFlowTok{return}\NormalTok{ best, best\_path}

\CommentTok{\# Example distance matrix}
\NormalTok{dist }\OperatorTok{=}\NormalTok{ [}
\NormalTok{    [}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{20}\NormalTok{],}
\NormalTok{    [}\DecValTok{10}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{25}\NormalTok{],}
\NormalTok{    [}\DecValTok{15}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{30}\NormalTok{],}
\NormalTok{    [}\DecValTok{20}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{0}\NormalTok{]}
\NormalTok{]}

\BuiltInTok{print}\NormalTok{(tsp\_bruteforce(dist))  }\CommentTok{\# (80, [0, 1, 3, 2, 0])}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-191}

Brute force is valuable for:

\begin{itemize}
\tightlist
\item
  Correctness: guarantees the right answer.
\item
  Benchmarking: provides a ground truth for optimization.
\item
  Small inputs: often feasible when \(n\) is small.
\item
  Teaching: clarifies the structure of search and evaluation.
\end{itemize}

It is the seed from which more refined algorithms (like DP,
backtracking, and heuristics) evolve.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-91}

Let \(S\) be the finite set of all possible solutions. If the algorithm
evaluates every \(s \in S\) and correctly computes its quality, and
selects the minimum (or maximum), the chosen \(s^*\) is provably
optimal: \[
s^* = \arg\min_{s \in S} f(s)
\] Completeness and correctness are inherent, though efficiency is not.

\subsubsection{Try It Yourself}\label{try-it-yourself-191}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Enumerate all subsets of \({1, 2, 3}\).
\item
  Check which subsets sum to 4.
\item
  Confirm all possibilities are considered.
\item
  Reflect on the time cost: \(2^n\) subsets for \(n\) elements.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-91}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & Input Size & Feasible? & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
TSP & n = 4 & ✅ & \(4! = 24\) paths \\
TSP & n = 10 & ❌ & \(10! \approx 3.6 \times 10^6\) \\
Subset Sum & n = 10 & ✅ & \(2^{10} = 1024\) subsets \\
Subset Sum & n = 30 & ❌ & \(2^{30} \approx 10^9\) subsets \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-83}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Enumeration & \(O(k^n)\) (varies) & \(O(n)\) \\
\end{longtable}

The Brute Force Pattern is the blank canvas of algorithmic design:
simple, exhaustive, and pure, a way to guarantee truth before seeking
elegance.

\subsection{92 Greedy Pattern}\label{greedy-pattern}

The Greedy Pattern builds a solution step by step, choosing at each
stage the locally optimal move, the one that seems best right now, with
the hope (and often the proof) that this path leads to a globally
optimal result.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-92}

Greedy algorithms are used when problems exhibit two key properties:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Greedy-choice property -- a global optimum can be reached by choosing
  local optima.
\item
  Optimal substructure -- an optimal solution contains optimal solutions
  to subproblems.
\end{enumerate}

You'll meet greedy reasoning everywhere: scheduling, pathfinding,
compression, and resource allocation.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-92}

Greedy thinking is ``take the best bite each time.'' There's no looking
back, no exploring alternatives, just a sequence of decisive moves.

General shape:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with an empty or initial solution.
\item
  Repeatedly choose the best local move (by some rule).
\item
  Stop when no more moves are possible or desired.
\end{enumerate}

\subsection{Example: Coin Change (Canonical
Coins)}\label{example-coin-change-canonical-coins}

Given coins \({25, 10, 5, 1}\), make change for 63 cents.

Greedy approach:

\begin{itemize}
\tightlist
\item
  Take largest coin \(\le\) remaining value.
\item
  Subtract and repeat. Result: \(25 + 25 + 10 + 1 + 1 + 1 = 63\) (6
  coins total)
\end{itemize}

Works for canonical systems, not all, a nice teaching point.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-85}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ greedy\_coin\_change(coins, amount):}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{sorted}\NormalTok{(coins, reverse}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
        \ControlFlowTok{while}\NormalTok{ amount }\OperatorTok{\textgreater{}=}\NormalTok{ c:}
\NormalTok{            amount }\OperatorTok{{-}=}\NormalTok{ c}
\NormalTok{            result.append(c)}
    \ControlFlowTok{return}\NormalTok{ result}

\BuiltInTok{print}\NormalTok{(greedy\_coin\_change([}\DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{], }\DecValTok{63}\NormalTok{))}
\CommentTok{\# [25, 25, 10, 1, 1, 1]}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-192}

The greedy pattern is a core design paradigm:

\begin{itemize}
\tightlist
\item
  Simple and fast -- often linear or \(O(n \log n)\).
\item
  Provably optimal when conditions hold.
\item
  Intuitive -- builds insight into structure of problems.
\item
  Foundation -- many approximation and heuristic algorithms are ``greedy
  at heart.''
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-92}

For problems with optimal substructure, we can often prove by induction:

If a greedy choice \(g\) leaves a subproblem \(P'\), and
\[\text{OPT}(P) = g + \text{OPT}(P')\] then solving \(P'\) optimally
ensures global optimality.

For coin change with canonical coins, this holds since choosing a larger
coin never prevents an optimal total.

\subsubsection{Try It Yourself}\label{try-it-yourself-192}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Apply the greedy method to Activity Selection: Sort activities by
  finishing time, pick earliest finishing one, and skip overlapping.
\item
  Compare against brute force enumeration.
\item
  Check if the greedy result is optimal, why or why not?
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-92}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1605}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5062}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Greedy Works?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Note
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Activity Selection & ✅ & Local earliest-finish leads to global max \\
Coin Change (1, 3, 4) for 6 & ❌ & 3+3 better than 4+1+1 \\
Huffman Coding & ✅ & Greedy merging yields optimal tree \\
Kruskal's MST & ✅ & Greedy edge selection builds MST \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-84}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Operation & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Selection & \(O(n \log n)\) (sorting) & \(O(1)\) \\
Step Choice & \(O(n)\) & \(O(1)\) \\
\end{longtable}

The Greedy Pattern is the art of decisive reasoning, choosing what seems
best now, and trusting the problem's structure to reward confidence.

\subsection{93 Divide and Conquer
Pattern}\label{divide-and-conquer-pattern}

The Divide and Conquer Pattern breaks a big problem into smaller,
similar subproblems, solves each one (often recursively), and then
combines their results into the final answer.

It's the pattern behind merge sort, quicksort, binary search, and fast
algorithms across mathematics and computation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-93}

We use divide and conquer when:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The problem can be split into smaller subproblems of the same type.
\item
  Those subproblems are independent and easier to solve.
\item
  Their solutions can be merged efficiently.
\end{enumerate}

It's the algorithmic mirror of mathematical induction, reduce, solve,
combine.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-93}

Think of divide and conquer as a recursive three-step dance:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide -- split the problem into smaller parts.
\item
  Conquer -- solve each part recursively.
\item
  Combine -- merge the sub-results into a final answer.
\end{enumerate}

Each recursive call tackles a fraction of the work until reaching a base
case.

\subsection{Example: Merge Sort}\label{example-merge-sort}

Sort an array \(A[1..n]\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide: split \(A\) into two halves.
\item
  Conquer: recursively sort each half.
\item
  Combine: merge the two sorted halves.
\end{enumerate}

Recurrence: \[T(n) = 2T\left(\frac{n}{2}\right) + O(n)\] Solution:
\[T(n) = O(n \log n)\]

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-86}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ merge\_sort(arr):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ arr}
\NormalTok{    mid }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{//} \DecValTok{2}
\NormalTok{    left }\OperatorTok{=}\NormalTok{ merge\_sort(arr[:mid])}
\NormalTok{    right }\OperatorTok{=}\NormalTok{ merge\_sort(arr[mid:])}
    \ControlFlowTok{return}\NormalTok{ merge(left, right)}

\KeywordTok{def}\NormalTok{ merge(left, right):}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ j }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ i }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(left) }\KeywordTok{and}\NormalTok{ j }\OperatorTok{\textless{}} \BuiltInTok{len}\NormalTok{(right):}
        \ControlFlowTok{if}\NormalTok{ left[i] }\OperatorTok{\textless{}=}\NormalTok{ right[j]:}
\NormalTok{            result.append(left[i])}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=} \DecValTok{1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            result.append(right[j])}\OperatorTok{;}\NormalTok{ j }\OperatorTok{+=} \DecValTok{1}
\NormalTok{    result.extend(left[i:])}\OperatorTok{;}\NormalTok{ result.extend(right[j:])}
    \ControlFlowTok{return}\NormalTok{ result}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-193}

Divide and conquer turns recursion into efficiency. It's a framework
for:

\begin{itemize}
\tightlist
\item
  Sorting (Merge Sort, Quick Sort)
\item
  Searching (Binary Search)
\item
  Matrix Multiplication (Strassen's Algorithm)
\item
  FFT (Fast Fourier Transform)
\item
  Geometry (Closest Pair, Convex Hull)
\item
  Data Science (Divide-and-Conquer Regression, Decision Trees)
\end{itemize}

It captures the principle: \emph{solve big problems by shrinking them.}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-93}

Assume each subproblem of size \(\frac{n}{2}\) is solved optimally.

If we combine \(k\) subresults with cost \(f(n)\), the total cost
follows the recurrence \[T(n) = aT\left(\frac{n}{b}\right) + f(n)\]

Using the Master Theorem, we compare \(f(n)\) with \(n^{\log_b a}\) to
find \(T(n)\).

For merge sort: \(a = 2, b = 2, f(n) = n\) ⇒ \(T(n) = O(n \log n)\).

\subsubsection{Try It Yourself}\label{try-it-yourself-193}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Apply divide and conquer to maximum subarray sum (Kadane's
  alternative).
\item
  Write a binary search with clear divide/conquer steps.
\item
  Visualize recursion tree and total cost at each level.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-93}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & Divide & Combine & Works Well? \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Merge Sort & Split array & Merge halves & ✅ \\
Quick Sort & Partition array & Concatenate & ✅ (average) \\
Binary Search & Split range & Return match & ✅ \\
Closest Pair & Divide plane & Compare boundary & ✅ \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-85}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Step & Cost \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Divide & \(O(1)\) or \(O(n)\) \\
Conquer & \(aT(n/b)\) \\
Combine & \(O(n)\) (typical) \\
\end{longtable}

Overall: \(O(n \log n)\) in many classic cases.

Divide and conquer is the essence of recursive decomposition, see the
whole by mastering the parts.

\subsection{94 Dynamic Programming
Pattern}\label{dynamic-programming-pattern}

The Dynamic Programming (DP) Pattern solves complex problems by breaking
them into overlapping subproblems, solving each once, and storing
results to avoid recomputation.

It transforms exponential recursive solutions into efficient polynomial
ones through memoization or tabulation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-94}

When a problem has:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Overlapping subproblems -- the same subtask appears multiple times.
\item
  Optimal substructure -- an optimal solution can be built from optimal
  subsolutions.
\end{enumerate}

Naive recursion repeats work. DP ensures each subproblem is solved once.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-94}

Think of DP as smart recursion:

\begin{itemize}
\tightlist
\item
  Define a state that captures progress.
\item
  Define a recurrence that relates larger states to smaller ones.
\item
  Store results to reuse later.
\end{itemize}

Two main flavors:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Top-down (Memoization) -- recursion with caching.
\item
  Bottom-up (Tabulation) -- fill a table iteratively.
\end{enumerate}

\subsection{Example: Fibonacci
Numbers}\label{example-fibonacci-numbers-1}

Naive recursion: \[F(n) = F(n-1) + F(n-2)\] This recomputes many values.

DP solution:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Base: \(F(0)=0, F(1)=1\)
\item
  Build up table: \[F[i] = F[i-1] + F[i-2]\]
\end{enumerate}

Result: \(O(n)\) time, \(O(n)\) space (or \(O(1)\) optimized).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-87}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ fib(n):}
\NormalTok{    dp }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ [}\DecValTok{0}\NormalTok{]}\OperatorTok{*}\NormalTok{(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{, n}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        dp[i] }\OperatorTok{=}\NormalTok{ dp[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ dp[i}\OperatorTok{{-}}\DecValTok{2}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ dp[n]}
\end{Highlighting}
\end{Shaded}

Or memoized recursion:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ functools }\ImportTok{import}\NormalTok{ lru\_cache}

\AttributeTok{@lru\_cache}\NormalTok{(}\VariableTok{None}\NormalTok{)}
\KeywordTok{def}\NormalTok{ fib(n):}
    \ControlFlowTok{if}\NormalTok{ n }\OperatorTok{\textless{}} \DecValTok{2}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ n}
    \ControlFlowTok{return}\NormalTok{ fib(n}\OperatorTok{{-}}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ fib(n}\OperatorTok{{-}}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-194}

DP is the core of algorithmic problem solving:

\begin{itemize}
\tightlist
\item
  Optimization: shortest paths, knapsack, edit distance
\item
  Counting: number of ways to climb stairs, partitions
\item
  Sequence analysis: LIS, LCS
\item
  Resource allocation: scheduling, investment problems
\end{itemize}

It's how we bring structure to recursion.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-94}

Let \(T(n)\) be the cost to solve all distinct subproblems. Since each
is solved once and combined in constant time:
\[T(n) = O(\text{number of states}) \times O(\text{transition cost})\]

For Fibonacci:

\begin{itemize}
\tightlist
\item
  States = \(n\)
\item
  Transition cost = \(O(1)\) ⇒ \(T(n) = O(n)\)
\end{itemize}

Memoization ensures every subproblem is visited at most once.

\subsubsection{Try It Yourself}\label{try-it-yourself-194}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write DP for coin change (ways to form a sum).
\item
  Trace longest common subsequence (LCS) table.
\item
  Compare top-down vs bottom-up performance.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-94}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & State & Transition & Time \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fibonacci & \(n\) & \(dp[n]=dp[n-1]+dp[n-2]\) & \(O(n)\) \\
Knapsack & \((i,w)\) & \(\max(\text{take}, \text{skip})\) & \(O(nW)\) \\
Edit Distance & \((i,j)\) & Compare chars & \(O(nm)\) \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-86}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Top-down Memoization & \(O(\text{\#states})\) &
\(O(\text{\#states})\) \\
Bottom-up Tabulation & \(O(\text{\#states})\) &
\(O(\text{\#states})\) \\
\end{longtable}

Dynamic Programming is divide and conquer with memory, think
recursively, compute once, reuse forever.

\subsection{95 Backtracking Pattern}\label{backtracking-pattern}

The Backtracking Pattern explores all possible solutions by building
them step by step and abandoning a path as soon as it becomes invalid.

It's a systematic search strategy for problems where we need to generate
combinations, permutations, or subsets, and prune impossible or
suboptimal branches early.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-95}

We face problems where:

\begin{itemize}
\tightlist
\item
  The solution space is large, but structured.
\item
  We can detect invalid partial solutions early.
\end{itemize}

Examples:

\begin{itemize}
\tightlist
\item
  N-Queens (place queens safely)
\item
  Sudoku (fill grid with constraints)
\item
  Subset Sum (choose elements summing to target)
\end{itemize}

Brute force explores everything blindly. Backtracking cuts off dead ends
as soon as they appear.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-95}

Imagine exploring a maze:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take a step (make a choice).
\item
  If it leads to a valid partial solution, continue.
\item
  If it fails, backtrack, undo and try another path.
\end{enumerate}

Each level of recursion corresponds to a decision point.

\subsection{Example: N-Queens Problem}\label{example-n-queens-problem}

We need to place \(n\) queens on an \(n \times n\) board so no two
attack each other.

At each row, choose a column that is safe. If none works, backtrack to
previous row.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-88}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ solve\_n\_queens(n):}
\NormalTok{    res, board }\OperatorTok{=}\NormalTok{ [], [}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{n}

    \KeywordTok{def}\NormalTok{ is\_safe(row, col):}
        \ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(row):}
\NormalTok{            c }\OperatorTok{=}\NormalTok{ board[r]}
            \ControlFlowTok{if}\NormalTok{ c }\OperatorTok{==}\NormalTok{ col }\KeywordTok{or} \BuiltInTok{abs}\NormalTok{(c }\OperatorTok{{-}}\NormalTok{ col) }\OperatorTok{==} \BuiltInTok{abs}\NormalTok{(r }\OperatorTok{{-}}\NormalTok{ row):}
                \ControlFlowTok{return} \VariableTok{False}
        \ControlFlowTok{return} \VariableTok{True}

    \KeywordTok{def}\NormalTok{ backtrack(row}\OperatorTok{=}\DecValTok{0}\NormalTok{):}
        \ControlFlowTok{if}\NormalTok{ row }\OperatorTok{==}\NormalTok{ n:}
\NormalTok{            res.append(board[:])}
            \ControlFlowTok{return}
        \ControlFlowTok{for}\NormalTok{ col }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n):}
            \ControlFlowTok{if}\NormalTok{ is\_safe(row, col):}
\NormalTok{                board[row] }\OperatorTok{=}\NormalTok{ col}
\NormalTok{                backtrack(row }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{                board[row] }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}  \CommentTok{\# undo}

\NormalTok{    backtrack()}
    \ControlFlowTok{return}\NormalTok{ res}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-195}

Backtracking is a universal solver for:

\begin{itemize}
\tightlist
\item
  Combinatorial search: subsets, permutations, partitions
\item
  Constraint satisfaction: Sudoku, graph coloring, N-Queens
\item
  Optimization with pruning (branch and bound builds on it)
\end{itemize}

It's not just brute force, it's guided exploration.

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-95}

Let \(S\) be the total number of possible states. Backtracking prunes
all invalid paths early, so actual visited nodes \(\le S\).

If each state takes \(O(1)\) time to check and recurse, total complexity
is proportional to the number of valid partial states, often far smaller
than full enumeration.

\subsubsection{Try It Yourself}\label{try-it-yourself-195}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve Subset Sum using backtracking.
\item
  Generate all permutations of \texttt{{[}1,2,3{]}}.
\item
  Implement Sudoku Solver (9×9 constraint satisfaction).
\end{enumerate}

Trace calls, each recursive call represents a partial decision.

\subsubsection{Test Cases}\label{test-cases-95}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1639}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3607}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2295}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problem
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Decision
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Constraint
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Output
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
N-Queens & Choose column & Non-attacking queens & Placements \\
Subset Sum & Include/Exclude & Sum ≤ target & Valid subsets \\
Sudoku & Fill cell & Row/Col/Subgrid unique & Completed grid \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-87}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Problem & Time & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
N-Queens & \(O(n!)\) worst & \(O(n)\) \\
Subset Sum & \(O(2^n)\) & \(O(n)\) \\
Sudoku & Exponential & Grid size \\
\end{longtable}

Backtracking is the art of searching by undoing, try, test, and retreat
until you find a valid path.

\subsection{96 Branch and Bound}\label{branch-and-bound}

The Branch and Bound pattern is an optimization framework that
systematically explores the search space while pruning paths that cannot
yield better solutions than the best one found so far.

It extends backtracking with bounds that let us skip unpromising
branches early.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-96}

We want to solve optimization problems where:

\begin{itemize}
\tightlist
\item
  The search space is combinatorial (e.g., permutations, subsets).
\item
  Each partial solution can be evaluated or bounded.
\item
  We seek the best solution under some cost function.
\end{itemize}

Examples:

\begin{itemize}
\tightlist
\item
  Knapsack Problem: maximize value under capacity.
\item
  Traveling Salesman Problem (TSP): find shortest tour.
\item
  Job Scheduling: minimize total completion time.
\end{itemize}

Brute-force search is exponential. Branch and Bound cuts branches that
cannot improve the best known answer.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-96}

Think of exploring a tree:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Branch: expand possible choices.
\item
  Bound: compute a limit on achievable value from this branch.
\item
  If bound ≤ best found so far, prune (stop exploring).
\item
  Otherwise, explore deeper.
\end{enumerate}

We use:

\begin{itemize}
\tightlist
\item
  Upper bound: best possible value from this path.
\item
  Lower bound: best value found so far.
\end{itemize}

Prune when upper bound ≤ lower bound.

\subsection{Example: 0/1 Knapsack}\label{example-01-knapsack}

Given items with weights and values, choose subset with max value ≤
capacity.

We recursively include/exclude each item, but prune branches that cannot
beat current best (e.g., exceeding weight or potential value too low).

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-89}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ knapsack\_branch\_bound(items, capacity):}
\NormalTok{    best\_value }\OperatorTok{=} \DecValTok{0}

    \KeywordTok{def}\NormalTok{ bound(i, curr\_w, curr\_v):}
        \CommentTok{\# Simple bound: add remaining items greedily}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(items):}
            \ControlFlowTok{return}\NormalTok{ curr\_v}
\NormalTok{        w, v }\OperatorTok{=}\NormalTok{ curr\_w, curr\_v}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(i, }\BuiltInTok{len}\NormalTok{(items)):}
            \ControlFlowTok{if}\NormalTok{ w }\OperatorTok{+}\NormalTok{ items[j][}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}=}\NormalTok{ capacity:}
\NormalTok{                w }\OperatorTok{+=}\NormalTok{ items[j][}\DecValTok{0}\NormalTok{]}
\NormalTok{                v }\OperatorTok{+=}\NormalTok{ items[j][}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{return}\NormalTok{ v}

    \KeywordTok{def}\NormalTok{ dfs(i, curr\_w, curr\_v):}
        \KeywordTok{nonlocal}\NormalTok{ best\_value}
        \ControlFlowTok{if}\NormalTok{ curr\_w }\OperatorTok{\textgreater{}}\NormalTok{ capacity:}
            \ControlFlowTok{return}
        \ControlFlowTok{if}\NormalTok{ curr\_v }\OperatorTok{\textgreater{}}\NormalTok{ best\_value:}
\NormalTok{            best\_value }\OperatorTok{=}\NormalTok{ curr\_v}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(items):}
            \ControlFlowTok{return}
        \ControlFlowTok{if}\NormalTok{ bound(i, curr\_w, curr\_v) }\OperatorTok{\textless{}=}\NormalTok{ best\_value:}
            \ControlFlowTok{return}
        \CommentTok{\# Include item}
\NormalTok{        dfs(i}\OperatorTok{+}\DecValTok{1}\NormalTok{, curr\_w }\OperatorTok{+}\NormalTok{ items[i][}\DecValTok{0}\NormalTok{], curr\_v }\OperatorTok{+}\NormalTok{ items[i][}\DecValTok{1}\NormalTok{])}
        \CommentTok{\# Exclude item}
\NormalTok{        dfs(i}\OperatorTok{+}\DecValTok{1}\NormalTok{, curr\_w, curr\_v)}

\NormalTok{    dfs(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ best\_value}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-196}

Branch and Bound:

\begin{itemize}
\tightlist
\item
  Generalizes backtracking with mathematical pruning.
\item
  Turns exponential search into practical algorithms.
\item
  Provides exact solutions when heuristics might fail.
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Integer programming
\item
  Route optimization
\item
  Scheduling and assignment problems
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-96}

Let \(U(n)\) be an upper bound of a subtree. If \(U(n) \le V^*\) (best
known value), no solution below can exceed \(V^*\).

By monotonic bounding, pruning preserves correctness --- no optimal
solution is ever discarded.

The algorithm is complete (explores all promising branches) and optimal
(finds global best).

\subsubsection{Try It Yourself}\label{try-it-yourself-196}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solve 0/1 Knapsack with branch and bound.
\item
  Implement TSP with cost matrix and prune by lower bounds.
\item
  Compare nodes explored vs brute-force enumeration.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-96}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.4167}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2833}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Items (w,v)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Capacity
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best Value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Branches Explored
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}(2,3),(3,4),(4,5){]} & 5 & 7 & Reduced \\
{[}(1,1),(2,2),(3,5),(4,6){]} & 6 & 8 & Reduced \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-88}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Problem & Time (Worst) & Time (Typical) & Space \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Knapsack & \(O(2^n)\) & Much less (pruning) & \(O(n)\) \\
TSP & \(O(n!)\) & Pruned significantly & \(O(n)\) \\
\end{longtable}

Branch and Bound is search with insight, it trims the impossible and
focuses only where the optimum can hide.

\subsection{97 Randomized Pattern}\label{randomized-pattern}

The Randomized Pattern introduces chance into algorithm design. Instead
of following a fixed path, the algorithm makes random choices that, on
average, lead to efficient performance or simplicity.

Randomization can help break symmetry, avoid worst-case traps, and
simplify complex logic.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-97}

We want algorithms that:

\begin{itemize}
\tightlist
\item
  Avoid pathological worst-case inputs.
\item
  Simplify decisions that are hard deterministically.
\item
  Achieve good expected performance.
\end{itemize}

Common examples:

\begin{itemize}
\tightlist
\item
  Randomized QuickSort: pivot chosen at random.
\item
  Randomized Search / Sampling: estimate quantities via random trials.
\item
  Monte Carlo and Las Vegas Algorithms: trade accuracy for speed or vice
  versa.
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-97}

Randomization can appear in two forms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Las Vegas Algorithm

  \begin{itemize}
  \tightlist
  \item
    Always produces the correct result.
  \item
    Runtime is random (e.g., Randomized QuickSort).
  \end{itemize}
\item
  Monte Carlo Algorithm

  \begin{itemize}
  \tightlist
  \item
    Runs in fixed time.
  \item
    May have a small probability of error (e.g., primality tests).
  \end{itemize}
\end{enumerate}

By picking random paths or samples, we smooth out bad cases and often
simplify logic.

\subsection{Example: Randomized
QuickSort}\label{example-randomized-quicksort}

Choose a pivot randomly to avoid worst-case splits.

At each step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pick random pivot \(p\) from array.
\item
  Partition array into smaller (\textless{} p) and larger
  (\textgreater{} p).
\item
  Recursively sort halves.
\end{enumerate}

Expected runtime is \(O(n \log n)\) even if input is adversarial.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-90}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random}

\KeywordTok{def}\NormalTok{ randomized\_quicksort(arr):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ arr}
\NormalTok{    pivot }\OperatorTok{=}\NormalTok{ random.choice(arr)}
\NormalTok{    left }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}}\NormalTok{ pivot]}
\NormalTok{    mid }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{==}\NormalTok{ pivot]}
\NormalTok{    right }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}}\NormalTok{ pivot]}
    \ControlFlowTok{return}\NormalTok{ randomized\_quicksort(left) }\OperatorTok{+}\NormalTok{ mid }\OperatorTok{+}\NormalTok{ randomized\_quicksort(right)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-197}

Randomized algorithms are:

\begin{itemize}
\tightlist
\item
  Simple: randomization replaces complex logic.
\item
  Efficient: often faster in expectation.
\item
  Robust: resistant to adversarial input.
\end{itemize}

They appear in:

\begin{itemize}
\tightlist
\item
  Sorting, searching, and hashing.
\item
  Approximation algorithms.
\item
  Cryptography and sampling.
\item
  Machine learning (e.g., SGD, bagging).
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-97}

Let \(T(n)\) be expected time of Randomized QuickSort:
\[T(n) = n - 1 + \frac{2}{n} \sum_{k=0}^{n-1} T(k)\]

Solving yields \(T(n) = O(n \log n)\). Random pivot ensures each element
has equal probability to split array, making balanced partitions likely
on average.

Expected cost avoids \(O(n^2)\) worst-case of fixed-pivot QuickSort.

\subsubsection{Try It Yourself}\label{try-it-yourself-197}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement Randomized QuickSort, run on sorted input.
\item
  Compare average time to standard QuickSort.
\item
  Try a random primality test (e.g., Miller--Rabin).
\item
  Use random sampling to approximate \(\pi\) via Monte Carlo.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-97}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Input & Expected Result & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}1,2,3,4,5{]} & {[}1,2,3,4,5{]} & Random pivot avoids worst-case \\
{[}5,4,3,2,1{]} & {[}1,2,3,4,5{]} & Still fast due to random splits \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-89}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3279}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2459}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1803}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Expected Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Randomized QuickSort & \(O(n \log n)\) & \(O(n^2)\) (rare) &
\(O(\log n)\) \\
Randomized Search & \(O(1)\) expected & \(O(n)\) worst & \(O(1)\) \\
\end{longtable}

Randomization turns rigid logic into flexible, average-case excellence,
a practical ally in uncertain or adversarial worlds.

\subsection{98 Approximation Pattern}\label{approximation-pattern}

The Approximation Pattern is used when finding the exact solution is too
expensive or impossible. Instead of striving for perfection, we design
algorithms that produce results \emph{close enough} to optimal, fast,
predictable, and often guaranteed within a factor.

This pattern shines in NP-hard problems, where exact methods scale
poorly.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-98}

Some problems, like Traveling Salesman, Vertex Cover, or Knapsack, have
no known polynomial-time exact solutions. We need algorithms that give
good-enough answers quickly, especially for large inputs.

Approximation algorithms ensure:

\begin{itemize}
\tightlist
\item
  Predictable performance.
\item
  Measurable accuracy.
\item
  Polynomial runtime.
\end{itemize}

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-98}

An approximation algorithm outputs a solution within a known ratio of
the optimal value:

If the optimal cost is \(\text{OPT}\), and our algorithm returns
\(\text{ALG}\), then for a minimization problem:

\[\frac{\text{ALG}}{\text{OPT}} \le \alpha\]

where \(\alpha\) is the approximation factor (e.g., 2, 1.5, or
\((1 + \epsilon)\)).

\subsection{Example: Vertex Cover
(2-Approximation)}\label{example-vertex-cover-2-approximation}

Problem: find smallest set of vertices touching all edges.

Algorithm:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Start with an empty set \(C\).
\item
  While edges remain:

  \begin{itemize}
  \tightlist
  \item
    Pick any uncovered edge \((u, v)\).
  \item
    Add both \(u\) and \(v\) to \(C\).
  \item
    Remove all edges incident to \(u\) or \(v\).
  \end{itemize}
\item
  Return \(C\).
\end{enumerate}

This guarantees \(|C| \le 2 \cdot |C^*|\), where \(C^*\) is the optimal
vertex cover.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-91}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ vertex\_cover(edges):}
\NormalTok{    cover }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
    \ControlFlowTok{while}\NormalTok{ edges:}
\NormalTok{        (u, v) }\OperatorTok{=}\NormalTok{ edges.pop()}
\NormalTok{        cover.add(u)}
\NormalTok{        cover.add(v)}
\NormalTok{        edges }\OperatorTok{=}\NormalTok{ [(x, y) }\ControlFlowTok{for}\NormalTok{ (x, y) }\KeywordTok{in}\NormalTok{ edges }\ControlFlowTok{if}\NormalTok{ x }\KeywordTok{not} \KeywordTok{in}\NormalTok{ (u, v) }\KeywordTok{and}\NormalTok{ y }\KeywordTok{not} \KeywordTok{in}\NormalTok{ (u, v)]}
    \ControlFlowTok{return}\NormalTok{ cover}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-198}

Approximation algorithms:

\begin{itemize}
\tightlist
\item
  Provide provable guarantees.
\item
  Scale to large problems.
\item
  Offer predictable trade-offs between time and accuracy.
\end{itemize}

Widely used in:

\begin{itemize}
\tightlist
\item
  Combinatorial optimization.
\item
  Scheduling, routing, resource allocation.
\item
  AI planning, clustering, and compression.
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-98}

Let \(C^*\) be optimal cover. Every edge must be covered by \(C^*\). We
select 2 vertices per edge, so:

\[|C| = 2 \cdot \text{(number of edges selected)} \le 2 \cdot |C^*|\]

Thus, the approximation factor is 2.

\subsubsection{Try It Yourself}\label{try-it-yourself-198}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement the 2-approx Vertex Cover algorithm.
\item
  Compare result size with brute-force solution for small graphs.
\item
  Explore \((1 + \epsilon)\)-approximation using greedy selection.
\item
  Apply same idea to Set Cover or Knapsack.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-98}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Graph & Optimal & Algorithm & Ratio \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Triangle & 2 & 2 & 1.0 \\
Square & 2 & 4 & 2.0 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-90}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3387}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.3065}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.1290}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2258}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Algorithm
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Time
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Guarantee
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Vertex Cover (Greedy) & \(O(E)\) & \(O(V)\) & 2-Approx \\
Knapsack (FPTAS) & \(O(n^3 / \epsilon)\) & \(O(n^2)\) &
\((1+\epsilon)\) \\
\end{longtable}

Approximation is the art of being \emph{nearly perfect, swiftly}, a
pragmatic bridge between theory and the real world.

\subsection{99 Online Algorithm Pattern}\label{online-algorithm-pattern}

The Online Algorithm Pattern is used when input arrives sequentially,
and decisions must be made immediately without knowledge of future data.
There's no rewinding or re-optimizing later, you commit as you go.

This pattern models real-time decision-making, from caching to task
scheduling and resource allocation.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-99}

In many systems, data doesn't come all at once. You must decide now, not
after seeing the full picture.

Typical scenarios:

\begin{itemize}
\tightlist
\item
  Cache replacement (decide which page to evict next).
\item
  Task assignment (jobs arrive in real time).
\item
  Dynamic routing (packets arrive continuously).
\end{itemize}

Offline algorithms know everything upfront; online algorithms don't, yet
must perform competitively.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-99}

An online algorithm processes inputs one by one. Each step:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Receive input item \(x_t\) at time \(t\).
\item
  Make a decision \(d_t\) using current state only.
\item
  Cannot change \(d_t\) later.
\end{enumerate}

Performance is measured by the competitive ratio:

\[
\text{Competitive Ratio} = \max_{\text{inputs}} \frac{\text{Cost}*{\text{ALG}}}{\text{Cost}*{\text{OPT}}}
\]

If \(\text{ALG}\)'s cost is at most \(k\) times optimal, the algorithm
is k-competitive.

\subsection{Example: Paging / Cache
Replacement}\label{example-paging-cache-replacement}

You have cache of size \(k\). Sequence of page requests arrives. If
requested page is not in cache → page fault → load it (evict one if
full).

Algorithms:

\begin{itemize}
\tightlist
\item
  FIFO (First In First Out): Evict oldest.
\item
  LRU (Least Recently Used): Evict least recently accessed.
\item
  Random: Evict randomly.
\end{itemize}

LRU is \(k\)-competitive, meaning it performs within factor \(k\) of
optimal.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-92}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ lru\_cache(pages, capacity):}
\NormalTok{    cache }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    faults }\OperatorTok{=} \DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ pages:}
        \ControlFlowTok{if}\NormalTok{ p }\KeywordTok{not} \KeywordTok{in}\NormalTok{ cache:}
\NormalTok{            faults }\OperatorTok{+=} \DecValTok{1}
            \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(cache) }\OperatorTok{==}\NormalTok{ capacity:}
\NormalTok{                cache.pop(}\DecValTok{0}\NormalTok{)}
\NormalTok{            cache.append(p)}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            cache.remove(p)}
\NormalTok{            cache.append(p)}
    \ControlFlowTok{return}\NormalTok{ faults}
\end{Highlighting}
\end{Shaded}

\subsubsection{Why It Matters}\label{why-it-matters-199}

Online algorithms:

\begin{itemize}
\tightlist
\item
  Reflect real-world constraints (no foresight).
\item
  Enable adaptive systems in streaming, caching, and scheduling.
\item
  Provide competitive guarantees even under worst-case input.
\end{itemize}

Used in:

\begin{itemize}
\tightlist
\item
  Operating systems (page replacement).
\item
  Networking (packet routing).
\item
  Finance (online pricing, bidding).
\item
  Machine learning (online gradient descent).
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-99}

For LRU Cache: Every cache miss means a unique page not seen in last
\(k\) requests. The optimal offline algorithm (OPT) can avoid some
faults but at most \(k\) times fewer. Thus:

\[
\text{Faults(LRU)} \le k \cdot \text{Faults(OPT)}
\]

So LRU is k-competitive.

\subsubsection{Try It Yourself}\label{try-it-yourself-199}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Simulate LRU, FIFO, Random cache on same request sequence.
\item
  Count page faults.
\item
  Compare with offline OPT (Belady's Algorithm).
\item
  Experiment with \(k=2,3,4\).
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-99}

\begin{longtable}[]{@{}lllll@{}}
\toprule\noalign{}
Pages & Cache Size & Algorithm & Faults & Ratio (vs OPT) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
{[}1,2,3,1,2,3{]} & 2 & LRU & 6 & 3.0 \\
{[}1,2,3,4,1,2,3,4{]} & 3 & LRU & 8 & 2.7 \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-91}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Algorithm & Time & Space & Competitive Ratio \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
FIFO & \(O(nk)\) & \(O(k)\) & \(k\) \\
LRU & \(O(nk)\) & \(O(k)\) & \(k\) \\
OPT (offline) & \(O(nk)\) & \(O(k)\) & 1 \\
\end{longtable}

Online algorithms embrace uncertainty, they act wisely \emph{now},
trusting analysis to prove they won't regret it later.

\subsection{100 Hybrid Strategy Pattern}\label{hybrid-strategy-pattern}

The Hybrid Strategy Pattern combines multiple algorithmic paradigms,
such as divide and conquer, greedy, and dynamic programming, to balance
their strengths and overcome individual weaknesses. Instead of sticking
to one design philosophy, hybrid algorithms adapt to the structure of
the problem and the size of the input.

\subsubsection{What Problem Are We
Solving?}\label{what-problem-are-we-solving-100}

No single paradigm fits all problems. Some inputs are small and benefit
from brute force; others require recursive structure; still others need
heuristics.

We need a meta-strategy that blends paradigms, switching between them
based on conditions like:

\begin{itemize}
\tightlist
\item
  Input size (e.g., small vs large)
\item
  Structure (e.g., sorted vs unsorted)
\item
  Precision requirements (e.g., exact vs approximate)
\end{itemize}

Hybrid strategies offer practical performance beyond theoretical
asymptotics.

\subsubsection{How It Works (Plain
Language)}\label{how-it-works-plain-language-100}

A hybrid algorithm uses \emph{decision logic} to pick the best method
for each situation.

Common patterns:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Small-case base switch: Use brute force when \(n\) is small (e.g.,
  Insertion Sort inside QuickSort).
\item
  Stage combination: Use one algorithm for setup, another for refinement
  (e.g., Greedy for initial solution, DP for optimization).
\item
  Conditional strategy: Choose algorithm based on data distribution
  (e.g., QuickSort vs HeapSort).
\end{enumerate}

\subsection{Example: Introsort}\label{example-introsort}

Introsort starts like QuickSort for average speed, but if recursion
depth grows too large (bad pivot splits), it switches to HeapSort to
guarantee \(O(n \log n)\) worst-case time.

Steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Partition using QuickSort.
\item
  Track recursion depth.
\item
  If depth \textgreater{} threshold (\(2 \log n\)), switch to HeapSort.
\end{enumerate}

This ensures best of both worlds: average speed + worst-case safety.

\subsubsection{Tiny Code (Python)}\label{tiny-code-python-93}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ introsort(arr, depth\_limit):}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(arr) }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ arr}
    \ControlFlowTok{if}\NormalTok{ depth\_limit }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ heapsort(arr)}
\NormalTok{    pivot }\OperatorTok{=}\NormalTok{ arr[}\BuiltInTok{len}\NormalTok{(arr)}\OperatorTok{//}\DecValTok{2}\NormalTok{]}
\NormalTok{    left }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textless{}}\NormalTok{ pivot]}
\NormalTok{    mid }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{==}\NormalTok{ pivot]}
\NormalTok{    right }\OperatorTok{=}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ arr }\ControlFlowTok{if}\NormalTok{ x }\OperatorTok{\textgreater{}}\NormalTok{ pivot]}
    \ControlFlowTok{return}\NormalTok{ introsort(left, depth\_limit }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) }\OperatorTok{+}\NormalTok{ mid }\OperatorTok{+}\NormalTok{ introsort(right, depth\_limit }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\emph{(Uses heapsort when depth limit is reached)}

\subsubsection{Why It Matters}\label{why-it-matters-200}

Hybrid strategies give real-world efficiency, predictable performance,
and robust fallback behavior. They mirror how expert developers build
systems, not one-size-fits-all, but layered and conditional.

Common hybrids:

\begin{itemize}
\tightlist
\item
  Timsort = MergeSort + InsertionSort
\item
  Introsort = QuickSort + HeapSort
\item
  Branch-and-Bound + Greedy = Search with pruning and heuristics
\item
  Neural + Symbolic = Learning + Logical reasoning
\end{itemize}

\subsubsection{A Gentle Proof (Why It
Works)}\label{a-gentle-proof-why-it-works-100}

Let \(A_1, A_2, \ldots, A_k\) be candidate algorithms with cost
functions \(T_i(n)\). Hybrid strategy \(H\) chooses \(A_i\) when
condition \(C_i(n)\) holds.

If decision logic ensures \[T_H(n) = \min_i { T_i(n) \mid C_i(n) }\]
then \(H\) performs at least as well as the best applicable algorithm.

Thus \(T_H(n) = O(\min_i T_i(n))\).

\subsubsection{Try It Yourself}\label{try-it-yourself-200}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Implement QuickSort + InsertionSort hybrid.
\item
  Set threshold \(n_0 = 10\) for switching.
\item
  Compare performance vs pure QuickSort.
\item
  Experiment with different thresholds.
\end{enumerate}

\subsubsection{Test Cases}\label{test-cases-100}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Input Size & Algorithm & Time & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & Insertion Sort & Fastest & Simplicity wins \\
1000 & QuickSort & Optimal & Low overhead \\
1e6 & Introsort & Stable & No worst-case blowup \\
\end{longtable}

\subsubsection{Complexity}\label{complexity-92}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1525}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2203}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2203}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2203}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1864}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Component
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Best
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Average
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Worst
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Space
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
QuickSort & \(O(n \log n)\) & \(O(n \log n)\) & \(O(n^2)\) &
\(O(\log n)\) \\
HeapSort & \(O(n \log n)\) & \(O(n \log n)\) & \(O(n \log n)\) &
\(O(1)\) \\
Introsort & \(O(n \log n)\) & \(O(n \log n)\) & \(O(n \log n)\) &
\(O(\log n)\) \\
\end{longtable}

A hybrid strategy is not just an algorithmic trick, it's a mindset:
combine precision, adaptability, and pragmatism to build algorithms that
thrive in the wild.




\end{document}
